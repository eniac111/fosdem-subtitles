WEBVTT

00:00.000 --> 00:11.920
Hi, everybody. Thanks for being here for this talk. That's a lot of people. I'm Nicolas

00:11.920 --> 00:18.160
Frankel. I've been a developer for a long time. And I would like to ask how many of

00:18.160 --> 00:28.480
you are developers in this room? Quite a lot. Who are ops? Just as many. And who are DevOps,

00:28.480 --> 00:40.040
whatever you mean by it. So this talk is intended for actually developers. Because I was or

00:40.040 --> 00:47.960
I still think I'm a developer. So if you are a nobs people and for this for you is not

00:47.960 --> 00:53.200
that super interesting. At least you can direct your developer colleagues to the talk so that

00:53.200 --> 01:03.800
they can understand how they can ease your work. Well, perhaps you've never seen that.

01:03.800 --> 01:12.920
But I'm old or experienced depending on how you see it. And when I was starting my career,

01:12.920 --> 01:18.960
monitoring was like a bunch of people sitting in front of screens the whole day. And actually

01:18.960 --> 01:24.880
I was lucky once in the south of France I was told, hey, this is the biggest monitoring

01:24.880 --> 01:31.080
site of all France. And actually it really looked like this. And of course there were

01:31.080 --> 01:37.760
people like watching it. And that was the easy way. Now I hope that you don't have that

01:37.760 --> 01:46.800
anymore. That it has become a bit more modern. Actually there is a lot of talk now about

01:46.800 --> 01:55.440
microservices, right? Who here is doing microservices? Yeah. Yeah. Because if you don't do microservices

01:55.440 --> 02:01.920
you are not a real developer. But even if you don't do microservices, so you are not

02:01.920 --> 02:06.520
a real developer and I encourage you not to be a real developer in that case, you probably

02:06.520 --> 02:13.040
are doing some kind of distributed work. It's become increasingly difficult to just like

02:13.040 --> 02:19.280
handle everything locally. And the problem becomes, yeah, if something bad happens, how

02:19.280 --> 02:27.080
can you locate how it works? Or even if something works as expected, how you can understand

02:27.080 --> 02:36.920
like the flow of your request across the network. I love Wikipedia. And here is the observability

02:36.920 --> 02:46.040
definition by Wikipedia which is long and in that case not that interesting. So I have

02:46.040 --> 02:56.400
a better one afterwards for tracing. So basically tracing helps you to understand the flow of

02:56.400 --> 03:05.440
a business request across all your components. Fabian, where is Fabian? Fabian is here.

03:05.440 --> 03:11.920
So he talked a lot about the metrics and the logging. So in this talk I will really focus

03:11.920 --> 03:20.840
on tracing because my opinion is that, well, metrics is easy. We do metrics since ages.

03:20.840 --> 03:27.320
Like we take the CPU, the memory, whatever. Now we are trying to get more like business

03:27.320 --> 03:34.120
related metrics. But it's still the same concept. Logging also. Now we do aggregated logging.

03:34.120 --> 03:41.920
And nothing by knowing. Tracing is I think the hardest part. So in the past there were

03:41.920 --> 03:50.840
already some tracing pioneers. Perhaps you've used some of them. And, well, now we are at

03:50.840 --> 03:57.920
the stage where we want to have something more standardized. So it starts with the trace

03:57.920 --> 04:14.400
context from the WC and the ID is that you start a trace and then other components will

04:14.400 --> 04:23.840
get the trace and will append their own trace to it. So it works very well in a web context.

04:23.840 --> 04:30.280
And it defines like two important concepts that Fabian thanks already described. So now

04:30.280 --> 04:46.520
I am done. So I have the same stupid stuff. So here you have oh, sorry. Yes. It reminds

04:46.520 --> 04:50.680
me of the story. I did the same to my colleagues. They didn't care about the presentation. They

04:50.680 --> 05:02.400
only remembered that. Okay. So here you have a trace. And here you have the different spans.

05:02.400 --> 05:10.440
So here the X one is the parent one. And then the Y and the Z one will text this X span

05:10.440 --> 05:17.600
as their parent span. So this is a single trace. This is a single request across your

05:17.600 --> 05:25.920
service. Web stuff is good, but it's definitely not enough. And so for that we have the open

05:25.920 --> 05:35.400
telemetry stuff. Open telemetry is just a big bag of miracles all set into a specific

05:35.400 --> 05:45.320
project. So it's basically APIs, SDK, tools, whatever under the open telemetry level. It

05:45.320 --> 05:53.720
implements the W3C trace context. If you have been doing some kind of tracing before, you

05:53.720 --> 05:59.720
might know it because it's like the merging of open tracing and open census. Good thing

05:59.720 --> 06:04.600
is the CNCF project. So basically there is some hope that it will last for a couple of

06:04.600 --> 06:11.800
years. The architecture is pretty simple. Basically you've got sources. You've got the

06:11.800 --> 06:18.960
open telemetry protocol. And as Tanveen mentioned, you dump everything into a collector. Collector

06:18.960 --> 06:27.400
we should be as close as possible to your sources. And then some tools are able to read

06:27.400 --> 06:39.360
like data from it and to display it into the way that we expect to see it. What happens

06:39.360 --> 06:45.400
after the open telemetry collector is not a problem of open telemetry. Just they are

06:45.400 --> 06:52.080
collectors that are compatible. And for example, you can use Jaeger or Zipkin in a way that

06:52.080 --> 06:58.880
allows you to dump your data, your open telemetry data into Jaeger or Zipkin into the open telemetry

06:58.880 --> 07:04.240
format. So you can reuse, and that is very important, you can reuse your infrastructure

07:04.240 --> 07:09.680
if you're already using the stools. Just switching to open telemetry. And then you're like you

07:09.680 --> 07:18.160
are using a standard and then you can switch your open telemetry back end with less issues.

07:18.160 --> 07:27.320
Now comes the fun developer part. If you are a developer, you probably are lazy. I know.

07:27.320 --> 07:36.200
I'm a developer. So the idea is open telemetry should make your life as a developer as easy

07:36.200 --> 07:47.080
as possible to help your ops colleague like diagnose your problems. And the easiest part

07:47.080 --> 07:54.640
if you do auto instrumentation. Auto instrumentation is only possible in cases where you have a

07:54.640 --> 08:00.840
platform when you have a run time. Fabian mentioned Java. Java as a run time which is

08:00.840 --> 08:11.640
the JVM. Python as a run time. Now if you have Rust, it's not as easy. So in that case,

08:11.640 --> 08:19.640
you are stuck. My advice if you are using a run time and probably most of you are using

08:19.640 --> 08:26.640
such run times, whether Java or whatever, use it. It's basically free. It's a low hanging

08:26.640 --> 08:32.800
fruit and there is no coupling. So basically you don't need extra dependencies as developers

08:32.800 --> 08:40.360
in your projects. So since it's called practical introduction, let's do some practice. So here

08:40.360 --> 08:47.900
I have a bit better than a hello world. So I have tried to model like an e-commerce shop

08:47.900 --> 08:55.480
with very simple stuff. It starts just asking for products. I will go through an API gateway

08:55.480 --> 09:00.400
which will forward the product to the catalog and the catalog doesn't know about the prices

09:00.400 --> 09:06.440
so it will ask the prices from a pricing service and it will ask the stocks from the stock

09:06.440 --> 09:19.760
service. The entry point is the most important thing because it gives the parents praise.

09:19.760 --> 09:25.400
Everything will be from that. So in general you have a reverse proxy or an API gateway

09:25.400 --> 09:32.760
depending on your use case. I work on the Apache API project. It uses the Nginx reverse

09:32.760 --> 09:38.220
proxy. On top you have an open REST because you want to have Lua to script and to autor

09:38.220 --> 09:44.760
load the configuration. Then you have lots of out of the box plugins. Let's see how it

09:44.760 --> 09:58.240
works. Now I have the code here. Is it the begin off? Good. So I might be very old because

09:58.240 --> 10:05.400
for me it wouldn't. Here that's my architecture. I'm using Docker Compose because I'm super

10:05.400 --> 10:12.240
lazy. I don't want to use Kubernetes. So I have Jaeger. I have all in one. I'm using

10:12.240 --> 10:18.680
the all included so I don't need to think about having the telemetry collector and the

10:18.680 --> 10:27.920
web to check the traces. I have only one single image. Then I have API 6. Then I have the

10:27.920 --> 10:35.240
catalog which I showed you. Of course I have couple of environment, my variable to configure

10:35.240 --> 10:43.960
everything. I wanted to focus on tracing so no metrics, no logs. I'm sending everything

10:43.960 --> 10:51.960
to Jaeger and then I do the same for pricing and I do the same for the stock. Normally

10:51.960 --> 10:59.840
at this point I already started because in general I have issues with the Java stuff.

10:59.840 --> 11:07.760
So here I'm doing a simple curl to the product. I've got the data which is not that important.

11:07.760 --> 11:13.760
And I can check on the web app how it works. So here I will go on the Jaeger UI. I see

11:13.760 --> 11:21.320
all my services. I can find the traces. Here you can find the latest one. And here is the

11:21.320 --> 11:30.880
thing. If I click on it, it might be a bit small, right? I cannot do much better. You

11:30.880 --> 11:37.080
can already see everything that I've shown you. So I start with the product from the

11:37.080 --> 11:44.560
API gateway. It forwards it to the product, to the catalog. Then I have the internal calls

11:44.560 --> 11:52.600
and I will show you how it works. Then I have the get request made from inside the application

11:52.600 --> 11:59.160
and then I have the stocks that responds here. Same here. And here we see something that

11:59.160 --> 12:08.120
was not mentioned on the component diagram. From the catalog to the stock I go directly.

12:08.120 --> 12:13.200
But from the catalog to the pricing I go back to the API gateway which is also a way to

12:13.200 --> 12:20.840
do that for whatever reason. And so this is something that was not mentioned on the PDF

12:20.840 --> 12:24.640
but you cannot cheat with open telemetry. It tells you exactly what happens and the

12:24.640 --> 12:34.700
flow. And the rest is the same. So regarding the code itself, I told you that I don't want

12:34.700 --> 12:45.680
anything to trouble the developer. So here I have nothing regarding open telemetry. If

12:45.680 --> 12:53.320
I write hotel, you see nothing. If I write telemetry, you see nothing. I have no dependency.

12:53.320 --> 13:03.960
The only thing that I have is in my Docker file and in my Docker file I get the latest

13:03.960 --> 13:13.160
open telemetry agent. So you can have your developers completely oblivious and you just

13:13.160 --> 13:19.100
provide them with this snippet and then when you run the Java application you just tell

13:19.100 --> 13:29.600
them A, run with the Java agent. Low hanging fruit, zero trouble. Any Java developer here?

13:29.600 --> 13:42.280
Not that many. Python? Okay. So it will be Python. Just the same here. Here it's a bit

13:42.280 --> 13:52.760
different. I add dependencies but actually I do nothing on it. So here I have no dependency

13:52.760 --> 13:58.600
on anything. Here I'm using a SQL database because again I'm lazy. I don't care that

13:58.600 --> 14:05.520
much. But here I have no dependency, no API call to open telemetry. The only thing that

14:05.520 --> 14:14.920
I have is in the Docker file again. I have this. Again, I'm using a runtime. It's super

14:14.920 --> 14:24.840
easy. I let the runtime, like, intercept the calls and send everything to open telemetry.

14:24.840 --> 14:33.600
And the last fun stuff is Rust. Any Rust developer? Please don't look at my code too much. I'm

14:33.600 --> 14:43.480
not a Rust developer. So I hope it won't be too horrible. And Rust is actually, well,

14:43.480 --> 14:48.840
not that standardized. So here I don't have any runtime. So I need to make the calls by

14:48.840 --> 14:56.920
myself. The hardest part is to find which library to use depending on which framework

14:56.920 --> 15:04.400
to use. So in this case I found one and perhaps there are better options. But I found this

15:04.400 --> 15:14.600
open telemetry OLTP stuff. And here this is because I'm using Exum. I'm using this library.

15:14.600 --> 15:20.800
And so far it works for me. I don't need to do a lot of stuff. I just, like, copy pasted

15:20.800 --> 15:32.160
this stuff. Copy paste developer. And afterwards in my main function I just need to say this

15:32.160 --> 15:39.880
and this. So I added two layers. So if you are, if you don't have any platform, any runtime,

15:39.880 --> 15:46.560
you actually need your developers to care about open telemetry. Otherwise it's fine.

15:46.560 --> 15:54.760
Now we already have pretty good, like, results. But we may want to do better. So we can also

15:54.760 --> 16:04.000
ask the developers once they are more comfortable to do manual instrumentation even in the case

16:04.000 --> 16:22.200
when there is a platform. Now I will docker compose down. And it takes a bit of time.

16:22.200 --> 16:44.520
I will prepare this. And on the catalog side, now I can have some additional codes. So this

16:44.520 --> 16:52.840
is a Spring Boot application. What I can do is add annotations. Like, I noticed there

16:52.840 --> 16:58.240
were a couple of Java developers. So it's the same with Kotlin. It's still on the JVM.

16:58.240 --> 17:03.640
So basically I'm adding annotations. And because Spring Boot can read the annotation at runtime,

17:03.640 --> 17:08.760
it can add those codes. So I don't have to, like, call the API explicitly. I just add

17:08.760 --> 17:23.200
some annotation and it should be done. On the Python side, I import this trace stuff.

17:23.200 --> 17:33.000
And then I can, with the tracer, add some, again, explicit traces. So internal traces.

17:33.000 --> 17:37.560
And from the first point of view, because I already, like, did it explicitly, it worked.

17:37.560 --> 17:41.760
Now you can see that I am in deep trouble because it happened a lot of time. The Java

17:41.760 --> 17:47.560
application doesn't start for a demo. And that's really, really fun. So I will try to

17:47.560 --> 17:59.320
docker compose down the catalog. And docker compose. Hey, what happens? Dash? Are you

17:59.320 --> 18:11.160
sure? No, no, no, no, no, no, no, no. Not with the new versions. Yes. That's fine. We

18:11.160 --> 18:37.120
are all here to learn. Down? What? Stop. Thanks. The stress, the stress. Yeah. Honestly, if

18:37.120 --> 18:46.640
there is any, like, person here able to tell me why this Java application sometimes has

18:46.640 --> 19:01.680
issues starting because I've added one gig at the beginning. And it's stuck always here.

19:01.680 --> 19:12.320
So I can tell you what you should see normally. If I'm lucky, I made a screenshot. And yes,

19:12.320 --> 19:20.720
here. But it's the beginning. It's the Rust one. So here, this is what you can have in

19:20.720 --> 19:25.160
Python. This is what I added explicitly. I have five minutes. Well, if the demo doesn't

19:25.160 --> 19:31.440
work, it will be much better. Then I won't have any problems with the timing. Here, you

19:31.440 --> 19:42.080
can see that this is the trace that, yeah, this is a trace that I did manually in Python.

19:42.080 --> 19:52.880
And here we can see that I filled the ID with the value. And on the Java side, again, nope,

19:52.880 --> 20:07.720
I think it will be here. This is not the manual stuff that I added. Yes, it is. You have the

20:07.720 --> 20:15.160
fetch here. You have the fetch here. So this is the span that I added manually. I'm afraid

20:15.160 --> 20:23.560
that at this point the demo just refused working. Yes, it's still stuck. I will stop there.

20:23.560 --> 20:35.080
I won't humiliate myself further when it's done. It's done. Perhaps if you are interested,

20:35.080 --> 20:40.260
you can follow me on Twitter. You can follow me on Mastodon. I don't know what's the ratio.

20:40.260 --> 20:45.560
More importantly, if you are interested about the GitHub repo, to do that by yourself, perhaps

20:45.560 --> 20:50.320
with better configuration of the compose with the right memory, it would work. And although

20:50.320 --> 20:57.040
the talk was not about Apache API 6, well, have a look at Apache API 6. It's an API getaway,

20:57.040 --> 21:08.920
the Apache way. Great. Are there some questions now?

21:08.920 --> 21:13.920
I never got so many up louds with a felling demo. Please remain seated. Please remain

21:13.920 --> 21:21.800
seated so we can have a Q&A. Who had a question? Thank you. Very good talk. I have two questions.

21:21.800 --> 21:28.160
So one is about this. Let's start with the first one. Right. Yes, yes, yes. How much

21:28.160 --> 21:34.280
overhead does this bring in Python and Java or Rust? How heavy is this instrumentation?

21:34.280 --> 21:41.000
That's a very good question. And the overhead of each request depends on your own infrastructure.

21:41.000 --> 21:46.680
But I always have an answer to that. Is it better to go fast and you don't know where

21:46.680 --> 21:55.720
you are going or to go a bit slower and to know where you are going? I think that whatever

21:55.720 --> 22:02.480
the costs, it's always easy to add additional resources and it doesn't cost you that much,

22:02.480 --> 22:08.600
whereas a debug incident across a distributed system can cost you days or even like weeks

22:08.600 --> 22:13.000
in engineering costs. And you are very, very expensive, right?

22:13.000 --> 22:18.920
Okay. Thank you. And the second one, have you encountered any funny issues with multi-threading

22:18.920 --> 22:23.880
or multi-processing? Something like when your server just now.

22:23.880 --> 22:30.160
Can you come closer to your mother? Your server just now was not starting. So some

22:30.160 --> 22:35.440
software when you have multi-threading or multi-processing, have you encountered any

22:35.440 --> 22:40.420
issues when the instrumentation caused you trouble?

22:40.420 --> 22:44.560
This is not production stuff. This is just better than the hello world. So I cannot tell

22:44.560 --> 22:49.880
you about prediction issues. You should find people who have these issues. As I mentioned,

22:49.880 --> 22:55.720
it's a developers-oriented talk. So it's more about pushing the developers to help

22:55.720 --> 23:01.840
ops to their job. For production issues, I must admit I have no clue.

23:01.840 --> 23:11.960
Hi. In the case of runtime, does it always work with also badly written application?

23:11.960 --> 23:19.440
I mean, how bad can application be before it stops working?

23:19.440 --> 23:24.480
I'm not sure I understood the question. So how often do you need to do it before it stops

23:24.480 --> 23:29.000
working? No, no, no. I mean, let's say I use deprecated

23:29.000 --> 23:37.120
libraries, bad clients, something that doesn't work as it's supposed to be for the instrumentation

23:37.120 --> 23:44.560
perspective. I mean, I do request to the network using UDP client, something I've written myself,

23:44.560 --> 23:55.440
some custom stuff that I'm imagining that the instrumentation sits between some layer

23:55.440 --> 24:05.440
of the network, which is going to the internet, for example. And so how bad can I be before

24:05.440 --> 24:11.520
it stops recognizing a request from junk? You cannot be banned.

24:11.520 --> 24:21.800
Well, it's a moral issue first. But then on the platform side, the host to instrumentation,

24:21.800 --> 24:28.840
they work with specific frameworks and tools. It's those frameworks and tools that know

24:28.840 --> 24:35.920
how to check what happens and to send the data to open telemetry.

24:35.920 --> 24:42.560
So if you don't play in this game, nothing will be sent.

24:42.560 --> 24:49.080
On the manual instrumentation side, it's an explicit call. So it depends what you want

24:49.080 --> 24:55.180
to send. Yeah, I was thinking of auto instrumentation.

24:55.180 --> 25:03.080
So let's say I do DNS resolution by myself and then I just throw a request to an IP.

25:03.080 --> 25:14.280
Let me show the Python stuff here. This is what I showed you in the screenshots.

25:14.280 --> 25:21.040
This is what I write. And this is the attributes that I want to have.

25:21.040 --> 25:29.440
So basically, if here you have something that is completely unrelated, it's up to you.

25:29.440 --> 25:33.480
That's why it's easier to start with auto instrumentation.

25:33.480 --> 25:39.600
And then once you get a general overview of what you have and your ops start saying, hey,

25:39.600 --> 25:47.040
perhaps we want to have more details here, then you can come with manual instrumentation.

25:47.040 --> 25:54.380
But start with the less expensive stuff. I didn't really answer the question.

25:54.380 --> 26:00.160
I understand it. But that's the best I can do regarding it.

26:00.160 --> 26:02.360
Sorry. Okay.

26:02.360 --> 26:10.240
And for the talk, for the agent you're using the Docker file, how you can configure it,

26:10.240 --> 26:17.040
for example, for the tracing for Jagger or other stuff.

26:17.040 --> 26:19.560
Regarding the Docker file, sorry. Yeah.

26:19.560 --> 26:25.600
How you can configure the agent to send the traces for Jagger or other...

26:25.600 --> 26:28.520
The Docker file doesn't mention where you send it.

26:28.520 --> 26:32.880
The Docker file just says, hey, I will use open telemetry.

26:32.880 --> 26:41.960
And it's during configuration, it's like in the Docker compulse file where I'm using agreed

26:41.960 --> 26:46.720
upon environment variables. Where I'm saying you should set it here or

26:46.720 --> 26:50.600
here or you should use logging or tracing or metrics or whatever.

26:50.600 --> 26:55.120
So that's very important to separate those concerns.

26:55.120 --> 27:00.280
On one side in the Docker file you say, hey, I'm ready for open telemetry.

27:00.280 --> 27:05.560
And when you actually deploy it to say, okay, a point telemetry will go there for the metrics

27:05.560 --> 27:12.200
and there for the tracing and for logging, I will disable it or whatever.

27:12.200 --> 27:14.400
Thank you for... Sorry, go ahead.

27:14.400 --> 27:20.800
Sorry. And then you have a Docker image that can be, like, reusable.

27:20.800 --> 27:24.000
Thank you for being good, first-line citizens to remain seated.

27:24.000 --> 27:27.960
Next question. Thank you for your presentation.

27:27.960 --> 27:37.240
So my question is, does open telemetry support error handling like Sentry?

27:37.240 --> 27:40.800
If not, is there any plans to do that?

27:40.800 --> 27:46.920
It's really useful to catch crashes and capture the context of the crash.

27:46.920 --> 27:49.800
So that's it. Thank you.

27:49.800 --> 27:56.280
If it happens, when you mean crashes of open telemetry itself or of the components that

27:56.280 --> 27:58.960
are like under watch?

27:58.960 --> 28:01.760
Yeah, of the application that's monitored.

28:01.760 --> 28:12.120
Fabian showed you how you could log and, like, bind your traces and your logs.

28:12.120 --> 28:14.000
So you could have both here.

28:14.000 --> 28:16.520
My focus was just on tracing.

28:16.520 --> 28:26.040
But you can reuse the same Docker GitHub repo and just, like, here.

28:26.040 --> 28:35.640
Put the logs somewhere in, I don't know, Elasticsearch or whatever.

28:35.640 --> 28:38.680
Because it's not a sponsored room.

28:38.680 --> 28:42.000
And then you can check... And you introduce some errors.

28:42.000 --> 28:44.360
And then you can check how the two are bound.

28:44.360 --> 28:47.840
And you can, like, drill down to where it failed.

28:47.840 --> 28:56.480
Okay. Thank you.
