1
0:00:00.000 --> 0:00:11.920
Hi, everybody. Thanks for being here for this talk. That's a lot of people. I'm Nicolas

2
0:00:11.920 --> 0:00:18.160
Frankel. I've been a developer for a long time. And I would like to ask how many of

3
0:00:18.160 --> 0:00:28.480
you are developers in this room? Quite a lot. Who are ops? Just as many. And who are DevOps,

4
0:00:28.480 --> 0:00:40.040
whatever you mean by it. So this talk is intended for actually developers. Because I was or

5
0:00:40.040 --> 0:00:47.960
I still think I'm a developer. So if you are a nobs people and for this for you is not

6
0:00:47.960 --> 0:00:53.200
that super interesting. At least you can direct your developer colleagues to the talk so that

7
0:00:53.200 --> 0:01:03.800
they can understand how they can ease your work. Well, perhaps you've never seen that.

8
0:01:03.800 --> 0:01:12.920
But I'm old or experienced depending on how you see it. And when I was starting my career,

9
0:01:12.920 --> 0:01:18.960
monitoring was like a bunch of people sitting in front of screens the whole day. And actually

10
0:01:18.960 --> 0:01:24.880
I was lucky once in the south of France I was told, hey, this is the biggest monitoring

11
0:01:24.880 --> 0:01:31.080
site of all France. And actually it really looked like this. And of course there were

12
0:01:31.080 --> 0:01:37.760
people like watching it. And that was the easy way. Now I hope that you don't have that

13
0:01:37.760 --> 0:01:46.800
anymore. That it has become a bit more modern. Actually there is a lot of talk now about

14
0:01:46.800 --> 0:01:55.440
microservices, right? Who here is doing microservices? Yeah. Yeah. Because if you don't do microservices

15
0:01:55.440 --> 0:02:01.920
you are not a real developer. But even if you don't do microservices, so you are not

16
0:02:01.920 --> 0:02:06.520
a real developer and I encourage you not to be a real developer in that case, you probably

17
0:02:06.520 --> 0:02:13.040
are doing some kind of distributed work. It's become increasingly difficult to just like

18
0:02:13.040 --> 0:02:19.280
handle everything locally. And the problem becomes, yeah, if something bad happens, how

19
0:02:19.280 --> 0:02:27.080
can you locate how it works? Or even if something works as expected, how you can understand

20
0:02:27.080 --> 0:02:36.920
like the flow of your request across the network. I love Wikipedia. And here is the observability

21
0:02:36.920 --> 0:02:46.040
definition by Wikipedia which is long and in that case not that interesting. So I have

22
0:02:46.040 --> 0:02:56.400
a better one afterwards for tracing. So basically tracing helps you to understand the flow of

23
0:02:56.400 --> 0:03:05.440
a business request across all your components. Fabian, where is Fabian? Fabian is here.

24
0:03:05.440 --> 0:03:11.920
So he talked a lot about the metrics and the logging. So in this talk I will really focus

25
0:03:11.920 --> 0:03:20.840
on tracing because my opinion is that, well, metrics is easy. We do metrics since ages.

26
0:03:20.840 --> 0:03:27.320
Like we take the CPU, the memory, whatever. Now we are trying to get more like business

27
0:03:27.320 --> 0:03:34.120
related metrics. But it's still the same concept. Logging also. Now we do aggregated logging.

28
0:03:34.120 --> 0:03:41.920
And nothing by knowing. Tracing is I think the hardest part. So in the past there were

29
0:03:41.920 --> 0:03:50.840
already some tracing pioneers. Perhaps you've used some of them. And, well, now we are at

30
0:03:50.840 --> 0:03:57.920
the stage where we want to have something more standardized. So it starts with the trace

31
0:03:57.920 --> 0:04:14.400
context from the WC and the ID is that you start a trace and then other components will

32
0:04:14.400 --> 0:04:23.840
get the trace and will append their own trace to it. So it works very well in a web context.

33
0:04:23.840 --> 0:04:30.280
And it defines like two important concepts that Fabian thanks already described. So now

34
0:04:30.280 --> 0:04:46.520
I am done. So I have the same stupid stuff. So here you have oh, sorry. Yes. It reminds

35
0:04:46.520 --> 0:04:50.680
me of the story. I did the same to my colleagues. They didn't care about the presentation. They

36
0:04:50.680 --> 0:05:02.400
only remembered that. Okay. So here you have a trace. And here you have the different spans.

37
0:05:02.400 --> 0:05:10.440
So here the X one is the parent one. And then the Y and the Z one will text this X span

38
0:05:10.440 --> 0:05:17.600
as their parent span. So this is a single trace. This is a single request across your

39
0:05:17.600 --> 0:05:25.920
service. Web stuff is good, but it's definitely not enough. And so for that we have the open

40
0:05:25.920 --> 0:05:35.400
telemetry stuff. Open telemetry is just a big bag of miracles all set into a specific

41
0:05:35.400 --> 0:05:45.320
project. So it's basically APIs, SDK, tools, whatever under the open telemetry level. It

42
0:05:45.320 --> 0:05:53.720
implements the W3C trace context. If you have been doing some kind of tracing before, you

43
0:05:53.720 --> 0:05:59.720
might know it because it's like the merging of open tracing and open census. Good thing

44
0:05:59.720 --> 0:06:04.600
is the CNCF project. So basically there is some hope that it will last for a couple of

45
0:06:04.600 --> 0:06:11.800
years. The architecture is pretty simple. Basically you've got sources. You've got the

46
0:06:11.800 --> 0:06:18.960
open telemetry protocol. And as Tanveen mentioned, you dump everything into a collector. Collector

47
0:06:18.960 --> 0:06:27.400
we should be as close as possible to your sources. And then some tools are able to read

48
0:06:27.400 --> 0:06:39.360
like data from it and to display it into the way that we expect to see it. What happens

49
0:06:39.360 --> 0:06:45.400
after the open telemetry collector is not a problem of open telemetry. Just they are

50
0:06:45.400 --> 0:06:52.080
collectors that are compatible. And for example, you can use Jaeger or Zipkin in a way that

51
0:06:52.080 --> 0:06:58.880
allows you to dump your data, your open telemetry data into Jaeger or Zipkin into the open telemetry

52
0:06:58.880 --> 0:07:04.240
format. So you can reuse, and that is very important, you can reuse your infrastructure

53
0:07:04.240 --> 0:07:09.680
if you're already using the stools. Just switching to open telemetry. And then you're like you

54
0:07:09.680 --> 0:07:18.160
are using a standard and then you can switch your open telemetry back end with less issues.

55
0:07:18.160 --> 0:07:27.320
Now comes the fun developer part. If you are a developer, you probably are lazy. I know.

56
0:07:27.320 --> 0:07:36.200
I'm a developer. So the idea is open telemetry should make your life as a developer as easy

57
0:07:36.200 --> 0:07:47.080
as possible to help your ops colleague like diagnose your problems. And the easiest part

58
0:07:47.080 --> 0:07:54.640
if you do auto instrumentation. Auto instrumentation is only possible in cases where you have a

59
0:07:54.640 --> 0:08:00.840
platform when you have a run time. Fabian mentioned Java. Java as a run time which is

60
0:08:00.840 --> 0:08:11.640
the JVM. Python as a run time. Now if you have Rust, it's not as easy. So in that case,

61
0:08:11.640 --> 0:08:19.640
you are stuck. My advice if you are using a run time and probably most of you are using

62
0:08:19.640 --> 0:08:26.640
such run times, whether Java or whatever, use it. It's basically free. It's a low hanging

63
0:08:26.640 --> 0:08:32.800
fruit and there is no coupling. So basically you don't need extra dependencies as developers

64
0:08:32.800 --> 0:08:40.360
in your projects. So since it's called practical introduction, let's do some practice. So here

65
0:08:40.360 --> 0:08:47.900
I have a bit better than a hello world. So I have tried to model like an e-commerce shop

66
0:08:47.900 --> 0:08:55.480
with very simple stuff. It starts just asking for products. I will go through an API gateway

67
0:08:55.480 --> 0:09:00.400
which will forward the product to the catalog and the catalog doesn't know about the prices

68
0:09:00.400 --> 0:09:06.440
so it will ask the prices from a pricing service and it will ask the stocks from the stock

69
0:09:06.440 --> 0:09:19.760
service. The entry point is the most important thing because it gives the parents praise.

70
0:09:19.760 --> 0:09:25.400
Everything will be from that. So in general you have a reverse proxy or an API gateway

71
0:09:25.400 --> 0:09:32.760
depending on your use case. I work on the Apache API project. It uses the Nginx reverse

72
0:09:32.760 --> 0:09:38.220
proxy. On top you have an open REST because you want to have Lua to script and to autor

73
0:09:38.220 --> 0:09:44.760
load the configuration. Then you have lots of out of the box plugins. Let's see how it

74
0:09:44.760 --> 0:09:58.240
works. Now I have the code here. Is it the begin off? Good. So I might be very old because

75
0:09:58.240 --> 0:10:05.400
for me it wouldn't. Here that's my architecture. I'm using Docker Compose because I'm super

76
0:10:05.400 --> 0:10:12.240
lazy. I don't want to use Kubernetes. So I have Jaeger. I have all in one. I'm using

77
0:10:12.240 --> 0:10:18.680
the all included so I don't need to think about having the telemetry collector and the

78
0:10:18.680 --> 0:10:27.920
web to check the traces. I have only one single image. Then I have API 6. Then I have the

79
0:10:27.920 --> 0:10:35.240
catalog which I showed you. Of course I have couple of environment, my variable to configure

80
0:10:35.240 --> 0:10:43.960
everything. I wanted to focus on tracing so no metrics, no logs. I'm sending everything

81
0:10:43.960 --> 0:10:51.960
to Jaeger and then I do the same for pricing and I do the same for the stock. Normally

82
0:10:51.960 --> 0:10:59.840
at this point I already started because in general I have issues with the Java stuff.

83
0:10:59.840 --> 0:11:07.760
So here I'm doing a simple curl to the product. I've got the data which is not that important.

84
0:11:07.760 --> 0:11:13.760
And I can check on the web app how it works. So here I will go on the Jaeger UI. I see

85
0:11:13.760 --> 0:11:21.320
all my services. I can find the traces. Here you can find the latest one. And here is the

86
0:11:21.320 --> 0:11:30.880
thing. If I click on it, it might be a bit small, right? I cannot do much better. You

87
0:11:30.880 --> 0:11:37.080
can already see everything that I've shown you. So I start with the product from the

88
0:11:37.080 --> 0:11:44.560
API gateway. It forwards it to the product, to the catalog. Then I have the internal calls

89
0:11:44.560 --> 0:11:52.600
and I will show you how it works. Then I have the get request made from inside the application

90
0:11:52.600 --> 0:11:59.160
and then I have the stocks that responds here. Same here. And here we see something that

91
0:11:59.160 --> 0:12:08.120
was not mentioned on the component diagram. From the catalog to the stock I go directly.

92
0:12:08.120 --> 0:12:13.200
But from the catalog to the pricing I go back to the API gateway which is also a way to

93
0:12:13.200 --> 0:12:20.840
do that for whatever reason. And so this is something that was not mentioned on the PDF

94
0:12:20.840 --> 0:12:24.640
but you cannot cheat with open telemetry. It tells you exactly what happens and the

95
0:12:24.640 --> 0:12:34.700
flow. And the rest is the same. So regarding the code itself, I told you that I don't want

96
0:12:34.700 --> 0:12:45.680
anything to trouble the developer. So here I have nothing regarding open telemetry. If

97
0:12:45.680 --> 0:12:53.320
I write hotel, you see nothing. If I write telemetry, you see nothing. I have no dependency.

98
0:12:53.320 --> 0:13:03.960
The only thing that I have is in my Docker file and in my Docker file I get the latest

99
0:13:03.960 --> 0:13:13.160
open telemetry agent. So you can have your developers completely oblivious and you just

100
0:13:13.160 --> 0:13:19.100
provide them with this snippet and then when you run the Java application you just tell

101
0:13:19.100 --> 0:13:29.600
them A, run with the Java agent. Low hanging fruit, zero trouble. Any Java developer here?

102
0:13:29.600 --> 0:13:42.280
Not that many. Python? Okay. So it will be Python. Just the same here. Here it's a bit

103
0:13:42.280 --> 0:13:52.760
different. I add dependencies but actually I do nothing on it. So here I have no dependency

104
0:13:52.760 --> 0:13:58.600
on anything. Here I'm using a SQL database because again I'm lazy. I don't care that

105
0:13:58.600 --> 0:14:05.520
much. But here I have no dependency, no API call to open telemetry. The only thing that

106
0:14:05.520 --> 0:14:14.920
I have is in the Docker file again. I have this. Again, I'm using a runtime. It's super

107
0:14:14.920 --> 0:14:24.840
easy. I let the runtime, like, intercept the calls and send everything to open telemetry.

108
0:14:24.840 --> 0:14:33.600
And the last fun stuff is Rust. Any Rust developer? Please don't look at my code too much. I'm

109
0:14:33.600 --> 0:14:43.480
not a Rust developer. So I hope it won't be too horrible. And Rust is actually, well,

110
0:14:43.480 --> 0:14:48.840
not that standardized. So here I don't have any runtime. So I need to make the calls by

111
0:14:48.840 --> 0:14:56.920
myself. The hardest part is to find which library to use depending on which framework

112
0:14:56.920 --> 0:15:04.400
to use. So in this case I found one and perhaps there are better options. But I found this

113
0:15:04.400 --> 0:15:14.600
open telemetry OLTP stuff. And here this is because I'm using Exum. I'm using this library.

114
0:15:14.600 --> 0:15:20.800
And so far it works for me. I don't need to do a lot of stuff. I just, like, copy pasted

115
0:15:20.800 --> 0:15:32.160
this stuff. Copy paste developer. And afterwards in my main function I just need to say this

116
0:15:32.160 --> 0:15:39.880
and this. So I added two layers. So if you are, if you don't have any platform, any runtime,

117
0:15:39.880 --> 0:15:46.560
you actually need your developers to care about open telemetry. Otherwise it's fine.

118
0:15:46.560 --> 0:15:54.760
Now we already have pretty good, like, results. But we may want to do better. So we can also

119
0:15:54.760 --> 0:16:04.000
ask the developers once they are more comfortable to do manual instrumentation even in the case

120
0:16:04.000 --> 0:16:22.200
when there is a platform. Now I will docker compose down. And it takes a bit of time.

121
0:16:22.200 --> 0:16:44.520
I will prepare this. And on the catalog side, now I can have some additional codes. So this

122
0:16:44.520 --> 0:16:52.840
is a Spring Boot application. What I can do is add annotations. Like, I noticed there

123
0:16:52.840 --> 0:16:58.240
were a couple of Java developers. So it's the same with Kotlin. It's still on the JVM.

124
0:16:58.240 --> 0:17:03.640
So basically I'm adding annotations. And because Spring Boot can read the annotation at runtime,

125
0:17:03.640 --> 0:17:08.760
it can add those codes. So I don't have to, like, call the API explicitly. I just add

126
0:17:08.760 --> 0:17:23.200
some annotation and it should be done. On the Python side, I import this trace stuff.

127
0:17:23.200 --> 0:17:33.000
And then I can, with the tracer, add some, again, explicit traces. So internal traces.

128
0:17:33.000 --> 0:17:37.560
And from the first point of view, because I already, like, did it explicitly, it worked.

129
0:17:37.560 --> 0:17:41.760
Now you can see that I am in deep trouble because it happened a lot of time. The Java

130
0:17:41.760 --> 0:17:47.560
application doesn't start for a demo. And that's really, really fun. So I will try to

131
0:17:47.560 --> 0:17:59.320
docker compose down the catalog. And docker compose. Hey, what happens? Dash? Are you

132
0:17:59.320 --> 0:18:11.160
sure? No, no, no, no, no, no, no, no. Not with the new versions. Yes. That's fine. We

133
0:18:11.160 --> 0:18:37.120
are all here to learn. Down? What? Stop. Thanks. The stress, the stress. Yeah. Honestly, if

134
0:18:37.120 --> 0:18:46.640
there is any, like, person here able to tell me why this Java application sometimes has

135
0:18:46.640 --> 0:19:01.680
issues starting because I've added one gig at the beginning. And it's stuck always here.

136
0:19:01.680 --> 0:19:12.320
So I can tell you what you should see normally. If I'm lucky, I made a screenshot. And yes,

137
0:19:12.320 --> 0:19:20.720
here. But it's the beginning. It's the Rust one. So here, this is what you can have in

138
0:19:20.720 --> 0:19:25.160
Python. This is what I added explicitly. I have five minutes. Well, if the demo doesn't

139
0:19:25.160 --> 0:19:31.440
work, it will be much better. Then I won't have any problems with the timing. Here, you

140
0:19:31.440 --> 0:19:42.080
can see that this is the trace that, yeah, this is a trace that I did manually in Python.

141
0:19:42.080 --> 0:19:52.880
And here we can see that I filled the ID with the value. And on the Java side, again, nope,

142
0:19:52.880 --> 0:20:07.720
I think it will be here. This is not the manual stuff that I added. Yes, it is. You have the

143
0:20:07.720 --> 0:20:15.160
fetch here. You have the fetch here. So this is the span that I added manually. I'm afraid

144
0:20:15.160 --> 0:20:23.560
that at this point the demo just refused working. Yes, it's still stuck. I will stop there.

145
0:20:23.560 --> 0:20:35.080
I won't humiliate myself further when it's done. It's done. Perhaps if you are interested,

146
0:20:35.080 --> 0:20:40.260
you can follow me on Twitter. You can follow me on Mastodon. I don't know what's the ratio.

147
0:20:40.260 --> 0:20:45.560
More importantly, if you are interested about the GitHub repo, to do that by yourself, perhaps

148
0:20:45.560 --> 0:20:50.320
with better configuration of the compose with the right memory, it would work. And although

149
0:20:50.320 --> 0:20:57.040
the talk was not about Apache API 6, well, have a look at Apache API 6. It's an API getaway,

150
0:20:57.040 --> 0:21:08.920
the Apache way. Great. Are there some questions now?

151
0:21:08.920 --> 0:21:13.920
I never got so many up louds with a felling demo. Please remain seated. Please remain

152
0:21:13.920 --> 0:21:21.800
seated so we can have a Q&A. Who had a question? Thank you. Very good talk. I have two questions.

153
0:21:21.800 --> 0:21:28.160
So one is about this. Let's start with the first one. Right. Yes, yes, yes. How much

154
0:21:28.160 --> 0:21:34.280
overhead does this bring in Python and Java or Rust? How heavy is this instrumentation?

155
0:21:34.280 --> 0:21:41.000
That's a very good question. And the overhead of each request depends on your own infrastructure.

156
0:21:41.000 --> 0:21:46.680
But I always have an answer to that. Is it better to go fast and you don't know where

157
0:21:46.680 --> 0:21:55.720
you are going or to go a bit slower and to know where you are going? I think that whatever

158
0:21:55.720 --> 0:22:02.480
the costs, it's always easy to add additional resources and it doesn't cost you that much,

159
0:22:02.480 --> 0:22:08.600
whereas a debug incident across a distributed system can cost you days or even like weeks

160
0:22:08.600 --> 0:22:13.000
in engineering costs. And you are very, very expensive, right?

161
0:22:13.000 --> 0:22:18.920
Okay. Thank you. And the second one, have you encountered any funny issues with multi-threading

162
0:22:18.920 --> 0:22:23.880
or multi-processing? Something like when your server just now.

163
0:22:23.880 --> 0:22:30.160
Can you come closer to your mother? Your server just now was not starting. So some

164
0:22:30.160 --> 0:22:35.440
software when you have multi-threading or multi-processing, have you encountered any

165
0:22:35.440 --> 0:22:40.420
issues when the instrumentation caused you trouble?

166
0:22:40.420 --> 0:22:44.560
This is not production stuff. This is just better than the hello world. So I cannot tell

167
0:22:44.560 --> 0:22:49.880
you about prediction issues. You should find people who have these issues. As I mentioned,

168
0:22:49.880 --> 0:22:55.720
it's a developers-oriented talk. So it's more about pushing the developers to help

169
0:22:55.720 --> 0:23:01.840
ops to their job. For production issues, I must admit I have no clue.

170
0:23:01.840 --> 0:23:11.960
Hi. In the case of runtime, does it always work with also badly written application?

171
0:23:11.960 --> 0:23:19.440
I mean, how bad can application be before it stops working?

172
0:23:19.440 --> 0:23:24.480
I'm not sure I understood the question. So how often do you need to do it before it stops

173
0:23:24.480 --> 0:23:29.000
working? No, no, no. I mean, let's say I use deprecated

174
0:23:29.000 --> 0:23:37.120
libraries, bad clients, something that doesn't work as it's supposed to be for the instrumentation

175
0:23:37.120 --> 0:23:44.560
perspective. I mean, I do request to the network using UDP client, something I've written myself,

176
0:23:44.560 --> 0:23:55.440
some custom stuff that I'm imagining that the instrumentation sits between some layer

177
0:23:55.440 --> 0:24:05.440
of the network, which is going to the internet, for example. And so how bad can I be before

178
0:24:05.440 --> 0:24:11.520
it stops recognizing a request from junk? You cannot be banned.

179
0:24:11.520 --> 0:24:21.800
Well, it's a moral issue first. But then on the platform side, the host to instrumentation,

180
0:24:21.800 --> 0:24:28.840
they work with specific frameworks and tools. It's those frameworks and tools that know

181
0:24:28.840 --> 0:24:35.920
how to check what happens and to send the data to open telemetry.

182
0:24:35.920 --> 0:24:42.560
So if you don't play in this game, nothing will be sent.

183
0:24:42.560 --> 0:24:49.080
On the manual instrumentation side, it's an explicit call. So it depends what you want

184
0:24:49.080 --> 0:24:55.180
to send. Yeah, I was thinking of auto instrumentation.

185
0:24:55.180 --> 0:25:03.080
So let's say I do DNS resolution by myself and then I just throw a request to an IP.

186
0:25:03.080 --> 0:25:14.280
Let me show the Python stuff here. This is what I showed you in the screenshots.

187
0:25:14.280 --> 0:25:21.040
This is what I write. And this is the attributes that I want to have.

188
0:25:21.040 --> 0:25:29.440
So basically, if here you have something that is completely unrelated, it's up to you.

189
0:25:29.440 --> 0:25:33.480
That's why it's easier to start with auto instrumentation.

190
0:25:33.480 --> 0:25:39.600
And then once you get a general overview of what you have and your ops start saying, hey,

191
0:25:39.600 --> 0:25:47.040
perhaps we want to have more details here, then you can come with manual instrumentation.

192
0:25:47.040 --> 0:25:54.380
But start with the less expensive stuff. I didn't really answer the question.

193
0:25:54.380 --> 0:26:00.160
I understand it. But that's the best I can do regarding it.

194
0:26:00.160 --> 0:26:02.360
Sorry. Okay.

195
0:26:02.360 --> 0:26:10.240
And for the talk, for the agent you're using the Docker file, how you can configure it,

196
0:26:10.240 --> 0:26:17.040
for example, for the tracing for Jagger or other stuff.

197
0:26:17.040 --> 0:26:19.560
Regarding the Docker file, sorry. Yeah.

198
0:26:19.560 --> 0:26:25.600
How you can configure the agent to send the traces for Jagger or other...

199
0:26:25.600 --> 0:26:28.520
The Docker file doesn't mention where you send it.

200
0:26:28.520 --> 0:26:32.880
The Docker file just says, hey, I will use open telemetry.

201
0:26:32.880 --> 0:26:41.960
And it's during configuration, it's like in the Docker compulse file where I'm using agreed

202
0:26:41.960 --> 0:26:46.720
upon environment variables. Where I'm saying you should set it here or

203
0:26:46.720 --> 0:26:50.600
here or you should use logging or tracing or metrics or whatever.

204
0:26:50.600 --> 0:26:55.120
So that's very important to separate those concerns.

205
0:26:55.120 --> 0:27:00.280
On one side in the Docker file you say, hey, I'm ready for open telemetry.

206
0:27:00.280 --> 0:27:05.560
And when you actually deploy it to say, okay, a point telemetry will go there for the metrics

207
0:27:05.560 --> 0:27:12.200
and there for the tracing and for logging, I will disable it or whatever.

208
0:27:12.200 --> 0:27:14.400
Thank you for... Sorry, go ahead.

209
0:27:14.400 --> 0:27:20.800
Sorry. And then you have a Docker image that can be, like, reusable.

210
0:27:20.800 --> 0:27:24.000
Thank you for being good, first-line citizens to remain seated.

211
0:27:24.000 --> 0:27:27.960
Next question. Thank you for your presentation.

212
0:27:27.960 --> 0:27:37.240
So my question is, does open telemetry support error handling like Sentry?

213
0:27:37.240 --> 0:27:40.800
If not, is there any plans to do that?

214
0:27:40.800 --> 0:27:46.920
It's really useful to catch crashes and capture the context of the crash.

215
0:27:46.920 --> 0:27:49.800
So that's it. Thank you.

216
0:27:49.800 --> 0:27:56.280
If it happens, when you mean crashes of open telemetry itself or of the components that

217
0:27:56.280 --> 0:27:58.960
are like under watch?

218
0:27:58.960 --> 0:28:01.760
Yeah, of the application that's monitored.

219
0:28:01.760 --> 0:28:12.120
Fabian showed you how you could log and, like, bind your traces and your logs.

220
0:28:12.120 --> 0:28:14.000
So you could have both here.

221
0:28:14.000 --> 0:28:16.520
My focus was just on tracing.

222
0:28:16.520 --> 0:28:26.040
But you can reuse the same Docker GitHub repo and just, like, here.

223
0:28:26.040 --> 0:28:35.640
Put the logs somewhere in, I don't know, Elasticsearch or whatever.

224
0:28:35.640 --> 0:28:38.680
Because it's not a sponsored room.

225
0:28:38.680 --> 0:28:42.000
And then you can check... And you introduce some errors.

226
0:28:42.000 --> 0:28:44.360
And then you can check how the two are bound.

227
0:28:44.360 --> 0:28:47.840
And you can, like, drill down to where it failed.

228
0:28:47.840 --> 0:28:56.480
Okay. Thank you.

