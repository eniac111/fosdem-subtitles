WEBVTT

00:00.000 --> 00:02.000
So, I'm going to give you a round of applause.

00:07.000 --> 00:09.000
Welcome our next speakers and give them a round of applause.

00:10.000 --> 00:12.000
APPLAUSE

00:18.000 --> 00:21.000
. Can you hear me? I guess you can.

00:22.000 --> 00:26.000
Hello, everyone, and welcome to the session about how we can use

00:26.000 --> 00:28.000
open telemetry on Kubernetes to collect traces, metrics, and

00:28.000 --> 00:30.000
how we can use open telemetry on Kubernetes to collect traces.

00:30.000 --> 00:32.000
So, my name is Pavel. I'm a software engineer at Red Hat.

00:34.000 --> 00:36.000
I'm a contributor and maintainer of open telemetry

00:36.000 --> 00:38.000
operator and the EAGLE project.

00:40.000 --> 00:42.000
My name is Ben and I'm also working on the open telemetry

00:42.000 --> 00:46.000
operator and spent most of the time on open telemetry.

00:48.000 --> 00:50.000
And so, as I mentioned on today's agenda, there is the open

00:50.000 --> 00:53.000
telemetry operator. We will show how you can use it to

00:53.000 --> 00:56.000
deploy the collector, how you can as well use it to instrument

00:56.000 --> 00:58.000
your workloads on Kubernetes.

00:59.000 --> 01:01.000
And after this brief introduction, we will walk you

01:01.000 --> 01:03.000
through use cases, how you can use it to collect traces,

01:03.000 --> 01:08.000
metrics, and logs. However, I will start with the history of

01:08.000 --> 01:12.000
open source observability. I'm doing this because I believe

01:12.000 --> 01:14.000
that if we understand the history, maybe we will better

01:14.000 --> 01:18.000
understand where we as industry are going.

01:21.000 --> 01:23.000
So, on this slide, you essentially see a timeline with

01:23.000 --> 01:28.000
the open source project. And it's divided into the upper

01:28.000 --> 01:32.000
and bottom parts. In the bottom, you see the open source

01:32.000 --> 01:35.000
projects or platforms that you can deploy, and they provide

01:35.000 --> 01:41.000
you with the storage and visualization capabilities for

01:41.000 --> 01:44.000
the observability data. Most of them work with distributed

01:44.000 --> 01:48.000
traces, however, some of them, like the Apache sky walking,

01:48.000 --> 01:53.000
hyper trace, and signals, those are more like end-to-end

01:53.000 --> 01:57.000
platforms that can show traces, metrics, and logs. I would like

01:57.000 --> 02:01.000
to focus on the upper part that shows you the open source data

02:01.000 --> 02:05.000
collection kind of frameworks. And what we see there,

02:05.000 --> 02:09.000
especially with open sensors and open telemetry, is that it's

02:09.000 --> 02:12.000
becoming more important that these frameworks kind of work

02:12.000 --> 02:20.000
with all the signals. For me, the data collection, especially

02:20.000 --> 02:24.000
for tracing started with Zipkin project. It gave us a stable

02:24.000 --> 02:27.000
data model that we as developers could use to export traces

02:27.000 --> 02:31.000
into Zipkin, but as well to many other kind of platforms that

02:31.000 --> 02:35.000
adopted Zipkin project. As a developer, when we wanted to use

02:35.000 --> 02:39.000
Zipkin clients, because the ecosystem hosted client

02:39.000 --> 02:42.000
libraries as well, it was a bit problematic in polyglot

02:42.000 --> 02:46.000
environments because those clients were using inconsistent

02:46.000 --> 02:51.000
APIs. There was no standardization. And so this

02:51.000 --> 02:55.000
problem then was partially solved with open tracing. The

02:55.000 --> 02:58.000
scope of the project was a bit wider. There was a

02:58.000 --> 03:02.000
specification, there was a document that defines which

03:02.000 --> 03:06.000
data should be collected, and as well how the API in those

03:06.000 --> 03:11.000
languages should look like. This enabled us to build

03:11.000 --> 03:15.000
reusable instrumentation libraries. And then you later

03:15.000 --> 03:19.000
open sensors project started with slightly different

03:19.000 --> 03:22.000
approach. There was no specification, there was no API,

03:22.000 --> 03:27.000
but there was SDK that everybody could use and a collector.

03:27.000 --> 03:31.000
So with open tracing, the approach was that developers

03:31.000 --> 03:36.000
would use the API and then at the build time provide the

03:36.000 --> 03:40.000
SDK from a vendor. With open sensors, everybody would use

03:40.000 --> 03:44.000
the SDK, and then the collector decides where the data should

03:44.000 --> 03:47.000
be sent. Those two projects were kind of competing, and then

03:47.000 --> 03:52.000
finally they merged into open telemetry in 2019. So the

03:52.000 --> 03:56.000
hotel, it adopted all the pieces from open tracing and open

03:56.000 --> 04:01.000
sensors, but kind of the biggest innovation in hotel is the

04:01.000 --> 04:07.000
auto instrumentation libraries or the agents. Those agents

04:07.000 --> 04:10.000
are production ready, most of them, because they were

04:10.000 --> 04:14.000
donated by one of the observability vendors. So they

04:14.000 --> 04:19.000
are production tested. So when we kind of summarize what

04:19.000 --> 04:22.000
happened is that we started with some instrumentation

04:22.000 --> 04:24.000
libraries, we started with a

04:26.000 --> 04:29.000
project, and since we have some kind of standardization, we

04:29.000 --> 04:32.000
could build reusable instrumentation libraries and kind

04:32.000 --> 04:36.000
of create more sophisticated instrumentations for run times.

04:36.000 --> 04:40.000
And now we are in an age that we have available in open source

04:40.000 --> 04:43.000
agents or auto instrumentation libraries that we can just

04:43.000 --> 04:47.000
grab, put into our platforms, and we will get telemetry data

04:47.000 --> 04:52.000
from our platform. And I think, you know, so where are we

04:52.000 --> 04:56.000
going? I think we are going into an era where we as developers

04:56.000 --> 05:00.000
we won't have to care about how the telemetry is created for us.

05:00.000 --> 05:05.000
It will be the instrumentation will become maybe the feature

05:05.000 --> 05:09.000
of the platform where we deploy the application. So this is one

05:09.000 --> 05:12.000
way to look at it. The other way might be that the

05:12.000 --> 05:15.000
observability will shift left, and since we have this data, we

05:15.000 --> 05:17.000
can do a lot of things. So we are going to look at the

05:17.000 --> 05:17.000
observability and the

05:17.000 --> 05:21.000
observability of the platform. And we will be utilizing it for

05:21.000 --> 05:26.000
other use cases, probably like testing and security.

05:26.000 --> 05:30.000
So with that, I would like to move to the open telemetry.

05:30.000 --> 05:35.000
And it's obviously open source project hosted in the

05:35.000 --> 05:38.000
community computing foundation, and its main goal is to provide

05:38.000 --> 05:42.000
vendor on neutral telemetry data collection. It's the second

05:42.000 --> 05:46.000
step. And it's a very large and there is several independent

05:46.000 --> 05:50.000
components that we can use. There is a specification that

05:50.000 --> 05:54.000
defines what data should be collected and how the API should

05:54.000 --> 05:58.000
look like. And obviously then there is the implementation of

05:58.000 --> 06:03.000
the API, the SDK and the standard data model called

06:03.000 --> 06:06.000
OTLP, or open telemetry protocol. These four pieces are

06:06.000 --> 06:09.000
meant to be used primarily by instrumentation authors or, you

06:09.000 --> 06:11.000
know, the user-based

06:13.000 --> 06:17.000
system. And the last two components, the auto

06:17.000 --> 06:20.000
instrumentation, or agent, and collector are meant to be used

06:20.000 --> 06:23.000
by end users to kind of roll out observability in their

06:23.000 --> 06:27.000
organization. To facilitate open telemetry deployment on

06:27.000 --> 06:31.000
Kubernetes, there is a helm chart and Kubernetes operator.

06:31.000 --> 06:35.000
What I would like to stress is that open telemetry is only

06:35.000 --> 06:37.000
available in the open telemetry

06:39.000 --> 06:41.000
collection. It's not the platform that you can deploy.

06:41.000 --> 06:45.000
It doesn't provide any storage or query APIs.

06:45.000 --> 06:49.000
So now let's go to the main part, the Kubernetes operator.

06:49.000 --> 06:53.000
The operator itself is a go-long application. It uses

06:53.000 --> 06:58.000
kubebuilder and it has three primary use cases. It can

06:58.000 --> 07:03.000
deploy the open telemetry collector as a deployment,

07:03.000 --> 07:05.000
for instance, it can also install your own

07:06.000 --> 07:09.000
workload. It can also install your own workload,

07:09.000 --> 07:13.000
or instead of a stateful set, it can as well inject the

07:13.000 --> 07:16.000
collector as a sitecard to your workload. The second use case is

07:16.000 --> 07:20.000
that it can instrument your workloads running on Kubernetes

07:20.000 --> 07:24.000
by using those instrumentation libraries or agents from open

07:24.000 --> 07:28.000
telemetry. And last but not least, it integrates with

07:28.000 --> 07:30.500
and split them across the collector instances

07:30.500 --> 07:33.240
that you have deployed.

07:33.240 --> 07:35.320
To enable this functionality, the operator

07:35.320 --> 07:38.480
provides two CRDs, one for the collector that

07:38.480 --> 07:42.080
is used to deploy the collector and integrate the primitives.

07:42.080 --> 07:45.200
And the second one is the instrumentation CRD,

07:45.200 --> 07:47.480
where you define how the applications should

07:47.480 --> 07:49.840
be instrumented.

07:49.840 --> 07:52.000
The operator itself then can be deployed

07:52.000 --> 07:58.880
through manifest files, home chart, or OLM.

07:58.880 --> 08:01.800
So what we see here is the Kubernetes cluster.

08:01.800 --> 08:06.120
There are three workloads, pod1, pod2, and pod3.

08:06.120 --> 08:09.800
The first workload is instrumented with the auto-SDK

08:09.800 --> 08:10.520
directly.

08:10.520 --> 08:12.440
So when we were building this application,

08:12.440 --> 08:15.800
we pulled in the auto dependency,

08:15.800 --> 08:19.520
and we compiled it against it, and used those APIs directly

08:19.520 --> 08:24.240
in our business code and in the middleware that we are using.

08:24.240 --> 08:27.560
The second pod is using the auto-instrumentation libraries

08:27.560 --> 08:30.640
that were injected by the operator

08:30.640 --> 08:34.080
through the admission webhook.

08:34.080 --> 08:38.360
And the third pod is using Zipkin instrumentation and permit

08:38.360 --> 08:39.840
use instrumentation libraries.

08:39.840 --> 08:44.880
And it has the collector sidecar as well injected

08:44.880 --> 08:47.400
by the operator.

08:47.400 --> 08:48.920
So essentially, the operator there,

08:48.920 --> 08:55.800
it reconciles three open telemetry CRs, two 4D collector,

08:55.800 --> 08:58.040
and one instrumentation.

08:58.040 --> 08:59.680
And then all these workloads, they

08:59.680 --> 09:02.840
send data to the collector deployed probably as a daemon

09:02.840 --> 09:04.400
set.

09:04.400 --> 09:07.400
And then this collector then does some data normalization

09:07.400 --> 09:11.120
and sends finally data into the platform of your choice, which

09:11.120 --> 09:14.560
can be permit use for metrics and the algorithm for traces.

09:14.560 --> 09:17.840
With that, I would like to move to the second part,

09:17.840 --> 09:20.160
explaining the CRDs in more detail.

09:20.160 --> 09:20.640
Yep.

09:20.640 --> 09:23.720
I think the microphone should work.

09:23.720 --> 09:26.040
Yeah, so with the CRDs for today,

09:26.040 --> 09:28.840
we wanted to show both of them.

09:28.840 --> 09:30.840
And we start with the collector one.

09:30.840 --> 09:33.640
The collector CID is a bit loaded.

09:33.640 --> 09:35.840
So therefore, we picked a few things here,

09:35.840 --> 09:41.240
which I would say are the most used or important.

09:41.240 --> 09:44.680
So as Pavel mentioned, there are different deployment modes,

09:44.680 --> 09:47.840
different use cases for the open telemetry collector.

09:47.840 --> 09:51.000
And in this specification, we can go to the mode

09:51.000 --> 09:53.560
and just specify it there.

09:53.560 --> 09:56.120
There's a handy thing, which is the sidecar.

09:56.120 --> 09:58.160
We would see it afterwards.

09:58.160 --> 09:59.880
But if we want to use it, we only

09:59.880 --> 10:02.520
go to the part definition of our deployment

10:02.520 --> 10:06.760
and inject the annotation we see on the top right.

10:06.760 --> 10:10.720
And if we go to the part definition of our deployment,

10:10.720 --> 10:13.440
if we go with the deployment mode or something like this

10:13.440 --> 10:16.800
and we want to expose it for collecting matrix

10:16.800 --> 10:19.520
locks and traces from a different system,

10:19.520 --> 10:21.520
for example, we can use the ingress type.

10:21.520 --> 10:24.880
We can set there a lot of more.

10:24.880 --> 10:27.400
We configure there a lot of more, like also the annotations,

10:27.400 --> 10:29.880
your ingress class.

10:29.880 --> 10:32.960
But yeah, mainly the operator takes care of everything,

10:32.960 --> 10:34.240
creating services.

10:34.240 --> 10:37.280
Also is able to balance your load there.

10:37.280 --> 10:41.440
And the last thing here is then the image section,

10:41.440 --> 10:43.880
which is also important.

10:43.880 --> 10:45.800
With the open telemetry operator,

10:45.800 --> 10:49.080
it usually shapes the core distribution of open telemetry

10:49.080 --> 10:51.840
by default. So in open telemetry,

10:51.840 --> 10:55.480
the collector is split into two repositories when you go up

10:55.480 --> 10:57.560
and look at that GitHub.

10:57.560 --> 11:02.080
So in core, you will find OTLP, a logging exporter,

11:02.080 --> 11:04.040
so some basic stuff.

11:04.040 --> 11:07.160
And in contrib, you find basically everything.

11:07.160 --> 11:12.000
So if you want to send your traces to some proprietary

11:12.000 --> 11:16.560
vendor or to Jager, you probably need to look there.

11:16.560 --> 11:19.480
OK, the next thing is then the configuration.

11:19.480 --> 11:21.720
The configuration for the open telemetry collector

11:21.720 --> 11:24.240
is here provided like it's usually

11:24.240 --> 11:25.960
done for the collector itself.

11:25.960 --> 11:28.360
So it's passed directly forward.

11:28.360 --> 11:30.520
It's split into three parts here.

11:30.520 --> 11:31.960
We see the receiving part there.

11:31.960 --> 11:34.640
We specify our OTLP receiver.

11:34.640 --> 11:37.560
Here it accepts GRPC on a specific port.

11:37.560 --> 11:40.240
It could also be there that we specify a parameters

11:40.240 --> 11:43.280
receiver, which is then scraping something.

11:43.280 --> 11:47.720
Then the optional part is basically the processing part.

11:47.720 --> 11:49.400
We might want to save some resources,

11:49.400 --> 11:52.960
and we batch them our telemetry data.

11:52.960 --> 11:56.680
And yeah, there are other useful things.

11:56.680 --> 11:58.440
And on the exporter section here,

11:58.440 --> 12:00.080
we use the logging exporter, which

12:00.080 --> 12:01.440
is part of the core distribution.

12:01.440 --> 12:04.280
But you can configure whatever you like.

12:04.280 --> 12:08.600
You can also have multiple exporters for one resource.

12:08.600 --> 12:09.680
There is one thing.

12:09.680 --> 12:11.400
On the right side, we see the extensions.

12:11.400 --> 12:15.360
It didn't fit on the slide, so it's there in this box.

12:15.360 --> 12:18.120
This is then used if you have, for example, an exporter,

12:18.120 --> 12:22.040
which needs some additional headers.

12:22.040 --> 12:24.280
You want to set a barrier token or something else,

12:24.280 --> 12:25.920
you can do it there.

12:25.920 --> 12:28.440
And then finally, we go to the service section

12:28.440 --> 12:31.400
where we have different pipelines for each signal.

12:31.400 --> 12:34.240
And then we can then configure a processor and receiver

12:34.240 --> 12:37.960
and exporter in the way we want it.

12:41.200 --> 12:43.320
So then there is another CD, which

12:43.320 --> 12:46.360
is used for the auto instrumentation.

12:46.360 --> 12:49.240
And it looks slightly different.

12:49.240 --> 12:50.680
So here we have also the exporter.

12:50.680 --> 12:52.880
In the specification, we have the exporter.

12:52.880 --> 12:57.040
And the exporter only exports OTLP,

12:57.040 --> 13:01.560
so which means if we want to export it to some backend

13:01.560 --> 13:04.880
of our choice, we usually instrument our application

13:04.880 --> 13:08.440
directly then for what this traces to a collector instance

13:08.440 --> 13:10.320
which is running next to it.

13:10.320 --> 13:16.680
And we can use the power of these processors.

13:16.680 --> 13:18.920
Then we can configure some other useful things,

13:18.920 --> 13:22.560
like how the context is propagated and the sample rate.

13:22.560 --> 13:25.120
And to use it, it's also quite easy.

13:25.120 --> 13:26.280
So we have our deployment.

13:26.280 --> 13:29.640
In this case, we can choose from this list

13:29.640 --> 13:31.200
of supported languages.

13:31.200 --> 13:33.040
We might use Java.

13:33.040 --> 13:35.480
And we only set this annotation on the pod level.

13:35.480 --> 13:41.440
And it will take care of adding the SDK and also

13:41.440 --> 13:44.200
setting and configuring the environment variables.

13:44.200 --> 13:47.080
If we use something like Rust, we

13:47.080 --> 13:51.000
can also use the inject SDK path annotation

13:51.000 --> 13:54.840
to configure then just the destination

13:54.840 --> 13:57.760
because then the SDK should be there.

13:57.760 --> 14:00.560
And if we have a setup where there is,

14:00.560 --> 14:03.320
let's say, some proxy in front like Envoy,

14:03.320 --> 14:10.680
we can then just skip the adding the auto instrumentation

14:10.680 --> 14:13.240
there by only configuring the container names

14:13.240 --> 14:16.200
we want to instrument.

14:16.200 --> 14:20.400
And we will see this in a minute a bit more in detail.

14:20.400 --> 14:23.120
So this is then basically what we would need to do.

14:23.120 --> 14:26.080
So we create this instrumentation CRD.

14:26.080 --> 14:27.160
We add this annotation.

14:27.160 --> 14:30.960
On the left, we see the pod, there is our application.

14:30.960 --> 14:36.320
And in this gray box, you see what automatically is added.

14:36.320 --> 14:39.160
And this is then forwarded in this example to a collector.

14:41.760 --> 14:43.680
And how does this work?

14:43.680 --> 14:46.240
So the operator in the admission webhook,

14:46.240 --> 14:50.240
he will add this init container.

14:50.240 --> 14:52.640
On the top left, we see how the container looks before.

14:52.640 --> 14:54.320
So there are no environment variables.

14:54.320 --> 14:58.200
It's just a plain application.

14:58.200 --> 14:59.760
And in the command section, there

14:59.760 --> 15:02.160
is then the copy, which copies the Java agent

15:02.160 --> 15:04.480
to our original container.

15:04.480 --> 15:06.960
And on the right side, we see the final result.

15:06.960 --> 15:09.720
We see the Java tool options where the container is loaded.

15:09.720 --> 15:14.400
And then we see all these environment variables

15:14.400 --> 15:15.360
to configure our SDK.

15:18.400 --> 15:21.520
And finally, what we have seen also in the presentation

15:21.520 --> 15:28.080
from Nicholas previously, we have here the Jaeger output.

15:28.080 --> 15:30.480
So we can see the resource attributes

15:30.480 --> 15:35.320
and all the beautiful stuff that comes with it.

15:35.320 --> 15:39.440
So next, we have a look at metrics.

15:39.440 --> 15:43.240
So there is the open telemetry SDK.

15:43.240 --> 15:46.000
So if you want to go with open telemetry metrics,

15:46.000 --> 15:48.920
but I assume a lot of people have already

15:48.920 --> 15:51.160
some parameter stuff in place.

15:51.160 --> 15:56.520
And the open telemetry operator also helps us with this.

15:56.520 --> 16:02.200
So we can make we look first on the receiver part on the bottom.

16:02.200 --> 16:05.320
We see there we configure the parameters receiver, which

16:05.320 --> 16:06.840
has a scrape configuration.

16:06.840 --> 16:10.240
And there we can, for example, add some static targets.

16:10.240 --> 16:13.600
So we assume we add three different scrape endpoints.

16:13.600 --> 16:18.320
Then afterwards, if the target allocator is enabled,

16:18.320 --> 16:20.480
this will then take these scrape targets

16:20.480 --> 16:26.440
and spread these targets across our replicas, which

16:26.440 --> 16:29.080
are then responsible for getting the metrics.

16:29.080 --> 16:32.680
And yeah, that's basically how it works.

16:32.680 --> 16:36.240
There is also an option to enable parameter CRs.

16:36.240 --> 16:38.680
So we can then forward to this one.

16:38.680 --> 16:41.360
And the target allocator, which is an extra instance created

16:41.360 --> 16:47.560
by the open telemetry operator, will then

16:47.560 --> 16:49.160
get the targets from there.

16:49.160 --> 16:51.280
So we see this here in this graphic.

16:51.280 --> 16:52.320
Quite good.

16:52.320 --> 16:53.800
On the left side, we see pod one,

16:53.800 --> 16:56.680
which is using open telemetry.

16:56.680 --> 16:58.760
And it's pushing the information telemetry data.

16:58.760 --> 17:01.560
It gets directly to a collector.

17:01.560 --> 17:03.880
And in this gray box, we see there

17:03.880 --> 17:10.080
we have two instances running instrumented with permittoys.

17:10.080 --> 17:12.400
And the collector one and collector two

17:12.400 --> 17:14.520
are pulling the information from there.

17:14.520 --> 17:17.080
So this is all managed then by the operator.

17:17.080 --> 17:18.120
We have seen the replicas.

17:18.120 --> 17:20.840
This is basically collector one and collector two.

17:20.840 --> 17:23.040
And since we enable the target allocator,

17:23.040 --> 17:25.400
we get the targets from there, so which is then

17:25.400 --> 17:27.640
coming from the pod monitor.

17:27.640 --> 17:32.280
And finally, we send the information somewhere.

17:32.280 --> 17:36.560
So the last thing here, the last signal are then locks.

17:36.560 --> 17:38.640
So for locks, there are different options.

17:38.640 --> 17:43.240
So the first one would be to use the open telemetry SDK,

17:43.240 --> 17:47.080
what we might don't want right now,

17:47.080 --> 17:48.400
because we need to do some work.

17:48.400 --> 17:50.360
But if we directly want to go ahead,

17:50.360 --> 17:51.840
there is the file lock receiver.

17:51.840 --> 17:55.840
We can configure it to get the information from disk.

17:55.840 --> 17:59.720
And yeah, it's available in the Confrib repository.

17:59.720 --> 18:01.440
And we have different parsers there,

18:01.440 --> 18:08.080
which help us to move the locks into the OTLP format.

18:08.080 --> 18:10.920
We will see in a minute how this looks like.

18:10.920 --> 18:12.960
And there are other options if you

18:12.960 --> 18:16.560
want to integrate with Fluent bit.

18:16.560 --> 18:19.040
So there is a forwarder, so you can use it

18:19.040 --> 18:21.880
as a kind of a gateway then.

18:21.880 --> 18:24.760
And yeah, the only thing we need to do then

18:24.760 --> 18:29.040
is we can configure it as a daemon set.

18:29.040 --> 18:32.600
We need to pass our information there.

18:32.600 --> 18:34.520
And the file lock receiver, for example,

18:34.520 --> 18:38.200
can then get all the locks.

18:38.200 --> 18:40.600
And how does this look like at the end?

18:40.600 --> 18:46.040
So this is when we exported the locks to the logging output,

18:46.040 --> 18:47.560
so it's done it out.

18:47.560 --> 18:49.800
We see that we have the resource attributes, which

18:49.800 --> 18:52.240
are added automatically.

18:52.240 --> 18:55.640
And yeah, we see then the lock information.

18:55.640 --> 18:58.280
And on the bottom, the trace ID and span ID,

18:58.280 --> 19:00.600
which are not given if we read it just from disk.

19:00.600 --> 19:01.760
But that's it.

19:04.360 --> 19:05.840
Then we are almost at the end.

19:05.840 --> 19:07.840
Thank you.

19:07.840 --> 19:08.840
Thank you.

19:08.840 --> 19:19.240
Thanks a lot for the interesting talk.

19:19.240 --> 19:22.920
Does anyone have questions?

19:22.920 --> 19:23.960
Any questions?

19:23.960 --> 19:24.800
Raise your hand.

19:27.800 --> 19:28.400
Question?

19:28.400 --> 19:35.960
Yeah, there we go.

19:35.960 --> 19:39.000
For the logging part, would you suggest

19:39.000 --> 19:44.000
to replace any kind of cluster logging with fluent bit,

19:44.000 --> 19:47.760
or that's sending it off to a low key or something

19:47.760 --> 19:53.960
with an open telemetry log scraping?

19:53.960 --> 19:58.680
Or is that complementary?

19:58.680 --> 20:00.760
So I'm not sure if I fully got it.

20:00.760 --> 20:02.760
So you want to?

20:02.760 --> 20:04.640
Well, we already used like file being

20:04.640 --> 20:08.600
to replace it for the logging part of the cluster.

20:08.600 --> 20:10.440
And then we see that this is just

20:10.440 --> 20:12.880
one of the ways to do it.

20:12.880 --> 20:14.760
Yeah, in this case, it's just another way.

20:14.760 --> 20:20.120
But the useful thing is if you have the open telemetry SDK,

20:20.120 --> 20:24.600
it will automatically add then the trace ID to it.

20:24.600 --> 20:26.520
And then you can correlate your signals.

20:34.160 --> 20:35.120
Sorry.

20:35.120 --> 20:38.720
So I'm super newbie to this.

20:38.720 --> 20:44.280
So I fail to understand how the open telemetry is

20:44.280 --> 20:47.320
trying to replace, for example, the log

20:47.320 --> 20:50.920
parsers like the telegraph, for example,

20:50.920 --> 20:53.560
which is able to generate promethyose metrics

20:53.560 --> 20:55.560
by log scraping.

20:55.560 --> 20:59.880
Also how Zipkin, which is the tracing thing,

20:59.880 --> 21:03.280
fits in the metric collection of all this picture.

21:03.280 --> 21:06.800
So I'm not trying to understand how you couple together

21:06.800 --> 21:12.520
all these sources and how open telemetry either replaces

21:12.520 --> 21:16.200
or either makes it easier to use all these technologies

21:16.200 --> 21:16.840
together.

21:16.840 --> 21:17.340
Thank you.

21:21.560 --> 21:23.120
Yeah, so maybe on this slide, you

21:23.120 --> 21:29.080
see that the third part is using the Zipkin and promethyose.

21:29.080 --> 21:34.240
And the collector can receive data in Zipkin format.

21:34.240 --> 21:36.680
It can scrape promethyose metrics,

21:36.680 --> 21:42.400
then transform this data into OTLT or Zipkin as well,

21:42.400 --> 21:45.560
and then send it to the other collector.

21:45.560 --> 21:47.720
So the collector essentially can receive data

21:47.720 --> 21:49.800
in multiple formats, transform them

21:49.800 --> 21:53.560
to the format of your choice, and then use that format

21:53.560 --> 21:54.640
to send it to other systems.

22:06.000 --> 22:08.600
Hello, and thanks for the talk.

22:08.600 --> 22:13.640
I'm just wondering what's your strategy of filtering health

22:13.640 --> 22:15.520
check requests, for example?

22:15.520 --> 22:20.400
Or the life probes requests that you get on the pod?

22:20.400 --> 22:23.640
Health checks like to avoid generating traces

22:23.640 --> 22:24.680
for health checks?

22:24.680 --> 22:25.520
Sorry?

22:25.520 --> 22:29.040
To avoid generating traces for health check endpoints?

22:29.040 --> 22:31.120
Yeah.

22:31.120 --> 22:34.000
That's a very good question.

22:34.000 --> 22:41.200
So you could maybe configure the collector to drop the data.

22:41.200 --> 22:43.200
But I think the best way would be

22:43.200 --> 22:46.840
to tell the instrumentation to keep

22:46.840 --> 22:49.040
instrumenting those endpoints.

22:49.040 --> 22:51.960
To be honest, I'm not sure if this is implemented

22:51.960 --> 22:54.200
in OTLT agents.

22:54.200 --> 22:57.600
But I saw a lot of discussions around this problem.

22:57.600 --> 22:59.400
So probably there will be some solution.

23:05.280 --> 23:09.880
We have time for one last question, if there is any.

23:09.880 --> 23:10.400
No?

23:10.400 --> 23:10.880
OK.

23:10.880 --> 23:12.160
Oh, no.

23:12.160 --> 23:13.320
Then thanks a lot.

23:13.320 --> 23:42.320
And I'll see you next time.
