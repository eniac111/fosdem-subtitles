WEBVTT

00:00.000 --> 00:14.080
I'm Marco Makkala. I've been working on E-NODB code for 20 years almost and today I will

00:14.080 --> 00:20.960
talk about one of my pet heads in E-NODB, this change buffer, which I long time suspected

00:20.960 --> 00:26.540
that it's causing bugs but I couldn't prove all of them. So I took a car analogies because

00:26.540 --> 00:33.040
some software people like car analogies are unsafe at any speed. It's from the 1960s.

00:33.040 --> 00:42.080
I'm a bicycle person myself. So what was the change buffer good for? It was something developed

00:42.080 --> 00:48.460
in the times of the spinning raster, hard disks. The idea was that when you are doing

00:48.460 --> 00:54.600
sequential I-O, like page reads or page writes, sequentially then the read-write head will

00:54.600 --> 01:02.880
move less on the hard disk. If you are doing random CX it could take a long time to position

01:02.880 --> 01:10.080
the head to the correct track and then wait for the sector to come under the track when

01:10.080 --> 01:17.280
it's rotating. So the idea of the change buffer was that instead of reading something

01:17.280 --> 01:22.160
from a page and then applying a change to that page, you would write a buffer change

01:22.160 --> 01:30.440
to somewhere else. So if a B3 secondary in a sleeve page is not in the memory, in that

01:30.440 --> 01:36.840
case we could, instead of reading the page to perform an insert, originally it was only

01:36.840 --> 01:42.920
insert buffering, we would write that insert operation into a separate insert buffer tree

01:42.920 --> 01:49.040
and then later when some other operation needs to read the page it would merge the changes

01:49.040 --> 01:54.960
in that buffer to the page. And these structures are persistent, so even the insert buffering

01:54.960 --> 02:00.600
could happen years ago and then at some point years later somebody wants to access that

02:00.600 --> 02:10.100
page and then you get the trouble. This was extended in MySQL 5.5 to cover delete operations

02:10.100 --> 02:16.600
and purge operations. Deleting in InnoDB only marks the record for deletion, same for update

02:16.600 --> 02:23.680
of a key in a secondary index, it will do delete marking and insert. So the purge is

02:23.680 --> 02:28.440
what is actually removing the record. Those operations could be buffered but not rollback

02:28.440 --> 02:36.400
of an insert, that was never buffered. And this leads to lots of problems like the change

02:36.400 --> 02:42.840
buffer is located in the InnoDB system tablespace and up to this time there is no mechanism

02:42.840 --> 02:47.840
to shrink the system tablespace. If you at some point use the change buffer a lot, the

02:47.840 --> 02:52.720
system tablespace will grow by some hundreds of gigabytes, there is no way to reclaim that

02:52.720 --> 03:01.320
space. In MariaDB we are working on something to help with that but it's not done yet. And

03:01.320 --> 03:07.560
then this obvious right amplification, if you are doing an insert, that's rather fine.

03:07.560 --> 03:13.680
Instead of doing just one insert, you are doing two inserts, you are doubling the write,

03:13.680 --> 03:19.520
plus you have to write some metadata, some index information so that the contents of

03:19.520 --> 03:23.960
the page can be interpreted correctly because the change buffer doesn't have access to the

03:23.960 --> 03:31.400
data dictionary. But for delete or delete marking, if you apply the change directly

03:31.400 --> 03:35.600
to the page, you would write one byte or a couple of bytes, now you have to copy the

03:35.600 --> 03:40.080
entire record which you are going to delete or delete mark to the change buffer and the

03:40.080 --> 03:46.200
metadata and then at some point it will be merged. And then there is some overhead, even

03:46.200 --> 03:51.280
if you are disabling the change buffer you still have some overhead, you have to maintain

03:51.280 --> 03:57.240
some metadata saying how full your pages are. If somebody is going to enable the change

03:57.240 --> 04:02.360
buffering or insert buffering later, this data has to be accurate otherwise you would

04:02.360 --> 04:07.400
get a page overflow. The insert buffering must know that the page will not get too full

04:07.400 --> 04:14.600
when you are buffering the insert and merging later. And then we got lots of nice corruptions

04:14.600 --> 04:19.640
where the secondary index gets out of sync with the primary key index. And these are

04:19.640 --> 04:25.520
very hard to reproduce. So why is it hard to reproduce? Well, the first part is the

04:25.520 --> 04:33.880
same as on the previous slide. It is exactly this that you cannot easily control when the

04:33.880 --> 04:40.520
change buffer merge happens. It's like the Spanish Inquisition in the month is Python

04:40.520 --> 04:49.520
Sketch. Nobody expects a change buffer merge. And to reproduce something, either as a user

04:49.520 --> 04:55.040
you are unlucky and as a tester you are lucky if you can reproduce this and you need lots

04:55.040 --> 05:01.120
of luck to get that because especially this purging of the history which is deleting records

05:01.120 --> 05:08.200
from the index, it can be blocked by reviews. If you have long-running transactions which

05:08.200 --> 05:13.840
are holding a review open, that will prevent purge from running. And then at some point

05:13.840 --> 05:17.920
that review will be closed and purge can start running. And then there is also this buffer

05:17.920 --> 05:23.520
pool. If a page is locked by something, it can't be written out and it can be evicted

05:23.520 --> 05:28.540
from the buffer pool. So the change buffer can't be used. And we have a debug setting

05:28.540 --> 05:33.760
that forces that, okay, user is asking for operation that could use the change buffer

05:33.760 --> 05:37.800
and we see the page is in the buffer pool. We are going to the evil and we evict the

05:37.800 --> 05:43.440
page. But we cannot do that because somebody could be holding a latch on that page or the

05:43.440 --> 05:47.880
current thread is holding a latch and the page was modified. And we cannot wait for

05:47.880 --> 05:55.840
page writes to happen because this latch is blocking the page write. So this is really

05:55.840 --> 06:03.040
difficult to test. And there was a recent fix to some hangs which were introduced in

06:03.040 --> 06:10.400
MySQL 5.7. We have that fix in the release that is coming up out next week. That one

06:10.400 --> 06:19.600
will make it even more tricky, this debug option. So in order for this to be effective, they

06:19.600 --> 06:25.720
have to do some smart tricks like abandon some tables for a while and let them cool

06:25.720 --> 06:30.520
down, use some other tables meanwhile and then come back.

06:30.520 --> 06:40.520
Well, we got some nice magic tools as well. We have this random query generator. It's

06:40.520 --> 06:48.560
also used at MySQL. And a grammar simplifier. We could start with the huge grammar of all

06:48.560 --> 06:55.360
of the SQL covering all the features and let it run. If the crash was frequent enough,

06:55.360 --> 07:02.760
then we could use this grammar simplifier. But in this case, this is very hard to reproduce

07:02.760 --> 07:07.600
back. We cannot use the simplifier. We cannot get any simpler grammar. We just have to run

07:07.600 --> 07:16.560
it all and hope for the best. But then we got this debugger, rr, record and replay.

07:16.560 --> 07:24.880
That one is really a huge productivity boost. We started using it maybe two or three years

07:24.880 --> 07:32.840
ago. So when you are able to reproduce a problem while running it under rr, what you would

07:32.840 --> 07:42.320
do is that you will save a trace, a deterministic trace of an execution that is interleaving

07:42.320 --> 07:50.320
processes or threads that are being monitored by it. It saves the system calls and the results

07:50.320 --> 07:56.720
and so on. And these threads can be debugged as many times as you want. You just need the

07:56.720 --> 08:02.440
same binaries, same libraries and compatible processor. Then you can run it. And you can

08:02.440 --> 08:08.320
set break points. You can set data watch points. And you can execute in forward and backward

08:08.320 --> 08:14.760
direction. You can see what happened before the bad thing was observed. And this can also

08:14.760 --> 08:23.640
be used for optimized code. You are debugging an optimized executable, then the debugger

08:23.640 --> 08:28.280
complains that some variable has been optimized out. Well, then you can just single step some

08:28.280 --> 08:34.520
instructions and get it from the registers because you can go backwards in time.

08:34.520 --> 08:41.200
So now I'm coming to describe one bug that we found last year. And actually there was

08:41.200 --> 08:47.960
a support customer last week who hit this bug or a consequence of this bug. So we had

08:47.960 --> 08:55.120
a bug that was doing this change buffer merge. It would hang because the change buffer got

08:55.120 --> 09:00.480
corrupted and we were testing some fixes in a branch for that. And then we got this assertion

09:00.480 --> 09:06.920
failure. This assertion failure essentially means that when it tried to insert a record

09:06.920 --> 09:13.760
that was insert buffered, it ran out of space in the page. And what was the reason? Well,

09:13.760 --> 09:21.000
there were some extra records in the page. And it turned out that, well, this is partly

09:21.000 --> 09:28.920
by design. Heik Kitori, the creator of InnoDB, he was a friend of lazy deletion or lazy operations.

09:28.920 --> 09:33.880
So drop index wouldn't clear anything from the change buffer. It would leave the garbage

09:33.880 --> 09:39.280
behind. And later on, if the same page is allocated for something else, then we would

09:39.280 --> 09:47.000
pay the price and free the space from the change buffer, delete the records. And in

09:47.000 --> 09:55.120
MySQL 5.7, there was a new feature, bulk insert creation or building indexes faster.

09:55.120 --> 10:02.280
And that codebase didn't do this adjustment correctly. It only cleared some bit, but it

10:02.280 --> 10:08.360
didn't remove the records. And there was a mandatory Oracle security thing I took several

10:08.360 --> 10:13.080
years ago before switching to MariaDB. It said something like, complexity is the friend

10:13.080 --> 10:20.160
of security bugs. I found it somehow fitting here. So the immediate root cause of this

10:20.160 --> 10:27.960
failure was that this new code cleared a bit that says that there are buffer changes for

10:27.960 --> 10:33.920
this page. So when somebody is going to use that page, he will see that, okay, there's

10:33.920 --> 10:39.200
nothing to do. I don't have to care about the change buffer. And then later on, something

10:39.200 --> 10:45.640
adds records to the page. And then these old records from the change buffer will come to

10:45.640 --> 10:51.960
the page as part of a merge. And how can we prove this using this RR tool? By the way,

10:51.960 --> 10:57.040
you can download the slides from the first in page. And you can also download an attachment

10:57.040 --> 11:04.160
that has a script replay recording of the RR session. So I'm only showing some high

11:04.160 --> 11:09.440
level view here, but you can download a debugger session that shows the exact commands and

11:09.440 --> 11:16.160
the output, which I'm going to present in the next slides. So the short version, how

11:16.160 --> 11:24.400
we can prove these claims in the debugger, we let it continue from the start to the crash

11:24.400 --> 11:30.360
or the assertion failure. Then we set the break point on a function that was the last

11:30.360 --> 11:35.800
one to access the change buffer bitmap bits. And from that function, we get the address

11:35.800 --> 11:42.440
of the bitmap bits for this page. And we can set the data watch point on that. And I found

11:42.440 --> 11:47.640
this hardware watch points are very powerful tool. It's really much easier for some things

11:47.640 --> 11:54.080
when you don't have an idea which code is going to modify or read something. And then

11:54.080 --> 11:58.720
based on this watch point, we get some call stacks where this change buffer bits were

11:58.720 --> 12:04.040
last changed. And then we set the break points on functions that insert records into the

12:04.040 --> 12:07.720
change buffer and delete records from there. And then we observe that, okay, there was

12:07.720 --> 12:14.440
nothing to delete records from the, for this page and basically proving this claim. So

12:14.440 --> 12:22.000
we are printing the index ID and index name to get some more detail to this proof.

12:22.000 --> 12:31.480
Oh, sorry. Okay, so we were unable to reproduce this with a small grammar. We just took something

12:31.480 --> 12:41.360
and we got lucky and got the trace and debugged it. A possible consequences of this bug are

12:41.360 --> 12:46.680
the wrong results. And that's of course, very difficult to prove. We don't have any testing

12:46.680 --> 12:53.400
tools to prove that really, or not many tools, or you could get the crash on change buffer

12:53.400 --> 12:58.320
merge. Like here we got, and that change buffer merge could happen anytime, even if you are

12:58.320 --> 13:03.080
running check table or check if your table is okay, then before my skull, my, my, maybe

13:03.080 --> 13:10.400
10.6, your server would crash because of this change buffer corruption. So in our case,

13:10.400 --> 13:15.080
it's what was a page overflow when applying an insert and change buffer doesn't allow

13:15.080 --> 13:21.680
any pages splitting. It must fit in the page. In the support case I mentioned one week ago,

13:21.680 --> 13:27.280
the case was that the page split failed. It ran out of space. You are taking one page,

13:27.280 --> 13:32.040
you are trying to copy part of the records to a new page and it ran out of space. How

13:32.040 --> 13:40.480
can that be? It turned out that the page content records for some other index, which apparently

13:40.480 --> 13:49.640
had been dropped earlier and that index apparently had not null columns. So the length of a variable

13:49.640 --> 13:57.160
length field was interpreted, was stored there for that index where this correct index would

13:57.160 --> 14:03.760
have the null bitmap. And then we would read the length of the record from a previous byte

14:03.760 --> 14:08.880
and that's how we would get this too long records being copied. Oh, five minutes left.

14:08.880 --> 14:17.360
I have to hurry up. So this, the parking, how it goes in detail, we continue to the

14:17.360 --> 14:23.680
end of the execution from the start, which, and then we reverse continue to go back from

14:23.680 --> 14:29.720
the abort signal. Then we set the temporary break point to this bitmap page access. Then

14:29.720 --> 14:38.840
we get, get to that break point and we get the, in a register we happen to have the byte

14:38.840 --> 14:44.840
address of the bitmap byte, which we are interested in. And then we reverse continue the, to the

14:44.840 --> 14:52.840
changes of that bit byte. So the last occurrence of that was for an insert that was buffered

14:52.840 --> 15:00.200
after the add index. And we continue from that. We see that this, the previous occurrence

15:00.200 --> 15:06.760
is the add index that is clearing the flag. And from that we can get the page number,

15:06.760 --> 15:13.440
which is affected and we can get the index ID and index name and the SQL statement, which

15:13.440 --> 15:21.920
is alter table. And then we set some more break points on this insert buffer delete

15:21.920 --> 15:26.480
and insert operations, set the condition that we want it only for this page. And then we

15:26.480 --> 15:32.720
reverse continue, we get the insert that was buffered before this add index. Apparently

15:32.720 --> 15:38.960
there was a drop index in between, but I didn't add statements to get a break point there

15:38.960 --> 15:47.120
this time. So the index name is different after the add index and index ID is different.

15:47.120 --> 15:52.320
And there was no call to the change buffer deletion. When we continue from this point

15:52.320 --> 15:58.800
to the end of the execution, we just reach the assertion failure again without any change

15:58.800 --> 16:08.760
buffer record deletion in between. So I'm quoting this finished ski jumper, who apparently

16:08.760 --> 16:16.880
was confusing to French phrases. He was wishing him a good trip when he is starting to do

16:16.880 --> 16:23.560
the ski jumping. And I'm wishing good trip for anybody who is using the change buffer.

16:23.560 --> 16:28.640
So, and the deja vu, yes, we have seen this shutdown hang actually earlier. There was

16:28.640 --> 16:37.160
a 10.1, MariaDB 10.1 support customer case. They got this hang and we had to do something

16:37.160 --> 16:46.560
to fix that. But in MariaDB 10.5, we made an other change, hopefully to reduce the chances

16:46.560 --> 16:55.920
of getting like random change buffer merge bugs because basically after this change buffer

16:55.920 --> 17:01.680
merge only happens when SQL statement needs that change buffer merge to happen. No background

17:01.680 --> 17:07.560
operation. So we had to adjust that previous fix for the 10.5 code base, but that was not

17:07.560 --> 17:15.360
adjusted correctly. And we were not able to reproduce this corruption or this hang earlier.

17:15.360 --> 17:26.680
So only quite lately we were able to reproduce it and then we were able to debug it properly.

17:26.680 --> 17:32.680
There are some other corruption caused by the change buffer. And one thing I want to

17:32.680 --> 17:40.640
notice that in MariaDB 10.6 recently there was a fix that we should not crash on any

17:40.640 --> 17:45.240
page corruption. If there are any cases where we are still crashing, I would be interested

17:45.240 --> 17:52.120
in details. And this includes a check table when there is a crash, when there is a failure

17:52.120 --> 17:57.360
during change buffer merge, it will not cause a crash. There was a mystery bug filed like

17:57.360 --> 18:06.080
12 years ago, MySQL bug. The customer got a crash during change buffer merge because

18:06.080 --> 18:13.360
the page got empty as a result of applying a purge operation. I can think of several

18:13.360 --> 18:19.200
bugs that have been fixed in MariaDB that could be the explanation. The last one, this

18:19.200 --> 18:27.280
one from the previous example, that cannot apply because that only was introduced in

18:27.280 --> 18:39.640
MySQL 5.7 which they didn't use. And of this list, the 30422, it's a clone of MySQL fix

18:39.640 --> 18:47.880
which is applicable to MariaDB 10.3 and 10.4. Others I don't think have been fixed in MySQL

18:47.880 --> 18:55.440
yet. So this teaches us that it really pays off to analyze any obscure failure you get

18:55.440 --> 19:03.680
from running with RR because there are games in there. And I think that assertions are

19:03.680 --> 19:08.280
like lottery tickets. If you don't write assertions in your code, then you can't win

19:08.280 --> 19:15.600
these kind of bug findings. And if you sometimes you can lose, you can write a bogus assertion,

19:15.600 --> 19:19.720
okay, you make mistake, you correct it and improve the assertion and then hopefully you

19:19.720 --> 19:29.640
will get something better later. Yeah, we have some mitigation for this in MariaDB.

19:29.640 --> 19:41.080
We don't access the data file when executing drop table. So in that case, we are avoiding

19:41.080 --> 19:47.840
maybe more crashes on drop table. And there was a bug in Unity with slow shutdown that

19:47.840 --> 19:53.840
the change buffer merge wouldn't check for log file overflow. So if the user got impatient

19:53.840 --> 19:59.520
and killed the server because it's taken too long time, then they could end up with unrecoverable

19:59.520 --> 20:07.240
database. And some more mitigation that we did, we disabled this change buffer by default,

20:07.240 --> 20:12.800
we deprecated the parameter and we removed the change buffer in the 11.0 release. The

20:12.800 --> 20:20.240
upgrade code for handling it, it was tested and I hope that if there is some corruption

20:20.240 --> 20:26.400
notice during the upgrade, it should still be possible to go back to the earlier version

20:26.400 --> 20:38.200
and then do something to correct. Yes, if there are any records in the change buffer,

20:38.200 --> 20:44.320
we ignore, we don't trust these bitmap bits. We go through the change buffer records and

20:44.320 --> 20:54.200
if there are any, we will apply them. Yeah, so that was basically what I wanted to say.

20:54.200 --> 21:03.560
And maybe this last slide, it's a good thing to have a nice layer design. If you optimize

21:03.560 --> 21:09.040
things by breaking this layer boundaries, then you're asking for trouble. That's basically

21:09.040 --> 21:18.280
what we can learn from this. Question. You said that you fixed a few things in MariaDB

21:18.280 --> 21:26.920
and they're not yet fixed in upstream. Are there bugs open upstream for fixing these

21:26.920 --> 21:34.720
things? I haven't filed any. I lost my skull bug account when I resigned Oracle. Okay,

21:34.720 --> 21:42.040
well, I'll velocity that with you so we can get this fixed in upstream file. Yeah, you

21:42.040 --> 21:49.040
are welcome to file bugs and maybe they will be fixed. Especially if it's a crashing bug.

21:49.040 --> 21:55.520
Yeah, but you can't repeat them so you have a hard time proving that. Well, there are

21:55.520 --> 22:02.640
tools obviously now to do that which weren't obvious before. I'm very persistent. Like

22:02.640 --> 22:07.240
once we know it exists in MariaDB and it has been fixed, somebody that is persistent enough

22:07.240 --> 22:13.240
should be able to. Yeah, but Oracle is not allowed to look at Oracle. Yes, I know. So

22:13.240 --> 22:19.240
how can they know how we can do it? I am so I can open the bug and I can't. You can't

22:19.240 --> 22:28.240
copy the code because then they're not allowed to see it. I'll find a bug report. Yes. How

22:28.240 --> 22:35.800
bad is the RR over 10? It is very bad. I mean, it's running, if you have multiple threats

22:35.800 --> 22:40.880
or processes, it's running them in a single on a single CPU core at the time. So that's

22:40.880 --> 22:46.840
why we are running hundreds of servers in parallel on a single server for several hours

22:46.840 --> 22:54.720
to get these traces. For normal debugging, maybe twice as slow as that. Actually also

22:54.720 --> 22:59.600
for normal debugging, there have been cases like if you have lots of conditional branches

22:59.600 --> 23:07.560
in your code, like this debug library or performance schema, that's causing those branches are

23:07.560 --> 23:12.480
never taken, but because RR is interested in conditional branches, I have seen a case

23:12.480 --> 23:21.080
where if I compile without these things, I get a crash or problem in, let's say like

23:21.080 --> 23:25.680
three seconds. And then I was curious, how long does it take if I use this stupid compilation

23:25.680 --> 23:32.080
options with this extra conditions for that particular thing, I interrupted it after two

23:32.080 --> 23:39.800
hours. So it was 7,000 seconds versus three seconds. So don't use conditional branches

23:39.800 --> 23:46.160
or unnecessary like debugging. Turn off all the code that you don't need. The conditional

23:46.160 --> 23:53.080
branches are evil for RR. But I have only four ways to debug code. There are no problems.

23:53.080 --> 24:01.920
But maybe you are not using it on like multi-threaded with context, switches and so on. Yeah, for

24:01.920 --> 24:24.840
single thread, there is basically no overhead.
