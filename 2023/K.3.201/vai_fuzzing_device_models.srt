1
0:00:00.000 --> 0:00:02.000
Hello everyone, my name is Andrea and today I'm going to tell you about the

2
0:00:02.000 --> 0:00:04.000
what we need to do to pass in the digital resume map.

3
0:00:04.000 --> 0:00:08.000
This presentation is not about passing the detail, but rather how we failed at it.

4
0:00:08.000 --> 0:00:16.000
So before I start, I need the details of passing, I will continue to teach about passing the detail.

5
0:00:16.000 --> 0:00:20.000
I hope some of you already know about it, I don't have a lot of time.

6
0:00:20.000 --> 0:00:24.000
So I'm going to go ahead and talk about the

7
0:00:24.000 --> 0:00:32.000
how to pass in the details.

8
0:00:32.000 --> 0:00:34.000
So passing is basically an automated testing technique.

9
0:00:34.000 --> 0:00:44.000
The idea is to just send random inputs to a program to see how it behaves in that case.

10
0:00:44.000 --> 0:00:50.000
And how it works is that you use typically a tool like a buzzer

11
0:00:50.000 --> 0:00:58.000
that is going to generate random input for you, and then you're going to call some functions with that random input.

12
0:00:58.000 --> 0:01:10.000
And the buzzer is going to record some findings, and if it finds any interesting input files, it's going to write them to where it works.

13
0:01:10.000 --> 0:01:16.000
Findings in this case can have crashes, can be hands, but can also be timeouts.

14
0:01:16.000 --> 0:01:20.000
So for fuzzing, when you first do it, you typically start from an empty corpus,

15
0:01:20.000 --> 0:01:24.000
but as you run fuzzing, you're going to generate some interesting input,

16
0:01:24.000 --> 0:01:30.000
which is helpful because in the int and int ones, you can just reuse those inputs and start from scratch.

17
0:01:30.000 --> 0:01:34.000
This helps with finding interesting things faster.

18
0:01:34.000 --> 0:01:40.000
So in RoseVMEM, we implemented fuzzing for VM-Bert.io.

19
0:01:40.000 --> 0:01:44.000
We have three fuzz targets, one for the BERT.io queue,

20
0:01:44.000 --> 0:01:50.000
one for the serialization of the BERT.io queue, and one for the BERT.io ISOG.

21
0:01:50.000 --> 0:01:56.000
In the RoseVMEM project, we all have implementation for the packet, so that's what we fuzzed.

22
0:01:56.000 --> 0:02:05.000
During fuzzing, we discovered three crashes, and only one of them is triggerable by a partition malicious driver.

23
0:02:05.000 --> 0:02:11.000
And what we have right now is that we are able to un-fuzz in for a very rest-heter-soment into the rescue method.

24
0:02:11.000 --> 0:02:18.000
To the name BERT.io repository, the fuzzing is implemented using libfuzzer.

25
0:02:18.000 --> 0:02:24.000
And besides the fuzzing that is happening in RoseVMEM itself,

26
0:02:24.000 --> 0:02:19.160
the folks from the hypervisor are also running fuzzing, and they also discover a timeout in the

27
0:02:29.000 --> 0:02:32.000
server.

28
0:02:32.000 --> 0:02:36.000
So this actually brings me to our first intro.

29
0:02:36.000 --> 0:02:42.000
So, what is it we want? It should be the output, so it's the entry.

30
0:02:42.000 --> 0:02:45.000
Afterwards.

31
0:02:45.000 --> 0:02:52.000
It's a people, and that is me.

32
0:02:52.000 --> 0:02:58.000
The first people is that you actually have to run the timeout

33
0:02:58.000 --> 0:03:02.000
that is appropriate for what you're doing fuzzing for.

34
0:03:02.000 --> 0:03:07.000
Because the people, for example, for the fuzzing that we are using is actually 20 minutes,

35
0:03:07.000 --> 0:03:11.000
and since we are just working with BERT.io, we have to choose,

36
0:03:11.000 --> 0:03:16.000
and there's nothing that can possibly take 20 minutes to process,

37
0:03:16.000 --> 0:03:21.000
so we have to adjust the timeout to 60 seconds in our case,

38
0:03:21.000 --> 0:03:27.000
and this is something that was written in by the folks from the hypervisor.

39
0:03:27.000 --> 0:03:32.000
Now, how we run fuzzing in RoseVMEM is at the library level.

40
0:03:32.000 --> 0:03:37.000
The advantages of this is that it's easy to set up.

41
0:03:37.000 --> 0:03:40.000
So, it's really important that it's easy to set up.

42
0:03:40.000 --> 0:03:42.000
It is a good thing. People are like,

43
0:03:42.000 --> 0:03:48.000
oh, but you're running fuzzing at the library level, so you don't have the kernel that's so easy,

44
0:03:48.000 --> 0:03:51.000
so simple, so they're like, yeah, it's great, right?

45
0:03:51.000 --> 0:03:54.000
And easy is a good thing.

46
0:03:54.000 --> 0:03:57.000
Yeah, it's a good thing because you can also run almost any host.

47
0:03:57.000 --> 0:04:02.000
You just have to have a fuzzer installed, and the repository,

48
0:04:02.000 --> 0:04:04.000
and then you just run fuzzer.

49
0:04:04.000 --> 0:04:07.000
And it also runs in a user space.

50
0:04:07.000 --> 0:04:10.000
There's also the disadvantages, of course, the first one being that

51
0:04:10.000 --> 0:04:14.000
you cannot cover the whole of what they have set up,

52
0:04:14.000 --> 0:04:19.000
so that means that you're going to have some things that are great to replace.

53
0:04:19.000 --> 0:04:25.000
And then, because you are fuzzing in user space, we need to do some more things for the driver.

54
0:04:25.000 --> 0:04:30.000
And this is, this is basically a bit complicated.

55
0:04:30.000 --> 0:04:34.000
And also, you can find false positives.

56
0:04:34.000 --> 0:04:37.000
With the false positives, the idea is that you will find

57
0:04:37.000 --> 0:04:40.000
crashes that otherwise would not be triggered by a driver,

58
0:04:40.000 --> 0:04:43.000
because maybe you have some other JSON trace.

59
0:04:43.000 --> 0:04:46.000
I don't think that it's really important to fix these ones as well,

60
0:04:46.000 --> 0:04:49.000
because you never know how you're going to change your code,

61
0:04:49.000 --> 0:04:56.000
and how it might end up actually triggering those findings in the future.

62
0:04:56.000 --> 0:04:59.000
And for the mocking of the driver, how it works,

63
0:04:59.000 --> 0:05:06.000
we already simplified here, but the idea is that the driver is writing something in memory,

64
0:05:06.000 --> 0:05:09.000
and then the device reads what the driver wrote in memory,

65
0:05:09.000 --> 0:05:13.000
and thus stops the data.

66
0:05:13.000 --> 0:05:16.000
The part that we want to fuzz in the machine,

67
0:05:16.000 --> 0:05:21.000
and the part that we want to fuzz in the machine is this side of the device,

68
0:05:21.000 --> 0:05:25.000
and then what we need to mock is actually the driver side of the application.

69
0:05:25.000 --> 0:05:30.000
And in the machine, what we did is that we started this mocking of the driver from the beginning,

70
0:05:30.000 --> 0:05:34.000
so we needed it anyway to run some unit tests,

71
0:05:34.000 --> 0:05:37.000
we needed for other tests as well.

72
0:05:37.000 --> 0:05:41.000
So we had an initial mock interface from the beginning,

73
0:05:41.000 --> 0:05:50.000
and when we wanted to fuzz, we just evolved a mock driver in order to support that as well.

74
0:05:50.000 --> 0:05:56.000
Okay, so at the high level, how it happens right now in Rasfira is that we parse the random bytes,

75
0:05:56.000 --> 0:06:01.000
we initialize the mock driver with the data that was parsed by fuzzer,

76
0:06:01.000 --> 0:06:08.000
so high level it ends up with some descriptors and some functions that have some random input

77
0:06:08.000 --> 0:06:19.000
that we need to process, and then we create a QM equal these random functions with random input.

78
0:06:19.000 --> 0:06:26.000
And yeah, the second big point is that if you are trying to do fuzzing

79
0:06:26.000 --> 0:06:30.000
and you just start when the project is already mature,

80
0:06:30.000 --> 0:06:34.000
what is going to happen is that's going to be a bit difficult,

81
0:06:34.000 --> 0:06:38.000
you might find it very complicated to retrofit it,

82
0:06:38.000 --> 0:06:44.000
so instead, I know that it's not necessarily viable to start fuzzing when you start a project,

83
0:06:44.000 --> 0:06:49.000
but what you can do instead is that you can keep fuzzing in the back of your head,

84
0:06:49.000 --> 0:06:55.000
and then when you create some mock objects or some unit tests,

85
0:06:55.000 --> 0:07:01.000
you can think about how you can actually reuse them in fuzzing as well.

86
0:07:01.000 --> 0:07:07.000
Which is what we did, but not very well.

87
0:07:07.000 --> 0:07:14.000
So one of the crashes that we actually found was that the mock driver was crashing on invalid input,

88
0:07:14.000 --> 0:07:19.000
so we had to adapt these actually to return errors,

89
0:07:19.000 --> 0:07:23.000
even though it was just one test, we couldn't just crash on invalid input anymore,

90
0:07:23.000 --> 0:07:28.000
so the idea is to return errors at the level where you want to be fuzzing,

91
0:07:28.000 --> 0:07:36.000
that can be processed at higher levels, and so the fuzzing can crash.

92
0:07:38.000 --> 0:07:42.000
And now for structural fuzzing.

93
0:07:42.000 --> 0:07:48.000
So without structural fuzzing, how it works is that the fuzzer is going to generate some random bytes,

94
0:07:48.000 --> 0:07:55.000
and then you have to interpret this as the bytes that you have to do for your library.

95
0:07:55.000 --> 0:08:02.000
With structural fuzzing it's really nice because there are some tools that are just going to basically

96
0:08:02.000 --> 0:08:05.000
interpret the random bytes as a structure that you actually need.

97
0:08:05.000 --> 0:08:07.000
So it's super nice.

98
0:08:07.000 --> 0:08:12.000
What it does is that it significantly reduces the code that you need to write,

99
0:08:12.000 --> 0:08:17.000
and even in Resfier and Risme, it's efficiently arbitrary.

100
0:08:17.000 --> 0:08:21.000
Now, we had to change it, unfortunately,

101
0:08:21.000 --> 0:08:25.000
but before we did that we had only 270 lines of code,

102
0:08:25.000 --> 0:08:30.000
and now we have around 740 lines of code for the fuzzer,

103
0:08:30.000 --> 0:08:38.000
and unfortunately it came with some problems, so that's why we had to actually fix it.

104
0:08:38.000 --> 0:08:42.000
The most important part is that it's not going to produce a fuzz,

105
0:08:42.000 --> 0:08:46.000
so you can't reuse the core fuzz that you had in previous runs,

106
0:08:46.000 --> 0:08:49.000
which was a big problem for us,

107
0:08:49.000 --> 0:08:58.000
because basically what happens is that arbitrary is introducing some randomness in the library,

108
0:08:58.000 --> 0:09:01.000
because it's writing the input,

109
0:09:01.000 --> 0:09:13.000
and that basically means that it cannot be used to purposeful for previous runs.

110
0:09:13.000 --> 0:09:20.000
The big point here is that we can rewrite the incremental improvements for the fuzzer,

111
0:09:20.000 --> 0:09:26.000
and we didn't check that what we want to implement can actually be integrated to the end.

112
0:09:26.000 --> 0:09:38.000
So instead, a better point would have been to make it if we can actually reuse the problems that we generated.

113
0:09:38.000 --> 0:09:43.000
Okay, and now about when fuzzing actually fails.

114
0:09:43.000 --> 0:09:47.000
So we had a PR, University of Man.

115
0:09:47.000 --> 0:09:50.000
At this point we were already running fuzzing for pull request,

116
0:09:50.000 --> 0:09:57.000
and there was a PR that was introducing actually an overflow.

117
0:09:57.000 --> 0:10:05.000
So here the overflow is that the packet header size addition to the packet length can actually overflow,

118
0:10:05.000 --> 0:10:09.000
because the packet length is set up by the driver.

119
0:10:09.000 --> 0:10:13.000
This bug, I actually found it during code review,

120
0:10:13.000 --> 0:10:20.000
so it was a bit unexpected because I was hoping that fuzzer is going to find it, which was not the case.

121
0:10:20.000 --> 0:10:28.000
So after some dive deep, I realized that writing fuzzer for just 15 minutes might not actually be enough,

122
0:10:28.000 --> 0:10:33.000
because the fuzzing, this bug was triggered twice in the government for 14 minutes instead.

123
0:10:33.000 --> 0:10:40.000
So how we fix that is that we had the fuzzing session that is optional and that runs for 24 hours.

124
0:10:40.000 --> 0:10:45.000
This one needs to be started manually by the University of Man maintainers,

125
0:10:45.000 --> 0:10:54.000
and should only be started when there are pull requests that actually impact the whole fuzzing situation.

126
0:10:54.000 --> 0:10:59.000
This is because we are also consuming a lot of resources.

127
0:10:59.000 --> 0:11:05.000
When doing fuzzing, you don't want to block all the pull requests for 24 hours.

128
0:11:05.000 --> 0:10:59.020
So typically the recipe on the site is based on the

129
0:11:06.020 --> 0:11:10.020
page that we use to execute.

130
0:11:10.020 --> 0:11:15.020
So blocking it for one day might not be reasonable for all the pull requests.

131
0:11:15.020 --> 0:11:20.020
So the people here were not planning fuzzing for long enough.

132
0:11:20.020 --> 0:11:27.020
And instead, we had to work our way to find a way to not block pull requests,

133
0:11:27.020 --> 0:11:32.020
but at the same time to provide for fuzzing.

134
0:11:32.020 --> 0:11:34.020
Put coverage for Rust.

135
0:11:34.020 --> 0:11:40.020
So in Rust, you can actually get coverage information by running a LLVM talk.

136
0:11:40.020 --> 0:11:44.020
In Rust, unfortunately, you only get live coverage.

137
0:11:44.020 --> 0:11:48.020
So basically, this was the starting point of the presentation.

138
0:11:48.020 --> 0:11:54.020
I was thinking I'm going to come here, and I'm going to show you how great it is to run fuzzing for 15 minutes,

139
0:11:54.020 --> 0:12:00.020
and then more minutes, and then the purpose, and all these really extravagant things.

140
0:12:00.020 --> 0:12:06.020
And so we ended up with fuzzing for 15 minutes, generating them for these regions,

141
0:12:06.020 --> 0:12:10.020
and the coverage of an early 2%.

142
0:12:10.020 --> 0:12:14.020
So I was like, well, that's okay. That's good.

143
0:12:14.020 --> 0:12:17.020
So then let's just run with some email purposes as well.

144
0:12:17.020 --> 0:12:20.020
So this is some purpose that we generated from unit tests.

145
0:12:20.020 --> 0:12:24.020
Let's just feed the fuzzer and see how this changed.

146
0:12:24.020 --> 0:12:27.020
There was no change, actually.

147
0:12:27.020 --> 0:12:30.020
So I was like, okay, it's not bad, not bad.

148
0:12:30.020 --> 0:12:32.020
Let's just run for two weeks.

149
0:12:32.020 --> 0:12:34.020
So what do you think is going to happen now?

150
0:12:34.020 --> 0:12:43.020
So actually, it's starting.

151
0:12:43.020 --> 0:12:45.020
It's starting, yeah.

152
0:12:45.020 --> 0:12:49.020
At this point, I was like, I have to change my presentation.

153
0:12:49.020 --> 0:12:51.020
It's not what I expected.

154
0:12:51.020 --> 0:12:53.020
But instead, I learned something, right?

155
0:12:53.020 --> 0:12:58.020
So you can't actually use coverage to decide when to stop fuzzing.

156
0:12:58.020 --> 0:13:02.020
So instead, what you can do is that you can use coverage information

157
0:13:02.020 --> 0:13:09.020
to see what parts of your code are not actually covered.

158
0:13:09.020 --> 0:13:13.020
And yeah, well, that's about it, actually.

159
0:13:13.020 --> 0:13:17.020
This is a summary of the people that we ran into,

160
0:13:17.020 --> 0:13:22.020
and I hope now we have a lot of questions.

161
0:13:22.020 --> 0:13:23.020
Yeah?

162
0:13:23.020 --> 0:13:30.020
Did you look at how the fuzzer works and then what areas were not covered

163
0:13:30.020 --> 0:13:33.020
and trying to figure out why it was the fuzzer areas?

164
0:13:33.020 --> 0:13:37.020
Yeah, so the question was if we looked at how the fuzzer works

165
0:13:37.020 --> 0:13:39.020
and what areas were not covered.

166
0:13:39.020 --> 0:13:41.020
Yes, we did, and I have a slide for that.

167
0:13:41.020 --> 0:13:44.020
Thanks for the question.

168
0:13:44.020 --> 0:13:48.020
Okay, so actually, I have two slides for that.

169
0:13:48.020 --> 0:13:53.020
There were some functions that we were not calling on purpose.

170
0:13:53.020 --> 0:13:57.020
So because on the Word.io queue, for example,

171
0:13:57.020 --> 0:14:01.020
we have some functions that are just iterating over the scriptor chains

172
0:14:01.020 --> 0:14:03.020
and then they're doing something with the data.

173
0:14:03.020 --> 0:14:07.020
And at the Word.io queue level, you can't do something with the data.

174
0:14:07.020 --> 0:14:10.020
So it's like, okay, this needs to be fuzzed at a higher level

175
0:14:10.020 --> 0:14:13.020
like at the device implementation level.

176
0:14:13.020 --> 0:14:16.020
So it's like, okay, we're not going to call these functions,

177
0:14:16.020 --> 0:14:18.020
which is a bit hilarious because that's where

178
0:14:18.020 --> 0:14:22.020
Trump hypervisor actually found the time-out problem,

179
0:14:22.020 --> 0:14:26.020
which we were not able to reproduce with Word.io queue, but still.

180
0:14:26.020 --> 0:14:32.020
And we actually did this one function that shouldn't be called during fuzzing.

181
0:14:32.020 --> 0:14:36.020
And then I reran the fuzzing, and, you know, it's a bit better,

182
0:14:36.020 --> 0:14:39.020
but it's still not great.

183
0:14:39.020 --> 0:14:46.020
And then I looked into what, well, actually, you can't see very well.

184
0:14:46.020 --> 0:14:47.020
That's unfortunate.

185
0:14:47.020 --> 0:14:51.020
Yeah, so I looked into what actually is not covered,

186
0:14:51.020 --> 0:14:56.020
and you're not seeing, so you have to trust me,

187
0:14:56.020 --> 0:15:04.020
that these are actually errors, so the printing of errors to files.

188
0:15:04.020 --> 0:15:08.020
So since in the fuzzer, we are not actually initializing

189
0:15:08.020 --> 0:15:12.020
a logger, these things cannot be triggered by files,

190
0:15:12.020 --> 0:15:19.020
so there's lots of this printing to a file that's kept really fuzzing.

191
0:15:19.020 --> 0:15:22.020
Yeah.

192
0:15:22.020 --> 0:15:23.020
Yeah?

193
0:15:23.020 --> 0:15:26.020
What's the truth taken to actually make sure the coverage

194
0:15:26.020 --> 0:15:28.020
goes everywhere, which needs to be covered,

195
0:15:28.020 --> 0:15:33.020
and so just covering sub-values, which clearly aren't good?

196
0:15:33.020 --> 0:15:35.020
I didn't understand the question.

197
0:15:35.020 --> 0:15:40.020
But what's the truth taken to make sure the errors that weren't covered

198
0:15:40.020 --> 0:15:44.020
are going to be covered in the future for me?

199
0:15:44.020 --> 0:15:51.020
Oh, okay, so the question was what measures are we taking

200
0:15:51.020 --> 0:15:55.020
in order to make sure that code that was covered

201
0:15:55.020 --> 0:15:58.020
before is going to still get covered in the next three issues?

202
0:15:58.020 --> 0:15:59.020
Yeah.

203
0:15:59.020 --> 0:16:01.020
None?

204
0:16:01.020 --> 0:16:06.020
So right now we're not doing anything, this whole coverage thing

205
0:16:06.020 --> 0:16:09.020
is just something that I need for the presentation,

206
0:16:09.020 --> 0:16:12.020
and it's not automatic in any way.

207
0:16:12.020 --> 0:16:16.020
This is actually a good point for future investment

208
0:16:16.020 --> 0:16:18.020
to make sure that we're still covering code,

209
0:16:18.020 --> 0:16:23.020
because what will help with as well is that we will make sure

210
0:16:23.020 --> 0:16:25.020
that new functions that we are adding to the code

211
0:16:25.020 --> 0:16:27.020
are also covered by the coverage.

212
0:16:27.020 --> 0:16:31.020
So it's a great point to make the way in your survival.

213
0:16:31.020 --> 0:16:32.020
Yeah?

214
0:16:32.020 --> 0:16:35.020
We're talking about the structure of our fuzzing,

215
0:16:35.020 --> 0:16:39.020
and you mentioned that you cannot use the code

216
0:16:39.020 --> 0:16:41.020
to expand a bit more, thank you.

217
0:16:41.020 --> 0:16:44.020
Yeah, okay, so the question was about structural well fuzzing

218
0:16:44.020 --> 0:16:47.020
and just that you cannot use them for this.

219
0:16:47.020 --> 0:16:51.020
Let me see if I actually have it over here.

220
0:16:51.020 --> 0:16:59.020
No, okay, so the idea is that what we were using,

221
0:16:59.020 --> 0:17:04.020
which is arbitrary, when it was taking the input from it,

222
0:17:04.020 --> 0:17:07.020
fuzzer was also adding some randomness to it.

223
0:17:07.020 --> 0:17:12.020
So because it was random, basically every time it was writing

224
0:17:12.020 --> 0:17:16.020
the purpose of the file, it was introducing some randomness to it,

225
0:17:16.020 --> 0:17:21.020
so when the same people would get the read again,

226
0:17:21.020 --> 0:17:24.020
it would not have been the same.

227
0:17:24.020 --> 0:17:26.020
Where did the randomness come from?

228
0:17:26.020 --> 0:17:28.020
Where did the randomness come from?

229
0:17:28.020 --> 0:17:31.020
This is just how arbitrary decided we implemented it.

230
0:17:31.020 --> 0:17:36.020
There is actually an issue in arbitrary that they are aware of the problem,

231
0:17:36.020 --> 0:17:38.020
but they are not actually...

232
0:17:38.020 --> 0:17:42.020
It doesn't seem like they are interested in fixing it for some reason.

233
0:17:42.020 --> 0:17:49.020
So what we ended up doing is that we ended up doing some custom serialization

234
0:17:49.020 --> 0:17:55.020
with input, which is also very well known for us to track each other.

235
0:17:55.020 --> 0:18:00.020
It's not much more into the latest part, and it doesn't produce.

236
0:18:03.020 --> 0:18:04.020
Yeah, okay.

237
0:18:04.020 --> 0:18:06.020
When you discovered what we did,

238
0:18:06.020 --> 0:18:11.020
does it transform into a unit test afterwards?

239
0:18:11.020 --> 0:18:15.020
The question is, when we discovered about the...

240
0:18:15.020 --> 0:18:19.020
So yeah, the way that we are fixing these kind of problems

241
0:18:19.020 --> 0:18:23.020
is that they are always adding a regression test for them,

242
0:18:23.020 --> 0:18:26.020
just to make sure that they don't do the information.

243
0:18:26.020 --> 0:18:28.020
And it was not a question.

244
0:18:28.020 --> 0:18:31.020
I was wondering about the computational requirements.

245
0:18:31.020 --> 0:18:33.020
So how many cores are you using?

246
0:18:33.020 --> 0:18:35.020
How many cores are you using?

247
0:18:35.020 --> 0:18:37.020
Are you using the exciting?

248
0:18:37.020 --> 0:18:44.020
So when we went for two weeks, we actually used 96 cores.

249
0:18:44.020 --> 0:18:49.020
In a unit test, when you are running on 20 cores,

250
0:18:49.020 --> 0:18:51.020
I don't know exactly how many.

251
0:18:51.020 --> 0:18:54.020
I think that's one? Maybe?

252
0:18:54.020 --> 0:18:58.020
I don't know, but I think we will be running on 96 cores as well.

253
0:18:58.020 --> 0:18:59.020
There was another one.

254
0:18:59.020 --> 0:19:01.020
Can I see that one?

255
0:19:01.020 --> 0:19:02.020
One minute.

256
0:19:02.020 --> 0:19:03.020
One minute.

257
0:19:03.020 --> 0:19:11.020
If you find a cover case, as I try to shrink the case into smaller cover case steps,

258
0:19:11.020 --> 0:19:13.020
it's making it a very long step.

259
0:19:13.020 --> 0:19:14.020
I'm sorry.

260
0:19:14.020 --> 0:19:15.020
All right.

261
0:19:15.020 --> 0:19:16.020
This is... I'm not going to...

262
0:19:16.020 --> 0:19:18.020
No, I need a little less chat afterwards.

263
0:19:18.020 --> 0:19:20.020
Yeah, I'll leave it there.

264
0:19:20.020 --> 0:19:39.020
Thanks.

