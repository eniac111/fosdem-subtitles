WEBVTT

00:00.000 --> 00:02.000
Hello everyone, my name is Andrea and today I'm going to tell you about the

00:02.000 --> 00:04.000
what we need to do to pass in the digital resume map.

00:04.000 --> 00:08.000
This presentation is not about passing the detail, but rather how we failed at it.

00:08.000 --> 00:16.000
So before I start, I need the details of passing, I will continue to teach about passing the detail.

00:16.000 --> 00:20.000
I hope some of you already know about it, I don't have a lot of time.

00:20.000 --> 00:24.000
So I'm going to go ahead and talk about the

00:24.000 --> 00:32.000
how to pass in the details.

00:32.000 --> 00:34.000
So passing is basically an automated testing technique.

00:34.000 --> 00:44.000
The idea is to just send random inputs to a program to see how it behaves in that case.

00:44.000 --> 00:50.000
And how it works is that you use typically a tool like a buzzer

00:50.000 --> 00:58.000
that is going to generate random input for you, and then you're going to call some functions with that random input.

00:58.000 --> 01:10.000
And the buzzer is going to record some findings, and if it finds any interesting input files, it's going to write them to where it works.

01:10.000 --> 01:16.000
Findings in this case can have crashes, can be hands, but can also be timeouts.

01:16.000 --> 01:20.000
So for fuzzing, when you first do it, you typically start from an empty corpus,

01:20.000 --> 01:24.000
but as you run fuzzing, you're going to generate some interesting input,

01:24.000 --> 01:30.000
which is helpful because in the int and int ones, you can just reuse those inputs and start from scratch.

01:30.000 --> 01:34.000
This helps with finding interesting things faster.

01:34.000 --> 01:40.000
So in RoseVMEM, we implemented fuzzing for VM-Bert.io.

01:40.000 --> 01:44.000
We have three fuzz targets, one for the BERT.io queue,

01:44.000 --> 01:50.000
one for the serialization of the BERT.io queue, and one for the BERT.io ISOG.

01:50.000 --> 01:56.000
In the RoseVMEM project, we all have implementation for the packet, so that's what we fuzzed.

01:56.000 --> 02:05.000
During fuzzing, we discovered three crashes, and only one of them is triggerable by a partition malicious driver.

02:05.000 --> 02:11.000
And what we have right now is that we are able to un-fuzz in for a very rest-heter-soment into the rescue method.

02:11.000 --> 02:18.000
To the name BERT.io repository, the fuzzing is implemented using libfuzzer.

02:18.000 --> 02:24.000
And besides the fuzzing that is happening in RoseVMEM itself,

02:24.000 --> 02:29.000
the folks from the hypervisor are also running fuzzing, and they also discover a timeout in the

02:29.000 --> 02:32.000
server.

02:32.000 --> 02:36.000
So this actually brings me to our first intro.

02:36.000 --> 02:42.000
So, what is it we want? It should be the output, so it's the entry.

02:42.000 --> 02:45.000
Afterwards.

02:45.000 --> 02:52.000
It's a people, and that is me.

02:52.000 --> 02:58.000
The first people is that you actually have to run the timeout

02:58.000 --> 03:02.000
that is appropriate for what you're doing fuzzing for.

03:02.000 --> 03:07.000
Because the people, for example, for the fuzzing that we are using is actually 20 minutes,

03:07.000 --> 03:11.000
and since we are just working with BERT.io, we have to choose,

03:11.000 --> 03:16.000
and there's nothing that can possibly take 20 minutes to process,

03:16.000 --> 03:21.000
so we have to adjust the timeout to 60 seconds in our case,

03:21.000 --> 03:27.000
and this is something that was written in by the folks from the hypervisor.

03:27.000 --> 03:32.000
Now, how we run fuzzing in RoseVMEM is at the library level.

03:32.000 --> 03:37.000
The advantages of this is that it's easy to set up.

03:37.000 --> 03:40.000
So, it's really important that it's easy to set up.

03:40.000 --> 03:42.000
It is a good thing. People are like,

03:42.000 --> 03:48.000
oh, but you're running fuzzing at the library level, so you don't have the kernel that's so easy,

03:48.000 --> 03:51.000
so simple, so they're like, yeah, it's great, right?

03:51.000 --> 03:54.000
And easy is a good thing.

03:54.000 --> 03:57.000
Yeah, it's a good thing because you can also run almost any host.

03:57.000 --> 04:02.000
You just have to have a fuzzer installed, and the repository,

04:02.000 --> 04:04.000
and then you just run fuzzer.

04:04.000 --> 04:07.000
And it also runs in a user space.

04:07.000 --> 04:10.000
There's also the disadvantages, of course, the first one being that

04:10.000 --> 04:14.000
you cannot cover the whole of what they have set up,

04:14.000 --> 04:19.000
so that means that you're going to have some things that are great to replace.

04:19.000 --> 04:25.000
And then, because you are fuzzing in user space, we need to do some more things for the driver.

04:25.000 --> 04:30.000
And this is, this is basically a bit complicated.

04:30.000 --> 04:34.000
And also, you can find false positives.

04:34.000 --> 04:37.000
With the false positives, the idea is that you will find

04:37.000 --> 04:40.000
crashes that otherwise would not be triggered by a driver,

04:40.000 --> 04:43.000
because maybe you have some other JSON trace.

04:43.000 --> 04:46.000
I don't think that it's really important to fix these ones as well,

04:46.000 --> 04:49.000
because you never know how you're going to change your code,

04:49.000 --> 04:56.000
and how it might end up actually triggering those findings in the future.

04:56.000 --> 04:59.000
And for the mocking of the driver, how it works,

04:59.000 --> 05:06.000
we already simplified here, but the idea is that the driver is writing something in memory,

05:06.000 --> 05:09.000
and then the device reads what the driver wrote in memory,

05:09.000 --> 05:13.000
and thus stops the data.

05:13.000 --> 05:16.000
The part that we want to fuzz in the machine,

05:16.000 --> 05:21.000
and the part that we want to fuzz in the machine is this side of the device,

05:21.000 --> 05:25.000
and then what we need to mock is actually the driver side of the application.

05:25.000 --> 05:30.000
And in the machine, what we did is that we started this mocking of the driver from the beginning,

05:30.000 --> 05:34.000
so we needed it anyway to run some unit tests,

05:34.000 --> 05:37.000
we needed for other tests as well.

05:37.000 --> 05:41.000
So we had an initial mock interface from the beginning,

05:41.000 --> 05:50.000
and when we wanted to fuzz, we just evolved a mock driver in order to support that as well.

05:50.000 --> 05:56.000
Okay, so at the high level, how it happens right now in Rasfira is that we parse the random bytes,

05:56.000 --> 06:01.000
we initialize the mock driver with the data that was parsed by fuzzer,

06:01.000 --> 06:08.000
so high level it ends up with some descriptors and some functions that have some random input

06:08.000 --> 06:19.000
that we need to process, and then we create a QM equal these random functions with random input.

06:19.000 --> 06:26.000
And yeah, the second big point is that if you are trying to do fuzzing

06:26.000 --> 06:30.000
and you just start when the project is already mature,

06:30.000 --> 06:34.000
what is going to happen is that's going to be a bit difficult,

06:34.000 --> 06:38.000
you might find it very complicated to retrofit it,

06:38.000 --> 06:44.000
so instead, I know that it's not necessarily viable to start fuzzing when you start a project,

06:44.000 --> 06:49.000
but what you can do instead is that you can keep fuzzing in the back of your head,

06:49.000 --> 06:55.000
and then when you create some mock objects or some unit tests,

06:55.000 --> 07:01.000
you can think about how you can actually reuse them in fuzzing as well.

07:01.000 --> 07:07.000
Which is what we did, but not very well.

07:07.000 --> 07:14.000
So one of the crashes that we actually found was that the mock driver was crashing on invalid input,

07:14.000 --> 07:19.000
so we had to adapt these actually to return errors,

07:19.000 --> 07:23.000
even though it was just one test, we couldn't just crash on invalid input anymore,

07:23.000 --> 07:28.000
so the idea is to return errors at the level where you want to be fuzzing,

07:28.000 --> 07:36.000
that can be processed at higher levels, and so the fuzzing can crash.

07:38.000 --> 07:42.000
And now for structural fuzzing.

07:42.000 --> 07:48.000
So without structural fuzzing, how it works is that the fuzzer is going to generate some random bytes,

07:48.000 --> 07:55.000
and then you have to interpret this as the bytes that you have to do for your library.

07:55.000 --> 08:02.000
With structural fuzzing it's really nice because there are some tools that are just going to basically

08:02.000 --> 08:05.000
interpret the random bytes as a structure that you actually need.

08:05.000 --> 08:07.000
So it's super nice.

08:07.000 --> 08:12.000
What it does is that it significantly reduces the code that you need to write,

08:12.000 --> 08:17.000
and even in Resfier and Risme, it's efficiently arbitrary.

08:17.000 --> 08:21.000
Now, we had to change it, unfortunately,

08:21.000 --> 08:25.000
but before we did that we had only 270 lines of code,

08:25.000 --> 08:30.000
and now we have around 740 lines of code for the fuzzer,

08:30.000 --> 08:38.000
and unfortunately it came with some problems, so that's why we had to actually fix it.

08:38.000 --> 08:42.000
The most important part is that it's not going to produce a fuzz,

08:42.000 --> 08:46.000
so you can't reuse the core fuzz that you had in previous runs,

08:46.000 --> 08:49.000
which was a big problem for us,

08:49.000 --> 08:58.000
because basically what happens is that arbitrary is introducing some randomness in the library,

08:58.000 --> 09:01.000
because it's writing the input,

09:01.000 --> 09:13.000
and that basically means that it cannot be used to purposeful for previous runs.

09:13.000 --> 09:20.000
The big point here is that we can rewrite the incremental improvements for the fuzzer,

09:20.000 --> 09:26.000
and we didn't check that what we want to implement can actually be integrated to the end.

09:26.000 --> 09:38.000
So instead, a better point would have been to make it if we can actually reuse the problems that we generated.

09:38.000 --> 09:43.000
Okay, and now about when fuzzing actually fails.

09:43.000 --> 09:47.000
So we had a PR, University of Man.

09:47.000 --> 09:50.000
At this point we were already running fuzzing for pull request,

09:50.000 --> 09:57.000
and there was a PR that was introducing actually an overflow.

09:57.000 --> 10:05.000
So here the overflow is that the packet header size addition to the packet length can actually overflow,

10:05.000 --> 10:09.000
because the packet length is set up by the driver.

10:09.000 --> 10:13.000
This bug, I actually found it during code review,

10:13.000 --> 10:20.000
so it was a bit unexpected because I was hoping that fuzzer is going to find it, which was not the case.

10:20.000 --> 10:28.000
So after some dive deep, I realized that writing fuzzer for just 15 minutes might not actually be enough,

10:28.000 --> 10:33.000
because the fuzzing, this bug was triggered twice in the government for 14 minutes instead.

10:33.000 --> 10:40.000
So how we fix that is that we had the fuzzing session that is optional and that runs for 24 hours.

10:40.000 --> 10:45.000
This one needs to be started manually by the University of Man maintainers,

10:45.000 --> 10:54.000
and should only be started when there are pull requests that actually impact the whole fuzzing situation.

10:54.000 --> 10:59.000
This is because we are also consuming a lot of resources.

10:59.000 --> 11:05.000
When doing fuzzing, you don't want to block all the pull requests for 24 hours.

11:05.000 --> 11:06.020
So typically the recipe on the site is based on the

11:06.020 --> 11:10.020
page that we use to execute.

11:10.020 --> 11:15.020
So blocking it for one day might not be reasonable for all the pull requests.

11:15.020 --> 11:20.020
So the people here were not planning fuzzing for long enough.

11:20.020 --> 11:27.020
And instead, we had to work our way to find a way to not block pull requests,

11:27.020 --> 11:32.020
but at the same time to provide for fuzzing.

11:32.020 --> 11:34.020
Put coverage for Rust.

11:34.020 --> 11:40.020
So in Rust, you can actually get coverage information by running a LLVM talk.

11:40.020 --> 11:44.020
In Rust, unfortunately, you only get live coverage.

11:44.020 --> 11:48.020
So basically, this was the starting point of the presentation.

11:48.020 --> 11:54.020
I was thinking I'm going to come here, and I'm going to show you how great it is to run fuzzing for 15 minutes,

11:54.020 --> 12:00.020
and then more minutes, and then the purpose, and all these really extravagant things.

12:00.020 --> 12:06.020
And so we ended up with fuzzing for 15 minutes, generating them for these regions,

12:06.020 --> 12:10.020
and the coverage of an early 2%.

12:10.020 --> 12:14.020
So I was like, well, that's okay. That's good.

12:14.020 --> 12:17.020
So then let's just run with some email purposes as well.

12:17.020 --> 12:20.020
So this is some purpose that we generated from unit tests.

12:20.020 --> 12:24.020
Let's just feed the fuzzer and see how this changed.

12:24.020 --> 12:27.020
There was no change, actually.

12:27.020 --> 12:30.020
So I was like, okay, it's not bad, not bad.

12:30.020 --> 12:32.020
Let's just run for two weeks.

12:32.020 --> 12:34.020
So what do you think is going to happen now?

12:34.020 --> 12:43.020
So actually, it's starting.

12:43.020 --> 12:45.020
It's starting, yeah.

12:45.020 --> 12:49.020
At this point, I was like, I have to change my presentation.

12:49.020 --> 12:51.020
It's not what I expected.

12:51.020 --> 12:53.020
But instead, I learned something, right?

12:53.020 --> 12:58.020
So you can't actually use coverage to decide when to stop fuzzing.

12:58.020 --> 13:02.020
So instead, what you can do is that you can use coverage information

13:02.020 --> 13:09.020
to see what parts of your code are not actually covered.

13:09.020 --> 13:13.020
And yeah, well, that's about it, actually.

13:13.020 --> 13:17.020
This is a summary of the people that we ran into,

13:17.020 --> 13:22.020
and I hope now we have a lot of questions.

13:22.020 --> 13:23.020
Yeah?

13:23.020 --> 13:30.020
Did you look at how the fuzzer works and then what areas were not covered

13:30.020 --> 13:33.020
and trying to figure out why it was the fuzzer areas?

13:33.020 --> 13:37.020
Yeah, so the question was if we looked at how the fuzzer works

13:37.020 --> 13:39.020
and what areas were not covered.

13:39.020 --> 13:41.020
Yes, we did, and I have a slide for that.

13:41.020 --> 13:44.020
Thanks for the question.

13:44.020 --> 13:48.020
Okay, so actually, I have two slides for that.

13:48.020 --> 13:53.020
There were some functions that we were not calling on purpose.

13:53.020 --> 13:57.020
So because on the Word.io queue, for example,

13:57.020 --> 14:01.020
we have some functions that are just iterating over the scriptor chains

14:01.020 --> 14:03.020
and then they're doing something with the data.

14:03.020 --> 14:07.020
And at the Word.io queue level, you can't do something with the data.

14:07.020 --> 14:10.020
So it's like, okay, this needs to be fuzzed at a higher level

14:10.020 --> 14:13.020
like at the device implementation level.

14:13.020 --> 14:16.020
So it's like, okay, we're not going to call these functions,

14:16.020 --> 14:18.020
which is a bit hilarious because that's where

14:18.020 --> 14:22.020
Trump hypervisor actually found the time-out problem,

14:22.020 --> 14:26.020
which we were not able to reproduce with Word.io queue, but still.

14:26.020 --> 14:32.020
And we actually did this one function that shouldn't be called during fuzzing.

14:32.020 --> 14:36.020
And then I reran the fuzzing, and, you know, it's a bit better,

14:36.020 --> 14:39.020
but it's still not great.

14:39.020 --> 14:46.020
And then I looked into what, well, actually, you can't see very well.

14:46.020 --> 14:47.020
That's unfortunate.

14:47.020 --> 14:51.020
Yeah, so I looked into what actually is not covered,

14:51.020 --> 14:56.020
and you're not seeing, so you have to trust me,

14:56.020 --> 15:04.020
that these are actually errors, so the printing of errors to files.

15:04.020 --> 15:08.020
So since in the fuzzer, we are not actually initializing

15:08.020 --> 15:12.020
a logger, these things cannot be triggered by files,

15:12.020 --> 15:19.020
so there's lots of this printing to a file that's kept really fuzzing.

15:19.020 --> 15:22.020
Yeah.

15:22.020 --> 15:23.020
Yeah?

15:23.020 --> 15:26.020
What's the truth taken to actually make sure the coverage

15:26.020 --> 15:28.020
goes everywhere, which needs to be covered,

15:28.020 --> 15:33.020
and so just covering sub-values, which clearly aren't good?

15:33.020 --> 15:35.020
I didn't understand the question.

15:35.020 --> 15:40.020
But what's the truth taken to make sure the errors that weren't covered

15:40.020 --> 15:44.020
are going to be covered in the future for me?

15:44.020 --> 15:51.020
Oh, okay, so the question was what measures are we taking

15:51.020 --> 15:55.020
in order to make sure that code that was covered

15:55.020 --> 15:58.020
before is going to still get covered in the next three issues?

15:58.020 --> 15:59.020
Yeah.

15:59.020 --> 16:01.020
None?

16:01.020 --> 16:06.020
So right now we're not doing anything, this whole coverage thing

16:06.020 --> 16:09.020
is just something that I need for the presentation,

16:09.020 --> 16:12.020
and it's not automatic in any way.

16:12.020 --> 16:16.020
This is actually a good point for future investment

16:16.020 --> 16:18.020
to make sure that we're still covering code,

16:18.020 --> 16:23.020
because what will help with as well is that we will make sure

16:23.020 --> 16:25.020
that new functions that we are adding to the code

16:25.020 --> 16:27.020
are also covered by the coverage.

16:27.020 --> 16:31.020
So it's a great point to make the way in your survival.

16:31.020 --> 16:32.020
Yeah?

16:32.020 --> 16:35.020
We're talking about the structure of our fuzzing,

16:35.020 --> 16:39.020
and you mentioned that you cannot use the code

16:39.020 --> 16:41.020
to expand a bit more, thank you.

16:41.020 --> 16:44.020
Yeah, okay, so the question was about structural well fuzzing

16:44.020 --> 16:47.020
and just that you cannot use them for this.

16:47.020 --> 16:51.020
Let me see if I actually have it over here.

16:51.020 --> 16:59.020
No, okay, so the idea is that what we were using,

16:59.020 --> 17:04.020
which is arbitrary, when it was taking the input from it,

17:04.020 --> 17:07.020
fuzzer was also adding some randomness to it.

17:07.020 --> 17:12.020
So because it was random, basically every time it was writing

17:12.020 --> 17:16.020
the purpose of the file, it was introducing some randomness to it,

17:16.020 --> 17:21.020
so when the same people would get the read again,

17:21.020 --> 17:24.020
it would not have been the same.

17:24.020 --> 17:26.020
Where did the randomness come from?

17:26.020 --> 17:28.020
Where did the randomness come from?

17:28.020 --> 17:31.020
This is just how arbitrary decided we implemented it.

17:31.020 --> 17:36.020
There is actually an issue in arbitrary that they are aware of the problem,

17:36.020 --> 17:38.020
but they are not actually...

17:38.020 --> 17:42.020
It doesn't seem like they are interested in fixing it for some reason.

17:42.020 --> 17:49.020
So what we ended up doing is that we ended up doing some custom serialization

17:49.020 --> 17:55.020
with input, which is also very well known for us to track each other.

17:55.020 --> 18:00.020
It's not much more into the latest part, and it doesn't produce.

18:03.020 --> 18:04.020
Yeah, okay.

18:04.020 --> 18:06.020
When you discovered what we did,

18:06.020 --> 18:11.020
does it transform into a unit test afterwards?

18:11.020 --> 18:15.020
The question is, when we discovered about the...

18:15.020 --> 18:19.020
So yeah, the way that we are fixing these kind of problems

18:19.020 --> 18:23.020
is that they are always adding a regression test for them,

18:23.020 --> 18:26.020
just to make sure that they don't do the information.

18:26.020 --> 18:28.020
And it was not a question.

18:28.020 --> 18:31.020
I was wondering about the computational requirements.

18:31.020 --> 18:33.020
So how many cores are you using?

18:33.020 --> 18:35.020
How many cores are you using?

18:35.020 --> 18:37.020
Are you using the exciting?

18:37.020 --> 18:44.020
So when we went for two weeks, we actually used 96 cores.

18:44.020 --> 18:49.020
In a unit test, when you are running on 20 cores,

18:49.020 --> 18:51.020
I don't know exactly how many.

18:51.020 --> 18:54.020
I think that's one? Maybe?

18:54.020 --> 18:58.020
I don't know, but I think we will be running on 96 cores as well.

18:58.020 --> 18:59.020
There was another one.

18:59.020 --> 19:01.020
Can I see that one?

19:01.020 --> 19:02.020
One minute.

19:02.020 --> 19:03.020
One minute.

19:03.020 --> 19:11.020
If you find a cover case, as I try to shrink the case into smaller cover case steps,

19:11.020 --> 19:13.020
it's making it a very long step.

19:13.020 --> 19:14.020
I'm sorry.

19:14.020 --> 19:15.020
All right.

19:15.020 --> 19:16.020
This is... I'm not going to...

19:16.020 --> 19:18.020
No, I need a little less chat afterwards.

19:18.020 --> 19:20.020
Yeah, I'll leave it there.

19:20.020 --> 19:39.020
Thanks.
