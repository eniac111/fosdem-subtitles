WEBVTT

00:00.000 --> 00:10.840
I'm going to talk about walking native stacks in BPF without frame pointers.

00:10.840 --> 00:11.840
Thanks.

00:11.840 --> 00:13.840
So, yeah.

00:13.840 --> 00:18.560
So, my name is Vaishali.

00:18.560 --> 00:24.920
I work at Polu-Simmons as a software engineer, mostly on profiling and eBPF related stuff.

00:24.920 --> 00:31.200
And before that I have worked in different corner subsystems as part of my job.

00:31.200 --> 00:32.200
My name is Javier.

00:32.200 --> 00:36.200
And I've been working at Polu-Simmons for a year, mostly working on native stack unwinding.

00:36.200 --> 00:41.640
And before I was working on web reliability and dev tooling at Facebook.

00:41.640 --> 00:44.840
So before we get into the talk, let's talk about the agenda.

00:44.840 --> 00:49.200
So we'll first address the first question, which is always being asked, that why there

00:49.200 --> 00:53.920
is a need for a DWARF-based stack walker in eBPF.

00:53.920 --> 00:59.120
And we will briefly go through the design of our stack walker, we'll also go from how

00:59.120 --> 01:02.280
we went from the prototype to making it production ready.

01:02.280 --> 01:06.920
And then what were a bunch of the learnings so far, especially when we are interacting

01:06.920 --> 01:09.600
with the eBPF subsystem of the kernel.

01:09.600 --> 01:13.000
And then our future plans.

01:13.000 --> 01:16.520
So as I said, we work on the production profilers.

01:16.520 --> 01:22.240
Generally sampling profilers collect the stack traces at particular intervals and attaches

01:22.240 --> 01:24.080
values to it.

01:24.080 --> 01:29.480
Note that profilers generally need both user application stacks and kernel stacks.

01:29.480 --> 01:33.120
Stack walking is part of the process for collecting the stack traces.

01:33.120 --> 01:38.680
In simple words, it involves iterating over all the stack frames and collecting the return

01:38.680 --> 01:39.680
addresses.

01:39.680 --> 01:48.320
Historically, there has been a dedicated register to store the value of it in both x86 and ARM.

01:48.320 --> 01:56.560
Although it has fallen victim of some of the compiler optimisations, so most of the runtime

01:56.560 --> 01:58.040
actually severs it.

01:58.040 --> 02:02.480
It's called frame pointer, as many of you have heard of it.

02:02.480 --> 02:09.400
And when we don't have the frame pointer, walking the stack becomes like magnitude of

02:09.400 --> 02:12.160
like a lengthy process.

02:12.160 --> 02:16.720
So instead of involving a couple of memory accesses per frame, which is quite fast,

02:16.720 --> 02:20.800
we will have to do more work in the stack walkers.

02:20.800 --> 02:24.040
The stack walking is also common practice in debuggers, right?

02:24.040 --> 02:30.160
So what's the current state of the world with respect to frame pointers?

02:30.160 --> 02:34.000
So it's not a problem for especially hyperscalers.

02:34.000 --> 02:38.880
As you may know, in production, they are always running the applications which has the frame

02:38.880 --> 02:44.600
pointers unable, because whenever they have to inspect the incidents, getting faster and

02:44.600 --> 02:48.120
the reliable stack registers must.

02:48.120 --> 02:59.480
Go runtime enables the frame pointers since go 1.7 in x86 and 1.12 in ARM64.

02:59.480 --> 03:04.520
Mac OS is always compiled with frame pointers.

03:04.520 --> 03:10.200
There's also an amazing work going on for the compact frame format.

03:10.200 --> 03:17.480
It's called simple frame format, and there has been like support being added in the tool

03:17.480 --> 03:24.240
chains, and now there is also like a mailing list discussion going on in the kernel about

03:24.240 --> 03:31.640
having an unwinded stack walker, sorry, a stack walker for unwinding the user stacks.

03:31.640 --> 03:34.000
But the thing is that we want it now.

03:34.000 --> 03:36.520
We want to support all the distros.

03:36.520 --> 03:39.240
We want to support all the run times.

03:39.240 --> 03:45.640
And the one thing that comes across a lot of this is dwarf, and that's why we are using

03:45.640 --> 03:46.640
it.

03:46.640 --> 03:48.720
So where does it come from?

03:48.720 --> 03:55.120
So like some of you might be wondering about like the exceptions in C++ or, for example,

03:55.120 --> 04:01.560
Rust tool chain which is like always disabling the frame pointers, but when you use the panic,

04:01.560 --> 04:04.640
it always has the full back dress.

04:04.640 --> 04:13.440
The reason is that it has the.eh frame section which is being used for that or debug frame.

04:13.440 --> 04:17.680
So most of the time either of the tool chains have this section.

04:17.680 --> 04:25.600
And the other idea is that you can also unwind the tables by synthesizing it from the object

04:25.600 --> 04:26.600
code.

04:26.600 --> 04:31.800
This is like the approach which is being used in org, one of the kernel second minder which

04:31.800 --> 04:35.960
was added I guess six years ago.

04:35.960 --> 04:40.200
So we'll talk about in detail about.eh frame in a minute.

04:40.200 --> 04:45.000
But before that, let's see who else is using.eh frame.

04:45.000 --> 04:48.440
So of course we are not the first one who are going to use it.

04:48.440 --> 04:51.640
Perf does that.

04:51.640 --> 04:59.920
Since I think since when the Perf event, open Cisco was introduced in 3.4, so it collects

04:59.920 --> 05:04.720
the registers for the profile processes as well as a copy of the stack for every sample.

05:04.720 --> 05:09.640
While this approach has been proven to work, there are a bunch of drawbacks which we wanted

05:09.640 --> 05:10.640
to avoid.

05:10.640 --> 05:14.200
One of the things is that kernel copies the user stake for every sample and this can be

05:14.200 --> 05:19.080
quite a bit of data, especially for the CPU intensive applications.

05:19.080 --> 05:23.320
Another thing is that when we are copying the data in the user space, the implications

05:23.320 --> 05:30.200
of one process having another process's data can also be complicated.

05:30.200 --> 05:33.560
So those are a bunch of things we wanted to avoid.

05:33.560 --> 05:39.800
And stack walking using BPF makes sense to us because we don't have to copy the whole

05:39.800 --> 05:40.800
stack.

05:40.800 --> 05:46.080
Instead, a lot of the information still stays in the kernel, especially in the case of stack

05:46.080 --> 05:47.880
walking mechanism.

05:47.880 --> 05:53.240
Once it has been implemented, we can leverage the Perf subsystem to get the samples on CPU

05:53.240 --> 05:57.440
cycles, instructions, access, et cetera.

05:57.440 --> 06:02.920
It can also help us to develop other tools like allocation tracers, runtime-specific

06:02.920 --> 06:07.880
profilers like for the JVM or Ruby, et cetera.

06:07.880 --> 06:13.480
Now some of you might be wondering that why do we want to implement something new when

06:13.480 --> 06:17.280
we already have BPF get stack ID?

06:17.280 --> 06:25.080
So the reason is that it also uses frame pointers to unwind it.

06:25.080 --> 06:29.720
Having a fully featured dwarf unwinder in kernel is unlikely to happen.

06:29.720 --> 06:31.680
There is a mailing list discussion.

06:31.680 --> 06:34.400
You can go and check it out.

06:34.400 --> 06:36.400
Why?

06:36.400 --> 06:41.560
So now before we dive into the design of our stack walker, I wanted to give some information

06:41.560 --> 06:45.840
on what ES frame has and how we can use it.

06:45.840 --> 06:54.640
So ES frame section contains one or more call frame information records.

06:54.640 --> 06:59.320
The main goal of the call frame information records is to provide answers on how to restore

06:59.320 --> 07:03.840
the register for the previous frame and the locations such as whether they have been pushed

07:03.840 --> 07:05.760
to the stack or not.

07:05.760 --> 07:09.540
And all of this would actually generate the huge unwind tables.

07:09.540 --> 07:12.600
And for these reasons, the format attempts to be compact.

07:12.600 --> 07:17.000
And it only contains the information that is being needed.

07:17.000 --> 07:23.440
The unwind tables encoded in the CFI format are in the form of opcodes.

07:23.440 --> 07:26.240
And we basically have to evaluate it.

07:26.240 --> 07:30.800
And then in the case of stack walking, once it has been evaluated, we generate the table

07:30.800 --> 07:36.680
that contains for each instruction boundary how to restore the value of the previous register.

07:36.680 --> 07:38.800
It has sort of two layers to it.

07:38.800 --> 07:44.560
One is this sort of helps with the repetitive patterns for compressing.

07:44.560 --> 07:48.400
And it allows for a more compact representation of some data.

07:48.400 --> 07:53.680
As in some cases, a specialized opcodes that consumes one or two or four bytes.

07:53.680 --> 07:58.400
So it doesn't have to be four bytes all the time.

07:58.400 --> 08:03.640
And the second layer is like a special opcode that contains under the set of opcodes which

08:03.640 --> 08:05.920
is like arbitrary expressions.

08:05.920 --> 08:09.960
And they need to be actually evaluated for that.

08:09.960 --> 08:17.120
And this would mean that we will actually have to implement the full below VM in the

08:17.120 --> 08:24.160
EBPF to evaluate any expression, which is not practical.

08:24.160 --> 08:31.200
So we are going to also mention what we are doing to actually come over those challenges.

08:31.200 --> 08:36.960
For those who are not aware of what is the general flow of the EBPF applications, generally

08:36.960 --> 08:38.520
this is how it would look like.

08:38.520 --> 08:40.400
Very high level overview.

08:40.400 --> 08:47.640
So in the user space, we are using the driver program, which is written in Go.

08:47.640 --> 08:49.720
We use the BPF Go.

08:49.720 --> 08:57.320
It creates the map, attaches the map, attaches the BPF program to the CPU cycles of perf

08:57.320 --> 09:03.480
content, and then reads, passes, and evaluates the EBPF section of the process.

09:03.480 --> 09:08.320
And in the BPF program, we fetched the table from the current PID and then have an unwinding

09:08.320 --> 09:12.840
algorithm which processes the reward for information.

09:12.840 --> 09:15.120
So we'll go in depth for each component.

09:15.120 --> 09:20.360
But let's see what the algorithm looks like.

09:20.360 --> 09:24.120
So first what we are doing is we are just reading three registers.

09:24.120 --> 09:30.560
First one is RIP, the second one is stack pointer, RSP, and the third one is RBP, which

09:30.560 --> 09:36.080
is commonly used as frame pointer when they are enabled.

09:36.080 --> 09:40.480
Next we are going for the unwind frame count, which is less than, and when it's less than

09:40.480 --> 09:44.000
maximum depth.

09:44.000 --> 09:46.760
We find the unwind table row for the program counter.

09:46.760 --> 09:51.160
Then we go for adding the instruction pointer to the stack, calculate the previous frames,

09:51.160 --> 09:56.880
stack pointer, update the registers, and continue with the next frame.

09:56.880 --> 10:00.160
So this is like a very simple binary search.

10:00.160 --> 10:06.440
But when it has to scale, we need to also think about storing the unwind information

10:06.440 --> 10:11.280
and how can it work with all the run times, et cetera.

10:11.280 --> 10:14.280
So Javier will now talk about that.

10:14.280 --> 10:15.280
Cool.

10:15.280 --> 10:20.080
So as Vaisal said, we need somewhere where to store the unwind information.

10:20.080 --> 10:23.920
We're going to look later at how this table looks like.

10:23.920 --> 10:26.720
But first let's see what are the possibilities here.

10:26.720 --> 10:31.000
So one possibility, for example, will be to store the unwind information in process.

10:31.000 --> 10:35.400
We could do this using a combination of P trace, mmap, and mlock.

10:35.400 --> 10:40.800
And this will require us to basically hijack the processes execution, introduce a new memory

10:40.800 --> 10:45.040
mapping inside of them, and then we have to lock the memory because in BPF and in our

10:45.040 --> 10:48.960
type of BPF programs, page faults are not allowed.

10:48.960 --> 10:54.040
The problem with these approaches, of course, will be altering the execution flow of applications,

10:54.040 --> 10:56.640
which is something that we never want to do.

10:56.640 --> 10:58.360
This complicates things a lot.

10:58.360 --> 11:01.760
For example, one of the biggest problems is the life cycle.

11:01.760 --> 11:07.040
So for example, if our profiler dies before we finish cleaning up, who is going to clean

11:07.040 --> 11:08.360
up that memory segment?

11:08.360 --> 11:12.960
Or how is this going to be perceived by developers if they see that the memory of their application

11:12.960 --> 11:18.120
has increased behind their backs just because some observability tool is doing something

11:18.120 --> 11:20.400
that is not great?

11:20.400 --> 11:23.560
But also there's another problem that is sharing memory is harder.

11:23.560 --> 11:27.280
There is same page optimization from the kernel.

11:27.280 --> 11:32.240
But if you don't think about that, it's a problem to have the same information generated

11:32.240 --> 11:37.040
over and over, for example, for libc for every single process in your machine.

11:37.040 --> 11:41.760
So that's why we ended up using another solution, which is pretty typical in the BPF space,

11:41.760 --> 11:43.920
which is using BPF maps.

11:43.920 --> 11:48.720
In case you're not familiar, BPF maps are data structures that can be written or read

11:48.720 --> 11:51.000
from both user and kernel space.

11:51.000 --> 11:55.480
We're using hash tables everywhere, which in the case of BPF, they're basically a mapping

11:55.480 --> 12:00.600
of bytes to bytes that store arbitrary information.

12:00.600 --> 12:06.120
So some BPF maps, some BPF programs as well allow to lazily allocate memory for their

12:06.120 --> 12:07.120
data structures.

12:07.120 --> 12:10.280
But in the case of our tracing program, we cannot do that.

12:10.280 --> 12:11.400
And this has some implications.

12:11.400 --> 12:16.600
So we need to memlock that, well, the kernel, sorry, user space memlocks that memory, and

12:16.600 --> 12:19.960
otherwise our program wouldn't be able to run.

12:19.960 --> 12:25.160
And by using this approach, we are also able to reuse these memory mappings, which is great,

12:25.160 --> 12:26.160
right?

12:26.160 --> 12:31.080
Because that means we don't have to do the same work over and over, and we use less space.

12:31.080 --> 12:34.600
So let's take a look at the logical representation of the unwind tables.

12:34.600 --> 12:38.840
So this is not how the layout is in memory, but think about, for example, the unwind tables

12:38.840 --> 12:41.960
for libc, MySQL, Zlib, and systemd.

12:41.960 --> 12:47.040
How they will be laid out in memory if we could allocate a large chunk of memory.

12:47.040 --> 12:50.160
But in reality, there's limits everywhere, obviously.

12:50.160 --> 12:52.960
And in BPF, we have done some tests.

12:52.960 --> 12:57.560
I mean, the machines that we want, the kernels we want to support, we can allocate up to

12:57.560 --> 13:03.900
25,000 unwind entries per value of the hash map.

13:03.900 --> 13:08.320
So obviously, this was a problem for us, because in some cases, we have some customers that

13:08.320 --> 13:14.160
have applications with unwind tables with three, four million unwind rows, which is

13:14.160 --> 13:15.160
quite ridiculous.

13:15.160 --> 13:20.320
Just to give you an idea, libc, I think, has like 60K entries.

13:20.320 --> 13:23.480
So having a couple million is significant.

13:23.480 --> 13:28.320
But yeah, we came up with the same solution that you would use in any other data-intensive

13:28.320 --> 13:32.800
application, which is to partition or shard the data.

13:32.800 --> 13:37.800
So the way we're doing this is we have multiple entries that are allocated when our profilers

13:37.800 --> 13:39.200
start running.

13:39.200 --> 13:42.760
We allocate a different number, depending on the available memory on the system and

13:42.760 --> 13:45.880
the overhead that you're willing to pay.

13:45.880 --> 13:53.160
And yeah, depending on how many shards you have, you have a different CPU to memory trade-off,

13:53.160 --> 13:55.400
because the more memory you use, it has to be locked in memory.

13:55.400 --> 14:00.400
It can never be swapped out, which is, in some applications, no ideal.

14:00.400 --> 14:03.080
But at the same time, that means that you don't have to regenerate the tables if they

14:03.080 --> 14:08.880
are full, and then you want to give other processes a fair chance to be profiled.

14:08.880 --> 14:13.760
So the way this will work, for example, for a process like systemd is that will be the

14:13.760 --> 14:17.360
representation of the size of its unwind tables.

14:17.360 --> 14:22.880
Because it's bigger than the size of a shard, it will have to be chunked.

14:22.880 --> 14:25.400
So here, we can see how this is chunked in two.

14:25.400 --> 14:32.360
The first chunk will go in the shard zero, and a bunch of the unwind entries from the

14:32.360 --> 14:35.200
tail will go to the shard one.

14:35.200 --> 14:42.040
And of course, because we have this new layer of indirection, we need to somehow keep track

14:42.040 --> 14:46.200
of all this bookkeeping and know what is the state of the world.

14:46.200 --> 14:49.680
We're doing this, of course, with more BVF maps.

14:49.680 --> 14:52.400
So our process has multiple mappings.

14:52.400 --> 14:55.860
Each mapping has one or more chunks.

14:55.860 --> 15:01.520
And then each chunk maps to exactly one shard, and in particular the region within one shard,

15:01.520 --> 15:08.280
because you can have from one unwind entry up to 2050k.

15:08.280 --> 15:10.760
Of course, this has the benefit that I was mentioning before.

15:10.760 --> 15:15.280
That is, because we were sharing the unwind tables, that means that we spend actually

15:15.280 --> 15:18.680
not that many CPU cycles doing all the work that Charlie was mentioning before.

15:18.680 --> 15:23.440
We need to find the elf section where the door of CFI information is, but also we need

15:23.440 --> 15:24.640
to parse, evaluate it.

15:24.640 --> 15:29.760
We have two levels of VM that have to run, which is not something that is very CPU consuming

15:29.760 --> 15:30.760
but still has to happen.

15:30.760 --> 15:35.480
It has to process a bunch of information and generate these unwind tables in our custom

15:35.480 --> 15:36.480
formats.

15:36.480 --> 15:43.000
So by sharing this, for example, LIPST will be shared for all the processes, so that means

15:43.000 --> 15:48.200
that we only need to add the bookkeeping data structures, which are really cheap to generate.

15:48.200 --> 15:52.560
In some of the tests that we've been running, we use less than 0.9% CPU within the total

15:52.560 --> 15:57.840
CPU cycles that our profiler uses to generate the unwind tables.

15:57.840 --> 16:01.360
Of course, there's a lot of things that we need to take into account, like, for example,

16:01.360 --> 16:03.800
what happens if we run out of space, right?

16:03.800 --> 16:08.480
So what we do is we adaptively decide what to do in the moment.

16:08.480 --> 16:14.760
We might wait a little bit until resetting the state, or we might decide to give chance

16:14.760 --> 16:18.240
to other processes to be profiled, so we wipe the whole thing and start again.

16:18.240 --> 16:21.000
As you can see, this is very similar to a Bump allocator.

16:21.000 --> 16:25.920
This is basically a Bump allocator that has been chunked up.

16:25.920 --> 16:33.360
So the process of unwinding this is we start with a PID, we check if it has unwind information,

16:33.360 --> 16:39.720
then we need to find the mapping, and for each mapping, we know the minimum and the

16:39.720 --> 16:45.040
maximum program counter, so we need to do a linear search to find it.

16:45.040 --> 16:46.040
Then we find the chunk.

16:46.040 --> 16:51.600
With the chunk, we already have the shared information, so once we have the shared information,

16:51.600 --> 16:54.520
we have to traverse up to 250,000 items.

16:54.520 --> 16:59.720
We do this with a simple binary search.

16:59.720 --> 17:04.600
This takes between seven or eight iterations.

17:04.600 --> 17:09.520
Once we have the unwind action that tells us how to restore the previous frame registers,

17:09.520 --> 17:14.520
we do those operations and we are ready to go to the next frame.

17:14.520 --> 17:17.640
We are pretty much done for that frame.

17:17.640 --> 17:24.120
If the stack trace is correct, we know this because basically a stack, when you have frame

17:24.120 --> 17:29.200
pointers, the bottom of the stack is defined in applications with frame pointers.

17:29.200 --> 17:32.400
When you reach RBP equals zero, this is defined by the API.

17:32.400 --> 17:37.440
When you have unwind tables, it's defined by not having that program counter cover by

17:37.440 --> 17:40.360
any unwind table and having RBP zero.

17:40.360 --> 17:45.080
This is a requirement by the API, so if some application doesn't respect it, it's completely

17:45.080 --> 17:46.080
broken.

17:46.080 --> 17:50.720
So once we verify that the stack is correct, that we have reached the bottom of the stack,

17:50.720 --> 17:56.200
we hash the addresses and we add the hash to a map and we bump a counter.

17:56.200 --> 18:02.440
We do this, I think it is 19 times a second for every single CPU in your box.

18:02.440 --> 18:06.560
Every couple seconds we collect all this information, we generate a profile, we send it to some

18:06.560 --> 18:10.280
server for inspection.

18:10.280 --> 18:14.000
Of course, BPF is an interesting environment to work with.

18:14.000 --> 18:16.360
It is amazing and we really, really like it.

18:16.360 --> 18:18.140
But we need to be aware of some stuff.

18:18.140 --> 18:24.160
First of all, because we cannot page in or page out pages that contain the unwind tables,

18:24.160 --> 18:25.600
that has to be locked in memory.

18:25.600 --> 18:30.600
We need to be very careful with how we organize our data and the layout of that data to make

18:30.600 --> 18:31.760
it as small as possible.

18:31.760 --> 18:35.680
So we basically pack every single thing that can be packed.

18:35.680 --> 18:39.320
Then there's some interesting BPF things that for most people that have written BPF programs,

18:39.320 --> 18:42.720
this is well known, but I just want to talk a little bit about how we are dealing with

18:42.720 --> 18:44.960
some of the BPF challenges.

18:44.960 --> 18:48.560
So one of these is a stack size which is easy to work around.

18:48.560 --> 18:52.440
If I am not mistaken, we have 512 bytes which is not a lot.

18:52.440 --> 18:56.680
So we use another BPF map that we use sort of a global data structure.

18:56.680 --> 19:00.560
And that stores basically like kind of your heap, if you will.

19:00.560 --> 19:05.440
And then for the program size, this is a limitation that comes in two ways.

19:05.440 --> 19:10.480
First, there's probably some limitation in the amount of how many upcodes you can load

19:10.480 --> 19:14.840
in the kernel, but also the BPF verifier that ensures that the BPF code is safe to load,

19:14.840 --> 19:15.840
for example.

19:15.840 --> 19:22.320
You don't do any dereference that could go wrong or that your program terminates.

19:22.320 --> 19:23.480
It has some limits.

19:23.480 --> 19:28.280
It could theoretically run forever trying to verify your program, but it has some limits.

19:28.280 --> 19:30.520
And we hit this limit everywhere in our code.

19:30.520 --> 19:33.560
For example, we hit it when running our binary search.

19:33.560 --> 19:37.840
It complains, saying that it is too complex for each to analyze.

19:37.840 --> 19:42.520
So what we do here is that not only we have sharded our data, we have sharded our code,

19:42.520 --> 19:44.080
our code and data, the same thing, right?

19:44.080 --> 19:49.440
So we basically have our program split into many subprograms, and we keep the states, and

19:49.440 --> 19:54.000
we basically execute one program after each other and continue the state.

19:54.000 --> 19:57.720
So one of the techniques we use is BPF tail calls.

19:57.720 --> 20:02.440
Two other things that are way more modern and they're amazing too are bounded loops

20:02.440 --> 20:05.220
and BPF loop, which is a wonderful helper.

20:05.220 --> 20:10.600
The problem is that while we use bounded loops right now, we don't use BPF loop because it's

20:10.600 --> 20:12.520
only supported in modern kernels.

20:12.520 --> 20:13.520
But it's great.

20:13.520 --> 20:16.520
If you can use it, you should.

20:16.520 --> 20:20.320
Now because we're a profiler and we want to minimize the impact we have on the machines

20:20.320 --> 20:24.100
we run, I want to talk a little bit about performance in user space.

20:24.100 --> 20:27.360
So many Go applications, well, our profiler is written in Go, and many Go applications

20:27.360 --> 20:29.760
and APIs are in design with performance in mind.

20:29.760 --> 20:34.880
And this is something that can be seen in the dwarf and elf library that Go ships with

20:34.880 --> 20:39.000
in the Sandal library, as well as binary read and binary write that we use everywhere because

20:39.000 --> 20:43.220
we're dealing with raw bytes and we read them and write them all the time to the BPF maps.

20:43.220 --> 20:50.920
So it is interesting to know that both these binary read and binary write low level APIs

20:50.920 --> 20:54.280
actually allocate in the fast path, which can be problematic.

20:54.280 --> 20:57.920
So there's a lot of things that in the future we're going to be reinventing to make faster.

20:57.920 --> 21:00.260
And then we profiler, profiler, alerting, production.

21:00.260 --> 21:04.440
We have found a lot of opportunities and there's a lot more work to do because there's not

21:04.440 --> 21:05.440
much time.

21:05.440 --> 21:09.200
We're going to quickly skip through testing, but the idea here is that we try to be pragmatic

21:09.200 --> 21:12.800
and we have a lot of unit tests for the core functions and then we use snapshot testing

21:12.800 --> 21:14.760
for the unwind tables.

21:14.760 --> 21:19.000
We have a GitHub repository where we have a visual representation of the unwind tables

21:19.000 --> 21:23.920
and then we generate them every time on CI and locally and we verify that there are no

21:23.920 --> 21:28.560
changes compared to last time.

21:28.560 --> 21:31.000
I think there's only like two or three minutes left.

21:31.000 --> 21:33.840
So let me talk about the different environments and some of the interesting stuff that we

21:33.840 --> 21:34.840
have found.

21:34.840 --> 21:39.200
While we were profiling our profiler in production, we realized that we were spending a ridiculous

21:39.200 --> 21:41.840
amount of CPU cycles reading files from disk.

21:41.840 --> 21:46.120
I think the total is just a bunch, a part of the flame graph, but I think in total it

21:46.120 --> 21:47.840
was like 20% of the CPU cycles.

21:47.840 --> 21:52.680
So it turns out this was because our cloud provider has very slow disks that are orders

21:52.680 --> 21:57.720
of magnitude slower than our fast NVMe's in the team.

21:57.720 --> 22:02.600
Another thing that is very interesting that is not a new fact and everybody knows about

22:02.600 --> 22:07.280
is that different configuration is the biggest source of trouble.

22:07.280 --> 22:11.320
And we could see this the other day and if you're interested you can check the pull request.

22:11.320 --> 22:17.520
The whole project is open source which is the interaction between signals and BPF.

22:17.520 --> 22:22.720
What happened basically, Go has an embedded profiler and we use it all in production for

22:22.720 --> 22:28.240
reasons, but it triggers SIGPROF a couple of times a second.

22:28.240 --> 22:32.440
That was interrupting the process execution and at that time our process was booting up

22:32.440 --> 22:36.360
and it was loading our BPF program because it's quite long and complex.

22:36.360 --> 22:39.840
The verifier takes a couple milliseconds to load it, but it was getting interrupted all

22:39.840 --> 22:40.840
the time.

22:40.840 --> 22:46.480
So the BPF whenever it detects that the verifier has been interrupted it retries the process,

22:46.480 --> 22:49.720
basically wasting all the previous CPU cycles because it starts from scratch.

22:49.720 --> 22:53.200
But then it retries up to five times and then it says I couldn't do it and of course when

22:53.200 --> 22:59.000
we can't load a BPF program we are completely useless so we just crash.

22:59.000 --> 23:02.440
There is many other considerations such as what do you do with short leaf processes because

23:02.440 --> 23:03.720
you have to generate metadata.

23:03.720 --> 23:08.840
But even though we have an optimizer for this, we are not that bad and we can profile processes

23:08.840 --> 23:12.160
that run even for one second in your box.

23:12.160 --> 23:15.680
And then the important thing here is that this is our format for our custom at one table

23:15.680 --> 23:16.680
but it doesn't matter.

23:16.680 --> 23:22.120
The important bit here is that it mostly fits in L2 cache so we basically incur on two L2

23:22.120 --> 23:25.720
misses and it is pretty fast.

23:25.720 --> 23:30.840
On a machine with a bunch of processes with up to 90 frames we can do the full and one

23:30.840 --> 23:34.080
processing 0.5 milliseconds.

23:34.080 --> 23:37.600
On a CPU that is five years old.

23:37.600 --> 23:38.600
Cool.

23:38.600 --> 23:40.920
So we are going to do mixing and wind modes.

23:40.920 --> 23:45.640
So being able to unwind JIT sections we are applying RM64 support by the end of the year

23:45.640 --> 23:48.880
and this feature is going to be enabled by default in a few weeks because right now it

23:48.880 --> 23:50.640
is under a feature flag.

23:50.640 --> 23:54.640
We have many other things we want to support including high level languages and we are

23:54.640 --> 23:55.640
open source.

23:55.640 --> 24:01.160
So if you want to contribute or you have anything you want to discuss we meet biweekly on Mondays

24:01.160 --> 24:02.400
as part of the program project.

24:02.400 --> 24:06.040
So there is a bunch of links that we are going to upload to the presentation in the Folsom

24:06.040 --> 24:19.520
website and thank you.
