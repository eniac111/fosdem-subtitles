1
0:00:00.000 --> 0:00:08.520
We're ready for our next talk.

2
0:00:08.520 --> 0:00:12.440
Mathieu is going to talk about MPTCP in the upstream kernel.

3
0:00:12.440 --> 0:00:13.440
Thanks.

4
0:00:13.440 --> 0:00:18.720
Yes, so hello everybody.

5
0:00:18.720 --> 0:00:24.280
So welcome to this short presentation about MPTCP in the Linux kernel.

6
0:00:24.280 --> 0:00:28.020
So it was a long road that started almost 15 years ago.

7
0:00:28.020 --> 0:00:33.480
So I'm indeed Mathieu Barthes, working at Tesserys in Louvannan, so it's 30 kilometers

8
0:00:33.480 --> 0:00:34.980
from here.

9
0:00:34.980 --> 0:00:39.460
And let's start by a quick overview of the agenda.

10
0:00:39.460 --> 0:00:45.560
So today I suggest to begin with a short introduction of multiparse TCP and its main use cases.

11
0:00:45.560 --> 0:00:51.040
I will try to be quick for those who already know about that, but still trying to make

12
0:00:51.040 --> 0:00:55.440
the concepts clear for everybody, hopefully.

13
0:00:55.440 --> 0:01:00.120
Then I will explain what we can do today and what's expected for later.

14
0:01:00.120 --> 0:01:05.760
I will finish by giving some explanation about why it took so long to have it included in

15
0:01:05.760 --> 0:01:08.120
the official versions.

16
0:01:08.120 --> 0:01:10.960
So MPTCP is short for multiparse TCP.

17
0:01:10.960 --> 0:01:15.960
This is an extension to TCP that breaks the assumption that a connection is linked to

18
0:01:15.960 --> 0:01:19.660
a fixed pair of IP addresses and ports.

19
0:01:19.660 --> 0:01:24.520
In one sentence, it allows to exchange data for a single connection over different paths,

20
0:01:24.520 --> 0:01:26.600
similar to mostly.

21
0:01:26.600 --> 0:01:32.240
Now that you can have multiple paths for the same connection, you can then have more redundancy,

22
0:01:32.240 --> 0:01:34.820
more bandwidth, and many more things.

23
0:01:34.820 --> 0:01:39.400
But enough with the nice definitions, let's have a look at a typical use case.

24
0:01:39.400 --> 0:01:45.380
Here is a classical MPTCP use case with smartphones.

25
0:01:45.380 --> 0:01:49.920
So a smartphone can typically connect to both Wi-Fi and cellular networks.

26
0:01:49.920 --> 0:01:55.640
That's a completely different view from the 70s, when TCP was designed and where everything

27
0:01:55.640 --> 0:02:00.080
was fixed and clearly not transportable.

28
0:02:00.080 --> 0:02:02.080
Let's take a typical scenario.

29
0:02:02.080 --> 0:02:07.280
So you are here in the room connected to the Wi-Fi access point.

30
0:02:07.280 --> 0:02:12.600
Quickly you realize that A, you have enough and don't want to listen to me anymore, and

31
0:02:12.600 --> 0:02:16.160
B, you got called by the smell of the fries outside.

32
0:02:16.160 --> 0:02:21.160
You then decide to watch the video stream about the history of fries, why not, on your

33
0:02:21.160 --> 0:02:26.240
smartphone and leave the building to get real ones, much better.

34
0:02:26.240 --> 0:02:32.600
Slowly the Wi-Fi signal will become weaker and weaker and likely the video will stop.

35
0:02:32.600 --> 0:02:40.080
It will only restart when the system detected the issue and each app will then have to handle

36
0:02:40.080 --> 0:02:44.960
that by reconnecting to the server and then continue where it was if it can.

37
0:02:44.960 --> 0:02:51.120
It's clearly not a smooth experience for both devs and end users, of course.

38
0:02:51.120 --> 0:02:56.560
In other words, do not leave the building if you don't have MPTCP on your phone.

39
0:02:56.560 --> 0:02:59.480
Of course, there are fries for everybody.

40
0:02:59.480 --> 0:03:04.560
So I guess you already got that MPTCP is going to improve this situation.

41
0:03:04.560 --> 0:03:09.600
And yes, it will because it helps supporting seamless handover scenarios.

42
0:03:09.600 --> 0:03:14.800
MPTCP allows to create multiple paths for the same connection.

43
0:03:14.800 --> 0:03:20.680
So these paths are called subflows and they look like TCP connection when you look at

44
0:03:20.680 --> 0:03:23.880
packet traces.

45
0:03:23.880 --> 0:03:29.600
Except that these packets contain additional TCP options to let the client and server attach

46
0:03:29.600 --> 0:03:30.600
new subflows.

47
0:03:30.600 --> 0:03:33.960
They can also announce available IP address.

48
0:03:33.960 --> 0:03:41.160
Of course, they need to have some numbers to reassemble the data and more things.

49
0:03:41.160 --> 0:03:46.440
Multiple paths can be used at the same time like here on the slide.

50
0:03:46.440 --> 0:03:52.120
So with the same workout scenario, the frustration of being disconnected from one network goes

51
0:03:52.120 --> 0:03:53.120
away.

52
0:03:53.120 --> 0:03:59.280
Indeed, MPTCP can quickly take the decision to continue the communication on another path

53
0:03:59.280 --> 0:04:08.080
and even use multiple paths at the same time when one can no longer cope with the demand.

54
0:04:08.080 --> 0:04:14.560
This kind of use case is already supported by Apple with apps like Siri, Maps, Music

55
0:04:14.560 --> 0:04:21.720
and others, but also by Samsung and LG in some countries like South Korea and Turkey.

56
0:04:21.720 --> 0:04:27.240
Another use case which is one that kept us busy for a bit of time at my company is the

57
0:04:27.240 --> 0:04:30.760
hybrid access network case.

58
0:04:30.760 --> 0:04:35.400
Many people are stuck at home with a not so great internet connection.

59
0:04:35.400 --> 0:04:41.040
That's usually because they are using a copper line and are far away from the street cabinet.

60
0:04:41.040 --> 0:04:46.040
Improving the situation is costly, but also takes time, especially if it is needed to

61
0:04:46.040 --> 0:04:52.000
dig new and long trenches to bring fiber to home.

62
0:04:52.000 --> 0:04:58.240
On the other hand, different assets of the network operator can be used, like the available

63
0:04:58.240 --> 0:05:02.880
capacity on the mobile network, so I mean 4G and 5G.

64
0:05:02.880 --> 0:05:09.040
With the help of a transplant proxy installed in the residential gateways for the client

65
0:05:09.040 --> 0:05:15.280
side and the telco cloud of the operator for the server side, Multipass TCP is used

66
0:05:15.280 --> 0:05:20.640
in the middle to offer more bandwidth to the end users.

67
0:05:20.640 --> 0:05:26.440
One last use case that can be quite interesting is that MPTCP can also play a key role in

68
0:05:26.440 --> 0:05:34.200
managing data between cellular networks like 5G and fix one like Wi-Fi.

69
0:05:34.200 --> 0:05:40.520
The 3GPP, which is the organization in charge of defining the 5G technologies, suggests

70
0:05:40.520 --> 0:05:45.760
operator to set up an ATSSS core function.

71
0:05:45.760 --> 0:05:52.000
The goal is to use MPTCP to have a seamless handover between networks, so 4G, 5G and

72
0:05:52.000 --> 0:05:58.200
Wi-Fi, not to break connection when you go from one to another, but also to reduce the

73
0:05:58.200 --> 0:06:03.760
utilization of the mobile network and avoid the situation of this mobile network in the

74
0:06:03.760 --> 0:06:04.760
future.

75
0:06:04.760 --> 0:06:13.000
MPTCP is then part of 5G, but I cannot tell you if this is the same 5G as the one they

76
0:06:13.000 --> 0:06:15.280
put in the COVID vaccine.

77
0:06:15.280 --> 0:06:24.200
Anyway, enough with the theory, how do we use it and what can we do with it today?

78
0:06:24.200 --> 0:06:27.200
So MPTCP in the upstream kernel is fairly new.

79
0:06:27.200 --> 0:06:31.200
A recent ten of kernel is required.

80
0:06:31.200 --> 0:06:37.880
An application can create an MPTCP circuit and use it like it would do with a TCP circuit.

81
0:06:37.880 --> 0:06:42.000
So it's just one line change.

82
0:06:42.000 --> 0:06:48.280
You can see on the slide that IP proto MPTCP is used instead of TCP.

83
0:06:48.280 --> 0:06:55.080
So yes, the application needs to explicitly pick MPTCP, but it is also possible to change

84
0:06:55.080 --> 0:07:01.660
the behaviour of existing applications by forcing them to create an MPTCP circuit thanks

85
0:07:01.660 --> 0:07:05.420
to LD preload.

86
0:07:05.420 --> 0:07:11.280
It is also required to configure the network side to tell the kernel that multiple interfaces

87
0:07:11.280 --> 0:07:12.280
can be used.

88
0:07:12.280 --> 0:07:19.440
So tools like Network Manager and MPTCP can help doing that automatically, but it is also

89
0:07:19.440 --> 0:07:25.040
possible to do it manually with the IP tool.

90
0:07:25.040 --> 0:07:27.820
So it's probably better with an example.

91
0:07:27.820 --> 0:07:34.520
So just install a recent GNU Linux distribution, so a Fedora, Ubuntu, you name it, then you

92
0:07:34.520 --> 0:07:36.800
set up the network configuration.

93
0:07:36.800 --> 0:07:43.040
So here in this example, you can see that we need to declare which other IP addresses

94
0:07:43.040 --> 0:07:46.840
can be used to create new subflows.

95
0:07:46.840 --> 0:07:52.920
That's for the client side on the top and also to signal the IP addresses to the other

96
0:07:52.920 --> 0:07:56.040
side.

97
0:07:56.040 --> 0:08:01.280
It is also needed to tell the kernel that traffic generated from one IP should go through

98
0:08:01.280 --> 0:08:03.000
the right interface.

99
0:08:03.000 --> 0:08:10.440
So here we do that manually, but this can be done of course by Network Manager and others.

100
0:08:10.440 --> 0:08:16.680
Finally at the end you can see that we need to run the application and here we use IP

101
0:08:16.680 --> 0:08:25.320
Iperf3 and we use it with MPTCP IH just to force it to create an MPTCP circuit.

102
0:08:25.320 --> 0:08:29.800
So the last table Linux kernel supports most of the protocol features.

103
0:08:29.800 --> 0:08:35.720
So using multiple subflows, announcing IP addresses, priority fast-close, which is the

104
0:08:35.720 --> 0:08:39.840
equivalent of TCP reset and many other things.

105
0:08:39.840 --> 0:08:44.080
It also supports many circuit options used by many apps.

106
0:08:44.080 --> 0:08:49.080
So for example TCP fast-open can be used with MPTCP for those who know what it is.

107
0:08:49.080 --> 0:08:54.660
And it's also important to support these options because some existing applications depends

108
0:08:54.660 --> 0:08:58.780
on them and would fail if they are not supported.

109
0:08:58.780 --> 0:09:04.960
It is also possible to retrieve information from the user space thanks to MIP counters,

110
0:09:04.960 --> 0:09:14.760
so also an INET-DAG interface and MPTCP circuit option, which is the equivalent of TCP info.

111
0:09:14.760 --> 0:09:20.400
It's also important to mention that two pass managers are available and one packet scheduler,

112
0:09:20.400 --> 0:09:23.600
but maybe better if I explain what it is.

113
0:09:23.600 --> 0:09:32.440
So quickly just about the MPTCP pass manager, so it's a component that is in charge of creating

114
0:09:32.440 --> 0:09:40.120
additional subflows, removing them if needed, announcing addresses, priority, etc.

115
0:09:40.120 --> 0:09:43.720
It is needed on both hands but serves different purposes.

116
0:09:43.720 --> 0:09:48.800
So for example here it is traditionally the client who creates new pass and the server

117
0:09:48.800 --> 0:09:53.760
which announce additional addresses.

118
0:09:53.760 --> 0:09:56.640
There are two pass managers available.

119
0:09:56.640 --> 0:10:02.440
One where the user can define global settings to get the same behavior for all the MPTCP

120
0:10:02.440 --> 0:10:09.520
connection, that's per net namespace, and also another one where the KNL notifies MPTCP

121
0:10:09.520 --> 0:10:14.360
events to user space via Netlink and accepts commands to create, for example, new subflow

122
0:10:14.360 --> 0:10:16.840
and announce IP addresses, etc.

123
0:10:16.840 --> 0:10:23.960
So ensure the user space can control the pass manager and take decision per connection.

124
0:10:23.960 --> 0:10:29.720
The other important component that I mentioned before is the MPTCP packet scheduler.

125
0:10:29.720 --> 0:10:36.920
Its role is to decide on which available pass the next packet will be sent to.

126
0:10:36.920 --> 0:10:42.240
So it can also decide to retransmit one packet to another pass if needed, and that's what

127
0:10:42.240 --> 0:10:44.960
we call a reinjection.

128
0:10:44.960 --> 0:10:51.640
The packet scheduler relies on the TCP congestion control algorithm used on each subflow to

129
0:10:51.640 --> 0:10:55.320
know if more data can be pushed.

130
0:10:55.320 --> 0:11:02.920
But additionally to better use all available resources and sometimes limited buffers, it

131
0:11:02.920 --> 0:11:07.880
has also to send packets in a way to reduce packet reordering on one side, but also on

132
0:11:07.880 --> 0:11:14.280
top of that it might decide to penalize some subflow that could impact the MPTCP connection

133
0:11:14.280 --> 0:11:20.000
because some networks are quite bad with losses, buffer bloat and others.

134
0:11:20.000 --> 0:11:26.640
So the packet scheduler in this case might also be able to trigger a reinjection of data

135
0:11:26.640 --> 0:11:33.640
from one subflow to another, like if a failure has been detected.

136
0:11:33.640 --> 0:11:39.760
So there is an internal packet scheduler for the moment, and only one, but other ones will

137
0:11:39.760 --> 0:11:43.840
be able to be built with eBPF.

138
0:11:43.840 --> 0:11:49.160
So yes, we need eBPF for the packet scheduler, and not just to look cool or to be accepted

139
0:11:49.160 --> 0:11:51.160
to conferences.

140
0:11:51.160 --> 0:11:58.000
So in fact, eBPF here will avoid us to maintain all sorts of different packet scheduler in

141
0:11:58.000 --> 0:11:59.000
the kernel.

142
0:11:59.000 --> 0:12:02.240
It's a bit similar to TCP congestion control.

143
0:12:02.240 --> 0:12:07.240
There are a few in the kernel, but sometimes no longer maintained.

144
0:12:07.240 --> 0:12:12.800
So quite a bit of work has already been done, and it is already possible to do some experimentation

145
0:12:12.800 --> 0:12:16.840
if you use a development version in OGetTree.

146
0:12:16.840 --> 0:12:21.160
But this work is currently on hold because we ended up discussing the behavior of the

147
0:12:21.160 --> 0:12:28.960
current internal scheduler and its API, and yes, some work is still needed here.

148
0:12:28.960 --> 0:12:36.040
But there are also some circuit options that need to be supported, but most likely they

149
0:12:36.040 --> 0:12:40.880
are specific to some very specific use cases.

150
0:12:40.880 --> 0:12:45.840
So it should be fine, but feel free to report them if some are missing.

151
0:12:45.840 --> 0:12:50.040
And one last thing that is worth mentioning is the support of Golang.

152
0:12:50.040 --> 0:12:57.360
As you may know, Golang does not depend on a C runtime library or libc, and it is then

153
0:12:57.360 --> 0:13:04.280
not possible to use the LD preload technique with MPTCPIs to use MPTCP.

154
0:13:04.280 --> 0:13:09.920
Also the default net package doesn't allow application to create MPTCP circuit on UDP

155
0:13:09.920 --> 0:13:18.440
or TCP, and a feature request has been sent to let apps easily create MPTCP circuit.

156
0:13:18.440 --> 0:13:25.000
But quickly the question Golang developers asked was, then why not using MPTCP by default

157
0:13:25.000 --> 0:13:27.080
when a stream connection is requested?

158
0:13:27.080 --> 0:13:30.240
So when asking for TCP.

159
0:13:30.240 --> 0:13:35.800
And the proposition has been accepted, so we hope that some application using the net

160
0:13:35.800 --> 0:13:42.480
package will be able to create MPTCP connection, and maybe later that will become the new default

161
0:13:42.480 --> 0:13:45.080
behavior.

162
0:13:45.080 --> 0:13:49.480
So I will now finish this presentation with a bit of history.

163
0:13:49.480 --> 0:13:55.600
I think it is worth telling you that because it was not easy to get MPTCP in the official

164
0:13:55.600 --> 0:14:00.240
Linux kernel, it could be good to say a few words about that.

165
0:14:00.240 --> 0:14:05.600
So still it was not as long an intense as having the full real-time support, and I see

166
0:14:05.600 --> 0:14:11.920
that some people here really know what I'm talking about.

167
0:14:11.920 --> 0:14:17.960
The development of MPTCP in the Linux kernel started in Belgium, at the university in Louvain

168
0:14:17.960 --> 0:14:21.080
and Eve, something like 15 years ago.

169
0:14:21.080 --> 0:14:23.760
Surprisingly, it didn't involve bees.

170
0:14:23.760 --> 0:14:25.720
No, of course it did.

171
0:14:25.720 --> 0:14:31.520
The legend says that the ID popped up when the young authors were drinking bees at a

172
0:14:31.520 --> 0:14:37.160
crowd pub where the bartender was able to cope with the high demand by using multiple

173
0:14:37.160 --> 0:14:42.680
bee pumps at the same time.

174
0:14:42.680 --> 0:14:47.960
More seriously, it started as a fork, but more to do some experimentation and to validate

175
0:14:47.960 --> 0:14:49.520
the concept.

176
0:14:49.520 --> 0:14:54.600
So at the beginning of his PhD, Sebastian just wanted to prove it could work.

177
0:14:54.600 --> 0:14:58.400
He started to modify TCP by adding more condition.

178
0:14:58.400 --> 0:15:03.680
So just if it is multi-pass TCP, do that, if not do something else.

179
0:15:03.680 --> 0:15:10.560
Later, more people, mostly Christophe and Gregory, joined the project to help Sebastian.

180
0:15:10.560 --> 0:15:16.480
They then took over his work to make it, let's call it, production ready, but also to be

181
0:15:16.480 --> 0:15:19.560
able to reach high performances.

182
0:15:19.560 --> 0:15:25.600
In other words, to get the modification in the Linux kernel were consequent and optimized

183
0:15:25.600 --> 0:15:29.640
for the MPTCP use case.

184
0:15:29.640 --> 0:15:36.480
In parallel, MPTCP v0 RFC has been published in 2013.

185
0:15:36.480 --> 0:15:42.320
The same year, a big company with a logo looking like an apple, if you see, announced its support

186
0:15:42.320 --> 0:15:44.520
for the client side.

187
0:15:44.520 --> 0:15:48.920
Of course they needed to have the support for the backend side, and I will let you imagine

188
0:15:48.920 --> 0:15:51.200
what they used.

189
0:15:51.200 --> 0:15:56.480
So if we concentrate on the very beginning of the project, we can say that it was easy

190
0:15:56.480 --> 0:16:00.680
to fork, but you will pay for it.

191
0:16:00.680 --> 0:16:05.480
Please don't read the two lines out of the context.

192
0:16:05.480 --> 0:16:09.720
But anyway, there are different utilization of a fork.

193
0:16:09.720 --> 0:16:11.960
You can pick your level.

194
0:16:11.960 --> 0:16:19.920
So I let you guess which one has been picked here, probably ultra-violence.

195
0:16:19.920 --> 0:16:22.160
Only because the Linux kernel is big.

196
0:16:22.160 --> 0:16:25.600
It's also complex, and the development is very active.

197
0:16:25.600 --> 0:16:31.520
So small modifications should not be difficult to maintain in a fork, but here we are talking

198
0:16:31.520 --> 0:16:39.040
about quite a lot of code, and an important part is modifying the network stack, which

199
0:16:39.040 --> 0:16:44.080
still has many adaptations specific to MPTCP.

200
0:16:44.080 --> 0:16:51.040
And in fact, from those that are even duplicated functions that were adapted for MPTCP case.

201
0:16:51.040 --> 0:16:56.200
So imagine that the code is modified on TCP side.

202
0:16:56.200 --> 0:17:00.880
We don't see it directly, and then we need to adapt it later to MPTCP.

203
0:17:00.880 --> 0:17:04.120
But still that was not the nightmare level.

204
0:17:04.120 --> 0:17:05.920
This is the nightmare level.

205
0:17:05.920 --> 0:17:12.560
So imagine that you have to deploy it on various embedded systems with different LTS kernels

206
0:17:12.560 --> 0:17:17.240
from very old version, like 3.4.

207
0:17:17.240 --> 0:17:22.320
So that's what we had to do at TESRS, and I explain why some of my colleagues here look

208
0:17:22.320 --> 0:17:28.240
like the avatar just by mentioning kernel backports.

209
0:17:28.240 --> 0:17:33.520
In the meantime, very old version have been deprecated, but thanks to the embedded system

210
0:17:33.520 --> 0:17:36.220
wall, this took time.

211
0:17:36.220 --> 0:17:43.960
So of course, this backboard job brought the drought of having to deal with many conflicts,

212
0:17:43.960 --> 0:17:49.240
but good tools like git re-re-re and top-git help a lot for that.

213
0:17:49.240 --> 0:17:55.400
So also add to that a bunch of batch script, and it was possible to automate most of this

214
0:17:55.400 --> 0:17:58.400
laborious task.

215
0:17:58.400 --> 0:18:01.600
Top-git allows us to create a tree with dependency.

216
0:18:01.600 --> 0:18:09.000
That's what we can not really clearly see on the side, but it's also very handy if a

217
0:18:09.000 --> 0:18:14.560
fork has to be maintained by a team where regular sync with the upstream have to be

218
0:18:14.560 --> 0:18:16.320
done as well.

219
0:18:16.320 --> 0:18:22.280
So at the end for us, what we were doing is that we were applying the patch at the bottom

220
0:18:22.280 --> 0:18:30.960
and then propagate it to all the kernel versions, and then we had to resolve a few conflicts.

221
0:18:30.960 --> 0:18:36.920
But likely we're not doing that too much.

222
0:18:36.920 --> 0:18:42.320
At the end, the fork is still quite well used today despite all the work that has been done

223
0:18:42.320 --> 0:18:44.960
on the upstream code.

224
0:18:44.960 --> 0:18:51.840
I even published new releases last Friday and probably one of the last one.

225
0:18:51.840 --> 0:18:57.760
But on the bright side, the migration process has started with just take time.

226
0:18:57.760 --> 0:19:03.160
The MPTCP support in the upstream kernel has started in 2020.

227
0:19:03.160 --> 0:19:05.000
Why a so long delay?

228
0:19:05.000 --> 0:19:10.400
Was it an homage to the Belgium Rideway company?

229
0:19:10.400 --> 0:19:13.120
It was not, in fact, a new idea.

230
0:19:13.120 --> 0:19:20.360
A few discussion and attempts have been made in the past, but were not successful.

231
0:19:20.360 --> 0:19:24.960
In our case, it was not an easy task to upstream MPTCP.

232
0:19:24.960 --> 0:19:32.200
First, because the Linux TCP stack is highly optimized, but also because the NetDev maintainers

233
0:19:32.200 --> 0:19:34.040
have been clear on that topic.

234
0:19:34.040 --> 0:19:39.200
It is okay to include MPTCP in the official Linux kernel, but the new implementation cannot

235
0:19:39.200 --> 0:19:45.720
affect the existing TCP stack, which means no performance regression, maintainable and

236
0:19:45.720 --> 0:19:52.400
possible to disable it, can be extended via user space.

237
0:19:52.400 --> 0:19:56.720
You know it's what I said earlier, you might already understand that we are not allowed

238
0:19:56.720 --> 0:19:59.640
to take the initial fork as it was.

239
0:19:59.640 --> 0:20:06.360
So it was built to support experiments and rapid changes, but not generic enough.

240
0:20:06.360 --> 0:20:12.600
Also at the end, it was and still used on environment where the majority of the connection

241
0:20:12.600 --> 0:20:16.920
are using MPTCP and not the opposite.

242
0:20:16.920 --> 0:20:19.000
So what were the solutions?

243
0:20:19.000 --> 0:20:22.080
A rewrite almost from scratch was needed.

244
0:20:22.080 --> 0:20:26.440
That's probably why it took so long to say, okay, we need to do it.

245
0:20:26.440 --> 0:20:32.340
A key difference with the upstream kernel is that a new circuit type is used.

246
0:20:32.340 --> 0:20:34.560
So there is no clean separation.

247
0:20:34.560 --> 0:20:41.520
The user space interacts with the MPTCP circuit, which controls the different TCP subfruits.

248
0:20:41.520 --> 0:20:51.160
Thanks to the TCP upper layer protocol, ULP, that was introduced in 2017 for KTLS, it was

249
0:20:51.160 --> 0:20:58.400
possible to minimize the modification in TCP code while still avoiding duplicating code.

250
0:20:58.400 --> 0:21:06.400
An SKB extension mechanism has also been initially developed for MPTCP, not to include the socket

251
0:21:06.400 --> 0:21:09.000
buffer side for the generic case.

252
0:21:09.000 --> 0:21:13.440
This is also used now by other components today.

253
0:21:13.440 --> 0:21:17.700
Also we had to be very careful when modifying the TCP stacks.

254
0:21:17.700 --> 0:21:22.480
So any ID to avoid that, we're good to take.

255
0:21:22.480 --> 0:21:27.660
One last point is that the APIs have been defined to have to maintain multiple versions

256
0:21:27.660 --> 0:21:34.280
of pass manager and packet scheduler in the kernel, even if the last one is still ongoing.

257
0:21:34.280 --> 0:21:38.920
But also one thing is that we needed to do a lot of work.

258
0:21:38.920 --> 0:21:44.560
Here I just want to say a special thanks to our ex-maintenor, Matt Martino and other fellows

259
0:21:44.560 --> 0:21:49.040
and Intel who had to step out very recently.

260
0:21:49.040 --> 0:21:53.320
In conclusion, it was a long road and it's not over.

261
0:21:53.320 --> 0:22:02.640
Thank you.

262
0:22:02.640 --> 0:22:03.640
Thank you.

263
0:22:03.640 --> 0:22:10.680
We have time for a couple of questions.

264
0:22:10.680 --> 0:22:17.040
Thank you.

265
0:22:17.040 --> 0:22:18.920
Just two quick questions.

266
0:22:18.920 --> 0:22:24.080
One, when you have multiple connections, can you kind of do it raid one sort of style,

267
0:22:24.080 --> 0:22:29.720
like where traffic goes on both simultaneously so that you don't have to resend something

268
0:22:29.720 --> 0:22:31.920
if something gets dropped?

269
0:22:31.920 --> 0:22:38.160
And can you speak also about SCTP and what's going on if it's dead or if you know?

270
0:22:38.160 --> 0:22:44.240
Because it's sort of in a similar space and I never understood why people focus more on

271
0:22:44.240 --> 0:22:46.280
MPTCP than SCTP.

272
0:22:46.280 --> 0:22:49.040
Thank you.

273
0:22:49.040 --> 0:22:57.000
I will maybe start just with the SCTP aspect because I don't know much about it.

274
0:22:57.000 --> 0:23:02.840
From what I remember is that here with multi-pass TCP, we do an extension to TCP.

275
0:23:02.840 --> 0:23:08.400
So most likely where TCP was working before, MPTCP can work.

276
0:23:08.400 --> 0:23:12.840
There are some exceptions with some nasty middle boxes, but I think that's the main

277
0:23:12.840 --> 0:23:18.360
reason why we can see multi-pass TCP in the field and maybe not SCTP.

278
0:23:18.360 --> 0:23:25.840
I think it is not dead and still used for data centers, but I don't know exactly about

279
0:23:25.840 --> 0:23:26.840
that.

280
0:23:26.840 --> 0:23:34.040
For the other question, I have not understood everything, you said that you wanted to aggregate

281
0:23:34.040 --> 0:23:35.040
multiple pass.

282
0:23:35.040 --> 0:23:40.040
I mean you have your two pass, can you send the same data simultaneously?

283
0:23:40.040 --> 0:23:41.040
Yes you can.

284
0:23:41.040 --> 0:23:47.160
So there is even a packet scheduler called redundant packet scheduler.

285
0:23:47.160 --> 0:23:55.760
There is one small bit that is important to mention is that each pass is still a TCP connection,

286
0:23:55.760 --> 0:23:59.920
which means that if you have some losses on one pass, you still need to retransmit it

287
0:23:59.920 --> 0:24:01.240
on the same pass.

288
0:24:01.240 --> 0:24:05.880
So at some point it might be okay to say that, okay, the other side received it via the other

289
0:24:05.880 --> 0:24:08.560
side, via the other pass.

290
0:24:08.560 --> 0:24:11.720
So if you got a loss on one pass.

291
0:24:11.720 --> 0:24:19.720
So the end host doesn't need it, but because there are middle boxes and others on the pass,

292
0:24:19.720 --> 0:24:23.400
you need to retransmit it at the TCP level.

293
0:24:23.400 --> 0:24:28.760
I don't know if it's clear, but you can do reinjection, but you need to continue retransmit

294
0:24:28.760 --> 0:24:29.760
on the same pass.

295
0:24:29.760 --> 0:24:34.560
You can't just, when you find it received that request, just drop it.

296
0:24:34.560 --> 0:24:37.360
If you want to do that, the best is probably to stop the connection.

297
0:24:37.360 --> 0:24:42.000
Like if you want to have a low latency thing, or if you want a low latency, maybe don't

298
0:24:42.000 --> 0:24:46.320
use TCP, but that's another question, not the topic.

299
0:24:46.320 --> 0:24:50.520
But if you want to do that, it's probably best to stop the pass and recreate it.

300
0:24:50.520 --> 0:24:54.320
Thank you.

301
0:24:54.320 --> 0:25:00.600
So I looked at the CCTLs for MPTCP, and I found one called DSS checksum.

302
0:25:00.600 --> 0:25:05.400
And reading the patch notes, it's something to do with middle boxes.

303
0:25:05.400 --> 0:25:08.080
So is that giving you issues?

304
0:25:08.080 --> 0:25:13.200
And why is it, and last question, pending that, why is it not on by default?

305
0:25:13.200 --> 0:25:15.080
Yes, no, good question.

306
0:25:15.080 --> 0:25:19.880
So in short, middle boxes are not nasty.

307
0:25:19.880 --> 0:25:24.360
They like to modify everything, and I will not comment too much about that because at

308
0:25:24.360 --> 0:25:30.160
my company, we do a transplant proxy, so we are kind of middle box.

309
0:25:30.160 --> 0:25:35.960
But what can happen is that middle boxes can change a lot of things in TCP.

310
0:25:35.960 --> 0:25:45.440
For example, you have all protocols, like FTP, where the IP address is sent on the by

311
0:25:45.440 --> 0:25:47.800
screen, but like in clear text.

312
0:25:47.800 --> 0:25:53.200
Which means that if you have a NAT, you probably have a NAT that starts to look at the connection,

313
0:25:53.200 --> 0:26:00.160
identify it is FTP, and modify the text in the by stream, like the IP addresses.

314
0:26:00.160 --> 0:26:02.960
But because it does that, the size can change.

315
0:26:02.960 --> 0:26:08.720
And if they don't update MPTCP header, because we need to add some information to be able

316
0:26:08.720 --> 0:26:16.120
to reassemble the data on the other hand, they can mess up with MPTCP.

317
0:26:16.120 --> 0:26:23.680
So there is this checksum mechanism, but there is one big inconvenience, is that for the

318
0:26:23.680 --> 0:26:28.400
moment, there is no hardware acceleration, so it's quite costly.

319
0:26:28.400 --> 0:26:35.240
And the other thing is that at the end, it's quite rare that you have some middle boxes

320
0:26:35.240 --> 0:26:37.480
modifying the by stream like that.

321
0:26:37.480 --> 0:26:42.520
I know that in the past, you had some, if you were going on some website, for example,

322
0:26:42.520 --> 0:26:48.000
with 480 without HTTPS, it's possible that some by stream were injected.

323
0:26:48.000 --> 0:26:52.720
And probably when they do the injection, they don't modify MPTCP.

324
0:26:52.720 --> 0:26:55.680
Sorry, we need to move on.

325
0:26:55.680 --> 0:26:56.680
Yeah, sorry.

326
0:26:56.680 --> 0:26:57.680
Otherwise we won't be on schedule.

327
0:26:57.680 --> 0:26:59.920
So that's why we don't have checksum, but thank you.

328
0:26:59.920 --> 0:27:00.920
Thank you so much for the talk.

329
0:27:00.920 --> 0:27:01.920
Thank you for the questions.

330
0:27:01.920 --> 0:27:13.080
Thank you very much.

331
0:27:13.080 --> 0:27:16.040
Thank you.

332
0:27:16.040 --> 0:27:24.400
Do you have a question?

