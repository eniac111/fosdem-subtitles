WEBVTT

00:00.000 --> 00:08.280
I am Gabor Sarnas and I'm here with David Proha.

00:08.280 --> 00:11.160
We work at CWI Amsterdam and we're here to

00:11.160 --> 00:13.980
present you the IDBC social network benchmark.

00:13.980 --> 00:15.440
What is the IDBC?

00:15.440 --> 00:18.480
The abbreviation stands for Linked Data Benchmark Council.

00:18.480 --> 00:21.320
It is a non-profit company founded in 2012,

00:21.320 --> 00:22.840
and its mission is to accelerate

00:22.840 --> 00:25.480
the progress in the field of graph data management.

00:25.480 --> 00:27.800
To this end, it designs and

00:27.800 --> 00:31.120
governs the use of graph benchmarks and everything we do

00:31.120 --> 00:34.480
is open source under the Apache version 2 license.

00:34.480 --> 00:36.600
From an organizational perspective,

00:36.600 --> 00:39.280
IDBC consists of more than 20 members

00:39.280 --> 00:42.320
who all have some vested interest in graph data management.

00:42.320 --> 00:45.040
We have financial service providers like the end group,

00:45.040 --> 00:48.500
database vendors like Oracle, Neo4j, and TIGR graph,

00:48.500 --> 00:50.520
cloud vendors like AWS,

00:50.520 --> 00:52.600
and hardware vendors like Intel.

00:52.600 --> 00:55.440
Also, we have individual contributors like David and

00:55.440 --> 00:58.000
me who contribute to the benchmarks.

00:58.000 --> 01:00.600
So to put things into context,

01:00.600 --> 01:03.200
the last two decades has seen a rise in

01:03.200 --> 01:06.360
the use of modern graph database management systems.

01:06.360 --> 01:09.120
Typically, the data model used in these systems is

01:09.120 --> 01:11.520
called the property graph which is a labeled graph,

01:11.520 --> 01:13.280
where both the nodes and the edges

01:13.280 --> 01:15.360
can have an arbitrary number of properties.

01:15.360 --> 01:18.400
For example, this is a small social network consisting of

01:18.400 --> 01:21.240
five person nodes and the single city node,

01:21.240 --> 01:22.800
which is the city of Spa.

01:22.800 --> 01:25.040
The properties can be on the nodes.

01:25.040 --> 01:28.160
For example, here the nodes have names and the edges have

01:28.160 --> 01:31.600
attributes like the date when the friendship was established.

01:31.600 --> 01:35.400
We can see that Bob and Carl met in 2015.

01:35.400 --> 01:38.240
If you want to run a query on the system,

01:38.240 --> 01:40.560
we can use a graph query where we

01:40.560 --> 01:42.720
look for matches of a given graph.

01:42.720 --> 01:46.260
So here, the query says we want to start from Bob.

01:46.260 --> 01:48.880
We want to use an arbitrary number of edges to reach

01:48.880 --> 01:51.680
some person who lives in Spa and we want

01:51.680 --> 01:55.460
to do an aggregation to return the number of those people.

01:55.460 --> 01:56.960
If you want to evaluate this,

01:56.960 --> 01:59.440
we then start from the person Bob,

01:59.440 --> 02:02.760
push to all the people transitively,

02:02.760 --> 02:06.480
which are known by Bob directly or via multiple edges.

02:06.480 --> 02:08.420
This means all four people here.

02:08.420 --> 02:11.600
We shrink it down to the people who actually live in Spa,

02:11.600 --> 02:14.600
then add up the results and get the result too.

02:14.600 --> 02:19.540
So graph databases use something called a visual graph syntax,

02:19.540 --> 02:22.040
also known as the SKR graph syntax,

02:22.040 --> 02:27.760
which is similar to the popular cipher language of Neo4j.

02:27.760 --> 02:30.040
Here, this query is actually really

02:30.040 --> 02:32.000
similar to the graph pattern that I have shown.

02:32.000 --> 02:34.760
So there are similarities in how the nodes are formulated,

02:34.760 --> 02:37.160
how the edges are captured in this text,

02:37.160 --> 02:39.760
and also how the transitive closure of

02:39.760 --> 02:42.280
the little asterisk is captured in the query language.

02:42.280 --> 02:46.680
So this is a very intuitive and concise way of formulating the queries.

02:46.680 --> 02:48.320
If we deconstruct this query,

02:48.320 --> 02:51.280
you can see three main components.

02:51.280 --> 02:52.760
The one is relational operators.

02:52.760 --> 02:55.240
Obviously, we still need relational operators.

02:55.240 --> 02:58.600
We want to be able to identify people by filtering.

02:58.600 --> 02:59.720
So we filter for Bob,

02:59.720 --> 03:00.940
we filter for Spa,

03:00.940 --> 03:02.960
and also we want to sometimes aggregate.

03:02.960 --> 03:06.000
So the count aggregation is part of this query.

03:06.000 --> 03:09.720
The pathfinding is really elegant in this formulation because we have

03:09.720 --> 03:13.720
nodes asterisk which captures that we can use an arbitrary number of edges.

03:13.720 --> 03:17.760
The pattern matching which connects the person to Spa is

03:17.760 --> 03:20.080
also very concise and readable.

03:20.080 --> 03:26.240
So what is interesting from a future of our perspective on graph databases?

03:26.240 --> 03:29.640
Obviously, relational operators are quite well known at this point,

03:29.640 --> 03:32.800
and there are endless papers and techniques on how to implement these.

03:32.800 --> 03:36.920
But we believe that pathfinding and pattern matching is really good in

03:36.920 --> 03:40.880
graph databases compared to traditional relational systems because they provide

03:40.880 --> 03:44.380
a more concise syntax and better algorithms and implementations.

03:44.380 --> 03:47.120
Interestingly enough, even in the last 15 years,

03:47.120 --> 03:50.840
there have been lots of papers on better BFS algorithms,

03:50.840 --> 03:54.880
better factorization representations for graph patterns,

03:54.880 --> 03:57.480
multi-waver, squares optimal joins, and so on.

03:57.480 --> 04:00.960
So we believe that this should be adopted by more and more systems.

04:00.960 --> 04:05.240
To this end, we designed benchmarks that try to push the state of the art and

04:05.240 --> 04:07.800
force systems to adopt better and better techniques.

04:07.800 --> 04:10.440
David, we'll talk about these benchmarks.

04:10.440 --> 04:15.040
Yeah. So I will give an overview about the social network benchmark.

04:15.040 --> 04:19.440
So first, we'll go through three steps of this benchmark.

04:19.440 --> 04:22.080
So the datasets, two example queries,

04:22.080 --> 04:25.000
and the update operations done in this benchmark.

04:25.000 --> 04:29.720
So here we see a small example of the datasets where on the left side,

04:29.720 --> 04:33.240
we see persons with friendships, forms, and network,

04:33.240 --> 04:37.840
and these persons post messages on the social network and can

04:37.840 --> 04:41.680
reply to each other forming a tree-shaped data structure.

04:41.680 --> 04:48.400
Now, we will do one query on this very small dataset example.

04:48.400 --> 04:52.280
So with query nine, we want to retrieve messages posted by

04:52.280 --> 04:58.240
a given person friends and friends of friends before a given date.

04:58.240 --> 05:00.280
The dates are here short for simplicity.

05:00.280 --> 05:02.720
So if we would start with Bob,

05:02.720 --> 05:05.880
we will traverse through their friends and friends of friends,

05:05.880 --> 05:11.560
retrieve the messages, and then filter out the ones that are actually before Saturday.

05:11.560 --> 05:14.960
Then we touch upon 10 nodes in this data.

05:14.960 --> 05:17.680
Suppose we would start from another person,

05:17.680 --> 05:19.360
so for example, Finn,

05:19.360 --> 05:23.960
and we traverse again to their friends and friends of friends.

05:23.960 --> 05:30.200
Here we see that we touched upon five different nodes,

05:30.200 --> 05:33.080
so half of the one of Bob.

05:33.080 --> 05:36.660
This difference can actually be troublesome

05:36.660 --> 05:40.800
since run times for the same queries are different,

05:40.800 --> 05:44.960
and therefore, it doesn't help in understanding what's happening.

05:44.960 --> 05:46.680
So for this benchmark,

05:46.680 --> 05:51.760
we actually want to select parameters that have similar run times,

05:51.760 --> 05:56.080
and also to actually stress the technical difficulties in these systems.

05:56.080 --> 05:59.920
So we select the parameters more carefully.

05:59.920 --> 06:04.560
So here we see a example of when we do not select the parameters carefully,

06:04.560 --> 06:06.040
just a uniform random,

06:06.040 --> 06:07.920
and we can see here a trial model,

06:07.920 --> 06:11.720
a distribution by model, and one with many outliers,

06:11.720 --> 06:14.040
and we don't want that.

06:14.040 --> 06:16.440
So in the datasets,

06:16.440 --> 06:18.560
there are also statistics provided.

06:18.560 --> 06:20.800
In this example,

06:20.800 --> 06:24.680
for each person, the number of friends and friends of friends,

06:24.680 --> 06:27.800
and then we want to select persons with

06:27.800 --> 06:31.960
similar number to get more predictable run times.

06:31.960 --> 06:33.960
So if we do that,

06:33.960 --> 06:38.080
then we can see here example that we have unimodal distributions,

06:38.080 --> 06:40.440
a bit very tight run times,

06:40.440 --> 06:47.160
and that improves also in understanding these behavior of the queries.

06:47.160 --> 06:50.320
So now we're going to the updates,

06:50.320 --> 06:55.280
and for example, if we have an GI who wants to be friends,

06:55.280 --> 06:57.040
we insert a nose edge,

06:57.040 --> 07:00.680
and this is then formed into the network.

07:00.680 --> 07:04.080
Suppose that the next operation is inserted in comments.

07:04.080 --> 07:08.560
So GI comments replies on a message posted by Eve,

07:08.560 --> 07:12.120
and both messages are posted on the same date.

07:12.120 --> 07:14.680
Then we have another problem,

07:14.680 --> 07:18.360
because when we are executing these operations concurrently,

07:18.360 --> 07:24.480
it can happen that the reply is earlier than the message in such a network,

07:24.480 --> 07:27.960
closing an error, and to mitigate this,

07:27.960 --> 07:31.200
we introduce dependency tracking.

07:31.200 --> 07:33.480
So for each operation,

07:33.480 --> 07:35.000
and also includes the edges,

07:35.000 --> 07:36.480
but just for simplicity,

07:36.480 --> 07:40.520
the notes are here with the dependent dates.

07:40.520 --> 07:45.280
We include for each operation a creation date and dependent date.

07:45.280 --> 07:49.240
The creation date is when it's scheduled to be executed,

07:49.240 --> 07:51.960
and the dependent date is the one that's like,

07:51.960 --> 07:53.520
in this case for M6,

07:53.520 --> 07:56.840
is the creation date of M3.

07:56.840 --> 08:02.040
Here, we can see actually that each operation is dependent on

08:02.040 --> 08:05.480
each other forming a whole chain in the social network.

08:05.480 --> 08:10.840
Suppose now that Eve wants to leave the social network and removes our account.

08:10.840 --> 08:14.080
So we start with deleting the notes Eve,

08:14.080 --> 08:16.040
and this will trigger cascading effects,

08:16.040 --> 08:19.720
but since we then need to remove the edges connected to Eve,

08:19.720 --> 08:21.640
the messages posted,

08:21.640 --> 08:25.080
and also the replies to those messages.

08:25.080 --> 08:29.800
We can actually see like there's this huge cascading effects,

08:29.800 --> 08:33.880
and that can actually have a large impact on the data distribution,

08:33.880 --> 08:38.040
and also therefore the executability of these operations.

08:38.040 --> 08:43.080
Furthermore, it also influences for selecting the parameters,

08:43.080 --> 08:44.920
which we have shown before,

08:44.920 --> 08:48.360
and we want to include this deletes because it prohibits

08:48.360 --> 08:50.400
appends only data structures in databases,

08:50.400 --> 08:53.560
and also stress the garbage collector of these systems.

08:53.560 --> 08:57.800
Now, we are going to give another example to also stress

08:57.800 --> 09:00.360
the temporal aspect of this benchmark.

09:00.360 --> 09:04.680
So suppose we want to find a path between two persons.

09:04.680 --> 09:08.080
So we have a start person and destination person,

09:08.080 --> 09:10.840
and for example, Finn and Gia.

09:10.840 --> 09:15.480
Then we can see here that we have a four-hole path between these persons.

09:15.480 --> 09:17.160
But at one point in the benchmark,

09:17.160 --> 09:21.720
it can happen that a note edge is removed,

09:21.720 --> 09:24.360
and then there is no path anymore.

09:24.360 --> 09:27.240
It can also happen that there's another edge

09:27.240 --> 09:28.880
inserted between Carl and Gia,

09:28.880 --> 09:31.280
and then we have a path again.

09:31.280 --> 09:33.880
So for the same parameters,

09:33.880 --> 09:36.280
we can actually have three different outcomes.

09:36.280 --> 09:39.400
To mitigate this, we do temporal parameter selection.

09:39.400 --> 09:43.640
So each parameter is assigned in a time bucket to actually ensure that

09:43.640 --> 09:48.520
we have similar results and therefore also similar run times.

09:48.520 --> 09:51.360
Now, going through the benchmark workflow,

09:51.360 --> 09:55.360
so we start by the data gen,

09:55.360 --> 09:57.000
and the data gen provides us with

09:57.000 --> 10:01.600
a temporal graph spanning of social media activity for three years,

10:01.600 --> 10:07.920
and it is simulated similar to Facebook social network.

10:07.920 --> 10:14.680
It's a Spark-based data generator that can generate data up to 30 terabytes,

10:14.680 --> 10:18.480
and it contains skewed datasets,

10:18.480 --> 10:24.400
for example, with the notes and person data in this data.

10:24.400 --> 10:29.840
So the output is a dataset suitable for loading into the system on a test,

10:29.840 --> 10:34.840
updates which are then executed during the benchmark,

10:34.840 --> 10:38.160
and statistics where we can select parameters.

10:38.160 --> 10:41.880
This election of the parameters is done in the parameter generator,

10:41.880 --> 10:45.040
and this ensures the stable query run times,

10:45.040 --> 10:47.960
and assigns parameters into a temporal bucket.

10:47.960 --> 10:52.760
So a parameter, it may include parameters that once are inserted

10:52.760 --> 11:00.120
into the datasets or before they are removed from the network.

11:00.120 --> 11:05.040
So then we have a benchmark driver who schedules these operations,

11:05.040 --> 11:10.520
and it ensures that they can be executed with using the dependency tracking,

11:10.520 --> 11:16.440
and this is especially important when executing the operations concurrently.

11:16.440 --> 11:20.600
Lastly, we have the system on the test where we have, for example,

11:20.600 --> 11:22.160
graph databases, triple stores,

11:22.160 --> 11:24.240
or relational databases, and now,

11:24.240 --> 11:27.760
Garber will go further into the workloads.

11:30.440 --> 11:34.480
Okay. So graph workloads are actually quite

11:34.480 --> 11:37.120
diverse in terms of what they are trying to achieve,

11:37.120 --> 11:40.440
and our benchmark reflects that by having multiple workloads.

11:40.440 --> 11:43.320
We have the social network benchmark interactive workload,

11:43.320 --> 11:45.440
which is transactional in nature.

11:45.440 --> 11:47.640
So it has loads of concurrent operations.

11:47.640 --> 11:50.120
The queries here are relatively simple.

11:50.120 --> 11:52.720
So they always start in one or two person nodes,

11:52.720 --> 11:55.280
the same as David presented before,

11:55.280 --> 11:58.680
and here the systems are striving to achieve a high throughput.

11:58.680 --> 12:02.760
So the competition is getting as many operations per second as possible.

12:02.760 --> 12:07.640
We are happy to report that we have official results from the last three years,

12:07.640 --> 12:11.440
where our system started with slightly above 5,000 operations per second,

12:11.440 --> 12:13.360
and have sped up exponentially,

12:13.360 --> 12:18.760
now being close to 17,000 operations per second on a 100 gigabyte dataset.

12:18.760 --> 12:23.200
The other workload of the social network benchmark is called business intelligence.

12:23.200 --> 12:27.600
This is an analytical workload where the queries touch on large portions of the data.

12:27.600 --> 12:32.760
For example, this query in this slide shows a case where we start from

12:32.760 --> 12:37.440
a given country and then find all triangles of friendships in that country.

12:37.440 --> 12:40.360
It's easy to see that this is a very heavy hitting operation.

12:40.360 --> 12:42.800
It may touch on billions of edges in the graph,

12:42.800 --> 12:46.600
and it also has to do a complex computation to find those people.

12:46.600 --> 12:51.800
So here, system can use either a bulk update or a concurrent update method,

12:51.800 --> 12:57.080
and they should also strive to get both the high throughput and low-query run times.

12:57.080 --> 12:58.880
This benchmark is relatively new.

12:58.880 --> 13:00.520
It was released at the end of last year,

13:00.520 --> 13:05.400
so we only have a single result which was done by a collaboration of Tiger Graph and AMD.

13:05.400 --> 13:08.720
We're happy to report that there are more audits underway,

13:08.720 --> 13:12.760
so we are going to release more results in 2023.

13:12.760 --> 13:16.200
So probably you can see from this presentation that

13:16.200 --> 13:19.960
these benchmarks can get fairly complex and implementing them is not trivial.

13:19.960 --> 13:23.680
So we did our best to provide everything our users need.

13:23.680 --> 13:25.720
For each of the workloads that we have presented,

13:25.720 --> 13:26.920
we have a specification,

13:26.920 --> 13:28.920
we have detailed academic papers who

13:28.920 --> 13:33.440
motivate the design choices and the architecture of these benchmarks.

13:33.440 --> 13:37.280
We release the data generator as well as pre-generated datasets,

13:37.280 --> 13:39.180
and we have benchmark drivers and

13:39.180 --> 13:42.200
at least two reference implementations for each of the workloads.

13:42.200 --> 13:45.880
Moreover, we have guidelines on how to execute these benchmarks correctly,

13:45.880 --> 13:48.160
how to validate the results of a given system,

13:48.160 --> 13:54.160
and how to ensure that the system will not lose your data or mingle up the transactions.

13:54.160 --> 13:57.760
So we have asset compliance tests and recovery tests.

13:57.760 --> 14:00.520
This leads us to our auditing process.

14:00.520 --> 14:01.920
Similarly to the TPC,

14:01.920 --> 14:04.240
the Transaction Processing Performance Council,

14:04.240 --> 14:07.600
we have a rigorous auditing process where vendors can

14:07.600 --> 14:10.560
commission an independent third party who will

14:10.560 --> 14:14.520
rerun the benchmark in an executable and reproducible manner,

14:14.520 --> 14:18.720
and they will write up it as a full disclosure report so that

14:18.720 --> 14:23.360
the benchmark is understandable by whoever wants to see that result.

14:23.360 --> 14:26.600
This is important because ad-dbc is trademarked worldwide,

14:26.600 --> 14:32.080
and we only allow official audited results to use the term ad-dbc benchmark result.

14:32.080 --> 14:35.880
This is not to say that we don't allow people to use this benchmark.

14:35.880 --> 14:40.480
Researchers, practitioners, and developers are welcome to use the benchmark.

14:40.480 --> 14:44.080
They can run it, they can report the results if it is accompanied by

14:44.080 --> 14:48.960
the appropriate disclaimer that this is not an official ad-dbc benchmark result.

14:48.960 --> 14:53.320
I would like to talk a bit about standard GraphQL languages.

14:53.320 --> 14:55.400
This is an important topic because this has been

14:55.400 --> 14:58.260
a pain point for Graph systems for many years.

14:58.260 --> 15:01.600
It's a bit of a tower of Babel out there with many languages,

15:01.600 --> 15:04.800
both of them using some visual Graph syntax,

15:04.800 --> 15:08.280
but always with slightly different semantics and a slightly different syntax,

15:08.280 --> 15:13.160
which makes it difficult for users to adopt these techniques and may put them in

15:13.160 --> 15:15.920
a position of being locked in by their vendors.

15:15.920 --> 15:18.560
So in the next couple of years,

15:18.560 --> 15:21.040
there are going to be new standard query languages.

15:21.040 --> 15:24.600
These focus on pathfinding and pattern matching.

15:24.600 --> 15:26.760
The first one is called SQL-PGQ.

15:26.760 --> 15:28.840
This is an extension to the SQL language,

15:28.840 --> 15:31.240
and PGQ stands for property graph queries.

15:31.240 --> 15:34.200
This is going to be released next summer,

15:34.200 --> 15:39.040
and GQL, the standalone GraphQL language is going to come out in 2024.

15:39.040 --> 15:42.480
We are happy to report that even though we have two new languages,

15:42.480 --> 15:44.520
the pattern matching core of them,

15:44.520 --> 15:48.800
the visual Graph syntax that we all know and love is going to be the same.

15:48.800 --> 15:52.560
So users can port at least those bits of their queries.

15:52.560 --> 15:54.920
To give you a taste of how this will look like,

15:54.920 --> 15:57.520
here is query nine that David presented in

15:57.520 --> 16:00.200
the social network benchmark interactive workload.

16:00.200 --> 16:02.480
This query can be formulated in SQL.

16:02.480 --> 16:04.920
It's not too difficult, but the new variants,

16:04.920 --> 16:09.840
SQL-PGQ and GQL can represent it as terms of a graph pattern,

16:09.840 --> 16:12.760
and this is a much more concise formulation.

16:12.760 --> 16:16.560
The difference is even more pronounced for query 13 with the path queries.

16:16.560 --> 16:19.320
Here, we can see that in SQL-PGQ,

16:19.320 --> 16:22.200
the pattern is really similar to the visual representation.

16:22.200 --> 16:23.840
It just has a source,

16:23.840 --> 16:26.680
a target, and arbitrary amount of

16:26.680 --> 16:29.560
nose edges denoted by nose asterisk in between.

16:29.560 --> 16:32.800
In SQL, this is a lot less readable,

16:32.800 --> 16:34.600
hard to maintain, and it's even less

16:34.600 --> 16:36.240
sufficient because it just implements

16:36.240 --> 16:38.600
a unidirectional search algorithm instead of doing

16:38.600 --> 16:42.320
a bidirectional search which has a better algorithmic complexity.

16:42.320 --> 16:46.320
The way IDBC is involved in these new query languages is manifold.

16:46.320 --> 16:50.240
First, it had the G-core design language released in 2018,

16:50.240 --> 16:52.200
which influenced these benchmarks.

16:52.200 --> 16:55.400
Then IDBC has the formal semantics working group which

16:55.400 --> 16:58.720
formalized the pattern matching core of these new languages.

16:58.720 --> 17:01.800
The IDBC is doing further research to

17:01.800 --> 17:05.680
conduct to advance the state of the art on graph schemas.

17:05.680 --> 17:08.480
We have an industry driven and a theory driven group,

17:08.480 --> 17:12.960
and what they do will end up in the new versions of these languages.

17:12.960 --> 17:16.360
An outlook is the IDBC Graph Analytics benchmark.

17:16.360 --> 17:22.400
This is a more wide benchmark because it can target analytical libraries like

17:22.400 --> 17:27.040
NetworkX, distributed systems like Apache Giraffe or the GraphBlast API.

17:27.040 --> 17:30.680
So this is everything that has to do with analyzing large graphs.

17:30.680 --> 17:33.240
Here, the graph is an untyped,

17:33.240 --> 17:36.440
unattributed graph so there are no properties or no labels.

17:36.440 --> 17:39.400
We do use the IDBC social network benchmark dataset,

17:39.400 --> 17:41.400
but it is stripped down to the person,

17:41.400 --> 17:43.080
knows person, core graph.

17:43.080 --> 17:45.640
Additionally, we have included a number of

17:45.640 --> 17:49.480
well-known datasets like Graph 500, Twitter, and so on.

17:49.480 --> 17:53.240
The algorithms that we run are mostly well-known graph algorithms.

17:53.240 --> 17:55.800
There is the BFS which starts from

17:55.800 --> 17:59.520
a given node and assigns the number of steps that need to be

17:59.520 --> 18:02.080
taken to all of the other nodes to reach them.

18:02.080 --> 18:05.680
We have the famous PageRank centrality algorithm which highlights

18:05.680 --> 18:07.800
the most important nodes in the network,

18:07.800 --> 18:11.760
and we have the local clustering coefficient,

18:11.760 --> 18:14.400
community detection using label propagation,

18:14.400 --> 18:17.160
weekly connected components, and shortest paths.

18:17.160 --> 18:20.760
So this benchmark is a bit simpler than the social network benchmark.

18:20.760 --> 18:23.360
It does not have a rigorous auditing process.

18:23.360 --> 18:26.880
We trust people that they can run this benchmark efficiently and

18:26.880 --> 18:30.560
correctly on their own infrastructure and they can report results.

18:30.560 --> 18:33.560
If they do so, they will be able to participate in

18:33.560 --> 18:35.120
the GraphRitix competition which has

18:35.120 --> 18:37.760
a leaderboard for the best implementations.

18:37.760 --> 18:41.360
So wrapping up, you should consider joining

18:41.360 --> 18:45.040
the IDBC because members can participate in the benchmark design.

18:45.040 --> 18:48.840
They have a say in where we are going in terms of including new features.

18:48.840 --> 18:51.380
They can commission audits if they are vendors,

18:51.380 --> 18:56.080
and members can gain access to these ISO standard drafts that I mentioned,

18:56.080 --> 18:57.800
CEQA, PGQ, and GQL.

18:57.800 --> 19:00.760
Otherwise, these are not available to general public.

19:00.760 --> 19:05.400
Pricing-wise, this is free for individuals and there is a yearly fee for companies.

19:05.400 --> 19:08.760
So to sum up, we have presented three benchmark,

19:08.760 --> 19:11.280
the social network benchmarks interactive workload,

19:11.280 --> 19:12.940
it's business intelligence workload,

19:12.940 --> 19:15.460
and the GraphRitix graph algorithms workload.

19:15.460 --> 19:16.860
We have more benchmarks.

19:16.860 --> 19:21.240
There is semantic publishing benchmark which is targeting RDF systems.

19:21.240 --> 19:24.160
Set in the media and publishing industry.

19:24.160 --> 19:27.240
There is the financial benchmark which is going to be released this year,

19:27.240 --> 19:30.080
which targets distributed systems and it uses

19:30.080 --> 19:33.620
the financial fraud detection domain as its area,

19:33.620 --> 19:36.680
and it imposes strict latency bounds on queries.

19:36.680 --> 19:39.540
So this is quite a different workload from the previous ones.

19:39.540 --> 19:43.520
Of course, graphs are ubiquitous and they have loads of use cases.

19:43.520 --> 19:45.840
So there are many future benchmark ideas

19:45.840 --> 19:48.680
including graph neural network, mining, and streaming.

19:48.680 --> 19:51.720
Thank you very much and we're open to any questions.

19:57.240 --> 19:59.000
Yes.

19:59.000 --> 20:00.560
So in this one overview,

20:00.560 --> 20:04.760
that was the graph dataset and the updates were separated.

20:04.760 --> 20:10.000
Is there a possibility to create a graph dataset where the updates are included in

20:10.000 --> 20:15.400
the dataset so that nodes and vertices get timestamps when they were deleted or when they were added?

20:15.400 --> 20:19.560
Yes. So the question is, is it possible to create something like

20:19.560 --> 20:25.520
a temporal graph with the timestamps of when the specific node is created and deleted?

20:25.520 --> 20:30.840
This is actually very easy because this is the first step that the DataGen creates.

20:30.840 --> 20:35.240
So when David said that it creates a social network of three years,

20:35.240 --> 20:39.240
that has everything that was ever created or deleted during those three years,

20:39.240 --> 20:42.520
and then we have attributes like creation date and deletion date.

20:42.520 --> 20:45.360
Then we turn it into something that's loadable to the database.

20:45.360 --> 20:50.560
We hide deletion dates because the database of course shouldn't be aware of this.

20:50.560 --> 20:55.000
But this is something that the DataGen supports out of the box.

20:55.000 --> 21:01.920
Okay. But then also to get this dataset with the deletion dates because you've already said it's hideable.

21:01.920 --> 21:07.760
It's hideable but we have one which is called the row temporal dataset and that is available.

21:07.760 --> 21:13.200
We even published that. So that's something that has a lot of

21:13.200 --> 21:16.520
chance to be influential in the streaming community I believe.

21:16.520 --> 21:24.640
All right. More questions. Yeah, Michael.

21:24.640 --> 21:29.240
Do you plan to extend to other domains from that perspective?

21:29.240 --> 21:30.800
So you have to social network one.

21:30.800 --> 21:31.200
Yeah.

21:31.200 --> 21:32.640
But it's an interesting one.

21:32.640 --> 21:35.020
It's for the retail or Netflix,

21:35.020 --> 21:40.560
Spotify, these user interactions on a more product and come out of one.

21:40.560 --> 21:44.440
I mean, you could map it to your style,

21:44.440 --> 21:47.920
but what are the other networks that are types of network?

21:47.920 --> 21:51.000
So the question is, can we extend to other domains?

21:51.000 --> 21:54.960
We usually emphasize that social networks is not really

21:54.960 --> 21:58.720
the domain that is the actual primary use case for graphs.

21:58.720 --> 22:01.320
We just use this because this is really easy to understand.

22:01.320 --> 22:03.480
We don't have to explain person to person.

22:03.480 --> 22:09.160
You can put in all sorts of interesting technological challenges to a graph domain like this.

22:09.160 --> 22:14.360
It would make sense and sometimes we are approached by our members saying,

22:14.360 --> 22:17.640
we want to do a new benchmark in the domain X,

22:17.640 --> 22:21.800
and we then send them the process that is

22:21.800 --> 22:24.740
required to get one of these benchmarks completed,

22:24.740 --> 22:26.800
and that's usually the end of the conversation.

22:26.800 --> 22:31.240
But we are definitely open to have more interesting benchmarks.

22:31.240 --> 22:35.120
Of course, a good data generator is worth gold

22:35.120 --> 22:38.480
to all the researchers and the vendors in this community.

22:38.480 --> 22:41.440
So that's usually a hard point and I would be

22:41.440 --> 22:44.880
definitely interested in having retail graph generator.

22:44.880 --> 22:46.360
Carlo?

22:46.360 --> 22:49.560
Hi. Question is basically,

22:49.560 --> 22:56.880
what do you see the impact of this will be on the industry as in it's pushing into,

22:56.880 --> 23:01.120
or it's more of a paradoxical evidence if

23:01.120 --> 23:08.880
the system would have improved or a system will get more robust as in that you detect stuff,

23:08.880 --> 23:13.480
just doing things and stuff get fixed or what was the?

23:13.480 --> 23:17.760
Yeah. So the question is about the potential impact.

23:17.760 --> 23:19.720
What could all this achieve?

23:19.720 --> 23:27.360
We believe that it will help accelerate the field in the sense that systems will get more mature,

23:27.360 --> 23:29.720
because if you want to get an audited result,

23:29.720 --> 23:32.000
you have to pass all the asset tests,

23:32.000 --> 23:35.040
you have to be able to recover after a crash,

23:35.040 --> 23:37.240
and ideally you would have to be fast.

23:37.240 --> 23:41.440
So that is hopefully one of the other things that systems will take away.

23:41.440 --> 23:43.940
They will have better optimizers,

23:43.940 --> 23:48.040
improved storage, better query execution engines.

23:48.040 --> 23:52.280
We have seen this in the aftermath of the TPC benchmarks.

23:52.280 --> 23:56.020
So those resulted in quite a big speed up.

23:56.020 --> 23:58.120
So that's one area.

23:58.120 --> 23:59.920
Of course, there is pricing.

23:59.920 --> 24:04.280
We would like that users can get more transactions per dollar.

24:04.280 --> 24:09.200
The third that we are personally quite interested in is the new accelerators that come out.

24:09.200 --> 24:12.040
So especially in the field of machine learning,

24:12.040 --> 24:16.000
there are cards that do fast sparse matrix multiplications.

24:16.000 --> 24:20.760
Those could be harnessed specifically for the analytical benchmarks that we have,

24:20.760 --> 24:25.100
and that would be interesting to see how big of a hassle it is to implement,

24:25.100 --> 24:29.160
and how big of a speed up they give.

24:30.000 --> 24:33.480
Cool. All right.

24:33.480 --> 25:02.840
Okay. Thank you very much.
