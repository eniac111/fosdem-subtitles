WEBVTT

00:00.000 --> 00:18.080
Okay, so hello, I'm Pavel Machek and I'm here to talk about cameras, but you can also talk

00:18.080 --> 00:26.600
to me about clicker train horses, mobile phones, kernel, smartwatch based on ESP32, Mobian

00:26.600 --> 00:36.200
or Malmo Vastar. So first thing first, video phones is not for cameras, it's for frame

00:36.200 --> 00:41.920
zebras and they are really very different, which is basically what this talk will be

00:41.920 --> 00:50.000
about. They can do remote controls, but they cannot do autofocus for you and so on. But

00:50.000 --> 00:56.200
the interface is fairly simple, you just open the video zero, select format and capture.

00:56.200 --> 01:05.280
Unfortunately what you get is blurry photo, which will be either all white or all black.

01:05.280 --> 01:14.440
This is with autofocus and auto something. Anyway, there are phones with smart sensors,

01:14.440 --> 01:21.840
one such example is pine phone and those are pretty close to the frame zebras. They do

01:21.840 --> 01:27.920
basically everything in hardware. This used to be a pretty common design in the past,

01:27.920 --> 01:34.760
which made a good sense at this point because USB had limited bandwidth and you could not

01:34.760 --> 01:42.040
push uncompressed data through it. It's easy to standardize, but it doesn't make much sense

01:42.040 --> 01:49.040
today. If you have like five lens on your phone, you don't want to have five JPEG and

01:49.040 --> 01:57.360
what can I call this there? So we are moving to dump sensors, which basically do bare minimum.

01:57.360 --> 02:04.560
There use parameters like exposure, gain, select area and so on. And it just passes

02:04.560 --> 02:13.000
the bare data over the fast bus and it usually ends up in your memory. And then you have

02:13.000 --> 02:21.120
component called ESP, which is image signal processor, which will do the JPEG conversion

02:21.120 --> 02:28.320
and such stuff. Unfortunately in case of the interesting phones, which is official Librem

02:28.320 --> 02:35.480
5, Pine Phone and Pine Phone Pro, we either don't have the processor or we don't have

02:35.480 --> 02:43.600
drivers for that. So this is how the image, this is a photo if you try to take it without

02:43.600 --> 02:52.920
the automatics. Can you recognize what's there? It's a USB connector. It's recognizable, I'd

02:52.920 --> 03:04.240
say. So what do we need to do? Nokia N900 is another example of complex design, which used

03:04.240 --> 03:10.280
to be very important historically. And actually the photos in the presentation are from N900

03:10.280 --> 03:16.760
with open source. In the real time, you need to do auto exposure because otherwise you

03:16.760 --> 03:23.160
will have black or white frame and you need auto exposure for auto focus. On most cameras

03:23.160 --> 03:27.880
you really want auto focus too because you can just focus to infinity and expect good

03:27.880 --> 03:33.040
image. And that's pretty much everything you need to do for the video recording in the

03:33.040 --> 03:40.120
real time. Then you have preview. Preview is a bit less important than the video recording,

03:40.120 --> 03:45.360
but it's also important. You will need to convert from buyer to RGB and you need to

03:45.360 --> 03:50.880
do gamma correction because the sensors are linear in one side and exponential on the

03:50.880 --> 04:00.120
other side. GPU can help here. And then there are extensive post processing steps like auto

04:00.120 --> 04:07.160
white balance, lens shading compensation, getting rid of bad pixels and probably many

04:07.160 --> 04:14.680
others I forgot about. Advantage of this is that this can be done after taking photos

04:14.680 --> 04:22.600
or after the video. And they are quite good tools for that, including rotaryp, euro and

04:22.600 --> 04:32.800
so on. So people were working unlike the other parts. This got some work done before. So

04:32.800 --> 04:39.240
what we are talking, for example, on the N900 you have LED flash, which is completely independent

04:39.240 --> 04:46.560
device. You have voice coils support for auto focus, which is again, it's a powered device

04:46.560 --> 04:52.680
somewhere on I2C. Then you have two sensors, front and back camera. You have GPIO switch

04:52.680 --> 05:00.080
to select which camera you want. And then you have ISP, which is quite a complex piece

05:00.080 --> 05:09.040
of hardware, which will not be important for this presentation because it will do without

05:09.040 --> 05:19.960
it. So tools to use. There is a great set of tools to use, but they have some limitations

05:19.960 --> 05:26.960
each. One which looks very nice is Gstreamer. And Gstreamer is really great if you have

05:26.960 --> 05:35.520
an unlimited CPU. Unfortunately, you don't have unlimited CPU. It's like if I was willing

05:35.520 --> 05:40.920
to hack its C code, it would be very powerful. But there is some learning curve involved

05:40.920 --> 05:50.200
in that too. And at the end, Gstreamer might be right to use, but I found other tools easier.

05:50.200 --> 05:58.200
There's FFF pack, which has quite nice and very simple command line interface. So I used

05:58.200 --> 06:03.660
it at the end. I didn't really need much. Just please take these images and compress

06:03.660 --> 06:11.040
me every video from there. There's megapixels. Megapixels is a very nice application focused

06:11.040 --> 06:18.000
on mobile phone, very well optimized, but its origin is pine phone and they don't use

06:18.000 --> 06:27.520
left camera there. So, not quite suitable. Then there's left camera. Everybody says left

06:27.520 --> 06:36.320
camera is future of video on Linux. It probably is, but there are still many steps to get

06:36.320 --> 06:45.680
there. And there's megapixels. Megapixels is fork of megapixels, which is ported to Libram

06:45.680 --> 06:53.360
5 and to lead camera more importantly. So in many ways, so megapixels actually currently

06:53.360 --> 06:59.280
looks nicer because it is based on newer GTK. On the other hand, megapixels use lead camera

06:59.280 --> 07:09.920
and that's important stuff. Okay. So this will be a bit of history and reasons and so

07:09.920 --> 07:17.000
on. I started to play with camera on pine phone and first idea was, hey, Gstreamer is

07:17.000 --> 07:23.280
there to capture video. Let's use Gstreamer, right? Okay. I started capturing raw bare

07:23.280 --> 07:31.120
data because that's what should be most portable. I did some shell scripting, media control

07:31.120 --> 07:38.560
to set up the pipelines. That's not fun. And then just use Gstreamer to save the bare images

07:38.560 --> 07:47.880
to the disk and I could do 200 kilopixels, which is not great, but better than no video

07:47.880 --> 08:00.320
at all maybe. And I realized that CPU can compress at 70 kilopixels images in real time,

08:00.320 --> 08:06.960
which is, well, people were doing this, but it's some time ago. So I tried to improve.

08:06.960 --> 08:16.640
There is IOVU format, the camera could do, which is the bare and converted to like for

08:16.640 --> 08:25.440
better processing. And I could capture up to 0.9 megapixel video with that. And if you

08:25.440 --> 08:33.880
were wanted, you could can take a look there. Maybe it's useful for someone, but well, there

08:33.880 --> 08:42.160
was a reason. The reason was called corrimatory and someone in Gstreamer decided to do a regression

08:42.160 --> 08:51.240
basically and all the Gstreamer stuff stopped working. And I realized that well, perhaps

08:51.240 --> 08:58.720
it wasn't good, too great to start with anyway. So I started looking around quickly. I found

08:58.720 --> 09:05.480
a lit camera, which is the future, right? And well, it's C++. It didn't work at all

09:05.480 --> 09:13.120
on pine phones. So I had to do some quite heavy patching. I get some help on the mailing

09:13.120 --> 09:21.120
list and I realized it has JPEG support, which is well, you avoid a lot of stuff because

09:21.120 --> 09:28.720
if JPEGs are already called space converted and compressed and so on, and I realized that

09:28.720 --> 09:37.560
maybe JPEG is work having second look. So I did. You can save data into megapixel resolution

09:37.560 --> 09:47.600
to flash because the flash is not fast enough, but it was like almost possible. So hey, JPEGs

09:47.600 --> 09:53.560
are four times smaller. Perhaps this could be adjusted and saving some this easy. So

09:53.560 --> 10:03.520
maybe we can, well, maybe we already have everything we need. And this is why how Unix

10:03.520 --> 10:12.560
camera was born. I realized second reason someone decided that pacing uncached data

10:12.560 --> 10:20.000
to user space is fun thing to do and the camera decided that passing a memory up to the application

10:20.000 --> 10:29.400
is great. I saw someone told my CPU because the performance penalty is about 10 times,

10:29.400 --> 10:35.800
but not it's just the way it is. I believe this needs to be fixed. If you fight with

10:35.800 --> 10:42.920
the streamer and the performance seems too bad, this is probably why it's too bad. And

10:42.920 --> 10:49.560
why I don't know, talk to your kind of person which can change it. By the way, in the old

10:49.560 --> 10:57.320
days we used to have a read interface to get data from the camera. This is deprecated.

10:57.320 --> 11:04.080
Of course it is faster to read the data than to get an cache memory, right? That's how

11:04.080 --> 11:13.560
badly uncached memory sucks. Anyway, so Unix camera started. Audio is really simple. You

11:13.560 --> 11:19.920
just create a small application to sound record sound, split it to chunks so you can have

11:19.920 --> 11:25.720
easy processing later and timestamp them, which is important for synchronization. Live

11:25.720 --> 11:33.760
camera with some small hacks can write 35 frames per second to megapixel this data to

11:33.760 --> 11:40.280
the file system. All you need to do is edit timestamp and sim link so your preview can

11:40.280 --> 11:48.440
tell you which is the latest image. Very easy. Control application, you probably don't want

11:48.440 --> 11:53.560
to start your video recognition from command line, but that's also very easy. You just

11:53.560 --> 12:03.040
take some GTK and Python. It creates timestamps, tailing, hey, start recognition now, and displays

12:03.040 --> 12:10.800
preview which is the most intensive thing there. This is basically what runs during

12:10.800 --> 12:17.360
the recording. This is to be a bit optimized. Post processing is not that important, right?

12:17.360 --> 12:25.400
So you just use Python to compress the resulting video stream. This is something I was pretty

12:25.400 --> 12:30.880
happy about. If you want to duplicate it, you will need some setup like patching the

12:30.880 --> 12:39.760
camera and so on, but code is out there and there will be easier method in future. So

12:39.760 --> 12:45.120
I like the solution because I could use multiple languages to do my camera recording, write

12:45.120 --> 12:51.440
language for the job. In the end, this was few hundreds of lines of code total. And it

12:51.440 --> 12:56.880
could do some quite interesting stuff, like you could take still pictures during recording.

12:56.880 --> 13:03.320
You simply copy the JTAG one more time. Easy. In video resolution, but if you are recording

13:03.320 --> 13:10.680
it at two megapixels from phone camera, I'd say this is going to be pretty decent picture

13:10.680 --> 13:17.000
anyway. You could take photos with arbitrary delay. You could even take photos before the

13:17.000 --> 13:21.040
user asked for them because you are taking all of them anyway, so you just don't delete

13:21.040 --> 13:35.480
them. This was fun. Then I've got access to Libram 5, which is different in important

13:35.480 --> 13:43.400
ways. It has dump sensor, so it won't give you JPEG. But it had better support. Let camera

13:43.400 --> 13:49.640
work there out of the box. There was millipix application. As I explained about before,

13:49.640 --> 13:57.280
it matched megapixels, but it had no auto exposure, auto weight balance or auto focus

13:57.280 --> 14:06.200
support. It couldn't report video. And there's more issues on Libram 5. Can you use some

14:06.200 --> 14:12.040
work? It only gives you 8-bit data, which is not really good enough for good photos.

14:12.040 --> 14:19.680
You can select one of these three resolutions, so megapixels, 3 megapixels or 13 megapixels.

14:19.680 --> 14:29.720
And for some reason, only 23.5 frames per second work. I don't know why. Hardware has

14:29.720 --> 14:36.080
face detection auto focus, which is a very cool sounding toy. And I have to thank Purism

14:36.080 --> 14:46.160
for their hardware and for the great work they did on the software stack. They are heroes.

14:46.160 --> 14:55.920
This is the best photo I got with Nokia 900. So millipixels. They are very simple application.

14:55.920 --> 15:01.560
There's small development teams, so it's easy to work with. It's plain C. It's easy to merge

15:01.560 --> 15:07.040
patches. It does all the processing on the CPU, which is great if you want to change

15:07.040 --> 15:15.240
the processing. So I started to do auto exposure because that's the most important part. And

15:15.240 --> 15:25.080
I did a very simple one. I prototyped on N900 years ago. So basically, if you have too much,

15:25.080 --> 15:33.640
two white pixels overexposed, you need to turn down the exposure. And if you don't have

15:33.640 --> 15:41.200
enough white enough pixels, you need to turn the exposure up. And this is it. And this

15:41.200 --> 15:46.400
works well enough. It takes a few seconds to converge. It can be improved. I don't know

15:46.400 --> 15:56.040
how to do that, but this is good enough to take photos. Other thing is auto white balance.

15:56.040 --> 16:00.200
This is not that important because you can do it in post-processing. Anyway, they did

16:00.200 --> 16:07.040
have manual white balance, so I felt it is easy enough to do. It will need some more

16:07.040 --> 16:13.720
work. Again, if it's too blue, you make it more red. If it's too red, you make it more

16:13.720 --> 16:22.840
blue. That's it. It works well enough. And in a few hundred lines of code, I had simple

16:22.840 --> 16:32.280
software only. Auto exposure, and I got that merged. Next step is autofocus. Autofocus

16:32.280 --> 16:40.360
is something which deserves more respect because you really want it tuned. But, well, if you

16:40.360 --> 16:46.440
want to do it simply, you just start from the infinity. You compute the blurriness of

16:46.440 --> 16:52.040
each frame, and you only need to take a look at part of the image if you want to save your

16:52.040 --> 16:58.040
CPU. And you start your sweep. You start to bring the focus closer. And when the image

16:58.040 --> 17:04.280
gets more blurry, well, you stop. You might want to go a little bit back because of the

17:04.280 --> 17:11.960
physical issues of the lens. But this works, well, better than manual focus. And I got

17:11.960 --> 17:21.240
it merged rather quickly. Next step was video. So I decided that I liked the ideas from the

17:21.240 --> 17:30.520
Unixi camera and simply did 0.8 megapixels recording directly to the disk. I hacked millipixels

17:30.520 --> 17:38.280
to save timestamp frames and left post processing after the user presses the stop button. Easy

17:38.280 --> 17:46.200
to do. Obvious to their disadvantages, right? You are now limited by the disk space. And

17:46.200 --> 17:51.000
maybe you could say it's not quite nice to the flash to just stream raw data to it.

17:51.800 --> 17:59.000
But hey, the flash is cheap and the phone will die anyway. Post processing is quite long. It

17:59.000 --> 18:06.200
takes five times slower than recording. I guess this could be optimized. This is again my old

18:06.200 --> 18:15.800
code. So I'm Python with FFmpeg. Ideally, that is hard to do the encoding. We should use it.

18:15.800 --> 18:23.880
But I feel that doing that is awful lot of work. Anyway, this is now upstream. So if you

18:23.880 --> 18:33.000
update your Libram 5, you should be able to take video. And I believe it's important to have

18:33.000 --> 18:41.160
something other than recording. Next thing I want to talk about, which is very exciting,

18:41.160 --> 18:49.160
is face detection autofocus. You may want to Google it for nice explanations.

18:49.160 --> 18:56.520
But basically, they have selected some blue pixels. They are special. And they are special

18:56.520 --> 19:04.440
in a way that they only take light from certain directions. So you have a lens. And if it's focused,

19:04.440 --> 19:13.960
it's okay. The light comes and meets at the sensor. But if you are autofocus, funny stuff happens.

19:13.960 --> 19:25.480
And the light from the left of the image ends up at a different place on the sensor than the light

19:25.480 --> 19:33.480
from the right part of the lens. But if you block the light based on the direction on the chip,

19:33.480 --> 19:42.760
which is easy to do, you can use it for focus. So if you take a line from the sensor, and you have

19:42.760 --> 19:49.960
the on the top, you will have left special pixels. And on the bottom, you have right special

19:49.960 --> 19:56.600
pixels, for example, then you have this, the three, you will see on the line will be at different

19:56.600 --> 20:03.960
positions on different special pixels. Well, and you can use this to focus, right? You just compute

20:03.960 --> 20:12.200
correlation between the two lines. And it directly tells you how much autofocus you are, and in which

20:12.200 --> 20:22.120
direction you should focus. This was great to play with. It was like hacking. Unfortunately,

20:22.120 --> 20:29.480
it is not too usable on LeBron five. They are two issues for the special pixels are quite far apart,

20:30.120 --> 20:36.680
which they basically have to because if you made all the pictures special, you would have you would

20:36.680 --> 20:44.040
lose your resolution. And it only works in the high resolution mode. And you don't want to run

20:44.040 --> 20:49.800
your preview in high resolution mode. So if someone is interested in a fade detection autofocus,

20:49.800 --> 20:55.240
I have the code code this on the on the GitLab somewhere. It was fun experiment, it worked.

20:56.600 --> 21:03.560
But I decided like, for your focus, you would probably do have to do hybrid like

21:03.560 --> 21:08.520
do course focus using the fade detection, and then do contrast detection on the on the end.

21:09.640 --> 21:17.160
Seems like a lot of work. And with the driver, which will only give you 23 frames per second,

21:17.160 --> 21:30.440
and so on. Well, I decided not to take this much. So I have some wish lists. And I think I have like

21:30.440 --> 21:36.040
five minutes left. So five minutes talking or five minutes questions, including everything,

21:36.600 --> 21:43.400
including everything. Okay, so I have a long wish list for all the world. I would like to have

21:43.400 --> 21:49.240
better media control support in the tools because it doesn't work. A piece changed and the tools

21:49.240 --> 21:55.640
didn't catch up. I would like library to get conversions between formats and so on, I would

21:55.640 --> 22:02.040
like better than a bit support. I would like multiple applications accessing the camera at

22:02.040 --> 22:09.000
the same time. Better support would be nice. And someone should really solve the question

22:09.000 --> 22:16.360
problem because that's bad. For live camera, I shouldn't be really hacking the pixels,

22:16.360 --> 22:23.160
I should be helping the camera. But live camera doesn't support software ISP. And I'm not a great

22:23.160 --> 22:30.120
C++ hacker, so I could do it, but they will reject the patches if I do. So I would much prefer them

22:30.120 --> 22:37.240
to do to do the preparation and then I would fill the code. And that's pretty much it. So time for

22:37.240 --> 22:39.640
questions.

22:39.640 --> 22:53.080
Sorry?

22:59.960 --> 23:03.160
Okay, so the comment is that they want my work on software ISP.

23:03.160 --> 23:12.520
And I guess I will want to cooperate, but live camera is not easy to hack for me because of the

23:12.520 --> 23:20.040
C++ stuff. So be patient and I may be... maybe it would be better if someone else did it.

23:20.040 --> 23:33.080
Yes, so well, there will not be much to see. So, you know, Millipix could use some work too,

23:33.080 --> 23:42.280
but I can take pictures. Trust me. I didn't use autofocus for this because...

23:42.280 --> 23:50.360
Yes, I can do it.

23:50.360 --> 23:57.000
Ah, okay. So it's no upstream, so you can just update your operating system and you will get one.

23:57.720 --> 24:04.200
And it should be possible to do just a short video recording too. So now you have all been

24:04.200 --> 24:14.600
recorded and now the CPU is busy converting that. And battery is low now. Yeah, somewhat. Okay, more questions?

24:14.600 --> 24:32.840
Okay, so I guess...
