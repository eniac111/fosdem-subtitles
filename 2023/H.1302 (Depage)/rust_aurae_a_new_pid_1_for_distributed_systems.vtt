WEBVTT

00:00.000 --> 00:07.000
Check, one, two, hello.

00:07.000 --> 00:08.000
Hello.

00:08.000 --> 00:10.000
Hi, where's Malte?

00:10.000 --> 00:13.000
Hi, nice to meet you.

00:13.000 --> 00:18.000
Okay, sorry, just like one of my hacker friends has been working with me on the project.

00:18.000 --> 00:22.000
I've actually never met him in person, so nice to meet you.

00:22.000 --> 00:28.000
Anyway, today we're going to be talking about Aura or Aude, however you want to pronounce it, is fine,

00:28.000 --> 00:31.000
which we're temporarily calling a distributed systems runtime,

00:31.000 --> 00:38.000
and that's the name that has caused the least amount of friction over the past few months.

00:38.000 --> 00:42.000
Okay, so my least favorite slide, my slide about me.

00:42.000 --> 00:47.000
So I'm an engineer, I work at GitHub, I help keep GitHub.com online.

00:47.000 --> 00:52.000
Sorry about the Shaw thing last week.

00:52.000 --> 00:55.000
Yeah, so I keep a lot of systems online.

00:55.000 --> 00:59.000
Some of you may or may not use them, all of you hopefully have good opinions of them.

00:59.000 --> 01:04.000
And then if you want to follow me on the Fetaverse, there's where you can follow me.

01:04.000 --> 01:07.000
So I'll do overview and context.

01:07.000 --> 01:13.000
So if you want to go to the GitHub repo, you can grab a photo of this or just remember it.

01:13.000 --> 01:18.000
The link to the slides are there right now, I just forced push to main like two seconds ago.

01:18.000 --> 01:24.000
So you can go and you can see the slides and there's like links to everything there that I'll be going over today.

01:24.000 --> 01:27.000
So if you want to grab that, go ahead and grab that.

01:27.000 --> 01:30.000
Okay, so we're going to start off, I'll do a little bit of context.

01:30.000 --> 01:33.000
I'll answer the question, what is Aura, what does it do?

01:33.000 --> 01:39.000
And then we'll spend the last two thirds of the presentation talking about Rust

01:39.000 --> 01:45.000
and why we decided to use Rust for the project and some reports about how it's going so far

01:45.000 --> 01:47.000
and some of my experience as well.

01:47.000 --> 01:52.000
Okay, so just show of hands, who here has heard of Aura before?

01:52.000 --> 01:56.000
Oh, God, okay.

01:56.000 --> 01:59.000
Well, thank you for following my project.

01:59.000 --> 02:04.000
That makes me very happy but also a little terrified.

02:04.000 --> 02:10.000
So anyway, Aura, it's an open source Rust project and it's aimed at simplifying node management at scale.

02:10.000 --> 02:18.000
And so when I talk about it, I usually say it's basically a generic execution engine for containers, VMs and processes.

02:18.000 --> 02:24.000
The really quick pitch that I'll give on Aura is all of these things, containers, VMs,

02:24.000 --> 02:29.000
hypervisors and basic process management is all that I do at GitHub

02:29.000 --> 02:32.000
and all that I have done in my career for the past 10 years.

02:32.000 --> 02:38.000
And I have used a plethora of tools to do this and I was tired of learning and managing all these different tools

02:38.000 --> 02:45.000
and so I hope that this will be the last tool I ever have to work on in my career.

02:45.000 --> 02:52.000
So I wrote a thesis about the project and I'm trying hard to continually reevaluate this thesis

02:52.000 --> 02:57.000
and basically it says that by bringing some deliberate runtime controls to a node,

02:57.000 --> 03:00.000
we can unlock a new generation of higher order distributed systems.

03:00.000 --> 03:05.000
And what I mean by that is in my experience, a lot of the things we do on a node are organic

03:05.000 --> 03:08.000
and grew over the past 30 years or so.

03:08.000 --> 03:12.000
And this is more of a deliberate set of what do we need in the enterprise

03:12.000 --> 03:16.000
and what do we need at a bare minimum on the node and I think that if we get that right,

03:16.000 --> 03:20.000
we're actually going to have a much more interesting conversations in the coming decades.

03:20.000 --> 03:27.000
So I also believe that simplifying the execution stack will foster and secure observable systems

03:27.000 --> 03:29.000
while reducing complexity and risk.

03:29.000 --> 03:35.000
And complexity, if you have ever ran Kubernetes, is the name of the game.

03:35.000 --> 03:39.000
Cool, so I'll be talking about these things called nodes today.

03:39.000 --> 03:44.000
So node is a keyword and when I say node pretty much always in life,

03:44.000 --> 03:50.000
but very specifically in this talk, what I mean is a single compute unit in a set.

03:50.000 --> 03:56.000
So this would be one or more computers that we're trying to group together and manage as a set of computers.

03:56.000 --> 04:02.000
So when we do one thing to a node, the sort of assumption here is you want to go and do this twice

04:02.000 --> 04:07.000
or three times or 10,000 times sometimes or so on.

04:07.000 --> 04:13.000
So when we say node, I want you to think of a set of computers or an array of computers.

04:13.000 --> 04:17.000
OK, so what does Aura do?

04:17.000 --> 04:22.000
So the thesis here is this is going to be a central control for every runtime process on a node.

04:22.000 --> 04:27.000
So whether you're running PID1 or a container or a virtual machine,

04:27.000 --> 04:32.000
the hope is that all of this can be funneled through the Aura binary at runtime

04:32.000 --> 04:39.000
and Aura will have the ability to not only manage it but also observe it and control it and start it and stop it.

04:39.000 --> 04:44.000
And who knows, maybe even one day debug it if I'm very lucky.

04:44.000 --> 04:48.000
It runs as a minimal init system. So this is important.

04:48.000 --> 04:52.000
A lot of folks want to compare Aura to systemd and the more I think about it,

04:52.000 --> 04:56.000
the more I think that I really believe Aura and systemd have different goals.

04:56.000 --> 04:59.000
Aura doesn't really want to become a desktop manager.

04:59.000 --> 05:05.000
In fact, it kind of wants to be the opposite of that. It wants to be as lightweight and as minimal as possible.

05:05.000 --> 05:09.000
In a perfect world, there would be no user space on an Aura system

05:09.000 --> 05:13.000
because we wouldn't actually want users touching a single computer.

05:13.000 --> 05:16.000
Remember, we're managing sets of computers.

05:16.000 --> 05:22.000
And so the hope here is that we can make this as lightweight as possible.

05:22.000 --> 05:25.000
Additionally, we want this thing to have a remote API.

05:25.000 --> 05:32.000
So the idea of a single person sitting at a desk and operating on a single node is kind of irrelevant here.

05:32.000 --> 05:37.000
So everything that we do on the node, whether it's scheduling another process like a bash shell

05:37.000 --> 05:42.000
or it's scheduling a container, should all come through this remote API.

05:42.000 --> 05:48.000
And we're going to learn more about this API in Rust specifically later on in the talk.

05:48.000 --> 05:55.000
Also, it runs on Linux. It right now is tightly coupled to the Linux kernel.

05:55.000 --> 05:59.000
So what doesn't it do? So it doesn't do generic desktop support.

05:59.000 --> 06:03.000
So that's just completely out of scope. I don't want to deal with your Bluetooth drivers.

06:03.000 --> 06:08.000
I don't want to deal with your sound drivers. I don't want to manage your desktop interface.

06:08.000 --> 06:12.000
I don't care. In a perfect world, this hooks up to the network,

06:12.000 --> 06:17.000
and that's about the most advanced user interface we're going to have to one of these nodes in a set.

06:17.000 --> 06:20.000
Additionally, higher order scheduling is out of scope.

06:20.000 --> 06:27.000
So when we talk about enterprise management, whether it's some sort of orchestration system like Kubernetes or not,

06:27.000 --> 06:31.000
a lot of those discussions very quickly go into the scheduling discussion.

06:31.000 --> 06:35.000
There was a really good article, I think it was yesterday or the day before, on Hacker News

06:35.000 --> 06:39.000
that came out of fly.io about their orchestrator experience with Nomad.

06:39.000 --> 06:42.000
I see somebody shaking their head. Yeah, you read the article.

06:42.000 --> 06:48.000
It was a great article, and maybe we can find a link to it and put it in the video or something for folks.

06:48.000 --> 06:55.000
But that conversation was very much about how do we make scheduling decisions with available resources today.

06:55.000 --> 06:59.000
And that is pretty much all I do at my day job at GitHub,

06:59.000 --> 07:03.000
and that's all I've been doing managing Kubernetes for the past five or six years.

07:03.000 --> 07:07.000
And so while I'm very interested in having that conversation,

07:07.000 --> 07:14.000
my hope is that by simplifying the node, we can make those scheduling conversations easier in the future.

07:14.000 --> 07:19.000
And what I mean by that is that we will have less to say about what we actually do on a node,

07:19.000 --> 07:22.000
and we can effectively make nodes boring.

07:22.000 --> 07:25.000
So it doesn't run on Darwin, it doesn't run on Windows.

07:25.000 --> 07:27.000
Like I said, we're tightly coupled to the Linux kernel,

07:27.000 --> 07:34.000
which if you haven't pieced it together yet is why Rust is very exciting for the project.

07:34.000 --> 07:39.000
Okay, so again in summary, where did ORIT come from?

07:39.000 --> 07:43.000
It came with challenges with complexity at scale, so we just want the node to be boring.

07:43.000 --> 07:49.000
And it became, there was this desire to simplify and secure the stack.

07:49.000 --> 07:53.000
So I do deeply believe that with simple systems come secure systems.

07:53.000 --> 08:00.000
Every hack that I've been a part of in the industry has usually started with some sort of disparate

08:00.000 --> 08:04.000
and un-node fragmented attack surface that somebody's been able to exploit

08:04.000 --> 08:08.000
and do some sort of lateral movement once they're into the system.

08:08.000 --> 08:13.000
So if we can simplify that and we can just make the conversation involve less moving pieces,

08:13.000 --> 08:16.000
my hope is that we can actually secure the stack.

08:16.000 --> 08:19.000
I also want there to be a stronger node API.

08:19.000 --> 08:24.000
So who here has ever debugged the kublet API before?

08:24.000 --> 08:26.000
Who here even knows what this is?

08:26.000 --> 08:28.000
Okay, so we have a handful of people.

08:28.000 --> 08:34.000
So the kublet is Kubernetes version of we're going to go run an agent on a node.

08:34.000 --> 08:36.000
It does have an API.

08:36.000 --> 08:41.000
Last I checked it was undocumented and it was tightly coupled with the Kubernetes control plane.

08:41.000 --> 08:42.000
We hope to break that.

08:42.000 --> 08:47.000
We hope to just have a generic API that you could use to run a single process remotely

08:47.000 --> 08:50.000
or you could schedule millions of processes remotely.

08:50.000 --> 08:57.000
And we want that to be a very strong and thoughtful API.

08:57.000 --> 09:02.000
One of the big lessons of running large distributed systems at scale is that

09:02.000 --> 09:07.000
the bigger you get, the less trust that you can have in the people working on your systems.

09:07.000 --> 09:13.000
So as I've grown either like my small mastodon server that's grown into a medium-sized mastodon server

09:13.000 --> 09:16.000
or even dealing with thousands of nodes at scale,

09:16.000 --> 09:22.000
one of the lessons that I've noticed is that all workloads tend to this untrusted banality.

09:22.000 --> 09:26.000
So the bigger you get, the less you can trust a single workload.

09:26.000 --> 09:29.000
And even if these workloads are on the same team as you,

09:29.000 --> 09:32.000
you really want to start looking at them as an isolation zone

09:32.000 --> 09:41.000
that you don't want to trust too much from the centralized control plane perspective.

09:41.000 --> 09:43.000
So we started off Aura with a few guiding principles.

09:43.000 --> 09:45.000
Number one, I wanted to be boring.

09:45.000 --> 09:47.000
So we're targeting a single binary.

09:47.000 --> 09:50.000
We want this binary to be polymorphic in nature.

09:50.000 --> 09:54.000
Who here is familiar with Busybox?

09:54.000 --> 09:55.000
Great. Yeah, Busybox.

09:55.000 --> 09:57.000
It's a good binary in my opinion.

09:57.000 --> 09:58.000
I really like what it does.

09:58.000 --> 10:02.000
There's a switch on arg zero and it basically behaves like however you call it.

10:02.000 --> 10:07.000
So we're trying to get some similar functionality into the Aura binary as well.

10:07.000 --> 10:09.000
And we also want this thing to be lightweight

10:09.000 --> 10:14.000
and have a very strong scope and be as low risk as possible.

10:14.000 --> 10:16.000
Additionally, we wanted this thing to be attainable.

10:16.000 --> 10:17.000
We wanted to play nice with others.

10:17.000 --> 10:20.000
So I knew that I wanted this to fit in neatly with Kubernetes.

10:20.000 --> 10:22.000
I knew I wanted this to fit in neatly with Linux.

10:22.000 --> 10:26.000
And I knew I wanted pretty much everyone in this room to feel realistically

10:26.000 --> 10:31.000
like they could be running this thing on their laptops one day as the project grows.

10:31.000 --> 10:36.000
And so in order to do that, the API was going to be the majority of what we were talking about

10:36.000 --> 10:39.000
as we began developing the project.

10:39.000 --> 10:41.000
And ultimately, I wanted to be functional.

10:41.000 --> 10:44.000
I don't want it to subserve the needs of a corporation.

10:44.000 --> 10:47.000
I don't want it to serve the needs of a higher order control plane.

10:47.000 --> 10:53.000
I literally just want a standard library for executing processes in containers and VMs at scale.

10:53.000 --> 10:55.000
What we do with that is out of scope.

10:55.000 --> 10:58.000
I just want it to work first and foremost.

10:58.000 --> 11:00.000
So ultimately, I want boring systems.

11:00.000 --> 11:06.000
And if you see in the background here, there's all of these subtle distributed system propaganda

11:06.000 --> 11:13.000
notes that you can go look at if you want to look at the slides later.

11:13.000 --> 11:16.000
So ultimately, I wanted the thing to be safe.

11:16.000 --> 11:20.000
So when we're looking at tenant security, one of the questions I ask is,

11:20.000 --> 11:22.000
how do we make it easy to do the right thing?

11:22.000 --> 11:25.000
And I think that comes from the underlying infrastructure.

11:25.000 --> 11:28.000
And in our case, Aura is the underlying infrastructure.

11:28.000 --> 11:35.000
And we intended to build a very strong project here that would unlock this sort of safe paradigm

11:35.000 --> 11:40.000
that we could give a team a binary, and they would be able to run their applications on top of it.

11:40.000 --> 11:44.000
And we wouldn't really have to worry about anybody sneaking out of their container

11:44.000 --> 11:48.000
or accessing any parts of the system so we didn't want them to access.

11:48.000 --> 11:55.000
So tenant security is a strong motivator for this as well.

11:55.000 --> 12:01.000
OK, so about six months ago on Twitch, which I do a Twitch stream,

12:01.000 --> 12:04.000
you should maybe follow me if you want to learn more about the project.

12:04.000 --> 12:06.000
But I started to write this paper.

12:06.000 --> 12:11.000
And it was mostly as some bro in chat was like, yo, why don't you just go rebuild system D?

12:11.000 --> 12:13.000
And I was just like, maybe I will.

12:13.000 --> 12:15.000
And so anyway, I ended up writing this paper.

12:15.000 --> 12:17.000
And so, well, here we are.

12:17.000 --> 12:19.000
And so the paper really grew.

12:19.000 --> 12:23.000
And it started to answer a bunch of questions about like, why should we should go write it and go?

12:23.000 --> 12:27.000
No, no, no, we should go write it in C, because C is going to be the most common language

12:27.000 --> 12:29.000
that will interface neatly with the kernel.

12:29.000 --> 12:31.000
And we can do EVPF probes and so on.

12:31.000 --> 12:33.000
No, no, no, no, we should go write it in Rust.

12:33.000 --> 12:34.000
And you can go look.

12:34.000 --> 12:35.000
There's a Google Doc.

12:35.000 --> 12:38.000
And it's just got all these comments of people from all over the internet and all over the industry

12:38.000 --> 12:40.000
arguing about what we should do.

12:40.000 --> 12:49.000
And eventually we settled on we want a lightweight node daemon and thus became the Aura runtime project.

12:49.000 --> 12:50.000
Okay.

12:50.000 --> 12:56.000
So this is where we shift from the conceptual what is Aura, how did we get here, what problems does it solve.

12:56.000 --> 13:00.000
And we start to get a little deeper into the code.

13:00.000 --> 13:05.000
So when we originally started the project, we started writing it in Go, the Go programming language.

13:05.000 --> 13:12.000
And there's two kind of predecessor projects that later turned into Aura, which is written in Rust.

13:12.000 --> 13:18.000
This first one that we call Aura Legacy, which up until about five, well, I guess 15 minutes ago now,

13:18.000 --> 13:23.000
but right before I walked into the room, this was a private GitHub repo.

13:23.000 --> 13:25.000
And I've gone ahead and actually opened it up.

13:25.000 --> 13:31.000
So if you want to go see the original code in Go, there's some really interesting things in there.

13:31.000 --> 13:38.000
We did some libp2p bit torrent style routing between nodes where you can build a mesh of nodes and things.

13:38.000 --> 13:47.000
But you can really see where this runtime daemon started and some of the original concepts that we were tinkering around with.

13:47.000 --> 13:51.000
Ultimately, though, we ran into a lot of the same problems that I ran into in Kubernetes,

13:51.000 --> 13:57.000
which was I needed to start recreating these objects and I needed to start reading some config,

13:57.000 --> 14:03.000
whether that be YAML or JSON or something similar, and then marshal that onto a struct in memory

14:03.000 --> 14:08.000
and then go and do arbitrary things with that, in our case, schedule a pod.

14:08.000 --> 14:12.000
And one of the things that was kind of outstanding in the back of my mind was what about access to libc?

14:12.000 --> 14:19.000
I knew as soon as we started scheduling containers and DMs, we absolutely were going to need native access to libc.

14:19.000 --> 14:24.000
Additionally, there's this project called NAML, which is basically Turing Complete Kubernetes Config.

14:24.000 --> 14:27.000
It's written in Go and it just uses the Go SDK.

14:27.000 --> 14:34.000
And that was yet another way of sort of validating this idea of we need to start making our system stronger

14:34.000 --> 14:39.000
and building stronger interfaces for teams to manage different parts of the stack.

14:39.000 --> 14:46.000
So those are the two sort of precursors to the Aura runtime as it exists today.

14:46.000 --> 14:53.000
But of course, writing in Go came with some challenges.

14:53.000 --> 14:57.000
The big one here is obviously native access to libc.

14:57.000 --> 15:01.000
We were going to be creating C groups against the Linux kernel.

15:01.000 --> 15:05.000
We definitely wanted to use the clone3 system call.

15:05.000 --> 15:12.000
And the container run times of today had some assumptions about how we were going to be executing the clone3 system call

15:12.000 --> 15:16.000
that, of course, I had to disagree with because, hi, have you met me?

15:16.000 --> 15:19.000
I have to disagree with everything.

15:19.000 --> 15:23.000
And we also wanted to implement some P trace functionality as well.

15:23.000 --> 15:29.000
So obviously, Go was going to give us some challenges here when it came to using C Go.

15:29.000 --> 15:38.000
So Rust became very exciting and definitely got a lot of attention very quickly as we were writing the Go side of things.

15:38.000 --> 15:41.000
We also wanted EVPF for networking.

15:41.000 --> 15:46.000
I personally want it for security and maybe for some other interesting service mesh ideas.

15:46.000 --> 15:51.000
But I do think that having EVPF for networking as a non-negotiable,

15:51.000 --> 15:56.000
we're definitely going to want to simplify what Kubernetes refers to as kubeproxy,

15:56.000 --> 16:00.000
that we can now invent our own name and hopefully simplify that later.

16:00.000 --> 16:02.000
But I digress.

16:02.000 --> 16:05.000
We also wanted some access to native virtualization library.

16:05.000 --> 16:07.000
So all the KVM stuff is written in C.

16:07.000 --> 16:13.000
And if you go look at the Firecracker code base, that is also written in Rust that vendors the KVM bindings.

16:13.000 --> 16:21.000
And so we knew we would want to access these three components and all three of these were going to be problematic with Go.

16:21.000 --> 16:29.000
Update as of about an hour ago, I went to the state of the Go room across the hall here.

16:29.000 --> 16:31.000
Did anybody else go to the Go talk this morning?

16:31.000 --> 16:34.000
Yeah, we got three or four hands up here.

16:34.000 --> 16:35.000
So this kind of pissed me off.

16:35.000 --> 16:40.000
Go has unwrap now as of 1.2.0.

16:40.000 --> 16:43.000
And they also freaking have.clone.

16:43.000 --> 16:46.000
And I was just like, bro, get off our keywords.

16:46.000 --> 16:50.000
This is totally like, this is our thing.

16:50.000 --> 16:56.000
So anyway, it's really exciting to see Go taking these concepts a little more seriously.

16:56.000 --> 17:01.000
And if you've ever written Rust before, who here has written unwrap in Rust?

17:01.000 --> 17:02.000
Put your hand.

17:02.000 --> 17:03.000
No, no, put your hands down.

17:03.000 --> 17:04.000
We're not supposed to do that.

17:04.000 --> 17:05.000
We're supposed to use other things.

17:05.000 --> 17:06.000
I don't know what we're supposed to use now.

17:06.000 --> 17:09.000
I just get so much shit on my Twitch stream every time I write unwrap.

17:09.000 --> 17:15.000
But yes, we do have unwrap and clone in Go now,

17:15.000 --> 17:19.000
which is just a strong indicator that we're likely doing something right with Rust.

17:19.000 --> 17:22.000
So anyway, I made the decision to move to Rust.

17:22.000 --> 17:25.000
And I didn't know very much about Rust when I made the decision.

17:25.000 --> 17:29.000
And I literally just started at the main function and said, we'll figure it out as we go.

17:29.000 --> 17:35.000
And I ordered the Rust book and just jumped in and started to write code with the hope

17:35.000 --> 17:39.000
of accessing kernel constructs and C groups and EBPF probes.

17:39.000 --> 17:43.000
So what could possibly go wrong here?

17:43.000 --> 17:46.000
OK, so how are we doing on time, by the way?

17:46.000 --> 17:47.000
We're 15 minutes in.

17:47.000 --> 17:49.000
OK, cool.

17:49.000 --> 17:54.000
So Rust, to help us solve the YAML problem,

17:54.000 --> 17:57.000
I suspect we're all familiar with feeding YAML to machines.

17:57.000 --> 18:00.000
We've all done this before at some point in our lifetime.

18:00.000 --> 18:04.000
OK, so this is a thing I do a lot working in large distributed systems.

18:04.000 --> 18:06.000
And I work with people who do this a lot.

18:06.000 --> 18:10.000
And we do it so much, we've tried to get really good at doing it.

18:10.000 --> 18:13.000
And that, I think, that's an interesting discussion.

18:13.000 --> 18:18.000
So in my opinion, so warning, Chris Nova opinions here,

18:18.000 --> 18:24.000
in my opinion, all config ultimately is going to drift towards Turing completion.

18:24.000 --> 18:28.000
So I see this C++ templates.

18:28.000 --> 18:29.000
Anybody?

18:29.000 --> 18:30.000
Anybody C++ templates?

18:30.000 --> 18:31.000
OK.

18:31.000 --> 18:37.000
Helm charts, customizing Kubernetes, any of the templating rendering languages

18:37.000 --> 18:39.000
that you see in web dev and front-end work,

18:39.000 --> 18:43.000
there's all kinds of interesting Python libraries that will allow you

18:43.000 --> 18:46.000
to interpolate your config and so on.

18:46.000 --> 18:51.000
In my opinion, a good balance is kind of something like Bash that is Turing complete,

18:51.000 --> 18:53.000
but it just comes with some strong guarantees.

18:53.000 --> 18:57.000
And so I knew very quickly that I didn't want to be feeding YAML to Aura.

18:57.000 --> 19:00.000
I definitely didn't want to recreate this idea of, like,

19:00.000 --> 19:03.000
we're going to have to manage 1,000 pieces of YAML

19:03.000 --> 19:06.000
because we have 1,000 different nodes.

19:06.000 --> 19:10.000
So I wanted to explore more about what are some options that we have here,

19:10.000 --> 19:13.000
so we're not just feeding YAML to machines anymore.

19:13.000 --> 19:17.000
So thus became this really interesting project of mine.

19:17.000 --> 19:22.000
We'll see if this pans out, which is this binary called AuraScript.

19:22.000 --> 19:25.000
So AuraScript is a Rust binary.

19:25.000 --> 19:27.000
We have it compiling with muzzle today,

19:27.000 --> 19:33.000
and it embeds all of the connection logic for a single machine.

19:33.000 --> 19:37.000
And so we'll talk more about the semantics of AuraScript in a second.

19:37.000 --> 19:42.000
But ultimately, what you need to understand to kind of get the initial motivation here

19:42.000 --> 19:49.000
is that this aims to be an alternative to managing YAML at scale.

19:49.000 --> 19:55.000
So I found this really fascinating TypeScript runtime called Dino.

19:55.000 --> 19:57.000
Have folks heard of Dino before?

19:57.000 --> 19:58.000
Can I swear in here?

19:58.000 --> 20:01.000
I effin love Dino.

20:01.000 --> 20:05.000
I'm sorry. I really like this project.

20:05.000 --> 20:07.000
If you want a good example of, like,

20:07.000 --> 20:10.000
hey, I just want to see a really successful Rust project

20:10.000 --> 20:12.000
that has a really strong community,

20:12.000 --> 20:15.000
I would encourage you to just go look at the Dino project.

20:15.000 --> 20:16.000
I think their code is beautiful.

20:16.000 --> 20:18.000
I think what it does is beautiful.

20:18.000 --> 20:21.000
I think the way that they manage the project is beautiful.

20:21.000 --> 20:23.000
It's just a really good quality project,

20:23.000 --> 20:25.000
and it solves a problem for us with Aura.

20:25.000 --> 20:28.000
And so Dino is basically, it's a runtime for TypeScript,

20:28.000 --> 20:30.000
and it's written in Rust.

20:30.000 --> 20:32.000
And the way the project is set up,

20:32.000 --> 20:36.000
that you can go and you can add your own custom interpretive logic,

20:36.000 --> 20:38.000
and you can build fancy things into the binary,

20:38.000 --> 20:43.000
and you can do things with the TypeScript interpretation at runtime,

20:43.000 --> 20:47.000
which is precisely what we needed to do with Aura.

20:47.000 --> 20:49.000
So here is the model now.

20:49.000 --> 20:52.000
So instead of feeding YAML to a single node,

20:52.000 --> 20:55.000
we now have this higher order set of libraries

20:55.000 --> 20:58.000
that we can statically compile into a binary,

20:58.000 --> 21:02.000
and we can interpret it directly on a machine.

21:02.000 --> 21:06.000
So in order for you to interface with an Aura node or a set of nodes,

21:06.000 --> 21:08.000
all you need is one binary,

21:08.000 --> 21:12.000
mtlsconfig, and then whatever TypeScript you want to write.

21:12.000 --> 21:16.000
And this is an alternative to, like, any of the Nomad command line tools,

21:16.000 --> 21:18.000
or the Mesos command line tools,

21:18.000 --> 21:21.000
or the Kubernetes kubectl kubectl command line tool.

21:21.000 --> 21:25.000
And now you can just write it all directly in TypeScript.

21:25.000 --> 21:31.000
So this is actually a concrete example of what would be,

21:31.000 --> 21:34.000
what systemd would call a unit file,

21:34.000 --> 21:36.000
what Kubernetes would call a manifest,

21:36.000 --> 21:40.000
and what Aura just calls a freaking TypeScript file,

21:40.000 --> 21:43.000
because we don't have fancy names for our stuff yet.

21:43.000 --> 21:46.000
So you can see here at the top,

21:46.000 --> 21:49.000
we basically contact the Aura standard library,

21:49.000 --> 21:51.000
we get a new client,

21:51.000 --> 21:55.000
and then we can allocate this thing called a cell.

21:55.000 --> 21:58.000
A cell is basically an abstraction for a C group.

21:58.000 --> 22:00.000
We cordon off a section of the system,

22:00.000 --> 22:02.000
and we say, like, we want to use a certain percentage

22:02.000 --> 22:04.000
of the available CPUs on a node,

22:04.000 --> 22:07.000
and I want it to only let processes run,

22:07.000 --> 22:09.000
in this case, for 0.4 seconds,

22:09.000 --> 22:11.000
and then we'll use the kernel to just kill the process

22:11.000 --> 22:13.000
if it runs longer than that.

22:13.000 --> 22:16.000
And so the first thing we would do is we would allocate that,

22:16.000 --> 22:20.000
which is an improvement over Kubernetes as it exists today,

22:20.000 --> 22:22.000
because we can allocate resources before we actually

22:22.000 --> 22:24.000
start anything in that area,

22:24.000 --> 22:28.000
and then we can go ahead and actually start whatever we want.

22:28.000 --> 22:31.000
And so you can see I simplified the example just for today,

22:31.000 --> 22:34.000
but it's just, it's remote command injection as a service.

22:34.000 --> 22:37.000
So this whole talk was just basically like how to go

22:37.000 --> 22:42.000
and run a bash command on a server.

22:42.000 --> 22:45.000
And so now you can express your commands and similar primitives

22:45.000 --> 22:50.000
that you would see in other run times directly in TypeScript.

22:50.000 --> 22:54.000
The interesting thing here is TypeScript is just natively

22:54.000 --> 22:59.000
more expressive than a lot of the AML things that we see today.

22:59.000 --> 23:01.000
In this case, we can actually do math,

23:01.000 --> 23:04.000
but I'm sure you can imagine you can do other things as well.

23:04.000 --> 23:07.000
You can access logic, loops, if statements,

23:07.000 --> 23:10.000
there's if branching, and so on.

23:10.000 --> 23:13.000
And so we were able to actually solve some of these like

23:13.000 --> 23:15.000
templatey, rendery style problems by just doing things

23:15.000 --> 23:19.000
natively in a well-known and easy to understand language

23:19.000 --> 23:22.000
such as TypeScript.

23:22.000 --> 23:24.000
So patterns started to emerge.

23:24.000 --> 23:28.000
So Rust gave us the ability to generate the TypeScript binary

23:28.000 --> 23:31.000
with all of the magic behind the scenes

23:31.000 --> 23:34.000
MTLS security config that we wanted.

23:34.000 --> 23:37.000
And so now the conversation was a little more like this,

23:37.000 --> 23:40.000
which is how do I manage a small set of TypeScript,

23:40.000 --> 23:43.000
and it's much more flexible, and you can start to actually

23:43.000 --> 23:46.000
express things the way that we used to and just express

23:46.000 --> 23:49.000
things statically, and then you can have all of your Turing

23:49.000 --> 23:52.000
complete logical components below, and you can mix

23:52.000 --> 23:56.000
and match these however you want.

23:56.000 --> 24:02.000
Okay, so in addition to addressing the YAML problem

24:02.000 --> 24:07.000
with DNO and TypeScript, Rust also helped us to solve

24:07.000 --> 24:10.000
the Sidecar problem, and by us I mean this is our hope

24:10.000 --> 24:14.000
as we operate our Mastodon servers and our various other

24:14.000 --> 24:17.000
ridiculous side projects that we operate,

24:17.000 --> 24:20.000
both in my basement and in a colo in Germany.

24:20.000 --> 24:24.000
So talking about Sidecars, who here knows what a Sidecar is?

24:24.000 --> 24:27.000
Show of hands. Okay, most folks do.

24:27.000 --> 24:30.000
Okay, so a Sidecar that is always available with the same

24:30.000 --> 24:33.000
features as a host. So this is going to sound a little bit

24:33.000 --> 24:36.000
weird, and this slide's going to look a little bit weird,

24:36.000 --> 24:38.000
but just bear with me as we kind of like unpack what's

24:38.000 --> 24:40.000
actually going on here.

24:40.000 --> 24:44.000
What we want, that I don't think we're talking about,

24:44.000 --> 24:48.000
is that sentence. I actually think what we want is we want

24:48.000 --> 24:52.000
a Sidecar to sit along our applications that does literally

24:52.000 --> 24:56.000
the exact same things we have to do on a given host whenever

24:56.000 --> 25:00.000
we're managing these workloads at scale.

25:00.000 --> 25:04.000
As I began looking into writing Sidecars at the host level,

25:04.000 --> 25:07.000
I began drilling deeper and deeper into the C programming

25:07.000 --> 25:10.000
language as I was writing this in Rust and just made the

25:10.000 --> 25:13.000
connection that memory safety was going to be key because

25:13.000 --> 25:16.000
we're going to be running these demons right alongside of

25:16.000 --> 25:21.000
your workload. And so unpacking the need to do this really

25:21.000 --> 25:26.000
helps you understand why we shifted over to Rust.

25:26.000 --> 25:31.000
So again, another Chris Nova opinion. Any sufficiently

25:31.000 --> 25:35.000
mature infrastructure service will evolve into a Sidecar.

25:35.000 --> 25:38.000
So if you have done any sort of structured logging, in my

25:38.000 --> 25:41.000
opinion, if you will continue to build structured logging

25:41.000 --> 25:44.000
and you will continue to ship logs, that will eventually

25:44.000 --> 25:46.000
turn into a Sidecar that you're going to want to go run

25:46.000 --> 25:48.000
beside your app so you have this transparent logging

25:48.000 --> 25:51.000
experience. You can rinse and repeat that paradigm for

25:51.000 --> 25:54.000
pretty much anything, secrets, authentication data, and so

25:54.000 --> 25:59.000
on. And so I started to see these patterns kind of surface.

25:59.000 --> 26:02.000
And very specifically, I started to look at how would I

26:02.000 --> 26:06.000
solve these with Rust. And as it turns out, the Rust

26:06.000 --> 26:10.000
ecosystem had a plethora of pleasant surprises for me as I

26:10.000 --> 26:14.000
started to explore what putting some of these features into

26:14.000 --> 26:18.000
a binary would look like. Logging was boring because we

26:18.000 --> 26:22.000
could just use Tokyo streams. Auth N and Auth Z was boring

26:22.000 --> 26:25.000
because all I had to do was just use the Rust derived

26:25.000 --> 26:28.000
primitives to just start applying Auth Z to each of our

26:28.000 --> 26:31.000
units in the source code. Identity was boring because I

26:31.000 --> 26:34.000
didn't even get to fight with open SSL anymore. We just had

26:34.000 --> 26:37.000
to use Rust TLS and that was easy. And so the network was

26:37.000 --> 26:41.000
also easy because we had native access to Linux and libc so

26:41.000 --> 26:45.000
we could just very boringly schedule a Linux device and we

26:45.000 --> 26:49.000
got a Linux device and it was pretty straightforward. So we

26:49.000 --> 26:55.000
were able to create this at the node and now my question was

26:55.000 --> 26:59.000
how do we bring this into the workload level at scale and I

26:59.000 --> 27:02.000
think this is where most of the conversations you start

27:02.000 --> 27:06.000
talking about things like Istio and service meshes and

27:06.000 --> 27:10.000
structured logging and so forth. And I actually think that

27:10.000 --> 27:14.000
we can simplify that conversation too. And so what we

27:14.000 --> 27:18.000
were able to do with Aura is we just spawned the root daemon

27:18.000 --> 27:21.000
and used that as the new PID one in any of our nested

27:21.000 --> 27:25.000
isolation zones. And when I say spawn I very directly mean

27:25.000 --> 27:28.000
like we literally read the byte code from the kernel and

27:28.000 --> 27:32.000
we build an image at runtime with the byte for byte, the

27:32.000 --> 27:35.000
same byte code that's running on the host and then we can

27:35.000 --> 27:38.000
just go and execute whatever we want against the same API

27:38.000 --> 27:42.000
as the original host runs and all of this is memory safe.

27:42.000 --> 27:46.000
So I can put this right next to your application in the same

27:46.000 --> 27:49.000
name spaces running in a container or running in a

27:49.000 --> 27:52.000
virtual machine and there's a relatively low risk of any

27:52.000 --> 27:57.000
sort of binary exploitation at scale. So here's a model of

27:57.000 --> 28:02.000
what that looks like. So on the left big side here we have

28:02.000 --> 28:05.000
the Aura host daemon and on the right we have the three

28:05.000 --> 28:08.000
types of isolation zones that you can run with a daemon.

28:08.000 --> 28:12.000
You have a cell sandbox which is effectively a C group, a

28:12.000 --> 28:15.000
pod sandbox which is a group of containers running in

28:15.000 --> 28:19.000
unique Linux name spaces and a virtual machine which is

28:19.000 --> 28:23.000
effectively a container with a kernel and some virtualization

28:23.000 --> 28:27.000
technology. All of this is possible with Rust natively

28:27.000 --> 28:31.000
and all of this was made possible by spawning the binary

28:31.000 --> 28:36.000
and creating these nested isolation zones at run time.

28:36.000 --> 28:39.000
Additionally, Rust was able to help solve the untrusted

28:39.000 --> 28:43.000
workload problem because of the memory safety and that Rust

28:43.000 --> 28:47.000
offers and because of this really interesting model that

28:47.000 --> 28:51.000
we have right here. So this is a zoomed in model that might

28:51.000 --> 28:54.000
look familiar if you've ever done any container escapes

28:54.000 --> 28:57.000
before and in this model basically what we're saying is

28:57.000 --> 29:01.000
we're replacing any sort of like pause or initialization

29:01.000 --> 29:05.000
sequence in an isolation zone with the same daemon we run

29:05.000 --> 29:08.000
on the host. So I think the Rust binary for Aura right now

29:08.000 --> 29:12.000
is about 40 megabytes and we can just copy that into a

29:12.000 --> 29:14.000
container and run that alongside your application. So it's

29:14.000 --> 29:20.000
a relatively small application run time that will sit right

29:20.000 --> 29:26.000
alongside of your app. So managing memory from

29:26.000 --> 29:31.000
MTLS and AuraD. So as I'm writing Rust, one of the things

29:31.000 --> 29:33.000
I notice is I start paying attention to memory management

29:33.000 --> 29:37.000
more. Every time I try to clone something or the freakin'

29:37.000 --> 29:40.000
borrow checker yells at me that kind of like is a small like

29:40.000 --> 29:44.000
grim reminder of my roots as a C developer. This is an

29:44.000 --> 29:47.000
interesting takeaway. The only memory that we need to share

29:47.000 --> 29:50.000
that multiple parts of the system have access to in this

29:50.000 --> 29:54.000
entire model whether we're creating containers or VMs is

29:54.000 --> 29:57.000
the shared MTLS config. So this is the only bit of shared

29:57.000 --> 30:01.000
memory that we really have to manage and Rust very clearly

30:01.000 --> 30:04.000
called that out and to be candid I don't think I would be

30:04.000 --> 30:07.000
able to be as comfortable with this model if I was doing

30:07.000 --> 30:11.000
this in something like Go. So Rust was able to help us

30:11.000 --> 30:15.000
solve the maintainability problem. So did somebody say

30:15.000 --> 30:19.000
Rust macros? So we have a really brilliant guy, Future

30:19.000 --> 30:24.000
Highway, who helps us work on the project and Future Highway

30:24.000 --> 30:27.000
is our resident macro guy. Does everybody here have a

30:27.000 --> 30:32.000
macro guy on your team? Because you should. He has made

30:32.000 --> 30:35.000
things a lot simpler for us. So one of the things we

30:35.000 --> 30:38.000
struggled with with Go and Kubernetes specifically was like

30:38.000 --> 30:42.000
how do we generate objects with unique logic? Rust macros

30:42.000 --> 30:45.000
were a solution to this for us. So if you've ever looked at

30:45.000 --> 30:47.000
the Kubernetes code base you can see we've created these

30:47.000 --> 30:50.000
things called CRDs that started out as third party resources

30:50.000 --> 30:54.000
and we've built this entire bespoke API machinery system

30:54.000 --> 30:58.000
that basically is a glorified macro system that allows us

30:58.000 --> 31:03.000
to generate Go in the project. So we're allowed to use Rust

31:03.000 --> 31:06.000
macros now and it's a very simple model in the code base.

31:06.000 --> 31:09.000
We basically have a combinatorics problem where we're

31:09.000 --> 31:11.000
able to map the different primitives to the different

31:11.000 --> 31:15.000
logical systems that are unique to us and we can generate

31:15.000 --> 31:21.000
our source code as needed. And so our source code ends up

31:21.000 --> 31:25.000
looking like this, which I think we've successfully achieved

31:25.000 --> 31:30.000
boring for a low level runtime. This is a fairly straightforward

31:30.000 --> 31:33.000
call and then we can be confident that the code it generates

31:33.000 --> 31:37.000
is unique to the project and encapsulates all of our

31:37.000 --> 31:41.000
concerns as maintainers. So really the whole conversation

31:41.000 --> 31:44.000
now is just the proto conversation. Everything can be

31:44.000 --> 31:47.000
generated by Rust macros. The whole project really is

31:47.000 --> 31:50.000
pretty much on auto-gen at this point. You can just go

31:50.000 --> 31:53.000
introduce a new field in the API and then you can spit out

31:53.000 --> 31:56.000
a new client. It'll plumb itself into the runtime. It'll

31:56.000 --> 31:58.000
plumb itself into the Aura Script library and everything

31:58.000 --> 32:03.000
is given to us for free just because of macros in Rust.

32:03.000 --> 32:07.000
And so this is our code path and the way that we're able

32:07.000 --> 32:10.000
to take advantage of macros. We do a lot of manual work.

32:10.000 --> 32:13.000
We fight with the borrow checker. We make some improvements.

32:13.000 --> 32:16.000
And then we get done and we encapsulate it into a macro.

32:16.000 --> 32:19.000
And we can simplify our code path by just replacing all of

32:19.000 --> 32:23.000
that with a macro after we've been done. And so this is

32:23.000 --> 32:27.000
the Aura project as it exists today, which again I'm very

32:27.000 --> 32:31.000
stoked to say that this is a very boring exercise.

32:31.000 --> 32:35.000
So a quick update and then I'll be done with my talk here.

32:35.000 --> 32:39.000
There's a few components, all of which are written in Rust

32:39.000 --> 32:42.000
here. Number one, the Aura D daemon is the main static

32:42.000 --> 32:44.000
binary that's written in Rust and compiled with muzzle.

32:44.000 --> 32:47.000
So we can ship that without any of the shared objects on

32:47.000 --> 32:51.000
the host directly into an isolation zone. AER is

32:51.000 --> 32:54.000
completely generated from proto client. So this is exciting.

32:54.000 --> 32:59.000
We can actually call a GRPC API directly from the client.

32:59.000 --> 33:02.000
We don't have to do any of the runtime plumbing. So if

33:02.000 --> 33:06.000
we add a bool to the proto file, we get dash dash bool

33:06.000 --> 33:09.000
directly in the client compiled for free without typing

33:09.000 --> 33:12.000
a single line of code. So this is a very exciting primitive

33:12.000 --> 33:15.000
for us. So we can just begin to have API conversations and

33:15.000 --> 33:18.000
not necessarily care about the internals of the program

33:18.000 --> 33:21.000
anymore. Aura script is completely generated and we

33:21.000 --> 33:25.000
have this exciting project down here, which is AE, which is

33:25.000 --> 33:30.000
an alternative command line client written in Go.

33:30.000 --> 33:33.000
So ultimately the lesson here is Rust was able to help us

33:33.000 --> 33:36.000
solve the boring problem. We have a very complicated, very

33:36.000 --> 33:39.000
obscure piece of technology that is you don't really have

33:39.000 --> 33:43.000
to do much to work on it anymore. Most of it's on autopilot

33:43.000 --> 33:46.000
at this point and most of the conversations are very

33:46.000 --> 33:49.000
philosophical in nature and not necessarily about how to

33:49.000 --> 33:52.000
implement things in the software.

33:52.000 --> 33:55.000
So takeaways about the project. Aura is completely

33:55.000 --> 33:58.000
stateless. So you can restart a node and it's basically

33:58.000 --> 34:01.000
empty until you push config to it, which means all of our

34:01.000 --> 34:04.000
systems are declarative like NixOS now and you can just

34:04.000 --> 34:07.000
pass things like TypeScript or JSON to them and it makes it

34:07.000 --> 34:11.000
easy to manage things like containers.

34:11.000 --> 34:14.000
Next we have some to-dos for the project and I would

34:14.000 --> 34:17.000
encourage you all to get involved. And if you want to

34:17.000 --> 34:21.000
see a demo of all this, I'll be out here in the hallway

34:21.000 --> 34:24.000
after the talk and you can come and you can track me

34:24.000 --> 34:28.000
down and I'm happy to give you a demo. So anyway, I think

34:28.000 --> 34:31.000
we have a few minutes for questions and five minutes for

34:31.000 --> 34:34.000
questions. So I'll take questions and if you want to

34:34.000 --> 34:38.000
get involved, here's how to get involved and I'm Chris

34:38.000 --> 34:40.000
Nova. Please clap.

34:40.000 --> 34:56.000
You mentioned the size of the binary being 40 megabytes.

34:56.000 --> 34:59.000
Is that with size optimization or no?

34:59.000 --> 35:01.000
Sorry, say that again.

35:01.000 --> 35:04.000
Is the size of the binary at 40 megabytes with size

35:04.000 --> 35:06.000
optimization applied already or not?

35:06.000 --> 35:09.000
No, that's completely unoptimized. That is just straight

35:09.000 --> 35:15.000
out of the compiler without any aftermarket tuning.

35:15.000 --> 35:18.000
Amazing talk. Quick question. So if I want to have just

35:18.000 --> 35:22.000
enough Linux to like pixie boot into this thing, do you guys

35:22.000 --> 35:25.000
have any templates because it feels like a shame to run it

35:25.000 --> 35:28.000
on something like Crel. I just need like enough of Linux to

35:28.000 --> 35:30.000
just pixie boot into that.

35:30.000 --> 35:33.000
Yeah, so the question is basically can we pixie boot this

35:33.000 --> 35:36.000
and then you mentioned Crel. Where we're going we don't

35:36.000 --> 35:41.000
need Red Hat. So I guess what I would say is in theory all

35:41.000 --> 35:45.000
you need to run is a static Linux kernel and Aura and a

35:45.000 --> 35:49.000
network connection and some NTLS config. And so everything

35:49.000 --> 35:52.000
else at that point, all of your packages, your services,

35:52.000 --> 36:03.000
your commands are passed to it via the API.

36:03.000 --> 36:07.000
Hi. You mentioned that you use a lot of macros. I've also

36:07.000 --> 36:11.000
run into problems where you have a combinatorial explosion

36:11.000 --> 36:16.000
of templates in C++ speak or something like that.

36:16.000 --> 36:19.000
What are your thoughts on generics for generating some of

36:19.000 --> 36:22.000
this rather than macros in order to be a bit more type safe

36:22.000 --> 36:24.000
I suppose?

36:24.000 --> 36:27.000
Personally I got a little drunk with generics, I'm not going

36:27.000 --> 36:30.000
to lie. When I first moved over from Go because I was just

36:30.000 --> 36:34.000
so excited about it, the reason I like macros is because we

36:34.000 --> 36:37.000
can add logic to them. So we have like, to give you an

36:37.000 --> 36:40.000
example, we have containers and we have VMs. So we'll have a

36:40.000 --> 36:44.000
section of the macro dedicated just to VMs that manages the

36:44.000 --> 36:47.000
kernel. And that's irrelevant to the container systems in

36:47.000 --> 36:50.000
the project because containers run on the host kernel. And so

36:50.000 --> 36:53.000
we can embed those small branches directly into the

36:53.000 --> 36:56.000
macro code so that macros generate slightly different

36:56.000 --> 37:00.000
outputs based off of the inputs that are given to them. So

37:00.000 --> 37:03.000
for Aura, when you're dealing with similar systems of code

37:03.000 --> 37:08.000
that have small nuances like we are, macros really, in my

37:08.000 --> 37:12.000
opinion, are the way to go. Did I answer your question?

37:12.000 --> 37:16.000
Looks like?

37:16.000 --> 37:21.000
Simple question. So can I actually give the configuration

37:21.000 --> 37:26.000
instead of our script or type of script just in Rust?

37:26.000 --> 37:32.000
Yeah, of course. So we have this Rust client here. It's

37:32.000 --> 37:36.000
basically a Rust SDK. And then we have a tool called AER

37:36.000 --> 37:39.000
which takes it a step further and is actually automatically

37:39.000 --> 37:43.000
generated with macros. And it's a compiled binary that you

37:43.000 --> 37:46.000
can just use from the command line. So you can just type

37:46.000 --> 37:50.000
commands directly into it and it will run against the server

37:50.000 --> 37:52.000
on the back end.

37:52.000 --> 37:54.000
Yeah, there's also an SDK. So you could write your own Rust

37:54.000 --> 37:58.000
code. And it's gRPC. So you could generate, you could write

37:58.000 --> 38:01.000
it in Go, and we do, and you could write it in Python or Ruby

38:01.000 --> 38:04.000
or realistically anything, any client you want.

38:04.000 --> 38:08.000
Hi. I was wondering when you talk about the remote API, have

38:08.000 --> 38:13.000
you considered a future direction to make this a unique

38:13.000 --> 38:14.000
kernel?

38:14.000 --> 38:18.000
A unique kernel. I have a slide for this. So I added a bunch

38:18.000 --> 38:21.000
of FAQ slides to the end because I knew that we were going to

38:21.000 --> 38:25.000
get all these good questions. The answer is it depends. Hold

38:25.000 --> 38:28.000
on. Let's see if I can't find it. You guys get to see. There

38:28.000 --> 38:33.000
it is. It depends. What does unique kernel mean to you? I

38:33.000 --> 38:35.000
think the most minimal system we could do would be a Linux

38:35.000 --> 38:39.000
kernel as it exists today, like good old-fashioned stock Linux

38:39.000 --> 38:41.000
giant make file to hold nine yards, and then the or a D

38:41.000 --> 38:44.000
daemon. And that would be the minimal system. Everything else

38:44.000 --> 38:47.000
you would need to pass to it at run time.

38:47.000 --> 38:55.000
I think we have time for about one more question.

38:55.000 --> 38:58.000
So you said it doesn't do any higher order scheduling. I

38:58.000 --> 39:01.000
guess I'm kind of curious what, if you want to do things like

39:01.000 --> 39:04.000
resilience or steering or, you know, if the job dies, bring

39:04.000 --> 39:07.000
up what are people typically using with ora?

39:07.000 --> 39:10.000
So ora is still very new. I think that my hope for the

39:10.000 --> 39:13.000
project is kind of like the same hope I had with my book,

39:13.000 --> 39:17.000
like solve the lower layer first and then that is going to

39:17.000 --> 39:20.000
open the door for higher order conversations in the future.

39:20.000 --> 39:23.000
My hope is that there's a whole ecosystem of schedulers,

39:23.000 --> 39:25.000
right? You change your scheduler, you change your

39:25.000 --> 39:30.000
socks. Well, maybe not that often, but the point would be

39:30.000 --> 39:33.000
that that's very specific to the needs of the current

39:33.000 --> 39:36.000
organization that's working on it. And I would hope that we

39:36.000 --> 39:39.000
can still use the Kubernetes scheduler or the Nomad

39:39.000 --> 39:43.000
scheduler to schedule jobs on ora.

39:43.000 --> 39:46.000
I know there's also some machine learning folks who have

39:46.000 --> 39:48.000
some data resiliency problems that are interested in ora

39:48.000 --> 39:54.000
right now and plan on using some weird global mesh that

39:54.000 --> 39:57.000
will do a peer-to-peer network around the world, kind of

39:57.000 --> 40:00.000
bit torrent, and then they intend to use ora for that.

40:00.000 --> 40:03.000
So I think there's some opportunities there. The project

40:03.000 --> 40:07.000
itself won't ever have an opinion on a scheduler. Maybe I

40:07.000 --> 40:09.000
personally will start another project to do that in the

40:09.000 --> 40:12.000
future or something, but this is the scope for now.

40:12.000 --> 40:15.000
So that's all the time we have.

40:15.000 --> 40:16.000
Okay.

40:16.000 --> 40:31.000
Can we hear it again?
