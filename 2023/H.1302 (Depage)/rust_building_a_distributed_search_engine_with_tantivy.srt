1
0:00:00.000 --> 0:00:07.000
I'll just yell.

2
0:00:07.000 --> 0:00:11.240
But yeah, so this is effectively my talk.

3
0:00:11.240 --> 0:00:15.080
It started out as a really big thing and then I realised 40 minutes wasn't actually that

4
0:00:15.080 --> 0:00:21.540
much time and so we sort of had to compress it down into a bit of a slightly smaller talk

5
0:00:21.540 --> 0:00:26.000
but hopefully covering the most interesting points in my opinion.

6
0:00:26.000 --> 0:00:27.160
So a bit about me.

7
0:00:27.160 --> 0:00:28.160
I'm Harrison.

8
0:00:28.160 --> 0:00:29.360
I come from London.

9
0:00:29.360 --> 0:00:35.400
I live in London and I work for QuickWit where, as Paul has said, we build basically a distributed

10
0:00:35.400 --> 0:00:38.280
search engine for logs.

11
0:00:38.280 --> 0:00:45.840
I am the creator of LNX which is a slightly different design of search engine, probably

12
0:00:45.840 --> 0:00:51.440
more akin to something like Elasticsearch or Algolia for all your lovely e-commerce

13
0:00:51.440 --> 0:00:53.280
websites.

14
0:00:53.280 --> 0:00:58.040
And you can contact me at Harrison at QuickWit.io.

15
0:00:58.040 --> 0:01:04.280
A little bit about LNX since this is basically the origin story of this talk really.

16
0:01:04.280 --> 0:01:06.720
It's a search engine built on top of TantrV.

17
0:01:06.720 --> 0:01:09.840
It's akin to Elasticsearch or Algolia as I've said.

18
0:01:09.840 --> 0:01:11.360
It's aimed at user-facing search.

19
0:01:11.360 --> 0:01:16.480
That's things like your e-commerce websites, your Netflix streaming platforms, things like

20
0:01:16.480 --> 0:01:17.480
that.

21
0:01:17.480 --> 0:01:22.000
It's not aimed to be your cost-effective log search engine.

22
0:01:22.000 --> 0:01:26.240
It doesn't really handle those hundreds of terabytes a day type workloads but it will

23
0:01:26.240 --> 0:01:29.720
handle thousands of queries a second per core.

24
0:01:29.720 --> 0:01:31.320
It's very easily configurable.

25
0:01:31.320 --> 0:01:36.280
It's designed to be really fast out of the box because it uses TantrV and it has an indexing

26
0:01:36.280 --> 0:01:42.680
throughput of about 30 to 60 megabytes a second on reasonable hardware with high availability

27
0:01:42.680 --> 0:01:47.160
coming soon which is the presence of this talk.

28
0:01:47.160 --> 0:01:49.360
So what is user-facing search?

29
0:01:49.360 --> 0:01:54.760
I've stolen Crunchyroll's website and I've typed some bad spelling in there and you see

30
0:01:54.760 --> 0:01:59.400
that a lot of the top results actually account for the fact that I can't spell.

31
0:01:59.400 --> 0:02:03.640
That's basically the biggest principle with these user-facing search engines is you have

32
0:02:03.640 --> 0:02:06.840
this concept of typo tolerance.

33
0:02:06.840 --> 0:02:10.840
This is a really good thing for users because users can't spell.

34
0:02:10.840 --> 0:02:16.360
The downside of this is that it has a lot of CPU time when we're checking those additional

35
0:02:16.360 --> 0:02:23.920
words and it makes things a lot more complicated and often documents are mutable and a lot

36
0:02:23.920 --> 0:02:30.640
of other things but also when you have these nice search experiences and you want low latency,

37
0:02:30.640 --> 0:02:36.120
something called search as you type has become more popular now and that means your amount

38
0:02:36.120 --> 0:02:40.840
of search as you're doing for a single user is increasing several times over because now

39
0:02:40.840 --> 0:02:47.520
every key stroke you press is a search versus typing it all in one go, hitting enter, user

40
0:02:47.520 --> 0:02:51.360
gets a bunch of results back goes, oh no, I've spelled something wrong or I can't see

41
0:02:51.360 --> 0:02:55.760
what I want on here so I'm going to type it again.

42
0:02:55.760 --> 0:03:00.800
That is effectively the principle of these search engines.

43
0:03:00.800 --> 0:03:04.240
We have Algolia at the bottom which is a very common one which I think most people know,

44
0:03:04.240 --> 0:03:08.840
very popular for document searching.

45
0:03:08.840 --> 0:03:12.680
We decided, hey, we don't want to use one of these pre-built systems, we don't want

46
0:03:12.680 --> 0:03:15.880
to use Elasticsearch, that's big, that's scary, I don't like it.

47
0:03:15.880 --> 0:03:19.040
We don't want to use Algolia because I don't have that much money.

48
0:03:19.040 --> 0:03:23.800
I'm just a lowly paid software developer, I can't be spending thousands of pounds on

49
0:03:23.800 --> 0:03:25.440
that.

50
0:03:25.440 --> 0:03:28.920
We look at some of the others but we go, no, we're just going to write it ourselves and

51
0:03:28.920 --> 0:03:32.960
then that's where we have a little look because we hear something about Tantavy, we hear something

52
0:03:32.960 --> 0:03:38.720
about Rust and it being blazingly fast as all things must be and so we go, okay, I like

53
0:03:38.720 --> 0:03:40.400
this, I like what it says.

54
0:03:40.400 --> 0:03:45.000
It says Apache Lucene, I think I've heard that before somewhere, written in Rust, I

55
0:03:45.000 --> 0:03:47.920
think I've definitely heard that before.

56
0:03:47.920 --> 0:03:53.080
We take a little look at what it is and it is effectively akin to Lucene which if you

57
0:03:53.080 --> 0:03:56.800
don't know what that is, it's a full text search engine as it's called.

58
0:03:56.800 --> 0:04:01.440
Tantavy in particular supports things like BM25 scoring which is just a fancy way of

59
0:04:01.440 --> 0:04:05.440
saying what words are relevant to this query.

60
0:04:05.440 --> 0:04:08.840
It supports something called incremental indexing which basically just means you don't have

61
0:04:08.840 --> 0:04:13.400
to re-index all of your documents every time you change one thing.

62
0:04:13.400 --> 0:04:18.400
You have fasted search, you have range queries and we have things like JSON fields which

63
0:04:18.400 --> 0:04:22.020
allow for a schema-less indexing as such.

64
0:04:22.020 --> 0:04:27.560
You can do aggregations which have some limitations in particular around JSON fields being a little

65
0:04:27.560 --> 0:04:33.680
bit limited but the biggest thing is it has a cheesy logo with a horse which I believe

66
0:04:33.680 --> 0:04:39.080
Paul drew himself so I think that needs a clap on its own but there are other features

67
0:04:39.080 --> 0:04:40.680
which I just haven't.

68
0:04:40.680 --> 0:04:41.680
Yes.

69
0:04:41.680 --> 0:04:50.160
But there are more features which I can fit on this slide in time of the essence.

70
0:04:50.160 --> 0:04:55.080
So you might be wondering what the basic implementation of Tantavy looks like and because it's a

71
0:04:55.080 --> 0:04:58.360
library it's actually really quite simple to do.

72
0:04:58.360 --> 0:05:01.720
So we have a couple of core things starting at the top as we define what's called that

73
0:05:01.720 --> 0:05:03.440
schema.

74
0:05:03.440 --> 0:05:10.720
Since Tantavy was originally a schema-based system, we need some way of telling Tantavy

75
0:05:10.720 --> 0:05:15.320
what the structure of our documents are and defining what properties they have.

76
0:05:15.320 --> 0:05:20.440
We can use something like a JSON field to give the impression of a schema-less index

77
0:05:20.440 --> 0:05:23.920
but schemas are good, we should use them.

78
0:05:23.920 --> 0:05:29.000
They come with lots of nice bells and whistles so in this case we've created a schema with

79
0:05:29.000 --> 0:05:36.920
the title field and you can see there we've added the text and stored flag which all that

80
0:05:36.920 --> 0:05:42.200
really says is I'm going to tokenize this field and then I'm going to store it so we

81
0:05:42.200 --> 0:05:45.880
can retrieve it later on once we've done the search.

82
0:05:45.880 --> 0:05:51.080
The second thing we do once we've done that is we create our index writer and in this

83
0:05:51.080 --> 0:05:56.960
case we're just letting Tantavy select the number of threads so by default, when you

84
0:05:56.960 --> 0:06:04.160
create this index writer and we give it a memory buffer, in this case about 50 megabytes,

85
0:06:04.160 --> 0:06:09.400
we will allocate n number of threads, I think up to eight threads depending on what your

86
0:06:09.400 --> 0:06:15.160
system is using so you don't really have to put much thought into the multi-threaded indexing.

87
0:06:15.160 --> 0:06:19.400
Then we're just adding a document really so we've created our document, we've added the

88
0:06:19.400 --> 0:06:24.800
text field, we've given it in this case the old man of the sea and we're going to put

89
0:06:24.800 --> 0:06:28.800
it to our indexer which is essentially just adding it to a queue for the threads to pull

90
0:06:28.800 --> 0:06:32.480
off, process, spare our disk.

91
0:06:32.480 --> 0:06:37.720
If we want to actually have that be visible to our users for searching and things like

92
0:06:37.720 --> 0:06:43.560
that, we need to commit the index so in Tantavy you can either commit or you can roll back

93
0:06:43.560 --> 0:06:49.000
and if you have a power failure midway through indexing, when you reload from disk it will

94
0:06:49.000 --> 0:06:53.800
be at the point of that last commit which is very, very useful so you don't leave with

95
0:06:53.800 --> 0:06:57.400
partial state and all that nasty things.

96
0:06:57.400 --> 0:07:01.240
And then once we've done that, we can actually search and in this case you can either build

97
0:07:01.240 --> 0:07:06.160
queries using traits which are very nice and you can mash them all together with lots of

98
0:07:06.160 --> 0:07:11.400
boxing and things or you can use the query parser which basically parses a nice little

99
0:07:11.400 --> 0:07:18.040
query language, in this case we've got a very simple phrase query as it's called, trouble

100
0:07:18.040 --> 0:07:21.300
that up and it spits out a query for us.

101
0:07:21.300 --> 0:07:26.200
We then pass that into our search executor which in this case we're executing the query

102
0:07:26.200 --> 0:07:30.380
and then we're passing what are called collectors and they are effectively just a simple thing

103
0:07:30.380 --> 0:07:33.800
to process the documents which have matched.

104
0:07:33.800 --> 0:07:40.080
So in this case I believe we've got the count collector and the top docs collector and the

105
0:07:40.080 --> 0:07:45.600
count collector does what it counts, a big surprise there and we have the top docs which

106
0:07:45.600 --> 0:07:51.520
collects the top K documents up to a given limit so in this case we've selected 10.

107
0:07:51.520 --> 0:07:56.840
We only have one document to match so this doesn't matter that much but if you have more

108
0:07:56.840 --> 0:08:02.320
you can limit your results, you can adjust how things are scored etc.

109
0:08:02.320 --> 0:08:07.440
Now that's all well and good in this example but this doesn't actually really account for

110
0:08:07.440 --> 0:08:12.240
spelling and as we discussed earlier users aren't very good at spelling or at least I'm

111
0:08:12.240 --> 0:08:17.600
not so we maybe we want a bit of type intolerance and in this case Tanh Tui does provide us

112
0:08:17.600 --> 0:08:23.080
with some additional way of doing this in the form of the fuzzy term query.

113
0:08:23.080 --> 0:08:42.320
It uses something called lem

114
0:08:42.320 --> 0:08:48.600
swapping a word around, removing it, adding new words, a bit of magic there really.

115
0:08:48.600 --> 0:08:53.400
And as you can see at the bottom this is effectively if we use just the regular full text search

116
0:08:53.400 --> 0:08:59.040
well if we enter the term hello will only match with the word hello but if we go with

117
0:08:59.040 --> 0:09:02.980
the term hell will only match with the word hell.

118
0:09:02.980 --> 0:09:09.440
If we use some fuzzy term query here we can actually match hell and hello which is very

119
0:09:09.440 --> 0:09:13.480
useful especially for the prefix search.

120
0:09:13.480 --> 0:09:19.800
This is built upon Tanh Tui's inverted index which uses something called a FST which is

121
0:09:19.800 --> 0:09:24.560
effectively a fancy word for saying we threw state machines at it and then made them return

122
0:09:24.560 --> 0:09:26.440
results.

123
0:09:26.440 --> 0:09:31.080
That's as much as I can describe how they work, the person who originally wrote the

124
0:09:31.080 --> 0:09:37.720
FST library in Rust burnt sushi, he has a blog on this, goes into a lot of depth, really

125
0:09:37.720 --> 0:09:42.960
really useful for that sort of thing but I can't elaborate any more on that.

126
0:09:42.960 --> 0:09:48.080
But all of this additional walking through our index and matching these additional words

127
0:09:48.080 --> 0:09:52.920
does come at the cost of some additional CPU.

128
0:09:52.920 --> 0:09:57.720
And once we've sort of got that what we're left with is this nice block of data on our

129
0:09:57.720 --> 0:09:59.240
disks really.

130
0:09:59.240 --> 0:10:05.240
So we have some metadata files here in particular meta.json that contains your schema along

131
0:10:05.240 --> 0:10:10.520
with a couple other things and we have our sort of core files which look very similar,

132
0:10:10.520 --> 0:10:13.720
if they look very similar to these things that's because they are.

133
0:10:13.720 --> 0:10:18.480
In particular we have our field norms, our terms, our store which is effectively a row

134
0:10:18.480 --> 0:10:26.400
level store log file, our positions, our IDs and our fast fields.

135
0:10:26.400 --> 0:10:36.160
And fast fields are effectively fast because we cut somewhat simple and equally vague name.

136
0:10:36.160 --> 0:10:44.600
But now that we've got all this stuff on disk, if we wrap it up in an API, we've got everything.

137
0:10:44.600 --> 0:10:50.080
In this case we've got a demo of NNX working here and we've got about I think 27 million

138
0:10:50.080 --> 0:10:55.160
documents and we're searching it with about millisecond latency.

139
0:10:55.160 --> 0:10:59.680
I think in total it's about 20 gigabytes on disk compressed.

140
0:10:59.680 --> 0:11:05.680
Which is pretty nice but there's sort of a bit of an issue here which is if we deploy

141
0:11:05.680 --> 0:11:11.400
this production and our site is very nice, we get lots of traffic, things increase, we

142
0:11:11.400 --> 0:11:15.800
go, hmm, well, search traffic's increased, our server's not coping, let's just scale

143
0:11:15.800 --> 0:11:16.800
up the server.

144
0:11:16.800 --> 0:11:22.920
And we can repeat this for quite a lot and in fact things like AWS allow you a stupid

145
0:11:22.920 --> 0:11:27.240
amount of cores and things like that which you can scale up very easily.

146
0:11:27.240 --> 0:11:31.880
But you keep going along with this and eventually something happens and in this case your data

147
0:11:31.880 --> 0:11:34.400
center's burnt down.

148
0:11:34.400 --> 0:11:40.280
If anyone remembers this, this happened in 2021, OVH basically caught fire and that was

149
0:11:40.280 --> 0:11:44.440
an end of I think a lot of sleeping people.

150
0:11:44.440 --> 0:11:50.160
And so yeah, your data center's on fire, search isn't able to do anything, you're losing money,

151
0:11:50.160 --> 0:11:54.000
no one's buying anything, management's breathing down your neck for a fix, you're having to

152
0:11:54.000 --> 0:11:56.400
load from a backup, what are you gonna do?

153
0:11:56.400 --> 0:12:01.200
And well, you think, ah, I should have made some replicas, I should have done something

154
0:12:01.200 --> 0:12:04.040
called high availability.

155
0:12:04.040 --> 0:12:08.200
And in this case what this means is we have, instead of having one node on one server ready

156
0:12:08.200 --> 0:12:14.040
to burn down, we have three nodes available to burn down at any point in time.

157
0:12:14.040 --> 0:12:17.480
And in this case we hope that we've put them in different what are called availability

158
0:12:17.480 --> 0:12:21.840
zones which mean, hey, if one data center burns down there's a very small likelihood

159
0:12:21.840 --> 0:12:26.680
or at least is it possible for another data center to burn down in the meantime.

160
0:12:26.680 --> 0:12:31.560
And this allows us to effectively operate even though one server is currently on fire

161
0:12:31.560 --> 0:12:37.520
or lost to the ether or I don't know, network has torn itself to pieces.

162
0:12:37.520 --> 0:12:39.600
And this does also mean we can upgrade.

163
0:12:39.600 --> 0:12:43.400
If we want to tear a server down and we want to restart it with some newer hardware, we

164
0:12:43.400 --> 0:12:46.680
can do that without interrupting our existing system.

165
0:12:46.680 --> 0:12:51.400
But this is sort of a hard thing to do because now we've got to work out a way of getting

166
0:12:51.400 --> 0:12:54.400
the same documents across all of our nodes.

167
0:12:54.400 --> 0:12:57.720
In this case it's sort of a share nothing architecture.

168
0:12:57.720 --> 0:13:02.960
This is done by Elasticsearch and basically most systems.

169
0:13:02.960 --> 0:13:04.440
So we're just replicating the documents.

170
0:13:04.440 --> 0:13:08.340
We're not replicating all of that process data we've just done.

171
0:13:08.340 --> 0:13:13.320
We need to apply them to each node and doing this approach makes it a bit simpler.

172
0:13:13.320 --> 0:13:19.240
In reality LNX and QuickWit do something a little bit different but this is easier.

173
0:13:19.240 --> 0:13:24.800
I say this is easier because the initial solution would be just spin up more nodes.

174
0:13:24.800 --> 0:13:28.120
Add some RPC in there, what can go wrong?

175
0:13:28.120 --> 0:13:32.480
And then deep down you can work out, it's like oh, do you mean networks aren't reliable?

176
0:13:32.480 --> 0:13:35.120
What's a raft and things like that?

177
0:13:35.120 --> 0:13:39.440
And so at that point you go, okay, this is harder than I thought.

178
0:13:39.440 --> 0:13:44.180
And you realize the world is in fact a scary place outside your happy little data center.

179
0:13:44.180 --> 0:13:50.280
And you need some way of organizing states independent on things catching on fire.

180
0:13:50.280 --> 0:13:52.800
And this is a hard problem to solve.

181
0:13:52.800 --> 0:13:57.880
And so you have a little look around and you go, well, Rust is quite a new system, it's

182
0:13:57.880 --> 0:14:03.280
quite a young ecosystem, we're quite limited so we can't necessarily pick a Paxos implementation

183
0:14:03.280 --> 0:14:05.180
off the shelf.

184
0:14:05.180 --> 0:14:10.680
We maybe have something called raft, so that's a leader-based approach and that means we

185
0:14:10.680 --> 0:14:14.680
elect a leader and we say, okay, leader, tell us what to do.

186
0:14:14.680 --> 0:14:19.960
And it will say, okay, you handle these documents, go do things with them.

187
0:14:19.960 --> 0:14:22.920
It's a very well-known algorithm, very easy to understand.

188
0:14:22.920 --> 0:14:26.880
It's probably the only algorithm which is really implemented widely in Rust.

189
0:14:26.880 --> 0:14:32.280
So there's two implementations, one of them by the Pincap group called RaftRS and the

190
0:14:32.280 --> 0:14:36.920
other by DataFuse Labs called Open Raft.

191
0:14:36.920 --> 0:14:40.680
Varying levels of completion or pre-made.

192
0:14:40.680 --> 0:14:45.920
So in this case you think, okay, I don't really know what I'm doing here, so maybe I shouldn't

193
0:14:45.920 --> 0:14:49.440
be managing my own raft cluster.

194
0:14:49.440 --> 0:14:54.480
And you hear something about eventual consistency and you hear, oh, it's leaderless, any node

195
0:14:54.480 --> 0:14:57.280
can handle the writes and then ship it off to the other nodes.

196
0:14:57.280 --> 0:15:01.520
As long as the operations are idempotent and that's a very key point which means you can

197
0:15:01.520 --> 0:15:05.720
basically ship the same document over and over and over again and they're not going

198
0:15:05.720 --> 0:15:10.760
to duplicate themselves or at least they don't act like they duplicate.

199
0:15:10.760 --> 0:15:14.160
And this gives us realistically a bit more freedom.

200
0:15:14.160 --> 0:15:17.480
If we want to change, we can change.

201
0:15:17.480 --> 0:15:23.600
And so we decide, let's go with eventual consistency because, yeah, I like it an easy life and

202
0:15:23.600 --> 0:15:25.800
it seemed easier.

203
0:15:25.800 --> 0:15:28.320
Yes.

204
0:15:28.320 --> 0:15:33.800
People laughing will agree that, yes, things that seem easier probably aren't.

205
0:15:33.800 --> 0:15:36.480
And so our diagram sort of looks something like this.

206
0:15:36.480 --> 0:15:40.600
And I'm scared to cross the white line so I'll try and point, but we have step one.

207
0:15:40.600 --> 0:15:46.160
A client sends the documents to any node that doesn't really care which one.

208
0:15:46.160 --> 0:15:50.360
That client then goes, okay, I'm going to send it to some of my peers and then wait

209
0:15:50.360 --> 0:15:52.600
for them to tell me that they've got the document.

210
0:15:52.600 --> 0:15:53.600
It's safe.

211
0:15:53.600 --> 0:15:58.640
And then once we've got the majority, which is a very common approach in these systems,

212
0:15:58.640 --> 0:16:01.360
we can tell the client, okay, your document is safe.

213
0:16:01.360 --> 0:16:05.220
Even if OHV burns down again, we're probably going to be okay.

214
0:16:05.220 --> 0:16:08.880
It doesn't need to wait for all of the nodes to respond because otherwise you're not really

215
0:16:08.880 --> 0:16:13.920
highly available because if one node goes down, you can't progress.

216
0:16:13.920 --> 0:16:17.280
And so this system is pretty good.

217
0:16:17.280 --> 0:16:22.680
There's just one small problem which is how in God's name do you do this?

218
0:16:22.680 --> 0:16:24.600
Many questions need to be answered.

219
0:16:24.600 --> 0:16:28.880
Many things, how do you test this or who's going to have the time to do this?

220
0:16:28.880 --> 0:16:33.160
And well, luckily, someone, aka me, spent the better part of six months of their free

221
0:16:33.160 --> 0:16:35.600
time dealing with this.

222
0:16:35.600 --> 0:16:38.960
And so I made a library.

223
0:16:38.960 --> 0:16:40.880
And in this case, it's called Data Cape.

224
0:16:40.880 --> 0:16:42.640
Woo, yes.

225
0:16:42.640 --> 0:16:44.200
In this case, this is called Data Cape.

226
0:16:44.200 --> 0:16:48.720
I originally was going to call it Data Lake, but unfortunately that already exists.

227
0:16:48.720 --> 0:16:51.680
So we added cake at the end and called it a day.

228
0:16:51.680 --> 0:16:56.600
It is effectively a tooling to create your own distributed systems.

229
0:16:56.600 --> 0:17:00.960
It doesn't have to be eventually consistent, but it just is designed to make your life

230
0:17:00.960 --> 0:17:01.960
a lot easier.

231
0:17:01.960 --> 0:17:07.520
And it only took about six rewrites to get it to the stage that it is.

232
0:17:07.520 --> 0:17:09.160
Because yeah, things are hard.

233
0:17:09.160 --> 0:17:13.960
And trying to work out what you want to do with something like that is awkward.

234
0:17:13.960 --> 0:17:18.480
But some of the features it includes is it includes the zero copy RPC framework.

235
0:17:18.480 --> 0:17:23.000
And this is built upon the popular archive framework, which is really, really useful

236
0:17:23.000 --> 0:17:26.760
if you're shipping a lot of data because you don't actually have to deserialize and allocate

237
0:17:26.760 --> 0:17:28.480
everything all over again.

238
0:17:28.480 --> 0:17:32.480
You can just treat an initial buffer as if it's the data, which if that sounds wildly

239
0:17:32.480 --> 0:17:34.720
and safe, it is.

240
0:17:34.720 --> 0:17:39.120
But there's a lot of tests and I didn't write it, so you're safe.

241
0:17:39.120 --> 0:17:44.720
We also add the membership and failure detection.

242
0:17:44.720 --> 0:17:49.840
And this is done using chit chat, which is a library we made at QuickWit.

243
0:17:49.840 --> 0:17:54.080
It uses the same algorithm as something like Cassandra or DynamoDB.

244
0:17:54.080 --> 0:17:58.080
And this allows the system to essentially work out what nodes are actually its friends

245
0:17:58.080 --> 0:18:02.400
and what it can do.

246
0:18:02.400 --> 0:18:07.040
And in this case, we've also implemented an eventually consistent store in the form of

247
0:18:07.040 --> 0:18:13.280
a key value system, which only requires one trait to implement.

248
0:18:13.280 --> 0:18:16.920
And the reason why I went with this is because if you implement anything more than one trait,

249
0:18:16.920 --> 0:18:18.440
people seem to turn off.

250
0:18:18.440 --> 0:18:22.400
And frankly, I did when I looked at the raft implementations.

251
0:18:22.400 --> 0:18:24.320
So we went with one storage trait.

252
0:18:24.320 --> 0:18:26.600
That's all you need to get this to work.

253
0:18:26.600 --> 0:18:28.640
We also have some pre-built implementations.

254
0:18:28.640 --> 0:18:31.240
I particularly like abusing SQLite.

255
0:18:31.240 --> 0:18:34.920
So there is an SQLite implementation and a memory version.

256
0:18:34.920 --> 0:18:42.000
And it also gives you some CRDTs, which are conflict-free replicated data types, I should

257
0:18:42.000 --> 0:18:43.600
say.

258
0:18:43.600 --> 0:18:46.800
And also something called a hybrid logical clock, which means it's a clock which you

259
0:18:46.800 --> 0:18:51.240
can have across your cluster where the nodes will stabilize themselves and prevent you

260
0:18:51.240 --> 0:18:56.620
from effectively having to deal with this concept of causality.

261
0:18:56.620 --> 0:19:01.580
And causality is definitely the biggest issue you will ever run into with distributed systems

262
0:19:01.580 --> 0:19:06.120
because time is suddenly not reliable.

263
0:19:06.120 --> 0:19:10.680
And so we go back to our original thing of, well, first we actually need a cluster.

264
0:19:10.680 --> 0:19:12.800
And in this case, it's really simple to do.

265
0:19:12.800 --> 0:19:16.780
All we need to do is we just create our node builder.

266
0:19:16.780 --> 0:19:22.320
We tell Data Cake, OK, we've got your addresses this, your peers are this, or you can start

267
0:19:22.320 --> 0:19:27.160
with one peer and they'll discover themselves, who their neighbors are.

268
0:19:27.160 --> 0:19:28.600
And you give them a node ID.

269
0:19:28.600 --> 0:19:29.600
They're integers.

270
0:19:29.600 --> 0:19:30.600
They're not strings.

271
0:19:30.600 --> 0:19:34.120
And the reason for that is because there's a lot of bit packing of certain data types

272
0:19:34.120 --> 0:19:37.680
going on and strings do not do well.

273
0:19:37.680 --> 0:19:42.680
And here we can also effectively wait for nodes to come onto the system so our cluster

274
0:19:42.680 --> 0:19:46.880
is stable and ready to go before we actually do anything else.

275
0:19:46.880 --> 0:19:50.240
And by the time we get to this point, our RPC systems are working.

276
0:19:50.240 --> 0:19:51.240
Nodes are communicating.

277
0:19:51.240 --> 0:19:54.140
Your clocks have synchronized themselves, mostly.

278
0:19:54.140 --> 0:19:58.160
And you can actually start adding something called extensions.

279
0:19:58.160 --> 0:20:05.240
Now extensions essentially allow you to extend your existing cluster.

280
0:20:05.240 --> 0:20:06.440
You can do this at runtime.

281
0:20:06.440 --> 0:20:11.840
They can be added and they can be unloaded all at runtime with state cleanup and everything

282
0:20:11.840 --> 0:20:16.000
else, which makes life a lot easier, especially for testing.

283
0:20:16.000 --> 0:20:20.500
They have access to the running node on this local system, which allows you to access things

284
0:20:20.500 --> 0:20:25.680
like the cluster clock, the RPC network, as it's called, which is the preestablished RPC

285
0:20:25.680 --> 0:20:27.620
connections.

286
0:20:27.620 --> 0:20:32.720
And you can essentially make this as simple or as complex as possible, which is essentially

287
0:20:32.720 --> 0:20:33.720
what I've done here.

288
0:20:33.720 --> 0:20:38.580
So I've created this nice little extension, which is absolutely nothing other than print

289
0:20:38.580 --> 0:20:42.360
what the current time is, which realistically I could do without.

290
0:20:42.360 --> 0:20:45.240
But nonetheless, I went with it.

291
0:20:45.240 --> 0:20:49.540
And this is what the eventual consistency store actually does under the hood, is it's

292
0:20:49.540 --> 0:20:51.440
just an extension.

293
0:20:51.440 --> 0:20:56.680
And here we can see that we're passing in a, I can't point that far, but we can, we

294
0:20:56.680 --> 0:21:00.640
pass in a memstore, which is our storage trait.

295
0:21:00.640 --> 0:21:07.600
We pass in our eventual consistency extension using this and we pass it to the data cake

296
0:21:07.600 --> 0:21:13.420
node and say, okay, go add this extension, give me the result back when you're ready.

297
0:21:13.420 --> 0:21:18.480
And in this case, our eventual consistency cluster actually returns us a storage handle,

298
0:21:18.480 --> 0:21:23.720
which allows us to do basically all of our lovely key value operations, should we wish,

299
0:21:23.720 --> 0:21:31.360
including delete, put, get, that's about all there is on the key value store.

300
0:21:31.360 --> 0:21:35.520
But there are also some bulk operations which allow for much more efficient replication

301
0:21:35.520 --> 0:21:37.760
of data.

302
0:21:37.760 --> 0:21:42.080
The only problem with this approach is it's not suitable for billion scale databases.

303
0:21:42.080 --> 0:21:46.880
So if you're trying to make the next Cassandra or Cilla, don't use this particular extension

304
0:21:46.880 --> 0:21:53.440
because it keeps the key value or the keys, sorry, in memory, which it uses to work out

305
0:21:53.440 --> 0:21:56.800
what keys have and have not been processed.

306
0:21:56.800 --> 0:22:01.200
And the reason for this is effectively because I didn't really trust users implementing this

307
0:22:01.200 --> 0:22:05.840
on the storage side correctly, which turned out to be a good choice because the amount

308
0:22:05.840 --> 0:22:09.840
of unit tests that this failed initially was a lot.

309
0:22:09.840 --> 0:22:13.640
And so now we've sort of got this ability to replicate our key values.

310
0:22:13.640 --> 0:22:16.120
Our life is a lot easier.

311
0:22:16.120 --> 0:22:21.160
In particular, we can actually go as far as essentially saying, okay, we've established

312
0:22:21.160 --> 0:22:27.400
our data connection, our key values, let's just use Tanteri as our persistent store.

313
0:22:27.400 --> 0:22:30.440
And this is effectively the simplest way to do it.

314
0:22:30.440 --> 0:22:34.000
And I've made a little demo here, which you can go to that link.

315
0:22:34.000 --> 0:22:41.000
I basically abused and slightly ignored certain things in particular correctness, but this

316
0:22:41.000 --> 0:22:43.240
will replicate your data.

317
0:22:43.240 --> 0:22:47.640
You may end up with duplicate documents because I didn't handle deduping.

318
0:22:47.640 --> 0:22:51.440
But in this case, we can fetch, we can delete, and we can index documents with Tanteri, and

319
0:22:51.440 --> 0:22:53.040
that's our persistent store.

320
0:22:53.040 --> 0:22:58.640
And here you can see we're doing about 20,000 documents in 400 milliseconds in the local

321
0:22:58.640 --> 0:23:00.640
cluster.

322
0:23:00.640 --> 0:23:02.660
Yes.

323
0:23:02.660 --> 0:23:08.440
And that is effectively the end.

324
0:23:08.440 --> 0:23:19.640
Great, so are there any questions?

325
0:23:19.640 --> 0:23:20.640
How long do we have left?

326
0:23:20.640 --> 0:23:23.640
Oh, how long do we have left?

327
0:23:23.640 --> 0:23:24.640
15 minutes.

328
0:23:24.640 --> 0:23:25.640
15.

329
0:23:25.640 --> 0:23:26.640
Nice.

330
0:23:26.640 --> 0:23:27.640
Wow.

331
0:23:27.640 --> 0:23:28.640
Excellent timing.

332
0:23:28.640 --> 0:23:33.640
Do we have a question down here in the front?

333
0:23:33.640 --> 0:23:34.640
Yes.

334
0:23:34.640 --> 0:23:42.720
So, I actually kind of saw in there.

335
0:23:42.720 --> 0:23:54.320
Do you have a way to provide from outside to the Tentivity transaction or Lynx transaction

336
0:23:54.320 --> 0:24:00.200
an external ID that I can use to integrate with the standard storage?

337
0:24:00.200 --> 0:24:02.280
Change the question would be an easier way.

338
0:24:02.280 --> 0:24:07.160
Do you have a way to say which level of data has been indexed?

339
0:24:07.160 --> 0:24:12.800
Yes, so in this case, I've sort of glossed over it a little bit because in reality, it's

340
0:24:12.800 --> 0:24:16.480
a little bit more complicated when you implement it.

341
0:24:16.480 --> 0:24:21.040
So in reality, when you actually implement this, you would probably have a, essentially,

342
0:24:21.040 --> 0:24:25.200
use the replication to replicate the initial documents, and then you would have a check

343
0:24:25.200 --> 0:24:29.400
mark to essentially work out what documents have and have not been indexed yet.

344
0:24:29.400 --> 0:24:34.720
Or you would add an additional step like a write-ahead log so that way you know that

345
0:24:34.720 --> 0:24:39.640
as long as the documents are there, you can make sure that your check, your commit point

346
0:24:39.640 --> 0:24:43.840
is always updated to the latest thing.

347
0:24:43.840 --> 0:24:48.940
In LNX, it's actually a little bit different again because the way it creates indexes is

348
0:24:48.940 --> 0:24:55.240
they are per checkpoint, so a new index has created every commit effectively.

349
0:24:55.240 --> 0:24:59.360
But you don't have to do that, and in this method, I didn't.

350
0:24:59.360 --> 0:25:06.040
So yeah, it doesn't do it here, but you can add a write-ahead log and you can basically

351
0:25:06.040 --> 0:25:09.720
do anything as long as the trait is implemented.

352
0:25:09.720 --> 0:25:11.120
Hello?

353
0:25:11.120 --> 0:25:12.440
Hello?

354
0:25:12.440 --> 0:25:13.600
Hi.

355
0:25:13.600 --> 0:25:14.600
Anymore?

356
0:25:14.600 --> 0:25:16.680
Okay, okay, okay.

357
0:25:16.680 --> 0:25:28.440
All right, so congratulations for the presentation.

358
0:25:28.440 --> 0:25:29.440
I think I can see you.

359
0:25:29.440 --> 0:25:30.440
Thank you.

360
0:25:30.440 --> 0:25:31.440
Yes, hello.

361
0:25:31.440 --> 0:25:32.440
So congratulations on the top.

362
0:25:32.440 --> 0:25:33.440
I'm just having a question regarding the matching that's happening beyond the search engine.

363
0:25:33.440 --> 0:25:34.440
Are there any plans to support something beyond the N20 class, such as vector space modeling

364
0:25:34.440 --> 0:25:47.440
or vector search, or is this something that's in the coming time?

365
0:25:47.440 --> 0:25:54.000
So let me see if I got that question right.

366
0:25:54.000 --> 0:26:00.440
So was that about extending Tan to V, so if you want to go beyond something like BM25

367
0:26:00.440 --> 0:26:03.440
or Lievenstein's distance and things like that?

368
0:26:03.440 --> 0:26:04.440
Yeah.

369
0:26:04.440 --> 0:26:12.440
What is the support apart from BM25 that are plans to support the other kind of searches,

370
0:26:12.440 --> 0:26:13.440
such as distance searches?

371
0:26:13.440 --> 0:26:18.000
I think things like vector search or word embedding search is still something which

372
0:26:18.000 --> 0:26:23.800
is quite far away and would need quite a big push to do with Tan to V specifically.

373
0:26:23.800 --> 0:26:27.600
If you want to add additional queries or additional functionality, it's quite easy to add with

374
0:26:27.600 --> 0:26:30.720
Tan to V, so it's actually just a query trait.

375
0:26:30.720 --> 0:26:37.720
So one of the things that NNX does, it actually has another query made called fast fuzzy,

376
0:26:37.720 --> 0:26:42.120
which actually uses another algorithm for pre-computing dictionaries in order to do

377
0:26:42.120 --> 0:26:43.920
the edit distance lookup.

378
0:26:43.920 --> 0:26:48.160
And that basically just involves creating another query.

379
0:26:48.160 --> 0:26:53.220
And you can customize effectively all of your query logic, all of your collecting logic,

380
0:26:53.220 --> 0:26:54.220
and things like that.

381
0:26:54.220 --> 0:26:59.120
So providing you're within the scope of the API, Tan to V will allow you to implement

382
0:26:59.120 --> 0:27:00.120
it yourself.

383
0:27:00.120 --> 0:27:04.000
Otherwise, things like the word embeddings, which are a little bit more complicated and

384
0:27:04.000 --> 0:27:06.900
require a bit more on the storage side, would need to.

385
0:27:06.900 --> 0:27:11.080
An issue and a very motivated individual to probably implement that, which currently we

386
0:27:11.080 --> 0:27:14.080
don't really have.

387
0:27:14.080 --> 0:27:30.080
So it's pretty little question.

388
0:27:30.080 --> 0:27:35.200
On all your sketches, the network, the subject network was fully connected.

389
0:27:35.200 --> 0:27:38.320
Is that important?

390
0:27:38.320 --> 0:27:40.360
Let me see if I can find which one that was.

391
0:27:40.360 --> 0:27:45.720
Was it this one or was it this one?

392
0:27:45.720 --> 0:27:52.720
Well on this one, it does not look fully connected, but I'm not sure if this diagram depicts connectivity,

393
0:27:52.720 --> 0:28:00.280
connectome, or just which messages has actually been dispatched.

394
0:28:00.280 --> 0:28:04.760
I'm going to cross the forbidden white line here because we're doing questions.

395
0:28:04.760 --> 0:28:11.480
And effectively, these are just indicating sending responses and getting things back.

396
0:28:11.480 --> 0:28:17.360
So these nodes don't actually, in a real system, you could have a network petition here, and

397
0:28:17.360 --> 0:28:19.400
your node one can no longer talk to node three.

398
0:28:19.400 --> 0:28:21.360
It's effectively lost to the ether.

399
0:28:21.360 --> 0:28:24.400
And maybe node two can also not do it.

400
0:28:24.400 --> 0:28:27.640
And in this case, it doesn't actually really care.

401
0:28:27.640 --> 0:28:31.960
All that you need to do is you need to achieve what's called a consistency level.

402
0:28:31.960 --> 0:28:36.360
Which means that if you want to progress, you have to reach that level, otherwise things

403
0:28:36.360 --> 0:28:39.600
are counted as not happening.

404
0:28:39.600 --> 0:28:44.120
And so in this case, if node three is down or can't be contacted, as long as node one

405
0:28:44.120 --> 0:28:50.040
can contact node two, and node two acknowledges the messages, things can still progress.

406
0:28:50.040 --> 0:28:51.360
This is the same with raft as well.

407
0:28:51.360 --> 0:28:55.080
So raft operates on what's called a quorum.

408
0:28:55.080 --> 0:29:01.200
But effectively, any one node can go down in a three node group, and the other two nodes

409
0:29:01.200 --> 0:29:04.400
can still progress, providing they have what's the majority.

410
0:29:04.400 --> 0:29:10.000
So we understand full connection of the network is not an important factor here.

411
0:29:10.000 --> 0:29:11.240
Well, it's nice to know.

412
0:29:11.240 --> 0:29:22.040
Thank you.

413
0:29:22.040 --> 0:29:24.280
Thank you for your talk.

414
0:29:24.280 --> 0:29:28.880
I see here that there is basically a consistency mechanism for indexing.

415
0:29:28.880 --> 0:29:33.120
Do you check as well if it had an over nodes when there is a search request as well?

416
0:29:33.120 --> 0:29:34.120
Say that again.

417
0:29:34.120 --> 0:29:35.720
Sorry, I didn't quite pick that up.

418
0:29:35.720 --> 0:29:40.040
Do you check if it had an over node when there is a search request?

419
0:29:40.040 --> 0:29:41.480
Not an indexing request?

420
0:29:41.480 --> 0:29:45.240
In this case, we have relaxed reads essentially.

421
0:29:45.240 --> 0:29:50.880
So we don't do, we're not searching across several nodes and getting the most updated

422
0:29:50.880 --> 0:29:55.960
version from that, which is part of the trade-off you make with the eventual consistency.

423
0:29:55.960 --> 0:29:59.640
You will have that with raft as well effectively, unless you contact the leader, you won't have

424
0:29:59.640 --> 0:30:02.760
the most update data when searching.

425
0:30:02.760 --> 0:30:09.760
But one of the things you do have to do if you go with the eventual consistency approach

426
0:30:09.760 --> 0:30:17.880
like we do here is you would need to effectively handle the idea that maybe you will have duplicate

427
0:30:17.880 --> 0:30:22.920
documents because something's been resent in the meantime, and so you'll need to be

428
0:30:22.920 --> 0:30:28.320
able to deduplicate that when you're searching or have some other method of handling it and

429
0:30:28.320 --> 0:30:29.800
deleting it from the index.

430
0:30:29.800 --> 0:30:34.000
So that means that effectively every node must have a copy of the data.

431
0:30:34.000 --> 0:30:38.360
I cannot have five nodes like a free repeat guard system or something like that?

432
0:30:38.360 --> 0:30:39.360
Yeah.

433
0:30:39.360 --> 0:30:44.920
So as long as if you've got a five node cluster and three nodes respond, you can immediately

434
0:30:44.920 --> 0:30:48.280
search from, if those three nodes have got the data, they can immediately be searched

435
0:30:48.280 --> 0:30:50.040
from effectively if you want.

436
0:30:50.040 --> 0:30:54.120
But the other nodes may take a little bit of time to catch up, which is the principle

437
0:30:54.120 --> 0:30:55.320
with eventual consistency.

438
0:30:55.320 --> 0:31:02.320
They'll eventually align themselves, but they're not all immediately able to reflect changes.

439
0:31:02.320 --> 0:31:05.640
One question down here.

440
0:31:05.640 --> 0:31:06.640
Hello.

441
0:31:06.640 --> 0:31:07.880
Just a simple one.

442
0:31:07.880 --> 0:31:11.580
In hindsight, would you take the raft part?

443
0:31:11.580 --> 0:31:15.360
In hindsight, probably not still.

444
0:31:15.360 --> 0:31:22.440
And the reason for that is because the current state of the Rust ecosystem with it means

445
0:31:22.440 --> 0:31:28.680
that there's a lot of black holes effectively around it.

446
0:31:28.680 --> 0:31:32.560
And so you're either going with an implementation which is very, very stripped down in just

447
0:31:32.560 --> 0:31:38.760
the state machine part, or going with an implementation which is very, very trait heavy and is a little

448
0:31:38.760 --> 0:31:42.760
bit opaque around what you need to test, what you don't need to test, and how it behaves

449
0:31:42.760 --> 0:31:44.120
under failure.

450
0:31:44.120 --> 0:31:49.600
So in this case, I like this approach more because it allowed me to implement things

451
0:31:49.600 --> 0:31:52.900
like network simulation, which the RPC framework supports.

452
0:31:52.900 --> 0:32:00.200
So we can actually simulate networks failing locally in tests and things like that, which

453
0:32:00.200 --> 0:32:04.560
makes me feel a little bit more confident than trying to just have the state machine

454
0:32:04.560 --> 0:32:08.800
and implement everything and all the handling correctly.

455
0:32:08.800 --> 0:32:13.960
But I think in future, yeah, you could use it, but it's just not quite at that state.

456
0:32:13.960 --> 0:32:14.960
Great.

457
0:32:14.960 --> 0:32:19.960
If that's all the questions, then...

458
0:32:19.960 --> 0:32:23.960
Should I stand up?

459
0:32:23.960 --> 0:32:28.400
Yeah, for sure.

460
0:32:28.400 --> 0:32:29.400
Actually no.

461
0:32:29.400 --> 0:32:32.600
What was I going to ask?

462
0:32:32.600 --> 0:32:41.200
So I'm not sure I quite got how... if the engine actually does any data sharding or

463
0:32:41.200 --> 0:32:43.520
there's a hash ring or...

464
0:32:43.520 --> 0:32:50.400
Yeah, so in this approach, for the simplicity of time really, we're not actually doing any

465
0:32:50.400 --> 0:32:52.720
data sharding.

466
0:32:52.720 --> 0:32:57.080
Servers are really quite big nowadays, so even for your e-commerce website, you can

467
0:32:57.080 --> 0:33:03.720
get a pretty huge server and the biggest issue tends to be replication and high availability.

468
0:33:03.720 --> 0:33:07.080
The data sharding is something that...

469
0:33:07.080 --> 0:33:11.680
QuickWit is something that would be concerned about because you've got so much data, you

470
0:33:11.680 --> 0:33:15.000
need to spread it across machines and things like that when you're searching.

471
0:33:15.000 --> 0:33:19.400
But in e-commerce, at the point in which you're searching across multiple machines, you're

472
0:33:19.400 --> 0:33:22.800
probably going to be looking at the higher latencies.

473
0:33:22.800 --> 0:33:27.800
So you would be better off dedicating one machine per search rather than several machines

474
0:33:27.800 --> 0:33:30.800
per search, really.

475
0:33:30.800 --> 0:33:32.800
Awesome.

476
0:33:32.800 --> 0:33:39.480
So I think that's all of our questions.

477
0:33:39.480 --> 0:33:43.760
Thank you.

