1
0:00:00.000 --> 0:00:09.880
All right, welcome.

2
0:00:09.880 --> 0:00:13.880
How do you like our little Duke rock stars here?

3
0:00:13.880 --> 0:00:18.760
So there's stickers going around somewhere so you can get some of these stickers.

4
0:00:18.760 --> 0:00:22.600
I think we have four different rock stars or something.

5
0:00:22.600 --> 0:00:29.360
Anyway, so stock is about Quarkus, obviously.

6
0:00:29.360 --> 0:00:30.360
Who am I?

7
0:00:30.360 --> 0:00:32.360
I'm a developer advocate at Red Hat.

8
0:00:32.360 --> 0:00:34.080
My name is Kevin Dubois.

9
0:00:34.080 --> 0:00:44.640
You can find me on Twitter or Macedon.

10
0:00:44.640 --> 0:00:52.080
So I know we've already talked in a few sessions today about traditional Java and the startup

11
0:00:52.080 --> 0:00:56.600
time and all that stuff, so I'll do that some more.

12
0:00:56.600 --> 0:01:00.520
So we'll talk about traditional Java.

13
0:01:00.520 --> 0:01:08.900
So traditional Java is, let me see the little hand.

14
0:01:08.900 --> 0:01:14.400
Traditional Java is designed for, let's say, different times, not designed for cloud-native

15
0:01:14.400 --> 0:01:15.400
workloads necessarily.

16
0:01:15.400 --> 0:01:22.480
It's designed for running kind of long time.

17
0:01:22.480 --> 0:01:27.120
And what's important in traditional Java is throughput at the expense of footprint.

18
0:01:27.120 --> 0:01:29.680
So footprint can be quite large, right?

19
0:01:29.680 --> 0:01:37.540
You typically have traditional Java applications running on pretty beefy servers.

20
0:01:37.540 --> 0:01:43.360
And they're designed to be long running, and you have dynamic loading and all that stuff

21
0:01:43.360 --> 0:01:45.340
with mutable systems.

22
0:01:45.340 --> 0:01:52.640
But in the cloud-native world, your throughput, you get that mostly through scaling.

23
0:01:52.640 --> 0:01:58.680
Your workloads are ephemeral, which means that if you think of containers, when you

24
0:01:58.680 --> 0:02:04.600
scale up a container, when you start up a new application, those containers are going

25
0:02:04.600 --> 0:02:09.560
to start up, and then maybe they're going to get rescheduled on a different node.

26
0:02:09.560 --> 0:02:12.240
And so containers kind of come and go.

27
0:02:12.240 --> 0:02:13.960
They're not going to be around.

28
0:02:13.960 --> 0:02:19.120
And if you change something in a container, that change is not going to last, right?

29
0:02:19.120 --> 0:02:24.200
Because that container, whatever you change inside, that's going to be gone when that

30
0:02:24.200 --> 0:02:28.440
container gets removed.

31
0:02:28.440 --> 0:02:35.000
So in that sense, we have to think of Java in a different way.

32
0:02:35.000 --> 0:02:40.200
We need to think about the footprint of it, because we want smaller containers that we

33
0:02:40.200 --> 0:02:44.400
can schedule across different servers.

34
0:02:44.400 --> 0:02:51.120
If you are familiar with Kubernetes and clusters, there's usually multiple servers on which

35
0:02:51.120 --> 0:02:52.680
it schedules containers.

36
0:02:52.680 --> 0:02:56.040
So we need to be able to handle that.

37
0:02:56.040 --> 0:03:06.000
And so that's where Quarkus started was kind of invented, I guess, because it's a framework

38
0:03:06.000 --> 0:03:13.240
that uses Java, but we call it supersonic because it starts up very fast subatomic because

39
0:03:13.240 --> 0:03:17.960
it's very small, like subatomic smaller than an atom.

40
0:03:17.960 --> 0:03:21.000
And it's still Java.

41
0:03:21.000 --> 0:03:29.200
So if we look at Quarkus in terms of startup time and in terms of memory usage, you can

42
0:03:29.200 --> 0:03:37.560
see here, this is a test that they did with a relatively small application running on

43
0:03:37.560 --> 0:03:39.640
a traditional cloud native stack.

44
0:03:39.640 --> 0:03:47.200
It took 136 megs of memory running the same application.

45
0:03:47.200 --> 0:03:54.040
With Quarkus, you already got pretty good gain in memory, right?

46
0:03:54.040 --> 0:03:55.540
And that's running on the JVM.

47
0:03:55.540 --> 0:03:58.640
So it's the exact same application running on the JVM.

48
0:03:58.640 --> 0:04:06.520
And then compiled down to a native, with GraalVM, you get, of course, even less memory usage.

49
0:04:06.520 --> 0:04:11.640
And you can see here, too, Quarkus starts up quite a bit faster than a traditional cloud

50
0:04:11.640 --> 0:04:16.440
native stack, which is ideal when we're talking about cloud native, when we're talking about

51
0:04:16.440 --> 0:04:23.120
containers, talking about serverless, where we need to start up really fast so we can

52
0:04:23.120 --> 0:04:27.660
react quickly to changing loads.

53
0:04:27.660 --> 0:04:30.280
So startup time is one thing.

54
0:04:30.280 --> 0:04:34.480
There's also the warm up issue.

55
0:04:34.480 --> 0:04:38.040
I don't know if issue is the right word.

56
0:04:38.040 --> 0:04:43.880
Actually when an application starts up, it takes a while with Java before you get your

57
0:04:43.880 --> 0:04:46.480
maximum throughput as well.

58
0:04:46.480 --> 0:04:54.920
So here we can see that, you know, like a traditional Java application, this is actually

59
0:04:54.920 --> 0:05:01.120
the points, and I think this is like 13 seconds or something, before it's actually able to

60
0:05:01.120 --> 0:05:06.700
be working at maximum throughput, which, you know, for this particular use case, it needed

61
0:05:06.700 --> 0:05:11.760
a certain amount of throughput to be able to handle load enough.

62
0:05:11.760 --> 0:05:14.840
And then you can see here with Quarkus, it goes quite a bit faster.

63
0:05:14.840 --> 0:05:18.160
Now Quarkus isn't just about fast startup time.

64
0:05:18.160 --> 0:05:21.160
It's not just about memory.

65
0:05:21.160 --> 0:05:24.200
But it is kind of a nice feature of Quarkus.

66
0:05:24.200 --> 0:05:31.160
So if we think of containers and Kubernetes nodes, traditional Java applications running

67
0:05:31.160 --> 0:05:37.880
on EAP or WebSphere or whatever, running on a Kubernetes node, you can see they take up

68
0:05:37.880 --> 0:05:39.200
quite a bit of space.

69
0:05:39.200 --> 0:05:48.760
Let's say that in this case, only four instances of the application can run, which isn't so

70
0:05:48.760 --> 0:05:55.800
ideal because if one of the pods, one of the containers goes down, that means you lose

71
0:05:55.800 --> 0:06:01.540
25% of your workload, right?

72
0:06:01.540 --> 0:06:06.920
If you look at Quarkus, on the JVM, you already have quite a bit more density, which means

73
0:06:06.920 --> 0:06:12.680
that if one of these guys goes down or needs to be rescheduled or whatever, you still have,

74
0:06:12.680 --> 0:06:18.240
you know, what is it, maybe 70% or something?

75
0:06:18.240 --> 0:06:21.840
That's still up.

76
0:06:21.840 --> 0:06:30.240
And we can compare that to Node.js or Go or something where Go has quite a smaller footprint

77
0:06:30.240 --> 0:06:36.480
and with Quarkus Native, we can actually be very comparable with Go, which is nice because

78
0:06:36.480 --> 0:06:43.600
that means that we can use our Java skills and not have to change languages and reinvent

79
0:06:43.600 --> 0:06:51.200
the wheel and still get all the benefits in the cloud-native world of having fast startup

80
0:06:51.200 --> 0:06:52.200
and everything.

81
0:06:52.200 --> 0:06:53.640
So how does that work?

82
0:06:53.640 --> 0:06:59.640
So a traditional Java application, basically build time is when you do your packaging and

83
0:06:59.640 --> 0:07:05.040
then as it starts up, it loads, config files, and then does class-pass scanning and build

84
0:07:05.040 --> 0:07:07.360
kind of its model of the world and everything.

85
0:07:07.360 --> 0:07:09.440
But this is when it starts up.

86
0:07:09.440 --> 0:07:14.040
So if you think of containers, again, that means that this all happens when the container

87
0:07:14.040 --> 0:07:16.120
starts up.

88
0:07:16.120 --> 0:07:20.360
And that takes a while.

89
0:07:20.360 --> 0:07:27.920
And then so with Quarkus, what we try to do is instead of doing all that, you know, at

90
0:07:27.920 --> 0:07:33.840
runtime at startup time, we're trying to do all of this or as much as we can during build

91
0:07:33.840 --> 0:07:41.080
time before the application actually gets packaged, which means that during runtime

92
0:07:41.080 --> 0:07:43.000
we have a lot less to do, right?

93
0:07:43.000 --> 0:07:44.800
So it starts up quite a bit faster.

94
0:07:44.800 --> 0:07:49.600
So that's kind of the cool thing about Quarkus.

95
0:07:49.600 --> 0:07:56.240
And then so you can use Quarkus on the JVM or you can compile it down to native, of course,

96
0:07:56.240 --> 0:08:00.960
just like most other frameworks.

97
0:08:00.960 --> 0:08:05.040
But there's some cool things about native compilation with Quarkus as well that we'll

98
0:08:05.040 --> 0:08:06.800
get into in just a second.

99
0:08:06.800 --> 0:08:09.880
So this is my favorite part about Quarkus.

100
0:08:09.880 --> 0:08:13.440
It's not necessarily, I mean, yes, it's nice that it starts up fast.

101
0:08:13.440 --> 0:08:17.080
It's nice that it has a small memory footprint.

102
0:08:17.080 --> 0:08:22.920
But what's really cool about Quarkus is that it has a bunch of different ways of making

103
0:08:22.920 --> 0:08:31.160
the experience of working with Java and Quarkus a lot more fun.

104
0:08:31.160 --> 0:08:35.960
So one of them is, you know, so of course it's based on standards.

105
0:08:35.960 --> 0:08:42.720
So Quarkus uses, you know, your Java EE standards, your Java standards, uses, you know, Vertex

106
0:08:42.720 --> 0:08:44.980
and all that good stuff.

107
0:08:44.980 --> 0:08:46.960
So if you're used to that, hey, great.

108
0:08:46.960 --> 0:08:52.840
You basically already know Quarkus for 99%.

109
0:08:52.840 --> 0:08:56.640
What's really cool with Quarkus is that there's this dev mode.

110
0:08:56.640 --> 0:09:02.280
Basically you can start Quarkus on your local machine in dev mode.

111
0:09:02.280 --> 0:09:09.240
It's going to start up and it's going to just keep checking to see if you make changes in

112
0:09:09.240 --> 0:09:10.480
the class path.

113
0:09:10.480 --> 0:09:14.920
And so every time you make a change, it's going to automatically reload when you, you

114
0:09:14.920 --> 0:09:18.440
know, let's say go into your browser, whatever, you make a new request.

115
0:09:18.440 --> 0:09:25.400
It's going to automatically reload your application so you don't need to recompile, redeploy

116
0:09:25.400 --> 0:09:28.480
every time you want to test something.

117
0:09:28.480 --> 0:09:29.800
Quarkus does that automatically.

118
0:09:29.800 --> 0:09:34.680
So you can just go to your browser, hit refresh, and it's there.

119
0:09:34.680 --> 0:09:38.040
So make a code change, refresh, it's there.

120
0:09:38.040 --> 0:09:44.440
Which you know, if you're a developer of a couple, you know, of some other language where

121
0:09:44.440 --> 0:09:49.720
that just happens, then that's not so cool, but in Java that's pretty cool, right?

122
0:09:49.720 --> 0:09:53.480
So you've got our little guy here that says wait, so you just save it and your code is

123
0:09:53.480 --> 0:09:55.600
running and it's Java.

124
0:09:55.600 --> 0:10:00.000
And the guy says, I know, right, supersonic Java.

125
0:10:00.000 --> 0:10:03.960
So that's pretty cool.

126
0:10:03.960 --> 0:10:08.200
Another cool thing with Quarkus is that it has this concept of developer services.

127
0:10:08.200 --> 0:10:12.000
So who knows test containers?

128
0:10:12.000 --> 0:10:17.100
So basically it uses test containers built into Quarkus.

129
0:10:17.100 --> 0:10:25.480
So let's say that I'm developing an application and I'm adding an extension to use Postgres

130
0:10:25.480 --> 0:10:31.760
database or a Kafka topic or something.

131
0:10:31.760 --> 0:10:36.800
Actually, well, of course you have to have a Docker or Podman or something running on

132
0:10:36.800 --> 0:10:38.360
your local machine.

133
0:10:38.360 --> 0:10:47.040
But Quarkus will look and see, hey, you've got this dependency on a database.

134
0:10:47.040 --> 0:10:49.520
Do you have something configured on your local machine?

135
0:10:49.520 --> 0:10:51.600
Do you have a database running on your local machine?

136
0:10:51.600 --> 0:10:54.240
Is that configured in your application properties?

137
0:10:54.240 --> 0:10:55.840
If not, no worries.

138
0:10:55.840 --> 0:11:03.600
I'm just going to start up a container with that dependency, for example, a Postgres database

139
0:11:03.600 --> 0:11:04.600
and wire that up.

140
0:11:04.600 --> 0:11:13.240
So it's going to set the configuration so that it connects to that database automatically.

141
0:11:13.240 --> 0:11:20.600
And then you can even go and see what exactly that configuration is and then copy it down.

142
0:11:20.600 --> 0:11:23.800
Anyway, so that's the developer services.

143
0:11:23.800 --> 0:11:29.640
So Kafka or, yeah, there's a whole bunch of different developer services that you can

144
0:11:29.640 --> 0:11:35.800
use just out of the box, which is pretty nice because otherwise having to configure a database

145
0:11:35.800 --> 0:11:42.160
on your local machine or, Lord forbid, a Kafka instance with all your zookeepers and all

146
0:11:42.160 --> 0:11:47.000
that stuff, that's not so easy.

147
0:11:47.000 --> 0:11:48.160
So you have live coding.

148
0:11:48.160 --> 0:11:50.960
You also have continuous testing.

149
0:11:50.960 --> 0:11:53.800
So kind of the same concept.

150
0:11:53.800 --> 0:11:58.400
So if you have unit tests, you start your continuous testing.

151
0:11:58.400 --> 0:12:06.040
So every time you make a code change, it knows, hey, this class is related to this unit test.

152
0:12:06.040 --> 0:12:10.400
So I'm going to rerun this unit test every time I make a change here or vice versa.

153
0:12:10.400 --> 0:12:17.560
If you're making a change in a unit test, it knows this is what I need to rerun.

154
0:12:17.560 --> 0:12:24.760
So it gives you quick and immediate feedback every time as you're developing, which, yeah,

155
0:12:24.760 --> 0:12:25.760
again, it's pretty handy.

156
0:12:25.760 --> 0:12:28.400
It also has a dev UI.

157
0:12:28.400 --> 0:12:34.160
So it has a UI in your browser where you can go and look at all these different developer

158
0:12:34.160 --> 0:12:39.680
services that are running, what Quark is doing.

159
0:12:39.680 --> 0:12:47.760
So again, I was talking at the start about Quark is doing some optimization, right?

160
0:12:47.760 --> 0:12:52.800
So during the compilation time.

161
0:12:52.800 --> 0:12:59.880
So in the dev UI, you can actually see what it's doing, how it's optimizing, and what

162
0:12:59.880 --> 0:13:03.360
it's going to remove from the class path.

163
0:13:03.360 --> 0:13:09.240
Because Quark is does some introspection to make sure that, hey, this is used or this

164
0:13:09.240 --> 0:13:11.000
actually isn't used by your code.

165
0:13:11.000 --> 0:13:17.920
So I'm going to remove all that from the compilation.

166
0:13:17.920 --> 0:13:25.440
Here's a Quark is CLI, which again, it's not super crazy.

167
0:13:25.440 --> 0:13:31.720
So you can either use Quark is with Gradle or Maven, or you can just use the Quark is

168
0:13:31.720 --> 0:13:38.880
CLI, which means that you can do like Quark is dev or Quark is build or whatever.

169
0:13:38.880 --> 0:13:46.960
You can even use, you can say Quark is image build or image push, and it's going to build

170
0:13:46.960 --> 0:13:47.960
your application.

171
0:13:47.960 --> 0:13:57.560
So build your application, build a container, and you can even push it automatically all

172
0:13:57.560 --> 0:14:01.920
from one command, which is kind of handy, right?

173
0:14:01.920 --> 0:14:07.760
And then one of the last but not least is unification of imperative and reactive programming.

174
0:14:07.760 --> 0:14:18.440
So Quark is has a lot of reactive programming kind of built in underneath.

175
0:14:18.440 --> 0:14:24.720
Now me, for example, I'm not a super deep expert in reactive programming.

176
0:14:24.720 --> 0:14:29.160
But what's nice with Quark is too is that I can write imperative code, right?

177
0:14:29.160 --> 0:14:35.640
So just every statement gets handled one at a time, and it blocks every time.

178
0:14:35.640 --> 0:14:38.400
Whereas with reactive, you've got these event loops.

179
0:14:38.400 --> 0:14:45.080
But you can use both at the same time in the same, even in the same code in the same class.

180
0:14:45.080 --> 0:14:49.560
So for those who are familiar with reactive, usually you kind of have to decide, hey, if

181
0:14:49.560 --> 0:14:54.160
I'm going to build a reactive application, that means I have to decide before I start

182
0:14:54.160 --> 0:15:00.120
writing this code, you know, that this framework that I'm going to use is reactive, and I can't

183
0:15:00.120 --> 0:15:01.920
combine the both.

184
0:15:01.920 --> 0:15:06.200
But with Quark is you can, which is nice.

185
0:15:06.200 --> 0:15:08.000
And best of all, it's still Java, right?

186
0:15:08.000 --> 0:15:10.920
So you get all these kind of features.

187
0:15:10.920 --> 0:15:17.760
And at the end of the day, if you're familiar with Java, this is really not reinventing

188
0:15:17.760 --> 0:15:19.840
the wheel at all.

189
0:15:19.840 --> 0:15:27.240
So it uses microprofile, Vertex, RestEasy, you know, like, and if you want to add extensions,

190
0:15:27.240 --> 0:15:29.620
you can interact directly with Kubernetes.

191
0:15:29.620 --> 0:15:32.920
So you can push your code directly to Kubernetes.

192
0:15:32.920 --> 0:15:39.240
You can create config maps or secrets directly from Quarkus.

193
0:15:39.240 --> 0:15:50.880
You can work really easily with Kafka and OpenShift, of course, Apache, Camel and all

194
0:15:50.880 --> 0:15:54.280
that.

195
0:15:54.280 --> 0:15:58.920
So in terms of native compilation, I think we've already had a few sessions about that.

196
0:15:58.920 --> 0:16:04.320
So I'm not going to go too deep into that other than, you know, if you can run Quarkus

197
0:16:04.320 --> 0:16:13.740
on the JVM and probably for 70 to 80% of the use cases, that's probably a good way to go.

198
0:16:13.740 --> 0:16:20.480
If you really want to have the fastest startup time and the smallest footprint, then you

199
0:16:20.480 --> 0:16:26.880
can do a native build of your Quarkus application with Quarkus, by the way, that's really easy,

200
0:16:26.880 --> 0:16:33.760
because if you create a new Quarkus application, it already automatically has a native profile

201
0:16:33.760 --> 0:16:34.760
built in.

202
0:16:34.760 --> 0:16:40.000
So you can decide, you know, as you're doing your compilation, whether you want to do a

203
0:16:40.000 --> 0:16:43.360
native build or not.

204
0:16:43.360 --> 0:16:48.000
But yeah, so Red Hat is on the GraalVM advisory board.

205
0:16:48.000 --> 0:16:55.440
And then there's the Mandrel project, which is a downstream distribution of GraalVM specifically

206
0:16:55.440 --> 0:17:01.320
for building Java native builds.

207
0:17:01.320 --> 0:17:09.320
And that's what Quarkus uses to, for example, if I do a native build and I don't have GraalVM

208
0:17:09.320 --> 0:17:15.200
installed on my local machine, Quarkus will, again, pull down a container.

209
0:17:15.200 --> 0:17:21.480
It's really good at pulling down containers to do a native build inside a container on

210
0:17:21.480 --> 0:17:22.480
your local machine.

211
0:17:22.480 --> 0:17:28.640
So again, then you don't need to have GraalVM installed and configured on your local machine.

212
0:17:28.640 --> 0:17:37.200
So it really tries to make your life as easy as possible and kind of have the benefits

213
0:17:37.200 --> 0:17:39.200
of a lot of the things.

214
0:17:39.200 --> 0:17:45.480
So if you're thinking of, should I do a native build or just run on the JVM, this is kind

215
0:17:45.480 --> 0:17:49.080
of an opinionated scoring.

216
0:17:49.080 --> 0:17:55.840
But if you want the maximum developer joy, the best and easiest monitoring, peak throughput

217
0:17:55.840 --> 0:18:01.480
and reduced max latency, then you want to run it on the JVM.

218
0:18:01.480 --> 0:18:06.360
If for you it's important to have the lowest memory footprint, a small packaging, and a

219
0:18:06.360 --> 0:18:13.100
very fast startup time, then a native build is probably the way to go.

220
0:18:13.100 --> 0:18:15.360
So what do you want to use?

221
0:18:15.360 --> 0:18:18.320
What can you use Quarkus for?

222
0:18:18.320 --> 0:18:21.300
Probably anything.

223
0:18:21.300 --> 0:18:26.320
So there are Quarkus-based Kubernetes operators.

224
0:18:26.320 --> 0:18:37.960
So there's an operator framework where you can create these automatic components in Kubernetes

225
0:18:37.960 --> 0:18:41.560
that manage resources in Kubernetes.

226
0:18:41.560 --> 0:18:44.400
You can create GitHub actions with Quarkus.

227
0:18:44.400 --> 0:18:48.680
You can create just regular jobs.

228
0:18:48.680 --> 0:18:54.960
Yes, you can build traditional Java applications, even monoliths with it.

229
0:18:54.960 --> 0:19:00.560
But this is, of course, a sweet spot of Quarkus's cloud-native application, so event-driven

230
0:19:00.560 --> 0:19:09.280
applications, reactive systems, microservices, and serverless and functions.

231
0:19:09.280 --> 0:19:12.640
So that's about it for my session.

232
0:19:12.640 --> 0:19:20.540
So if you want to check out Quarkus more, developers.redhat.com has a ton of resources

233
0:19:20.540 --> 0:19:24.360
on Quarkus, on a lot of developer stuff.

234
0:19:24.360 --> 0:19:32.920
This dn.dev slash Quarkus tutorial is just a nice, lightweight introduction to Quarkus,

235
0:19:32.920 --> 0:19:39.680
where you can create an application from scratch and then add some components as you go.

236
0:19:39.680 --> 0:19:50.240
You add a database and then check out the live dev mode and all that stuff.

237
0:19:50.240 --> 0:19:54.400
So it's a pretty nice thing.

238
0:19:54.400 --> 0:20:00.120
Like I said, if you want to keep up to date, you can follow me on Twitter or Macedon.

239
0:20:00.120 --> 0:20:06.800
I try to post interesting stuff, but I don't know if that's really true, but we'll see.

240
0:20:06.800 --> 0:20:07.800
All right.

241
0:20:07.800 --> 0:20:08.800
That's it for me.

242
0:20:08.800 --> 0:20:09.800
Thank you.

243
0:20:09.800 --> 0:20:10.800
Any questions?

244
0:20:10.800 --> 0:20:11.800
Yes.

245
0:20:11.800 --> 0:20:15.800
One of the first slides you compared startup time and peak performance and like the probably

246
0:20:15.800 --> 0:20:16.800
the image was only about 50% of peak performance of OpenJDK.

247
0:20:16.800 --> 0:20:17.800
So is that really true?

248
0:20:17.800 --> 0:20:41.880
Like I knew that it's lower peak performance, but just a few percent seems.

249
0:20:41.880 --> 0:20:45.680
I don't remember exactly the numbers on there.

250
0:20:45.680 --> 0:20:47.760
Yeah.

251
0:20:47.760 --> 0:20:48.760
So that yeah.

252
0:20:48.760 --> 0:20:50.760
So the warm up.

253
0:20:50.760 --> 0:20:51.760
Yeah.

254
0:20:51.760 --> 0:20:52.760
Like the.

255
0:20:52.760 --> 0:20:56.360
Yeah, definitely.

256
0:20:56.360 --> 0:21:02.600
So the peak throughput time, there was a slide about the three graphs.

257
0:21:02.600 --> 0:21:10.920
So yeah, I think with the native compilation, you're not going to have necessarily more

258
0:21:10.920 --> 0:21:17.720
throughput than on the JVM, but you do get the startup time.

259
0:21:17.720 --> 0:21:22.160
You know, like the time it takes to get to the maximum throughput is faster when you're

260
0:21:22.160 --> 0:21:23.160
when you're native.

261
0:21:23.160 --> 0:21:24.160
I get it.

262
0:21:24.160 --> 0:21:25.160
But if I end up at just 50%, that's just not acceptable.

263
0:21:25.160 --> 0:21:29.160
Like if it's like 80, 90% okay, that's fine.

264
0:21:29.160 --> 0:21:30.160
Yeah.

265
0:21:30.160 --> 0:21:31.160
Yeah.

266
0:21:31.160 --> 0:21:32.160
Yeah.

267
0:21:32.160 --> 0:21:33.160
We can look at it later.

268
0:21:33.160 --> 0:21:34.160
Yeah.

269
0:21:34.160 --> 0:21:35.160
Yes.

270
0:21:35.160 --> 0:21:45.960
Yeah, that's it.

271
0:21:45.960 --> 0:21:46.960
Yeah.

272
0:21:46.960 --> 0:21:47.960
Yeah.

273
0:21:47.960 --> 0:22:06.480
Yeah.

274
0:22:06.480 --> 0:22:14.160
So the question was how easy is it to migrate to Quarkus from, for example, spring boots.

275
0:22:14.160 --> 0:22:19.120
So Quarkus has spring compatibility extensions.

276
0:22:19.120 --> 0:22:26.880
And so that makes it relatively easy because basically you're for the most part, you won't

277
0:22:26.880 --> 0:22:29.520
have to change your code.

278
0:22:29.520 --> 0:22:33.080
You just have to add the, you know, add the spring extensions.

279
0:22:33.080 --> 0:22:37.100
Of course, in your palm, you're going to need to make some changes.

280
0:22:37.100 --> 0:22:40.000
But it's fairly straightforward.

281
0:22:40.000 --> 0:22:49.120
And my colleague, Eric D'Andrea, he wrote a book on spring, let's say, Quarkus for spring

282
0:22:49.120 --> 0:22:50.120
developers.

283
0:22:50.120 --> 0:22:54.440
And he does talks too.

284
0:22:54.440 --> 0:22:59.320
But if you want on that developers.redhat.com, you can find, you know, there's a section

285
0:22:59.320 --> 0:23:02.560
about books and you can find that book.

286
0:23:02.560 --> 0:23:06.320
But it's, yeah, overall pretty straightforward.

287
0:23:06.320 --> 0:23:12.920
So like I said, there are extensions so that you can keep using your spring annotations.

288
0:23:12.920 --> 0:23:24.240
Now would I recommend you just migrating your application and keeping all your spring dependencies?

289
0:23:24.240 --> 0:23:26.000
Probably not.

290
0:23:26.000 --> 0:23:33.520
But it's kind of a nice way to migrate without too much work and then afterwards maybe migrate

291
0:23:33.520 --> 0:23:35.680
further.

292
0:23:35.680 --> 0:23:36.680
Any more questions?

293
0:23:36.680 --> 0:23:37.680
Yes?

294
0:23:37.680 --> 0:23:42.680
What are the advantages of the packages that you've produced and why don't you use what

295
0:23:42.680 --> 0:23:52.680
you've produced on everything instead of Quarkus on the computer?

296
0:23:52.680 --> 0:23:57.480
It's so faster than on the one.

297
0:23:57.480 --> 0:24:00.440
So the question, if I understand correctly, right?

298
0:24:00.440 --> 0:24:04.680
So the question is, why should you use native?

299
0:24:04.680 --> 0:24:05.680
Yes.

300
0:24:05.680 --> 0:24:06.680
Compilation?

301
0:24:06.680 --> 0:24:11.680
On the graph, native is way faster and less smaller.

302
0:24:11.680 --> 0:24:20.840
So why don't we always use native on the JVM?

303
0:24:20.840 --> 0:24:28.400
Because on the JVM, you have all the kind of capabilities that the JVM brings, right?

304
0:24:28.400 --> 0:24:36.200
So in terms of garbage collection, in terms of throughput and everything, JVM is very

305
0:24:36.200 --> 0:24:39.200
optimized to do that.

306
0:24:39.200 --> 0:24:46.120
When you do a native build, the GraalVM compiler is going to do kind of an opinionated approach

307
0:24:46.120 --> 0:24:48.440
of how to do your native build.

308
0:24:48.440 --> 0:24:49.880
But then that's also it.

309
0:24:49.880 --> 0:24:54.160
It's not going to be able to optimize afterwards like the JVM does.

310
0:24:54.160 --> 0:24:57.480
Kind of depends.

311
0:24:57.480 --> 0:24:59.240
I think we're out of time.

312
0:24:59.240 --> 0:25:01.240
If anybody has any more questions.

313
0:25:01.240 --> 0:25:02.240
Yeah.

314
0:25:02.240 --> 0:25:27.840
Thank you so much.

