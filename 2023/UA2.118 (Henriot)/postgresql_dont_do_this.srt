1
0:00:00.000 --> 0:00:17.320
But what you should not do in Postgres, so please welcome Jimmy Angelagos.

2
0:00:17.320 --> 0:00:19.560
Thanks very much.

3
0:00:19.560 --> 0:00:28.480
I'm a senior solutions architect at EDB, and I am grateful to EDB for allowing me to make

4
0:00:28.480 --> 0:00:36.520
Postgres my day job, because it is an excellent database, it is an excellent community, and

5
0:00:36.520 --> 0:00:41.640
thank you all for attending a talk with such a clickbaity title.

6
0:00:41.640 --> 0:00:43.960
And thank you to the guys at home for clicking.

7
0:00:43.960 --> 0:00:46.800
So why this title?

8
0:00:46.800 --> 0:00:48.120
I didn't come up with it.

9
0:00:48.120 --> 0:00:57.240
So this title is the title of Postgres Wiki page that's called Don't Do This, and I got

10
0:00:57.240 --> 0:01:02.240
all the content from there, so that's the end of the talk.

11
0:01:02.240 --> 0:01:06.800
So this talk is not all inclusive, right?

12
0:01:06.800 --> 0:01:10.760
I'm not going to tell you all the mistakes you can make with Postgres.

13
0:01:10.760 --> 0:01:11.760
Who can?

14
0:01:11.760 --> 0:01:18.460
I mean, there is literally nothing that you cannot mess up with, no matter which database

15
0:01:18.460 --> 0:01:19.460
you use.

16
0:01:19.460 --> 0:01:23.440
You can always find a way to mess up.

17
0:01:23.440 --> 0:01:28.720
But these are some of the things that we've noticed that people are doing wrong in general

18
0:01:28.720 --> 0:01:30.200
with Postgres.

19
0:01:30.200 --> 0:01:35.520
So some of them are misconceptions, like I believe this thing works this way, but it

20
0:01:35.520 --> 0:01:38.080
doesn't.

21
0:01:38.080 --> 0:01:44.160
Some things are confusing because of the way they're implemented in Postgres, especially

22
0:01:44.160 --> 0:01:52.000
things that are not part of the SQL standard, but Postgres extensions to the SQL standard,

23
0:01:52.000 --> 0:01:57.680
although to be fair, Postgres is the most SQL standard compliant database.

24
0:01:57.680 --> 0:02:00.480
It just has some things on top of it.

25
0:02:00.480 --> 0:02:05.440
Other databases implement a subset of the SQL standard and also confusing things.

26
0:02:05.440 --> 0:02:09.560
So we're a bit better from that respect.

27
0:02:09.560 --> 0:02:15.440
And some common mistakes that people make that usually have a significant impact in

28
0:02:15.440 --> 0:02:16.800
production environments.

29
0:02:16.800 --> 0:02:24.480
So we'll be looking at some bad examples of SQL that you can write in Postgres.

30
0:02:24.480 --> 0:02:30.760
We'll be looking at some improper data types for storing certain things.

31
0:02:30.760 --> 0:02:37.080
Andreas had a good talk this morning about this covering many of the same topics.

32
0:02:37.080 --> 0:02:44.740
We will be looking at wrong ways to use Postgres features.

33
0:02:44.740 --> 0:02:51.240
And also some things that affect your performance and affect the security of the server that

34
0:02:51.240 --> 0:02:53.840
you need to be aware of.

35
0:02:53.840 --> 0:03:00.140
So let's start off with some bad SQL.

36
0:03:00.140 --> 0:03:04.320
First and foremost, not in.

37
0:03:04.320 --> 0:03:07.600
As in the Boolean, not in, right?

38
0:03:07.600 --> 0:03:10.900
It doesn't work the way you expect it to.

39
0:03:10.900 --> 0:03:20.120
So when you're writing, select something where something else is not in this subquery, you

40
0:03:20.120 --> 0:03:25.720
have to keep in mind that SQL and Postgres by extension is not Python and it's not Ruby.

41
0:03:25.720 --> 0:03:32.000
So it doesn't behave the way you expect it to if you're used to writing not in Booleans

42
0:03:32.000 --> 0:03:34.060
in programming languages.

43
0:03:34.060 --> 0:03:42.400
So select A from table one where A not in one constant, right?

44
0:03:42.400 --> 0:03:44.960
So it's always true.

45
0:03:44.960 --> 0:03:50.040
And null returns nothing.

46
0:03:50.040 --> 0:04:00.280
Because if you perform not in and there's even one null, the result is null.

47
0:04:00.280 --> 0:04:02.880
Not false, null.

48
0:04:02.880 --> 0:04:12.660
So equally, select A from table one, a more real world scenario where A is not in select

49
0:04:12.660 --> 0:04:15.960
B from table two.

50
0:04:15.960 --> 0:04:21.600
Even if one B is null, then the whole result is null.

51
0:04:21.600 --> 0:04:26.740
So it's not doing what you're expecting it to.

52
0:04:26.740 --> 0:04:30.880
Let's say that table two has no null Bs, right?

53
0:04:30.880 --> 0:04:32.520
B is not null.

54
0:04:32.520 --> 0:04:34.640
Why is this still bad?

55
0:04:34.640 --> 0:04:36.960
And you should not use it.

56
0:04:36.960 --> 0:04:42.400
Because it doesn't optimize well in the Postgres query planner.

57
0:04:42.400 --> 0:04:49.280
And instead of performing what is known as an anti-join, so it's the complete opposite

58
0:04:49.280 --> 0:04:50.280
of a join.

59
0:04:50.280 --> 0:04:55.080
Show me the rows you cannot join from this table.

60
0:04:55.080 --> 0:04:58.360
The Postgres query planner chooses a subplan.

61
0:04:58.360 --> 0:05:03.540
And if that's a hashed subplan, that's kind of okay.

62
0:05:03.540 --> 0:05:08.160
If it's a simple subplan, then the performance of this thing is disastrous.

63
0:05:08.160 --> 0:05:12.440
So even if you don't have nulls, you don't want to use it.

64
0:05:12.440 --> 0:05:15.520
What should you use instead?

65
0:05:15.520 --> 0:05:21.280
You should use an anti-join, as we just said, which looks something like this.

66
0:05:21.280 --> 0:05:28.200
Select column from table one where not exists is a better way to write not in.

67
0:05:28.200 --> 0:05:37.640
So wherever column from table two does not exist where table one column equals table

68
0:05:37.640 --> 0:05:38.640
two column.

69
0:05:38.640 --> 0:05:47.080
So you want the rows that table two doesn't can't match up to table one.

70
0:05:47.080 --> 0:05:51.080
So that's an anti-join.

71
0:05:51.080 --> 0:05:57.760
Or another way you could write this is select column from table one and use a left join.

72
0:05:57.760 --> 0:06:07.300
So left join table two using the column, using this Postgres shorthand for join on column

73
0:06:07.300 --> 0:06:12.400
equals column, but in this case I'm using column because it's the same name in both

74
0:06:12.400 --> 0:06:13.400
tables.

75
0:06:13.400 --> 0:06:18.520
So left join where table two dot call is null.

76
0:06:18.520 --> 0:06:20.640
What does that do?

77
0:06:20.640 --> 0:06:27.200
If it cannot find matches on the left-hand side to the right-hand side, then the right-hand

78
0:06:27.200 --> 0:06:31.960
side the result from table two is a null.

79
0:06:31.960 --> 0:06:35.520
And that's how you get your anti-join.

80
0:06:35.520 --> 0:06:44.560
To be fair, not in is okay if you know that there are no nulls and you cannot know that

81
0:06:44.560 --> 0:06:49.900
for a table and as we said it has performance implications, but when you're excluding constants

82
0:06:49.900 --> 0:06:51.940
that's fine, right?

83
0:06:51.940 --> 0:06:57.180
Because if you have an index and you're able to tell that none of this is in the index,

84
0:06:57.180 --> 0:06:59.440
then you're fine to use not in.

85
0:06:59.440 --> 0:07:06.720
But generally speaking, try to prefer not exists or anti-joins.

86
0:07:06.720 --> 0:07:17.720
Another thing is that we've seen people use the wrong way without knowing is between,

87
0:07:17.720 --> 0:07:24.240
especially when you write a query with a where clause that specifies between timestamp one

88
0:07:24.240 --> 0:07:26.140
and timestamp two.

89
0:07:26.140 --> 0:07:28.760
Why is that?

90
0:07:28.760 --> 0:07:34.040
Because between A and B is inclusive.

91
0:07:34.040 --> 0:07:35.960
It's a closed interval.

92
0:07:35.960 --> 0:07:42.880
So when you're saying between one and 100, you're saying include one and also include

93
0:07:42.880 --> 0:07:47.000
100 in the results.

94
0:07:47.000 --> 0:07:48.360
When is this bad?

95
0:07:48.360 --> 0:07:57.200
This is bad when you're a bank, let's say, and you want to sum up the transactions for

96
0:07:57.200 --> 0:07:59.160
the day, right?

97
0:07:59.160 --> 0:08:03.240
The amounts from all transactions from the day.

98
0:08:03.240 --> 0:08:06.560
And your DBA has written the following query.

99
0:08:06.560 --> 0:08:12.780
Select some of the amounts from transactions where transaction timestamp is between the

100
0:08:12.780 --> 0:08:16.480
end of the previous day and the end of the current day, right?

101
0:08:16.480 --> 0:08:17.880
So it should be fine.

102
0:08:17.880 --> 0:08:18.880
No, it's not.

103
0:08:18.880 --> 0:08:26.240
Because if a transaction has happened exactly at midnight, you'll get it twice.

104
0:08:26.240 --> 0:08:30.340
Because when you run that query tomorrow, it's going to return the same row because

105
0:08:30.340 --> 0:08:35.000
you've included midnight in both queries, right?

106
0:08:35.000 --> 0:08:38.180
So that's a bad thing.

107
0:08:38.180 --> 0:08:44.680
So it's better to be explicit instead and use select some amount from transactions where

108
0:08:44.680 --> 0:08:53.400
transaction timestamp is greater or equal than and transaction timestamp is less than

109
0:08:53.400 --> 0:08:57.160
excluding the equality with midnight, right?

110
0:08:57.160 --> 0:08:59.880
So that is very, very safe.

111
0:08:59.880 --> 0:09:02.520
And there's no way to read it wrong.

112
0:09:02.520 --> 0:09:08.680
It's very explicit, very clear.

113
0:09:08.680 --> 0:09:10.400
Another thing.

114
0:09:10.400 --> 0:09:13.640
Using uppercase and identifiers.

115
0:09:13.640 --> 0:09:18.780
Many people like to do this because it looks very professional.

116
0:09:18.780 --> 0:09:24.520
Because they're used to some database that was out there in the 80s that only could support

117
0:09:24.520 --> 0:09:27.320
uppercase table names.

118
0:09:27.320 --> 0:09:34.820
And that database can now use lowercase, but the habit is still there.

119
0:09:34.820 --> 0:09:38.920
Now why is that a bad thing in Postgres?

120
0:09:38.920 --> 0:09:45.480
So if you use table or column names that are all capitals or mixed case, Postgres will

121
0:09:45.480 --> 0:09:53.280
just ignore you and make everything lowercase unless you use double quotes around the names.

122
0:09:53.280 --> 0:09:59.380
So create table Plurp and create table Quux.

123
0:09:59.380 --> 0:10:04.000
What are the consequences of issuing these two DDLs?

124
0:10:04.000 --> 0:10:16.120
It creates a table named Plurp, lowercase, and the table named Quux with a capital Q.

125
0:10:16.120 --> 0:10:17.120
Why is that a problem?

126
0:10:17.120 --> 0:10:22.560
So table here is shorthand for select star from Plurp.

127
0:10:22.560 --> 0:10:30.400
So table Plurp works because it's not quoted, so Postgres ignores the case.

128
0:10:30.400 --> 0:10:35.200
Table Plurp, quoted, even if it's exactly the same way we specified it when we were

129
0:10:35.200 --> 0:10:36.880
creating the table, will fail.

130
0:10:36.880 --> 0:10:41.840
And it will say there's no such table.

131
0:10:41.840 --> 0:10:49.480
Equally table Quux fails because there's no lowercase table Quux.

132
0:10:49.480 --> 0:10:52.860
Table Quux in double quotes works fine.

133
0:10:52.860 --> 0:10:56.060
So you can see how you can mess up your schema with this.

134
0:10:56.060 --> 0:11:00.440
If you give your schema to a developer and they're not aware that there's a difference

135
0:11:00.440 --> 0:11:06.480
between double quoted and unquoted table names, then you get in trouble.

136
0:11:06.480 --> 0:11:13.680
I think.NET by default, even if you don't do anything, double quotes everything.

137
0:11:13.680 --> 0:11:21.400
So if you make the mistake of including capitals there, then they're not going to work in Postgres.

138
0:11:21.400 --> 0:11:27.840
So unless you create the tables from within.NET, that is.

139
0:11:27.840 --> 0:11:32.380
So the same goes for column names.

140
0:11:32.380 --> 0:11:38.840
If you want pretty column names in your output and your reports, then just use select call

141
0:11:38.840 --> 0:11:41.280
as pretty name.

142
0:11:41.280 --> 0:11:42.700
Double quote the pretty name.

143
0:11:42.700 --> 0:11:43.700
It can have spaces.

144
0:11:43.700 --> 0:11:46.040
It can have emoji, whatever you want.

145
0:11:46.040 --> 0:11:51.920
And Postgres will just return exactly that name and you don't have to change your column

146
0:11:51.920 --> 0:11:58.960
name in your table to make accounting happy.

147
0:11:58.960 --> 0:12:07.840
Now moving on from SQL, let's look at the wrong use of some of Postgres's built in data

148
0:12:07.840 --> 0:12:11.120
types.

149
0:12:11.120 --> 0:12:13.400
Again time stamps.

150
0:12:13.400 --> 0:12:24.640
So if you create a column that is type timestamp, that means timestamp without time zone.

151
0:12:24.640 --> 0:12:31.480
So these are naive time stamps and they represent a local time somewhere, but you don't know

152
0:12:31.480 --> 0:12:34.220
where.

153
0:12:34.220 --> 0:12:38.800
It stores a date and a time with no time zone information.

154
0:12:38.800 --> 0:12:45.200
There's no way to retrieve the time zone where this row was inserted.

155
0:12:45.200 --> 0:12:46.560
And why is that a bad thing?

156
0:12:46.560 --> 0:12:49.060
Because arithmetic breaks down totally.

157
0:12:49.060 --> 0:12:56.560
You cannot add and subtract dates and intervals and anything else because you can't calculate,

158
0:12:56.560 --> 0:13:01.460
you can't make computations of what the time would be because of things such as time zone

159
0:13:01.460 --> 0:13:05.880
changes and daylight savings times.

160
0:13:05.880 --> 0:13:10.880
So it's meaningless and will give you the wrong results.

161
0:13:10.880 --> 0:13:17.400
So instead, please use timestamp TZ or TZ if you're British.

162
0:13:17.400 --> 0:13:22.240
Timestamp with time zone is the equivalent.

163
0:13:22.240 --> 0:13:27.240
Timestamp TZ is the shorthand and that stores a moment in time.

164
0:13:27.240 --> 0:13:34.840
A moment in time means the number of seconds that have passed from midnight at the beginning

165
0:13:34.840 --> 0:13:38.660
of the 1st of January 2000.

166
0:13:38.660 --> 0:13:48.240
So it's absolute, it's definite, and you know exactly which moment in time you're specifying.

167
0:13:48.240 --> 0:13:53.840
The arithmetic works correctly, as you would expect.

168
0:13:53.840 --> 0:14:00.540
And this by default displays in your time zone, but you can also choose to display it

169
0:14:00.540 --> 0:14:02.000
at time zone.

170
0:14:02.000 --> 0:14:09.720
So if you've inserted something which is midnight UTC and you wanted an Eastern time, that would

171
0:14:09.720 --> 0:14:11.180
automatically convert it.

172
0:14:11.180 --> 0:14:17.240
If you said at time zone Eastern, it would automatically convert it to minus five hours

173
0:14:17.240 --> 0:14:23.800
or minus six hours if there's a DST difference between the two time zones.

174
0:14:23.800 --> 0:14:26.160
So you don't have to worry about the conversions.

175
0:14:26.160 --> 0:14:30.480
Just use timestamp with time zone and you won't have to worry about it.

176
0:14:30.480 --> 0:14:36.080
Even if you don't need time zone calculations and all of your operations and all of your

177
0:14:36.080 --> 0:14:41.360
queries are coming from within the same time zone, it's better to use this.

178
0:14:41.360 --> 0:14:45.640
Because then when you have to export your data and give it to someone else, they know

179
0:14:45.640 --> 0:14:50.640
exactly what this means, even if they don't know your time zone.

180
0:14:50.640 --> 0:14:58.440
So also if you've decided to only use UTC throughout your organization, then don't use

181
0:14:58.440 --> 0:15:03.160
timestamp to store UTC because Postgres doesn't know it is UTC.

182
0:15:03.160 --> 0:15:11.120
It just sees a local time and doesn't know where it is so it can't convert it.

183
0:15:11.120 --> 0:15:21.320
Now something less frequently used is the type time TZ or time with time zone.

184
0:15:21.320 --> 0:15:27.240
That is a quirk of SQL.

185
0:15:27.240 --> 0:15:32.840
It is there because the standard specifies it and that's the only way Postgres implements.

186
0:15:32.840 --> 0:15:36.120
That's the only reason why Postgres has implemented this.

187
0:15:36.120 --> 0:15:45.840
So time with time zone has questionable usefulness because time zones in the real world have

188
0:15:45.840 --> 0:15:48.240
little meaning without dates.

189
0:15:48.240 --> 0:15:54.560
It can be the middle of the day in Australia and the previous day here.

190
0:15:54.560 --> 0:16:02.720
So it will be times in some time zone but the date is different and you don't know it.

191
0:16:02.720 --> 0:16:11.320
So the offset can vary with day lag savings time and that's a bad thing because time TZ

192
0:16:11.320 --> 0:16:20.760
has a fixed offset and that makes it impossible to do date calculations across day lag savings

193
0:16:20.760 --> 0:16:23.400
times boundaries.

194
0:16:23.400 --> 0:16:27.720
So just use timestamp TZ instead.

195
0:16:27.720 --> 0:16:29.160
There's also a space saving.

196
0:16:29.160 --> 0:16:31.400
For some reason this thing is 12 bytes.

197
0:16:31.400 --> 0:16:33.480
I don't know why.

198
0:16:33.480 --> 0:16:35.120
A timestamp is 8 bytes.

199
0:16:35.120 --> 0:16:42.520
So just use timestamp TZ or timestamp with time zone instead.

200
0:16:42.520 --> 0:16:45.640
Current underscore time is another favorite.

201
0:16:45.640 --> 0:16:49.600
Current time is timestamp TZ.

202
0:16:49.600 --> 0:16:52.440
So we just said don't use timestamp TZ.

203
0:16:52.440 --> 0:16:58.720
Instead use current timestamp or the function now to get the current time with the time

204
0:16:58.720 --> 0:17:04.880
zone and local timestamp that returns the timestamp if you just want to know what time

205
0:17:04.880 --> 0:17:09.520
it is here in your local time zone.

206
0:17:09.520 --> 0:17:17.680
Equally you can use current date for a date and local time for the local time.

207
0:17:17.680 --> 0:17:20.040
These are not timestamps.

208
0:17:20.040 --> 0:17:24.680
These are dates sometimes, right?

209
0:17:24.680 --> 0:17:28.200
This is one of my favorites.

210
0:17:28.200 --> 0:17:33.560
This morning address showed that many people when they want to store a string they just

211
0:17:33.560 --> 0:17:37.480
create car 255.

212
0:17:37.480 --> 0:17:41.440
That should take care of it.

213
0:17:41.440 --> 0:17:43.480
What is the problem with that?

214
0:17:43.480 --> 0:17:48.180
It's that this is padded with white space up to N.

215
0:17:48.180 --> 0:17:57.160
So if you create a car 255 and you insert a single character to store, then that inserts

216
0:17:57.160 --> 0:18:05.720
254 blank spaces after it in the database for no reason.

217
0:18:05.720 --> 0:18:09.960
The padding spaces are useless because they are ignored when comparing.

218
0:18:09.960 --> 0:18:13.200
But equally they create a problem.

219
0:18:13.200 --> 0:18:19.440
Because they don't work for like expressions and they don't work for regular expressions.

220
0:18:19.440 --> 0:18:24.120
Because a regex will see the spaces.

221
0:18:24.120 --> 0:18:25.240
So it's inconsistent.

222
0:18:25.240 --> 0:18:27.480
So just don't use it.

223
0:18:27.480 --> 0:18:33.520
And anyway, you're not gaining anything by specifying a limit in the number of characters

224
0:18:33.520 --> 0:18:38.440
because it's not even stored as a fixed with field in Postgres.

225
0:18:38.440 --> 0:18:41.160
The storage is exactly the same.

226
0:18:41.160 --> 0:18:46.540
You're just wasting space by adding white space.

227
0:18:46.540 --> 0:18:49.680
Performance wise, it's even worse.

228
0:18:49.680 --> 0:18:54.940
Because Postgres is spending the extra time discarding those zeros when you're requesting

229
0:18:54.940 --> 0:18:56.360
a result.

230
0:18:56.360 --> 0:18:59.560
That it's supposed to ignore those zeros.

231
0:18:59.560 --> 0:19:12.760
Also, another consequence of car N is that an index created for a character of N length

232
0:19:12.760 --> 0:19:20.800
may not work with a query that accepts a text parameter or a var car parameter with no limit.

233
0:19:20.800 --> 0:19:24.640
The index is created for a different data type.

234
0:19:24.640 --> 0:19:26.760
Therefore it does not apply to that query.

235
0:19:26.760 --> 0:19:32.320
So also limits are bad.

236
0:19:32.320 --> 0:19:33.400
Always.

237
0:19:33.400 --> 0:19:35.540
Limits on strings are bad.

238
0:19:35.540 --> 0:19:39.920
If you create a company name and you think 50 characters are enough, I don't know any

239
0:19:39.920 --> 0:19:42.920
company name that has more than 50 characters.

240
0:19:42.920 --> 0:19:47.480
Then you get a customer that's called Peterson's and Sons and Friends Bits and Parts Limited,

241
0:19:47.480 --> 0:19:50.520
which is 54.

242
0:19:50.520 --> 0:19:55.600
And then you have to go and change the column width in the database and your DBA starts

243
0:19:55.600 --> 0:20:05.560
wearing even though they selected the character length themselves because they were told to.

244
0:20:05.560 --> 0:20:08.240
Also it's useless for restricting length.

245
0:20:08.240 --> 0:20:14.400
It throws an error, okay, but it doesn't make sure that the length is exactly what you want.

246
0:20:14.400 --> 0:20:24.900
So if you want a four digit pin and you enter it as car four, that is not enforced if someone

247
0:20:24.900 --> 0:20:26.240
enters a three digit pin.

248
0:20:26.240 --> 0:20:27.240
You need an extra check.

249
0:20:27.240 --> 0:20:29.440
So it doesn't guarantee anything.

250
0:20:29.440 --> 0:20:36.040
So to restrict length and make sure that the length of what everyone enters is consistent,

251
0:20:36.040 --> 0:20:40.900
then use a check constraint and enforce it.

252
0:20:40.900 --> 0:20:44.020
So bottom line is just use text.

253
0:20:44.020 --> 0:20:50.280
Text is the same as the confusingly named var car with no parenthesis.

254
0:20:50.280 --> 0:20:59.960
So text, money, get away from the type money because it's useless.

255
0:20:59.960 --> 0:21:06.260
It's fixed point, which means that it doesn't handle fractions of a cent, right?

256
0:21:06.260 --> 0:21:12.120
So for finance, that's very bad because you usually have subdivisions of the lowest denomination

257
0:21:12.120 --> 0:21:16.920
of currency, whether it's a cent or a penny or whatever else.

258
0:21:16.920 --> 0:21:24.320
So the rounding may be off and that is a bad thing in finance.

259
0:21:24.320 --> 0:21:30.020
Another bad thing is that it doesn't know which currency it's storing the values for.

260
0:21:30.020 --> 0:21:37.980
So it assumes that the currency is what you specified in LC monetary.

261
0:21:37.980 --> 0:21:42.520
And if you don't know what LC monetary is, it's just going to assume whatever it finds

262
0:21:42.520 --> 0:21:47.200
in your Unix configuration or Linux.

263
0:21:47.200 --> 0:21:50.140
Even worse, it accepts garbage input.

264
0:21:50.140 --> 0:21:57.780
So if you select that thing and convert it to money, it casts it to whatever it believes

265
0:21:57.780 --> 0:22:00.520
is right.

266
0:22:00.520 --> 0:22:10.840
And because my laptop was set up for UK pounds, it assumed that that's UK pounds.

267
0:22:10.840 --> 0:22:18.040
So just use numeric and store the currency in another column for that row with a foreign

268
0:22:18.040 --> 0:22:25.720
key so you know which currency that is.

269
0:22:25.720 --> 0:22:36.440
Serial, how many people here use serial and like it?

270
0:22:36.440 --> 0:22:39.720
So I will explain why you shouldn't like it.

271
0:22:39.720 --> 0:22:42.260
It used to be useful shorthand.

272
0:22:42.260 --> 0:22:44.640
It is still useful shorthand.

273
0:22:44.640 --> 0:22:52.720
But it's now less useful than it used to be because it's non-SQL standard and it messes

274
0:22:52.720 --> 0:22:54.920
up the permissions when you use it.

275
0:22:54.920 --> 0:23:01.120
So permissions for sequences created using serial automatically created using the serial

276
0:23:01.120 --> 0:23:03.060
keyword when creating a table.

277
0:23:03.060 --> 0:23:06.640
They need to be managed separately from the table.

278
0:23:06.640 --> 0:23:15.840
So a consequence of this disconnect is that create table like another table with a table

279
0:23:15.840 --> 0:23:20.360
that uses serial will use the same sequence from the other table.

280
0:23:20.360 --> 0:23:24.000
And you don't want that usually.

281
0:23:24.000 --> 0:23:32.280
So instead we've come up with identity columns that are more verbose but much clearer in

282
0:23:32.280 --> 0:23:36.840
what they do because they're attached to the table that created them.

283
0:23:36.840 --> 0:23:48.300
So create table, ID, big int generated by default as identity and also primary key.

284
0:23:48.300 --> 0:23:54.440
With an identity column, you don't need to know the name of the sequence.

285
0:23:54.440 --> 0:24:01.840
So when you alter table tab, alter column ID, restart 1000, you don't need to know what

286
0:24:01.840 --> 0:24:03.320
the sequence is called.

287
0:24:03.320 --> 0:24:04.540
It's attached to the table.

288
0:24:04.540 --> 0:24:10.480
So it will just restart the sequence from 1000.

289
0:24:10.480 --> 0:24:15.640
A side note here, if your application is depending on a serial sequence to generate things like

290
0:24:15.640 --> 0:24:21.380
receipt IDs, receipt numbers, that is something you should generally generate in your application

291
0:24:21.380 --> 0:24:26.600
to make sure that there are no gaps because there's no guarantees whatsoever that a sequence

292
0:24:26.600 --> 0:24:29.980
in Postgres will have no gaps, right?

293
0:24:29.980 --> 0:24:34.480
If you try to insert something and there's an error and you roll back, you've skipped

294
0:24:34.480 --> 0:24:37.080
over that sequence number.

295
0:24:37.080 --> 0:24:38.520
Never goes back.

296
0:24:38.520 --> 0:24:39.920
Cool.

297
0:24:39.920 --> 0:24:48.480
So now let's look at improper usage of Postgres features.

298
0:24:48.480 --> 0:24:52.760
Character encoding SQL underscore ASCII.

299
0:24:52.760 --> 0:24:58.080
It is not a database encoding that you should be using unless you know exactly what you're

300
0:24:58.080 --> 0:24:59.660
doing.

301
0:24:59.660 --> 0:25:07.400
So things like storing text from the 1960s where there were no character sets other than

302
0:25:07.400 --> 0:25:10.680
ASCII.

303
0:25:10.680 --> 0:25:18.640
When you specify that your database is encoding is SQL ASCII, you are skipping all encoding

304
0:25:18.640 --> 0:25:21.540
conversion and all encoding validation.

305
0:25:21.540 --> 0:25:23.640
So it will accept just anything.

306
0:25:23.640 --> 0:25:29.920
And it will assume that if your character has a byte value from 0 to 127, that it's

307
0:25:29.920 --> 0:25:30.920
ASCII.

308
0:25:30.920 --> 0:25:37.660
And if it's over 127 to 255, then it will not even try.

309
0:25:37.660 --> 0:25:41.560
It will just store it and not interpret it as anything.

310
0:25:41.560 --> 0:25:47.280
So it doesn't behave the same way as a character set setting.

311
0:25:47.280 --> 0:25:50.120
And it's very bad that this is the default.

312
0:25:50.120 --> 0:25:58.320
Fortunately, most distributions, the packages that Devrim makes for distributions have UTF-8

313
0:25:58.320 --> 0:25:59.840
as the default.

314
0:25:59.840 --> 0:26:04.520
So that's a safer choice.

315
0:26:04.520 --> 0:26:09.480
Also when you use SQL ASCII, you can end up storing a mixture of encodings because it

316
0:26:09.480 --> 0:26:12.360
doesn't check and validate anything.

317
0:26:12.360 --> 0:26:15.480
So once you've done that, there's no going back.

318
0:26:15.480 --> 0:26:19.520
There's no way to recover the original strings because you don't know which encoding they

319
0:26:19.520 --> 0:26:21.760
came from.

320
0:26:21.760 --> 0:26:24.000
Rules.

321
0:26:24.000 --> 0:26:28.880
Rules are a thing that predates SQL and Postgres.

322
0:26:28.880 --> 0:26:32.880
When it was just Postgres, not PostgreSQL.

323
0:26:32.880 --> 0:26:40.640
It's a very old thing that has its specific purpose and its purpose is not to work like

324
0:26:40.640 --> 0:26:42.480
a trigger.

325
0:26:42.480 --> 0:26:47.360
Rules do not apply conditional logic.

326
0:26:47.360 --> 0:26:54.680
They rewrite your queries to modify them or add extra queries on top of them.

327
0:26:54.680 --> 0:27:01.400
So any rule that's non-trivial, so any rule that's not like a select or an update into

328
0:27:01.400 --> 0:27:06.520
a view is going to have unintended consequences because it's going to execute the original

329
0:27:06.520 --> 0:27:11.920
query if it's an insert and then apply the rule and then generate another row potentially

330
0:27:11.920 --> 0:27:14.480
or change the value of the row you inserted.

331
0:27:14.480 --> 0:27:21.280
So also, as we said, it's older than SQL and Postgres and it's non-SQL standard.

332
0:27:21.280 --> 0:27:28.480
So unless you're using rules to create views that you can write to, use a trigger instead.

333
0:27:28.480 --> 0:27:31.460
That's what you want to use.

334
0:27:31.460 --> 0:27:36.240
There's an exhaustive blog post by Depeche that you can read.

335
0:27:36.240 --> 0:27:41.800
You will find the link in the slides afterwards.

336
0:27:41.800 --> 0:27:53.840
Table inheritance is a relic of the time of object-oriented databases.

337
0:27:53.840 --> 0:27:59.160
If you remember, up on our website, we used to say that Postgres is an object-relational

338
0:27:59.160 --> 0:28:00.880
database.

339
0:28:00.880 --> 0:28:02.880
Maybe we still do.

340
0:28:02.880 --> 0:28:04.880
Okay.

341
0:28:04.880 --> 0:28:07.640
But everything in Postgres is an object.

342
0:28:07.640 --> 0:28:08.640
Fine.

343
0:28:08.640 --> 0:28:15.800
So that doesn't mean that table inheritance applies to tables because it seemed like a

344
0:28:15.800 --> 0:28:21.240
good idea before ORMs that you would have some sort of inheritance from a table type

345
0:28:21.240 --> 0:28:24.520
to another table type.

346
0:28:24.520 --> 0:28:29.880
And the way you would write that was create table events, let's say, with an ID and some

347
0:28:29.880 --> 0:28:34.040
columns and then create the table meetings.

348
0:28:34.040 --> 0:28:36.720
Meetings are events, right?

349
0:28:36.720 --> 0:28:43.680
And they have a scheduled time, but all the other characteristics of an event.

350
0:28:43.680 --> 0:28:49.680
So why not create table, inherits the other table?

351
0:28:49.680 --> 0:28:58.040
It's also used to implement partitioning in Postgres before Postgres 10, but is now incompatible

352
0:28:58.040 --> 0:29:01.760
with the new way of partitioning after Postgres 10.

353
0:29:01.760 --> 0:29:10.800
So you cannot inherit from a partition table and you cannot add inheritance to a table

354
0:29:10.800 --> 0:29:13.920
that's partitioned.

355
0:29:13.920 --> 0:29:18.240
So if you've got it in your database, there is a way to undo it.

356
0:29:18.240 --> 0:29:20.860
And I will just skim over it.

357
0:29:20.860 --> 0:29:25.520
You can replace it with a foreign key relationship between the two tables.

358
0:29:25.520 --> 0:29:28.400
And it works exactly the same way.

359
0:29:28.400 --> 0:29:38.560
So create table new meetings like meetings.

360
0:29:38.560 --> 0:29:47.560
Table inheritance is scary.

361
0:29:47.560 --> 0:29:50.480
I apologize.

362
0:29:50.480 --> 0:29:52.120
It's not for young guys.

363
0:29:52.120 --> 0:29:58.640
So create table new meetings like meetings creates it in exactly the same way.

364
0:29:58.640 --> 0:30:03.200
Alter table to add another column to store the foreign key relationship.

365
0:30:03.200 --> 0:30:10.760
So that should have been event ID, excuse me.

366
0:30:10.760 --> 0:30:12.280
Anyway.

367
0:30:12.280 --> 0:30:16.640
So you copy the data from the old table into the new table.

368
0:30:16.640 --> 0:30:23.020
So insert into new meetings, select everything from meetings, including the ID.

369
0:30:23.020 --> 0:30:28.160
You create the required constraints, triggers, et cetera, everything you need for the table,

370
0:30:28.160 --> 0:30:31.180
new meetings.

371
0:30:31.180 --> 0:30:36.440
And if you have a very large table, you can apply a very dirty hack that says that because

372
0:30:36.440 --> 0:30:41.680
I know that the data in the other table is valid, I don't need to validate it again.

373
0:30:41.680 --> 0:30:49.640
So I add the constraint, the foreign key constraint as not valid.

374
0:30:49.640 --> 0:30:53.520
If you're doing this on a live system that needs to be online while you're making this

375
0:30:53.520 --> 0:30:58.280
change, create a trigger so that changes coming into meetings can go into new meetings as

376
0:30:58.280 --> 0:31:00.920
well.

377
0:31:00.920 --> 0:31:07.520
And the dirtiness of the hack comes in the fact that you should really not be touching

378
0:31:07.520 --> 0:31:09.460
PG catalog at all.

379
0:31:09.460 --> 0:31:13.880
But if you do know that your constraint is valid because the data in your existing table

380
0:31:13.880 --> 0:31:19.280
is valid, you just go ahead and update PG constraint set, constraint validated equals

381
0:31:19.280 --> 0:31:28.420
true for that foreign key constraint we just created.

382
0:31:28.420 --> 0:31:37.380
And then finally, in order not to do lengthy locking when you're doing this, begin a transaction

383
0:31:37.380 --> 0:31:41.820
in a code block, an anonymous code block.

384
0:31:41.820 --> 0:31:45.920
You alter table meetings, rename to old meetings.

385
0:31:45.920 --> 0:31:52.160
Then you change new meetings that has exactly the same content now with an additional column.

386
0:31:52.160 --> 0:31:53.880
You rename it to meetings.

387
0:31:53.880 --> 0:31:56.880
You drop the old table and then you commit.

388
0:31:56.880 --> 0:31:57.880
Be careful.

389
0:31:57.880 --> 0:32:06.000
Also create a trigger to insert, update, delete items and events as they get changed in meetings.

390
0:32:06.000 --> 0:32:07.000
And that's about it.

391
0:32:07.000 --> 0:32:13.200
You've gotten rid of your table inheritance.

392
0:32:13.200 --> 0:32:18.640
Another very confusing thing, if you look at the Postgres documentation, it explains

393
0:32:18.640 --> 0:32:20.600
very well how to do this.

394
0:32:20.600 --> 0:32:23.360
But this is probably not what you want to do.

395
0:32:23.360 --> 0:32:29.320
So partitioning by multiple keys is not partitioning on multiple levels.

396
0:32:29.320 --> 0:32:38.720
So let's say we create a table transactions and it has a location code and the timestamp,

397
0:32:38.720 --> 0:32:40.600
among other columns.

398
0:32:40.600 --> 0:32:46.060
And I want to partition it by timestamp and also location code.

399
0:32:46.060 --> 0:32:52.320
Because I want a separate table for each time period, for each location code.

400
0:32:52.320 --> 0:33:05.000
So I create table transactions, 2023.02a for values from timestamp 2023, so the first of

401
0:33:05.000 --> 0:33:13.040
February to the first of March, and for location codes, AAA to BAA.

402
0:33:13.040 --> 0:33:18.720
Then I create the second partition.

403
0:33:18.720 --> 0:33:25.400
And 2023.02b is a partition of transactions for values from the same time period, but

404
0:33:25.400 --> 0:33:28.680
different locations.

405
0:33:28.680 --> 0:33:33.360
So I'm using locations BAA to BZZ.

406
0:33:33.360 --> 0:33:35.400
Error.

407
0:33:35.400 --> 0:33:39.900
Partition transactions 2023.02b would overlap.

408
0:33:39.900 --> 0:33:42.200
Why is that?

409
0:33:42.200 --> 0:33:50.560
Because you're specifying limits for the keys within each partition.

410
0:33:50.560 --> 0:33:55.340
So it will accept values that satisfy those keys.

411
0:33:55.340 --> 0:33:58.560
But this is not sub-partitioning.

412
0:33:58.560 --> 0:34:01.200
What you do want is sub-partitioning.

413
0:34:01.200 --> 0:34:06.380
You want to partition by one key and then partition those tables by another key.

414
0:34:06.380 --> 0:34:08.360
That is the way to do it correctly.

415
0:34:08.360 --> 0:34:14.520
So you create table transactions, location type, etc., etc., partition by range of timestamp

416
0:34:14.520 --> 0:34:16.680
first.

417
0:34:16.680 --> 0:34:20.220
Because we want the first level of partitioning to be timestamp based.

418
0:34:20.220 --> 0:34:30.360
Then you create table partitions as a partition of transactions for values from February to

419
0:34:30.360 --> 0:34:38.920
the 1st of March and we choose hash partitioning within those partitions for the location code.

420
0:34:38.920 --> 0:34:49.560
And all that means over there is that when I create the first partition, it's for values

421
0:34:49.560 --> 0:34:56.600
with modulus four remainder zero means just divided by four equal parts.

422
0:34:56.600 --> 0:35:03.800
And that creates a partition, a table that is partitioned by both things.

423
0:35:03.800 --> 0:35:04.800
Sub-partitioned.

424
0:35:04.800 --> 0:35:09.600
Now let's talk a little bit about performance.

425
0:35:09.600 --> 0:35:19.320
One thing we see people doing all the time is using many more connections than they should

426
0:35:19.320 --> 0:35:20.320
be.

427
0:35:20.320 --> 0:35:24.340
Accepting many more connections into their Postgres server than they should be.

428
0:35:24.340 --> 0:35:26.160
The default is very sensible.

429
0:35:26.160 --> 0:35:29.640
It's at 100 connections.

430
0:35:29.640 --> 0:35:37.660
We see things like 5,000 connections in production on a server with 32 CPUs.

431
0:35:37.660 --> 0:35:43.920
A server with 32 CPUs, there's no way on earth it's going to do more than 32 things at the

432
0:35:43.920 --> 0:35:46.680
same time, right?

433
0:35:46.680 --> 0:35:48.680
It's common sense.

434
0:35:48.680 --> 0:35:57.400
You may accept up to 100 things with 32 CPUs and interleave and overlap.

435
0:35:57.400 --> 0:35:58.400
That's fine.

436
0:35:58.400 --> 0:36:03.240
Or one of the connections may be idle and you take advantage of that to serve the other

437
0:36:03.240 --> 0:36:04.240
connections.

438
0:36:04.240 --> 0:36:05.600
But 5,000 is excessive.

439
0:36:05.600 --> 0:36:07.400
And we'll see why.

440
0:36:07.400 --> 0:36:10.680
Because Postgres is process based.

441
0:36:10.680 --> 0:36:14.800
And for every new client connection, it spawns a new process.

442
0:36:14.800 --> 0:36:21.640
The new process comes with interprocess communication through semaphores and shared memory.

443
0:36:21.640 --> 0:36:23.520
And that has an overhead.

444
0:36:23.520 --> 0:36:27.740
So every process you add to the system adds to that overhead.

445
0:36:27.740 --> 0:36:34.080
And you run the risk of your CPU spending most of its time doing context switching between

446
0:36:34.080 --> 0:36:38.120
one process and the other.

447
0:36:38.120 --> 0:36:44.780
So accessing the same objects from multiple connections may cause many lightweight locks

448
0:36:44.780 --> 0:36:49.680
to appear, what are called latches in other databases.

449
0:36:49.680 --> 0:36:56.400
And if you're trying to access the same objects from many client connections, then that lock,

450
0:36:56.400 --> 0:37:00.040
even if it's not explicit, it becomes heavily contented.

451
0:37:00.040 --> 0:37:06.460
And the other connections trying to access that object will slow each other down.

452
0:37:06.460 --> 0:37:14.120
So instead of opening one connection that does 400 times the work, you open 400 connections

453
0:37:14.120 --> 0:37:17.880
that do 1 400th the amount of work.

454
0:37:17.880 --> 0:37:19.840
And that doesn't perform the same.

455
0:37:19.840 --> 0:37:21.280
That performs worse.

456
0:37:21.280 --> 0:37:23.840
Because it's making your data hotter for no reason.

457
0:37:23.840 --> 0:37:27.840
Because they compete for access to that data.

458
0:37:27.840 --> 0:37:30.080
And also there's no fair queuing.

459
0:37:30.080 --> 0:37:31.680
It's more or less random.

460
0:37:31.680 --> 0:37:36.600
So lightweight locks don't have queuing, so you don't know who will get priority.

461
0:37:36.600 --> 0:37:39.680
There's no guaranteed quality of service.

462
0:37:39.680 --> 0:37:51.080
Now mitigation strategy is also you need to be aware that before Postgres 13 there's the

463
0:37:51.080 --> 0:37:55.680
issue of snapshot contention.

464
0:37:55.680 --> 0:38:02.560
So each transaction keeps an MVCC snapshot, even if it's idle.

465
0:38:02.560 --> 0:38:10.320
And so you can end up using server resources even for idle connections and slow everything

466
0:38:10.320 --> 0:38:11.880
else down.

467
0:38:11.880 --> 0:38:15.860
So this is contention that is caused by too much concurrency.

468
0:38:15.860 --> 0:38:22.120
So instead of opening 5,000 connections, just put a PG bouncer in front of your database

469
0:38:22.120 --> 0:38:28.400
or another connection puller and just allow fewer connections into the database while

470
0:38:28.400 --> 0:38:32.840
accepting the client connections from the connection puller.

471
0:38:32.840 --> 0:38:38.400
That way you throttle or you introduce latency on the application side, but that's not always

472
0:38:38.400 --> 0:38:43.720
bad because in some cases it can protect your service performance, which is more important

473
0:38:43.720 --> 0:38:49.760
than making, let's say, a noninteractive client wait for a few milliseconds more.

474
0:38:49.760 --> 0:38:56.040
It sounds counterintuitive, but it leads to higher performance overall.

475
0:38:56.040 --> 0:39:01.960
High transaction rate is also a problem when you're burning through transactions very quickly

476
0:39:01.960 --> 0:39:08.400
because there's a lot of detail here about the way transaction IDs work in Postgres,

477
0:39:08.400 --> 0:39:14.280
but the bottom line is that there's 4.2 billion transaction IDs.

478
0:39:14.280 --> 0:39:20.600
The future for you is 2.1 billion transactions in the future and the past is another 2.1 billion

479
0:39:20.600 --> 0:39:21.600
transactions.

480
0:39:21.600 --> 0:39:30.880
So if you are writing with a huge data rate with, let's say, an OLTP workload that can

481
0:39:30.880 --> 0:39:40.520
go through 2.1 billion transactions in a week, that will overrun the last transaction and

482
0:39:40.520 --> 0:39:44.240
you will no longer know whether that transaction is in the past or in the future.

483
0:39:44.240 --> 0:39:45.240
That's a problem.

484
0:39:45.240 --> 0:39:46.520
Postgres won't let you do that.

485
0:39:46.520 --> 0:39:50.680
It will shut down to avoid doing that.

486
0:39:50.680 --> 0:39:58.280
The solution that we came up with is called freezing, where you go through the table and

487
0:39:58.280 --> 0:40:05.960
you mark each row as, that you know to be old, as frozen, and you know that that row

488
0:40:05.960 --> 0:40:12.000
is always in the past, even if it has a transaction ID from another time.

489
0:40:12.000 --> 0:40:18.740
So the problem is you need to make sure that Postgres has the chance to freeze those rows

490
0:40:18.740 --> 0:40:21.000
before the wrap around.

491
0:40:21.000 --> 0:40:24.200
So what can you do?

492
0:40:24.200 --> 0:40:26.920
You can reduce the number of transactions.

493
0:40:26.920 --> 0:40:28.680
You can use batching.

494
0:40:28.680 --> 0:40:36.160
Instead of committing 100 things, just batch them or 1,000 things and that automatically

495
0:40:36.160 --> 0:40:45.040
uses 1,000 transactions less, sorry, 1,000 the transaction rate that you have.

496
0:40:45.040 --> 0:40:46.400
And that helps.

497
0:40:46.400 --> 0:40:54.880
Also, it helps to bump up the effectiveness of auto vacuum and that takes care of freezing.

498
0:40:54.880 --> 0:40:57.880
Another favorite is people that turn off auto vacuum.

499
0:40:57.880 --> 0:41:02.520
So the thing that actually makes multi-view concurrency control work.

500
0:41:02.520 --> 0:41:05.080
So don't turn it off.

501
0:41:05.080 --> 0:41:09.120
This work is removing dead tuples, freezing things, among other things.

502
0:41:09.120 --> 0:41:15.720
It does have overhead because it scans tables and indexes and acquires locks and gives them

503
0:41:15.720 --> 0:41:18.560
up voluntarily.

504
0:41:18.560 --> 0:41:21.600
And that's why it has limited capacity by default.

505
0:41:21.600 --> 0:41:25.640
But the defaults are not suitable for production workload.

506
0:41:25.640 --> 0:41:31.920
So if you're concerned about the overhead of auto vacuum, then turning it off is not

507
0:41:31.920 --> 0:41:36.440
the solution because the alternative is worse.

508
0:41:36.440 --> 0:41:39.600
You can risk shutting down your database.

509
0:41:39.600 --> 0:41:45.880
Or accumulating bloat because there's no way to avoid the vacuum in Postgres yet.

510
0:41:45.880 --> 0:41:53.000
And when you outrun vacuum by writing faster than your database can auto vacuum it, then

511
0:41:53.000 --> 0:41:58.320
you may come up with a bloat runaway that requires a vacuum full.

512
0:41:58.320 --> 0:42:02.320
And that takes a total lock on the table and nobody can use it.

513
0:42:02.320 --> 0:42:10.480
So instead of turning off auto vacuum, actually make it work harder and you can find in the

514
0:42:10.480 --> 0:42:16.280
Postgres documentation how to make it work harder in order to avoid bloat and transaction

515
0:42:16.280 --> 0:42:19.240
ID wraparound.

516
0:42:19.240 --> 0:42:25.040
There's some standard stuff here about explicit locking.

517
0:42:25.040 --> 0:42:32.200
If your application needs to lock things to make sure that concurrency, oops, out of

518
0:42:32.200 --> 0:42:35.200
power.

519
0:42:35.200 --> 0:42:47.200
Can I use something else?

520
0:42:47.200 --> 0:43:03.080
I have a copy.

521
0:43:03.080 --> 0:43:17.760
Can you?

522
0:43:17.760 --> 0:43:18.760
Can you?

523
0:43:18.760 --> 0:43:19.760
Thanks.

524
0:43:19.760 --> 0:43:24.120
Okay, so there were only like two or three slides.

525
0:43:24.120 --> 0:43:27.840
If you're really interested in knowing them, you can talk to Jimmy afterwards.

526
0:43:27.840 --> 0:43:30.640
But you can ask now questions about what he already talked about.

527
0:43:30.640 --> 0:43:33.280
So we have like five minutes for questions.

528
0:43:33.280 --> 0:43:36.040
So if you have a question, please raise your hand and we are going to bring the microphone

529
0:43:36.040 --> 0:43:37.040
to you so you can ask questions.

530
0:43:37.040 --> 0:43:39.040
There is a question there.

531
0:43:39.040 --> 0:43:40.040
Good.

532
0:43:40.040 --> 0:43:41.040
Thanks.

533
0:43:41.040 --> 0:43:42.040
It's on the website.

534
0:43:42.040 --> 0:43:43.040
Hi, Greto.

535
0:43:43.040 --> 0:43:53.720
Is there any difference on how, is there any difference in how Varkar and Varkar N are stored

536
0:43:53.720 --> 0:43:54.720
on the disk?

537
0:43:54.720 --> 0:43:56.240
Sorry, I didn't hear your question.

538
0:43:56.240 --> 0:44:01.680
Is there any difference in how Varkar and Varkar N and text are stored on disk?

539
0:44:01.680 --> 0:44:04.160
No, Varkar is exactly the same as text.

540
0:44:04.160 --> 0:44:05.160
It's the same type.

541
0:44:05.160 --> 0:44:06.160
Okay.

542
0:44:06.160 --> 0:44:08.680
So it doesn't matter like also for indexes like I know in my SQL.

543
0:44:08.680 --> 0:44:10.640
No, no, it doesn't make a difference.

544
0:44:10.640 --> 0:44:13.360
But Varkar with a limit is a different type.

545
0:44:13.360 --> 0:44:14.360
Got it.

546
0:44:14.360 --> 0:44:15.360
Thank you.

547
0:44:15.360 --> 0:44:16.360
Thanks.

548
0:44:16.360 --> 0:44:17.360
Another question?

549
0:44:17.360 --> 0:44:20.360
I just want to browse.

550
0:44:20.360 --> 0:44:21.360
Questions, questions?

551
0:44:21.360 --> 0:44:24.320
Jimmy, I have a question.

552
0:44:24.320 --> 0:44:30.720
So you were talking about money and why does money is actually implemented?

553
0:44:30.720 --> 0:44:33.120
Is it SQL standard or?

554
0:44:33.120 --> 0:44:34.120
Connected.

555
0:44:34.120 --> 0:44:36.240
Sorry, what was the question?

556
0:44:36.240 --> 0:44:41.480
If money is so bad as a data type, why is it implemented in Postgres?

557
0:44:41.480 --> 0:44:46.800
Because it was actually deprecated because of those bad things that we talked about.

558
0:44:46.800 --> 0:44:47.800
Twice.

559
0:44:47.800 --> 0:44:48.880
Twice.

560
0:44:48.880 --> 0:44:54.280
As Andreas pointed out this morning, and people requested it, so we reinstated it twice.

561
0:44:54.280 --> 0:44:55.280
Oops.

562
0:44:55.280 --> 0:44:56.280
There you go.

563
0:44:56.280 --> 0:44:58.280
So people wanted it.

564
0:44:58.280 --> 0:45:01.280
People wants money.

565
0:45:01.280 --> 0:45:04.920
Different kind of money, exactly.

566
0:45:04.920 --> 0:45:05.920
Any other questions?

567
0:45:05.920 --> 0:45:11.760
Okay, we have another question here.

568
0:45:11.760 --> 0:45:14.120
Quick question about table inheritance.

569
0:45:14.120 --> 0:45:19.480
So I know I've read the Postgres documentation about all its flaws and why you shouldn't

570
0:45:19.480 --> 0:45:22.880
use it, especially now that there's partitioning.

571
0:45:22.880 --> 0:45:30.200
But overall, I think the idea of having tables that have some common columns but then diverge

572
0:45:30.200 --> 0:45:34.000
on some others is an interesting idea.

573
0:45:34.000 --> 0:45:36.440
There's other ways to solve it.

574
0:45:36.440 --> 0:45:43.600
Like in previous jobs, I've implemented one table that had all the common columns and

575
0:45:43.600 --> 0:45:46.840
then one separate table for each variation.

576
0:45:46.840 --> 0:45:54.640
But are there other solutions that you implement for those types of ORMs?

577
0:45:54.640 --> 0:46:01.840
Why not use ORMs to make as complicated a data model as you like, but not store the

578
0:46:01.840 --> 0:46:06.320
complexity as inheritance relationships on the database?

579
0:46:06.320 --> 0:46:13.920
But doesn't that create larger tables that you'll have to read no matter if the data

580
0:46:13.920 --> 0:46:14.920
is sparse?

581
0:46:14.920 --> 0:46:17.480
You need to link them as a foreign key relationship.

582
0:46:17.480 --> 0:46:20.920
So you're just storing an extra identifier, I guess.

583
0:46:20.920 --> 0:46:21.920
Yeah.

584
0:46:21.920 --> 0:46:22.920
Thank you.

585
0:46:22.920 --> 0:46:23.920
Okay.

586
0:46:23.920 --> 0:46:24.920
Never mind.

587
0:46:24.920 --> 0:46:32.640
So, anyway, before the last thing I wanted to tell you, right, it was the security slides.

588
0:46:32.640 --> 0:46:34.080
They're important.

589
0:46:34.080 --> 0:46:39.640
Never use trust over TCPIP in your PGHBA conf.

590
0:46:39.640 --> 0:46:43.280
That was the most important thing I had to say in the remainder of the slides.

591
0:46:43.280 --> 0:46:47.520
Do not trust anything coming from TCPIP.

592
0:46:47.520 --> 0:46:54.360
Always use password, MD5 certificate, SCRAM authentication.

593
0:46:54.360 --> 0:46:55.360
That was the last thing.

594
0:46:55.360 --> 0:46:56.360
Sorry.

595
0:46:56.360 --> 0:46:57.360
I'll take your question.

596
0:46:57.360 --> 0:46:58.360
No, thanks.

597
0:46:58.360 --> 0:47:02.560
I'm just curious as to why outer left join isn't implemented.

598
0:47:02.560 --> 0:47:04.400
It's just left join.

599
0:47:04.400 --> 0:47:08.680
Is that, of course, it's the same thing as using the anti-join you used earlier.

600
0:47:08.680 --> 0:47:11.760
I'm just curious why it isn't implemented.

601
0:47:11.760 --> 0:47:13.920
It's the same thing.

602
0:47:13.920 --> 0:47:16.800
Outer left join is the same thing as left join in Postgres.

603
0:47:16.800 --> 0:47:17.800
Yeah, I know.

604
0:47:17.800 --> 0:47:25.320
But outer left join should be, according to my old books of SQL 89 or something, just

605
0:47:25.320 --> 0:47:27.840
anti-join left side.

606
0:47:27.840 --> 0:47:32.800
So you do not take the center part where the rings meet.

607
0:47:32.800 --> 0:47:35.560
You remove the intersection, just take the left part.

608
0:47:35.560 --> 0:47:36.560
Right.

609
0:47:36.560 --> 0:47:40.760
So, yeah, the way Postgres implements it is it just enters null for the things that don't

610
0:47:40.760 --> 0:47:43.040
exist, that don't correspond.

611
0:47:43.040 --> 0:47:46.040
And the right join would put the nulls on the other side.

612
0:47:46.040 --> 0:47:47.040
That's the difference.

613
0:47:47.040 --> 0:47:54.040
There was another question here before.

614
0:47:54.040 --> 0:47:57.280
Okay.

615
0:47:57.280 --> 0:48:06.160
So you mentioned about the date and the time handling.

616
0:48:06.160 --> 0:48:12.520
Is there any way in Postgres that doesn't involve an awful lot of hackery to deal with

617
0:48:12.520 --> 0:48:13.520
partial dates?

618
0:48:13.520 --> 0:48:18.840
For example, if I say I'm going to take the train tomorrow morning or I'm going on holiday

619
0:48:18.840 --> 0:48:22.240
in August.

620
0:48:22.240 --> 0:48:25.680
So you want to store, like, August?

621
0:48:25.680 --> 0:48:28.840
Well, August 24th.

622
0:48:28.840 --> 0:48:30.320
Right.

623
0:48:30.320 --> 0:48:32.760
So you can use a date with no context.

624
0:48:32.760 --> 0:48:35.240
You can use a date that says August 24th.

625
0:48:35.240 --> 0:48:38.680
No, not as in August 24th as in August 2024.

626
0:48:38.680 --> 0:48:39.680
Okay.

627
0:48:39.680 --> 0:48:47.080
So you can just use extract from that date or truncate and lose all the other context

628
0:48:47.080 --> 0:48:50.560
of that date and only store August 2024.

629
0:48:50.560 --> 0:48:52.560
Thank you.

630
0:48:52.560 --> 0:48:59.560
We have time for the very last question here.

631
0:48:59.560 --> 0:49:01.720
Somebody who already...

632
0:49:01.720 --> 0:49:06.920
Hi, when you write V2 of this presentation, what are the other don't do's that you would

633
0:49:06.920 --> 0:49:07.920
add?

634
0:49:07.920 --> 0:49:08.920
Sorry, I couldn't...

635
0:49:08.920 --> 0:49:12.360
Are there other like don't do's to involve, like, I don't know, like, foreign data wrappers

636
0:49:12.360 --> 0:49:13.360
or well?

637
0:49:13.360 --> 0:49:15.920
I guess the more exotic parts of Postgres that you would say...

638
0:49:15.920 --> 0:49:18.600
Yeah, as I said, this talk couldn't be all inclusive.

639
0:49:18.600 --> 0:49:23.160
It was the top things that we see people doing wrong every day.

640
0:49:23.160 --> 0:49:25.520
Fair enough.

641
0:49:25.520 --> 0:49:27.160
Right.

642
0:49:27.160 --> 0:49:30.160
Well, thanks, everybody, for staying until the very last talk.

643
0:49:30.160 --> 0:49:32.160
Thank you.

644
0:49:32.160 --> 0:49:34.160
Excellent.

645
0:49:34.160 --> 0:49:45.960
And remember, you can now get out here on the front because there are no more talks.

646
0:49:45.960 --> 0:49:48.240
You can pick up your stickers here.

647
0:49:48.240 --> 0:49:51.320
And once again, thank you, Jimmy, for your presentation.

648
0:49:51.320 --> 0:50:00.680
Cheers.

