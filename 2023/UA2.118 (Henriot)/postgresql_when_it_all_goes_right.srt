1
0:00:00.000 --> 0:00:15.360
We are starting. Please be quiet. Couple of things. First of all, welcome. Here I am to

2
0:00:15.360 --> 0:00:21.040
introduce our next speaker, Pablo in our PostgreSQL Dev Room, who's going to talk about Go. Just

3
0:00:21.040 --> 0:00:26.800
a few practical things. When you exit, please exit from the back. And if you want to go

4
0:00:26.800 --> 0:00:34.080
out in between the talk, please be quiet. Because this Dev Room is very loud and these chairs are

5
0:00:34.080 --> 0:00:50.480
very freaky. So yes. That being said, enjoy. Hello people. How are you today? It was yesterday fun.

6
0:00:50.480 --> 0:01:00.720
Um, because first two talks were not really crowded. But mine is good already. Yeah. My

7
0:01:00.720 --> 0:01:08.240
name is Pablo Golop. I'm working for CyberTech. So I'm a senior consultant in the body of a young

8
0:01:08.240 --> 0:01:19.600
developer. So today, a couple of words about my company. CyberTech is purely PostgreSQL company.

9
0:01:20.960 --> 0:01:30.240
We work with clients only if they have PostgreSQL. If they don't, we install it. And they can work

10
0:01:30.240 --> 0:01:40.160
with us from that point. We are having several branches all over, not all over, but the world,

11
0:01:40.720 --> 0:01:50.160
some of them in South America, most of them are in Europe. Not now.

12
0:01:50.160 --> 0:01:59.280
I wanted to restart. So some of our customers, so choose your fighter. Some of our products.

13
0:02:00.000 --> 0:02:10.320
So we are not only consulting people, but we do products. Yeah. Why PostgreSQL? You know why.

14
0:02:10.320 --> 0:02:18.480
It's cool. Absolutely. So what I'm, what will be, I'm talking about today. So first of all,

15
0:02:18.480 --> 0:02:23.760
I want to introduce you to the Go language. How many of you have an idea what the Go language is?

16
0:02:25.760 --> 0:02:32.000
Okay. So I don't need like start from the beginning explaining what the compiler is,

17
0:02:32.000 --> 0:02:41.760
and etc. So yeah. Okay. Then I will say a couple of words about IDEs and editors we are using.

18
0:02:41.760 --> 0:02:52.160
Then I will describe drivers for PostgreSQL specifically. Some useful extensions.

19
0:02:53.680 --> 0:03:00.080
How we do testing, how we do releases, how we do continuous integration, development, etc. And then

20
0:03:00.080 --> 0:03:15.520
probably I hope we'll have a question session. Okay. So why Go? First of all, when I start my

21
0:03:15.520 --> 0:03:23.280
first project, I like that Go produces the native one binary for every platform. I said, wow.

22
0:03:23.280 --> 0:03:30.960
Wow. I just can build everything from the same command line for every previous system and

23
0:03:30.960 --> 0:03:36.560
architecture I want to. And I don't need virtual machines and other crap. Just like Go.

24
0:03:38.960 --> 0:03:48.880
It's simple enough. It has a good community. It now has already very comprehensive tools

25
0:03:48.880 --> 0:04:00.960
and support by GitHub, et cetera, et cetera. Yeah. So cross-platform is somehow connected

26
0:04:00.960 --> 0:04:09.360
with the native binaries for every architecture. So this is the last developer survey for Go

27
0:04:09.360 --> 0:04:20.080
asking how people are using Go language for what kind of. So speaking about Postgres,

28
0:04:20.080 --> 0:04:28.960
I would say the data processing is somehow connected. Before that, we had like these answers

29
0:04:28.960 --> 0:04:42.880
where you can see that databases is like half of the projects people were using. Probably you know,

30
0:04:42.880 --> 0:04:51.200
if not, so the top products written Go are Kubernetes and Docker, OpenShift, then

31
0:04:51.200 --> 0:05:04.400
Hugo, the fastest framework for building statistical sites, etc., etc. Postgres-related

32
0:05:04.400 --> 0:05:17.360
Go products which are written in Go are the CockroachDB, both Postgres operators from

33
0:05:17.360 --> 0:05:26.960
Zalando and from Crunchy, WallG, PgCenter, PgWatch, PgTimeTable, so on and so on. So if you

34
0:05:27.520 --> 0:05:36.560
want to find more projects, more applications written in Go, please go to this site, to this repo.

35
0:05:37.120 --> 0:05:43.680
There are a lot of them. A lot of them. Yeah. Okay. So what about tooling?

36
0:05:43.680 --> 0:05:56.320
Because when I was starting, I used Sublime Text. There was no proper IDE to work with,

37
0:05:56.960 --> 0:06:05.120
no debugger, no these kind of things. Right now, according to the last year developer survey,

38
0:06:05.120 --> 0:06:19.280
the most used IDE is VS Code, then Goland by JetBrains, and then Vimeo Veeam and Sublime Text is 1%.

39
0:06:22.640 --> 0:06:28.640
I was saying at the conference that I will try Goland and will tell you about how it is different

40
0:06:28.640 --> 0:06:38.720
from VS Code. No. Still didn't try it. But I think it's good. So these are the answers

41
0:06:38.720 --> 0:06:45.600
from the previous years. So as you can see, the intention is the same. So VS Code and Top

42
0:06:45.600 --> 0:06:55.920
and Google Language, etc., etc. Goland. Sorry. What I'm using, I'm using VS Code with the official

43
0:06:55.920 --> 0:07:05.840
plugin installed. Then I'm using the T-parse, command line utility to make these fancy tables

44
0:07:05.840 --> 0:07:19.760
out of test output. Linter, of course. Tip 9. I tried GitLab CoPilot. It's not bad. But I don't

45
0:07:19.760 --> 0:07:27.520
want to spend my money on this. I have my own head. Go release to produce the packages and

46
0:07:27.520 --> 0:07:37.600
binaries like in one go. Then PostgresQL, of course. And the last, but at least the Gitpod I.O.,

47
0:07:37.600 --> 0:07:45.200
which is pretty much the same thing as a GitHub workspace. But it's free for open source developers.

48
0:07:45.200 --> 0:07:50.960
So it's good if you want to try something new and you don't want to install everything on your

49
0:07:50.960 --> 0:07:59.120
machine or to set up the virtual machine. You can go there, run it in your browser, drink

50
0:07:59.120 --> 0:08:05.520
and beer on the beach and try something new. It's okay. If you're done, you just close your browser,

51
0:08:06.640 --> 0:08:14.720
close your top and it's gone. Now, about drivers, about the PostgresQL part of the

52
0:08:14.720 --> 0:08:27.840
stock. The whole idea of the stock started after I tried to find good tutorials about how to start

53
0:08:27.840 --> 0:08:34.320
to work with PostgresQL. A lot of them, not all of them, but a lot of them say, okay,

54
0:08:34.320 --> 0:08:45.440
just use ORM and you're fine. Well, why? If I need to like to create utility to use like three

55
0:08:45.440 --> 0:08:54.080
commands, right? Why should I use like ORM? And yeah, don't get me wrong. ORMs are fine if you

56
0:08:54.080 --> 0:09:05.200
know what you are doing. They solve the problems, but you don't need to put it everywhere.

57
0:09:06.400 --> 0:09:12.080
And you don't need to start from it. Because otherwise you will be learning ORM,

58
0:09:12.080 --> 0:09:20.720
but not learning PostgresQL itself, right? Yeah. We have SQL for that.

59
0:09:20.720 --> 0:09:30.240
So, during this talk, I will not be explaining ORMs and how to work with that. I will explain

60
0:09:30.240 --> 0:09:37.280
the basic drivers. Anyway, ORMs are using drivers on the low level to speak to the PostgresQL,

61
0:09:37.280 --> 0:09:47.440
right? So, we should know how to use them. So, the thing is in Go that we have these databases

62
0:09:47.440 --> 0:09:57.680
QL interfaces, interfaces is just like an agreement on what methods are available from,

63
0:09:57.680 --> 0:10:07.200
I don't know, from object, from structure, whatever. And for each database, there should be

64
0:10:08.080 --> 0:10:14.800
a special driver, an implementation for these interface, right? So, the first official

65
0:10:14.800 --> 0:10:26.240
implementation for the PostgresQL in the Go world was libpq. It's good. It's proven. It's

66
0:10:27.040 --> 0:10:35.040
a long time on the market, but it is in maintenance mode right now for two years probably. It's not

67
0:10:35.040 --> 0:10:43.280
bad. It's okay. You can be sure that this functionality is solid. But if you want more,

68
0:10:43.280 --> 0:10:50.400
and if you start a new project, jackcpgx is the way to go. Because

69
0:10:53.680 --> 0:10:57.600
you can use it with whatever you want. I will show you later.

70
0:10:59.920 --> 0:11:08.000
So, yeah, we are scientists and we do graphs. So, unlike of Python or not Python, but

71
0:11:08.000 --> 0:11:16.240
the NPM, JavaScript work, we don't have this statistic for how many times a particular

72
0:11:16.240 --> 0:11:24.160
package was downloaded, used, whatever. So, the most funny way is to use GitHub stars

73
0:11:25.760 --> 0:11:33.680
and, yeah, to build this stuff. So, as you can see, the pjx is one year,

74
0:11:33.680 --> 0:11:46.160
started one year later, but now it's going to be very popular. So, in 2019-20, there was an

75
0:11:46.160 --> 0:11:51.840
announcement that the libpq is going to maintain small and the pjx started to grow.

76
0:11:54.160 --> 0:12:01.360
So, what if you are, if your project is using already databasesql or you want to follow

77
0:12:01.360 --> 0:12:10.080
tutorials or techniques and to use this databaseql standard de facto interfaces? For that purpose,

78
0:12:10.800 --> 0:12:19.280
pjx has a special wrapper. So, you can still use databaseql interface,

79
0:12:20.640 --> 0:12:28.000
but you can underneath on the low level, you will use the pjx package.

80
0:12:28.000 --> 0:12:37.840
So, you should use pjx solely if you are starting a new project or your project is

81
0:12:38.480 --> 0:12:46.480
aiming only post-baseql, right? Then you don't need databaseql, but if you are dependent on

82
0:12:46.480 --> 0:12:54.320
orm or you are dependent on other package which want you to use databaseql, right? You go for

83
0:12:54.320 --> 0:13:05.360
wrapper. In that case, the dependency will use this wrapper to speak to databaseql and you will

84
0:13:05.360 --> 0:13:15.520
use the power of pjx. So, there are a lot of unique features that are not present, not implemented

85
0:13:16.160 --> 0:13:22.480
in the standard library and they cannot be implemented because this interface is

86
0:13:22.480 --> 0:13:27.680
common, it is the same for every possible database. So, for example, you cannot add

87
0:13:28.240 --> 0:13:34.640
methods with a copy support because only post-baseql do copy support, right?

88
0:13:35.520 --> 0:13:45.760
So, the most cool feature is that pjx supports binary transport protocol and it supports

89
0:13:45.760 --> 0:13:56.800
natively all built-in Postgres types. And if you create user types, it will support them out of the

90
0:13:56.800 --> 0:14:03.760
box unless they are very complicated. But even in that case, you can create a special interface or a

91
0:14:03.760 --> 0:14:14.080
special object structure that will tell pjx how to encode, decode the values of your types.

92
0:14:14.080 --> 0:14:24.320
So, as I said, yeah, copy protocol, logging, yeah, and for connection pooling, you have this

93
0:14:24.320 --> 0:14:33.680
afterconnect hook. So, the idea in your language is that the database object that you have is

94
0:14:34.320 --> 0:14:41.600
pool by default. So, it can create additional connections and you never know how many active,

95
0:14:41.600 --> 0:14:48.560
well, you can know, but you can never tell how many connections you have right now. And this,

96
0:14:48.560 --> 0:14:54.960
for example, afterconnect hook helps you to prepare your session, prepare your new open

97
0:14:54.960 --> 0:14:59.600
connection for something, like add some identifier, log in or whatever.

98
0:14:59.600 --> 0:15:12.640
Yeah, listen notify is implemented natively. What else? Yeah, different JSON,

99
0:15:12.640 --> 0:15:18.800
HStore, large objects. So, everything you need is already there.

100
0:15:18.800 --> 0:15:36.720
Nice thing about pjx is in December probably the new major version 5 release was, and it was a

101
0:15:36.720 --> 0:15:48.560
huge step forward, especially in the term of dependencies. V4, version 4 was good, but it has

102
0:15:48.560 --> 0:16:06.400
so many external dependencies that, for example, it's not the thing anymore, and it's very cool.

103
0:16:07.280 --> 0:16:15.280
So, yeah, hello world. You probably all know how to write it in the database SQL.

104
0:16:15.280 --> 0:16:26.480
With the interface, so you're just using that import package. But instead of using

105
0:16:27.280 --> 0:16:35.920
libq, you are specifying pjx as the lead, which is the wrapper for the standard library.

106
0:16:36.560 --> 0:16:44.800
And then all things are the same. No difference. No difference. So, if you want to update your

107
0:16:44.800 --> 0:16:53.360
project, you just change the import part, the import of libq to the pjx standard lib and you are fine.

108
0:16:56.320 --> 0:17:07.760
If you want to use pjx directly, you are fine to do that. The thing is here that

109
0:17:07.760 --> 0:17:18.720
the pjx return the one connection only. So, if you don't need a pool of connections or if you want

110
0:17:18.720 --> 0:17:25.440
to be sure that only one connection is live, one connection is used, you are going with pjx connect.

111
0:17:26.640 --> 0:17:35.280
But please remember that you cannot use this structure, this connection, in parallel. So,

112
0:17:35.280 --> 0:17:44.720
you need to know that at one point in time only one thread or one go routine can talk to the database.

113
0:17:45.920 --> 0:17:52.400
Otherwise, you're good. But if you want a pool of connections, you are going with pjx pool.

114
0:17:55.200 --> 0:18:04.240
And I don't know, what can I add here? It's obvious. It's pooling. You can pass it to the

115
0:18:04.240 --> 0:18:10.000
go routines and it will create additional connections as you go and you can limit

116
0:18:10.000 --> 0:18:18.080
upper number of connections, et cetera, et cetera. It's very flexible. Okay. About useful extensions.

117
0:18:21.440 --> 0:18:29.040
For my first project, I started with the libq as well. It's way to go. That's how we grow.

118
0:18:29.040 --> 0:18:38.400
And later, I understand that I want this copy functionality badly. I need that.

119
0:18:39.600 --> 0:18:50.720
So, I started to look at the pjx, how to switch it. And I didn't want to lose this SQL things

120
0:18:50.720 --> 0:18:58.240
because when you're encoding, decoding your structures, slices, arrays, whatever, write

121
0:18:58.240 --> 0:19:07.200
from rows or two rows, right? That's what most people think the ORM do. It just translates the

122
0:19:07.200 --> 0:19:15.200
rows into the structures. But, yeah, it's very useful. So, like, if you are working with the

123
0:19:15.200 --> 0:19:22.560
old database SQL or libq, you are importing this SQL thing and you can have a lot of new methods

124
0:19:22.560 --> 0:19:36.720
like you can struct the row into the structure or you can scan the color into the variable or you can

125
0:19:36.720 --> 0:19:46.800
create a slice from your rows, et cetera, et cetera. It's very cool. Pjx at that time

126
0:19:51.600 --> 0:20:03.600
provided that. But with the latest version 5, everything is already there. Better is included.

127
0:20:03.600 --> 0:20:14.480
Probably you can find cases where you want more control over decoding and coding.

128
0:20:15.600 --> 0:20:25.120
But after this guy was introduced, wrote to struct by name, written by me, by the way.

129
0:20:25.120 --> 0:20:36.160
Yeah. Everything became very easy. So, before that, we had only row to struct by position.

130
0:20:36.800 --> 0:20:46.160
So, if your structure fields are in the same position as your field in your row,

131
0:20:46.160 --> 0:20:52.720
result set, you're fine. You're just, like, doing the back and forth. But if you want to skip some

132
0:20:52.720 --> 0:21:00.480
fields or, for example, if you have some nonpublic fields in the structure but still want to use this

133
0:21:00.480 --> 0:21:06.080
functionality to decode and code from the result set, this is the way to go.

134
0:21:08.720 --> 0:21:11.360
Yeah. Now about testing.

135
0:21:11.360 --> 0:21:24.960
We all know it's very essential, right? And I heard a lot this statement that you need to write

136
0:21:24.960 --> 0:21:38.720
your tests first and only then implementation. I never did. Maybe one of us tried it. Oh, go.

137
0:21:38.720 --> 0:21:48.320
Go. I'm too lazy. Because I never know where at the end I will go with my code. I'm starting,

138
0:21:48.320 --> 0:21:53.760
like, okay, I will implement this thing that will return this integer. And then, oh, no, let's do

139
0:21:53.760 --> 0:22:01.600
this. CTE with a lot of things. Yeah. And if I write a test before, I need to follow it.

140
0:22:01.600 --> 0:22:08.320
Right? No, it's not funny. How we do testing? So, I would say there are three main approaches.

141
0:22:08.320 --> 0:22:19.280
The first one, obviously, is to start a real PostgreSQL server. You can have your local

142
0:22:19.280 --> 0:22:26.160
installation on the test environment or you can download it during the test running, install it,

143
0:22:26.160 --> 0:22:33.120
initialize, et cetera, then cache. But it's still the same. It's a real PostgreSQL server.

144
0:22:33.120 --> 0:22:48.160
The second approach would be mocking libraries for database SQL that would be Datadog, go SQL mock.

145
0:22:49.040 --> 0:22:58.400
And for PgX, I created this PgX mock, which is the brother of the SQL mock, but, yeah, works with PgX.

146
0:22:58.400 --> 0:23:05.680
I hope you know what is mocking and how these things are working, right? So, yeah.

147
0:23:06.400 --> 0:23:13.760
We are pretending that we are a PostgreSQL server and our application, our tests,

148
0:23:14.560 --> 0:23:17.920
are thinking that they are speaking to the real server. But, in fact,

149
0:23:17.920 --> 0:23:24.640
we just throw the needed answers to the application. So, the rows, okay, this is row,

150
0:23:24.640 --> 0:23:30.960
this is row, this is the answer. Oh, no, that was a row. Let's see how you will react with that,

151
0:23:30.960 --> 0:23:40.800
et cetera, et cetera. But if you want to test on the protocol level, there is also some

152
0:23:40.800 --> 0:23:53.760
very low libraries, like PgMock, which is just the real low-level mocking protocol.

153
0:23:54.960 --> 0:24:03.200
CockroachDB has its own test server, which is just like an import CockroachDB test server and

154
0:24:03.200 --> 0:24:16.480
use it in your test. And another library is copyist. Okay. Let's try to maybe...

155
0:24:19.840 --> 0:24:21.360
It's not very useful.

156
0:24:24.480 --> 0:24:25.760
No, let's get back...

157
0:24:25.760 --> 0:24:44.400
Okay, so how to create a test, how to use this PgMock thing. So, if you read the readme on the

158
0:24:44.400 --> 0:24:49.680
repository, you will see that no change is required to your application. That's a lie.

159
0:24:49.680 --> 0:25:01.840
Okay. You need to provide an interface because the PgX return structures is a connection or a pool.

160
0:25:03.040 --> 0:25:14.640
We cannot mock structures. We can mock interfaces. So, I'm defining PgXe interface here and say to my

161
0:25:14.640 --> 0:25:23.840
method, to my function, that I will use this interface. Please use that. And for my function,

162
0:25:26.960 --> 0:25:33.360
it doesn't care, would it be a real connection or would it be mocking or anything. It just knows

163
0:25:33.360 --> 0:25:43.760
that this object has this method and it's enough for that. Okay. So, yeah, we write a code kind of

164
0:25:44.560 --> 0:25:52.000
shitty. We're trying to come in, we're trying to roll back, et cetera, et cetera, et cetera, how to

165
0:25:52.000 --> 0:26:00.320
test it. So, I will start with the successful test cases. I'm a very positive person.

166
0:26:00.320 --> 0:26:12.000
So, first thing first, though, I'm creating the mocking object. PgX, mock, new pool.

167
0:26:13.760 --> 0:26:22.400
Then I will tell my mocking object how should my session looks like, right? So, I'm saying I'm

168
0:26:22.400 --> 0:26:31.200
expecting that we will start a transaction. I'm expecting the game. Then I'm expecting that the

169
0:26:31.200 --> 0:26:40.800
code will try to execute update statement, right? And when this happens, please return to this code

170
0:26:41.360 --> 0:26:49.040
the new result that update was successful and we updated one row, right? After that, I expect

171
0:26:49.040 --> 0:26:57.600
that the code will try to insert something and I expect that the arguments for this statement

172
0:26:57.600 --> 0:27:06.960
would be two and three. If that is the case, please tell that everything is good. We insert one row

173
0:27:08.000 --> 0:27:15.600
and after all that, I expect that the code will commit the transaction, right? That is what I'm

174
0:27:15.600 --> 0:27:24.480
expecting from the code. Then I'm calling my function record starts and instead of the

175
0:27:24.480 --> 0:27:34.400
PgX, I'm passing the mocking object, mock, and two and three arguments, right? And if anything goes

176
0:27:34.400 --> 0:27:44.160
wrong, the test cases fail, right? But another thing I want to check, if every expectation I

177
0:27:44.160 --> 0:27:54.400
set were met. For example, after the commit, my code might want to write a log to the database

178
0:27:54.400 --> 0:28:04.960
or do other things. I don't expect that thing from it and these expectations were met will fail

179
0:28:05.760 --> 0:28:12.000
if something else is happening inside this function which is not being expected,

180
0:28:12.000 --> 0:28:23.760
right? So for fail, for failure is pretty much the same. We are telling that we wait, we expect to

181
0:28:23.760 --> 0:28:32.080
start transaction, we expect to start update statement, but let's pretend we want to test

182
0:28:32.080 --> 0:28:42.240
how our code will behave if the insert statement will fail. So we are telling, so when insert

183
0:28:42.240 --> 0:28:49.200
statement is coming with the arguments two and three, let's pretend that error happened. Return

184
0:28:49.200 --> 0:28:59.600
error to our code and the error with some error text, but very beautiful. We are starting our

185
0:28:59.600 --> 0:29:06.400
function, but in that case, we know that it should fail. That's why we are checking our error to be

186
0:29:07.840 --> 0:29:15.680
not nil. We are waiting error, right? And the same for expectations were met. So for example,

187
0:29:15.680 --> 0:29:22.720
if we failed and our code tries to do more than we are expecting, we say, no, please don't.

188
0:29:22.720 --> 0:29:34.160
Please don't. Yeah. So and then you are just using go test and with the tip parts,

189
0:29:35.040 --> 0:29:46.960
thingy, I just love how the tables look after this output. So like for this case, we have like one

190
0:29:46.960 --> 0:29:54.480
package and we have two test cases, right? But in real application, you might have hundreds,

191
0:29:54.480 --> 0:30:04.320
hundreds of test cases and dozens of packages. They all be listed and you can see a coverage for

192
0:30:05.120 --> 0:30:14.080
every package and you can see probably coverage for every test case, how many passes, how many

193
0:30:14.080 --> 0:30:22.960
fails, et cetera, et cetera. Also, you want to probably investigate what is the coverage.

194
0:30:23.600 --> 0:30:32.240
For that, you are using the built-in go to cover tool that will produce temporary HTML files and

195
0:30:32.240 --> 0:30:41.920
will open them in your browser. So you see a combo box with the list of files in your application

196
0:30:41.920 --> 0:30:48.880
and you just go through all your code. The red one is not covered by our test cases.

197
0:30:49.520 --> 0:30:57.200
The green one covered by our test cases. For example, in this case, our main function

198
0:30:57.200 --> 0:31:05.280
is not covered at all because it's tricky to test the main function. That's why you should

199
0:31:05.280 --> 0:31:12.800
like put it outside of everything and make it like two, three lines and only use your packages

200
0:31:14.240 --> 0:31:29.760
inside. Okay. So time for continuous integration and continuous deliver.

201
0:31:29.760 --> 0:31:37.680
Yeah. So we are working as a company, we are working in GitHub. But I'm pretty sure that

202
0:31:37.680 --> 0:31:44.640
the same functionality is available on GitHub and Big Bucket and everywhere.

203
0:31:45.280 --> 0:31:54.400
Right? So for every my project, I want to have at least five actions, GitHub actions.

204
0:31:54.400 --> 0:32:05.600
The first one is dependable. I want my repository is constantly being checked if any package I'm

205
0:32:05.600 --> 0:32:13.840
dependent on is updated. Right? So it will update, okay, we have a new minor or whatever version of

206
0:32:13.840 --> 0:32:19.440
this package. It will automatically create the pull request. I will check the output. I will check

207
0:32:19.440 --> 0:32:27.440
if tests are fine, if everything is okay. Okay. Very good. I like this, you know, because

208
0:32:27.440 --> 0:32:30.720
you can do three pull requests per day and you are super productive.

209
0:32:32.960 --> 0:32:40.960
Then what I want to also always have is a code QL which will build your

210
0:32:40.960 --> 0:32:51.600
own sources and will investigate the possible security vulnerabilities.

211
0:32:53.200 --> 0:33:02.240
Build and test. I'm using that for pull requests only because if you are firing them on every push

212
0:33:02.240 --> 0:33:15.120
and the test is heavy, it's not fine. The release will produce the binaries and packages

213
0:33:15.760 --> 0:33:23.280
when the new release is created. And the docker is the same, like, for release it will produce

214
0:33:23.280 --> 0:33:33.680
a special tag and push it. But for every commit it will produce a special docker image which you can

215
0:33:35.200 --> 0:33:44.480
try immediately, right? Like a night build. Yeah, so dependable is very simple. For example, for

216
0:33:44.480 --> 0:33:53.280
almost all my repositories, I first want to check the go code itself, so package ecosystem go mode,

217
0:33:54.400 --> 0:34:02.720
and I want to use the latest GitHub actions as well. That's important. So I like check them

218
0:34:02.720 --> 0:34:12.480
check daily and that's usually enough. For code QL, nothing special when you create these actions

219
0:34:12.480 --> 0:34:21.760
from the GitHub interface, it will fill all the fields for you. I never changed the important

220
0:34:21.760 --> 0:34:28.960
thing there, only removed some comments and we're fine. Build and test. I hope you can see what is

221
0:34:28.960 --> 0:34:40.080
going on there. No? Sorry, I didn't want to switch to the editor because I cannot work like that.

222
0:34:40.080 --> 0:34:49.440
Yeah, so I will tell you, so I usually run all my tests on three different platforms, Windows,

223
0:34:49.440 --> 0:35:01.040
MacOS, and Linux. The good thing is all the workers already have PostgreSQL installed on them,

224
0:35:01.600 --> 0:35:09.280
but the thing is that it's not started. So for you, essential is to start PostgreSQL and then run

225
0:35:09.280 --> 0:35:17.760
your tests, and you are fine. Usually, the version of PostgreSQL is behind two or three minor versions,

226
0:35:18.480 --> 0:35:26.480
but it's okay. If you want just like the latest one, you can go with the Docker images instead of

227
0:35:26.480 --> 0:35:40.880
that one. So there in the build action, we have Linter. So no, without Linter, we cannot accept

228
0:35:40.880 --> 0:35:52.160
any changes or pull requests. And then we are using we are generating the coverage report to

229
0:35:52.160 --> 0:36:04.800
put them everywhere. See, 99% of code is covered. Let's lie. Okay, so release is a little bit simpler.

230
0:36:05.440 --> 0:36:13.360
As I said, we are using Go release. It's absolutely fabulous piece of software. It may produce

231
0:36:13.360 --> 0:36:22.400
everything for everything. So the GitHub action code is simple because everything is stored in the

232
0:36:22.400 --> 0:36:29.680
YAML configuration file where you set up the name, the architecture, the O-system, everything.

233
0:36:30.400 --> 0:36:40.640
And then you're just like, okay, let's check out our code and let's release it. And the

234
0:36:40.640 --> 0:36:50.080
cool thing about this, this is the Go release. The Go release will create a change log automatically

235
0:36:50.080 --> 0:36:58.560
for you based on your pull requests. So when I'm releasing, it's just like I copy paste it,

236
0:36:58.560 --> 0:37:09.280
just sort it by the like what added, what fixed, and whatever. And I'm done. The release is very

237
0:37:09.280 --> 0:37:17.440
simple for me. Absolutely. Before that, I spent two days on each release to produce all these

238
0:37:17.440 --> 0:37:25.200
binaries, et cetera, et cetera. Okay, Docker. Go release can produce Docker images.

239
0:37:27.440 --> 0:37:37.440
I'm too lazy to rewrite this. And yeah, I'm using like another special GitHub actions to build a

240
0:37:37.440 --> 0:37:45.920
Docker. You can build them for every possible platform. And this Apple M1, M2, silicon thing

241
0:37:45.920 --> 0:38:03.600
is whatever. It's just working. Okay. Takeaways. Oh. The Go is popular.

242
0:38:03.600 --> 0:38:07.680
Devrim doesn't like Go. Yes.

243
0:38:11.520 --> 0:38:18.080
Maybe this is the last time you see this talk, like when everything goes right. He said that

244
0:38:18.640 --> 0:38:32.960
I need to switch to Rust. So maybe next, I will go out when Rust goes right. So no, no. Should I

245
0:38:32.960 --> 0:38:43.840
stick to the Go? Okay. We can do both. Yeah. So a lot of developers are using databases with Go,

246
0:38:43.840 --> 0:38:50.800
of course. You can use whatever it did or whatever operating system you are. By the way,

247
0:38:50.800 --> 0:38:57.520
a lot of people are using Windows, which is not common for like Postgres community, for example.

248
0:38:57.520 --> 0:39:08.720
But it's fine if your system can produce whatever you want. You don't care. You just work on what

249
0:39:08.720 --> 0:39:18.160
you have. Right? So Kubernetes, you can use whatever you want with the Postgres. If you want

250
0:39:18.160 --> 0:39:27.520
to use Orm, please do. But remember, you're responsible for that. Use it wisely. Otherwise, you can use

251
0:39:28.800 --> 0:39:40.160
libpq package or new pjx. And you can use whatever GitHub, GitLab, Bitbucket you want.

252
0:39:40.160 --> 0:39:53.200
And the most amazing thing about Go is the backward compatibility. You can build whatever in the

253
0:39:53.200 --> 0:40:03.440
future. Whatever code you want. And it still will be compatible with the oldest something

254
0:40:03.440 --> 0:40:13.040
written ages before. Even now, when we have generics, when we have a cool thing is in Go,

255
0:40:13.040 --> 0:40:24.160
they are still compatible with that old things. Okay. So, yeah. Don't be stranger. Check my

256
0:40:24.160 --> 0:40:37.920
GitHub account. Check our blog. Yeah. Some of our projects. And if you have questions,

257
0:40:37.920 --> 0:40:49.520
or maybe you have a question to Devrim, why he hates Go. Okay. I'm not sure what the problem is.

258
0:40:49.520 --> 0:40:55.040
I provide everything you need. Take my binders and put them in your packaging whatever.

259
0:40:56.000 --> 0:41:01.680
And either it should be a binary or download the internet.

260
0:41:03.200 --> 0:41:06.960
Which is not. Not internet. No. Not internet.

261
0:41:08.560 --> 0:41:15.120
There are only four dependencies. Okay. For a new created application which uses pjx to connect to

262
0:41:15.120 --> 0:41:23.360
the PostgreSQL, there are only one direct dependencies. There are only four indirect dependencies.

263
0:41:24.000 --> 0:41:31.280
Two of them are libraries from Google. One of them library from CoreOS.

264
0:41:33.600 --> 0:41:41.280
I don't remember. And one of them is by the same author because he's using this package

265
0:41:41.280 --> 0:41:52.080
in other ways. Yeah. So, questions? Microphone.

266
0:41:59.360 --> 0:42:05.040
Hi. A couple of slides back. You went to a certain functionality where you were asking,

267
0:42:05.040 --> 0:42:11.600
you did select and then you put in a structure in order to get results from. Like, it's like,

268
0:42:11.600 --> 0:42:18.960
yeah. I have a question on that one. It's, yeah. This one. Yeah. That's one. Exactly. Yeah. Yeah.

269
0:42:18.960 --> 0:42:24.880
So, you're asking a select star. And then some stuff. And then you ask me by the rows. Does the

270
0:42:26.960 --> 0:42:30.480
actual connection. So, if you're running this on one machine, you're running PostgreSQL on another

271
0:42:30.480 --> 0:42:35.680
machine. There's a network, of course, in between. There's data going back and forth. Is all the data

272
0:42:35.680 --> 0:42:41.840
being sent from PostgreSQL server to your GoPro or not? The reason I'm asking is because let's say

273
0:42:41.840 --> 0:42:47.840
there's a fourth field which is a huge JSON field or a huge binary field which contains like a

274
0:42:47.840 --> 0:42:52.720
megabyte of data per record. Is it then sending, if you're asking a hundred records, a thousand

275
0:42:52.720 --> 0:42:57.520
records, is it sending a gigabyte over the network or is it only sending those three fields? Okay.

276
0:42:57.520 --> 0:43:05.600
I got you. Yeah. Thank you. Very good question. So, in this particular case, it shouldn't be star.

277
0:43:06.640 --> 0:43:12.640
First of all, we should always list a column we want to have. I'm just too lazy.

278
0:43:12.640 --> 0:43:26.480
And this is not my code. But it's like, you know, it shows. Yeah. So, in this case, yes. Everything.

279
0:43:26.480 --> 0:43:39.920
Can we do automatic, can we add columns from a database automatically?

280
0:43:43.120 --> 0:43:47.360
Yes, we can. But for that, we should use SQL C,

281
0:43:47.360 --> 0:43:59.360
SQL C package, which is exactly for that. So, you are, it is pre-built or hooks or whatever.

282
0:43:59.360 --> 0:44:09.120
So, when you say go build, you have a special like SQL files like I want this field from that

283
0:44:09.120 --> 0:44:17.680
and that and it will go through it and it will build automatically the appropriate structures for go.

284
0:44:17.680 --> 0:44:23.360
And then you can use it. Yeah. It's just a lot of information. I cannot like put it into the one target.

285
0:44:25.040 --> 0:44:31.520
Yeah. But yeah. About if we are loading at all at once, yes, we do in this case.

286
0:44:31.520 --> 0:44:42.000
But the Postgres protocol itself supports row by row functionality. And it's possible to use

287
0:44:42.640 --> 0:44:47.600
that functionality with this package. So, we can like, yeah, say that.

288
0:44:52.960 --> 0:44:59.040
Hello. Thank you for the talk. I have one question about this driver. Actually,

289
0:44:59.040 --> 0:45:05.680
it's kind of only way to work with Postgres, for my opinion. And I'm a little bit worried that this

290
0:45:05.680 --> 0:45:14.800
driver is not supported by Postgres community, let's say. It's supported by someone. And what is

291
0:45:14.800 --> 0:45:21.600
the life cycle of this software? And it may be it will die, you say, how is about new features to it?

292
0:45:21.600 --> 0:45:27.200
And all this question arises when you work with it. Because if your management says, okay,

293
0:45:27.200 --> 0:45:33.200
let's use Java, and in Java, it's kind of stable, this Postgres driver, and you know that you always

294
0:45:33.200 --> 0:45:38.720
have the new version. What is about this software? Yeah. Thank you for the question. So, versioning

295
0:45:38.720 --> 0:45:47.360
and all who is owner, and that kind of stuff. So, as a Postgres community, we support on the C library,

296
0:45:47.360 --> 0:46:01.200
which is libpq, and Java, which is JDBC, right? That's all. All others... Yeah. Who uses C++?

297
0:46:02.640 --> 0:46:12.720
Okay. So, all other libraries are maintained by someone. By the way, libpq is not a standard

298
0:46:12.720 --> 0:46:21.360
library in terms of made by Go. It's also maintained by one person. So, how we do in this case,

299
0:46:21.360 --> 0:46:30.720
we just fork it and use it if we want something new. If I did everything better than the maintainer,

300
0:46:30.720 --> 0:46:38.240
the owner of the Pgx will accept my Postgres proposals, and we are stink, right? If not,

301
0:46:38.240 --> 0:46:43.120
I will beat them, and I will be popular.

302
0:46:50.480 --> 0:46:55.680
I have a question regarding testing strategies in CI CD, so you have shown that it's possible to

303
0:46:55.680 --> 0:47:00.640
mock Postgres scale, right? But sometimes you are relying on some feature of Postgres scale,

304
0:47:00.640 --> 0:47:05.680
or possibly you are relying on some extension Postgres. You want to test with a real Postgres scale.

305
0:47:05.680 --> 0:47:11.840
Yes. What you can recommend. So, I have seen in use CI CD, you are executing some PSK commands.

306
0:47:11.840 --> 0:47:16.160
Do you have a dedicated instance for running tests, or are you using screen containers?

307
0:47:16.160 --> 0:47:25.120
No. So, my GitHub actions are using preinstalled PostgresQL on the GitHub workers. They already

308
0:47:25.120 --> 0:47:37.600
have Postgres, like, 15.1 probably nowadays. So, I'm okay if they are behind several versions.

309
0:47:38.320 --> 0:47:43.920
I don't need to test for a specific feature or a bug or whatever. But if I want to,

310
0:47:43.920 --> 0:47:55.200
in my GitHub action, I may specify the Docker image against which I want to test. For example,

311
0:47:55.200 --> 0:48:03.680
if I want to test the latest master from the Postgres community, I will build my own image

312
0:48:03.680 --> 0:48:16.320
docker and will run my test against it. And I'm fine. Okay. Thank you.

