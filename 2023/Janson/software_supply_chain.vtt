WEBVTT

00:00.000 --> 00:06.720
Hi, I'm Brian Bellendorf.

00:06.720 --> 00:11.860
I'm the general manager for the Open Source Security Foundation, which is a project hosted

00:11.860 --> 00:17.280
at the Linux Foundation, but has its own rather large membership and set of activities and

00:17.280 --> 00:18.280
the like.

00:18.280 --> 00:22.280
And I thought I'd take the time to talk to you this morning about some of the things

00:22.280 --> 00:27.480
that we learned coming out of the Log4Shell incident, and in general what we're doing

00:27.480 --> 00:32.320
at the OpenSSF to try to improve the state of security across all of open source software.

00:32.320 --> 00:35.920
And I do apologize for using the term software supply chain.

00:35.920 --> 00:40.680
I know folks are sometimes very sensitive to thinking of themselves as suppliers.

00:40.680 --> 00:41.680
You're all developers.

00:41.680 --> 00:42.800
You're all building components.

00:42.800 --> 00:46.160
You're all handing things off to the next person, right?

00:46.160 --> 00:52.080
And I just want to be sensitive to that and recognize a lot of us pursue this not just

00:52.080 --> 00:57.320
to write code for our companies or for other people to use, but because we love it, because

00:57.320 --> 00:58.720
it's like a form of literature.

00:58.720 --> 01:03.520
And so I come to this very much from an expansive view of what software is.

01:03.520 --> 01:08.160
But if you'll indulge me with the term software supply chain, you know, lots has been made

01:08.160 --> 01:14.080
about the fact that today, 2023, open source software is incredibly pervasive, because

01:14.080 --> 01:20.360
the further upstream you go in most software supply chains, even if the end result is proprietary

01:20.360 --> 01:24.440
software, the further upstream, the much more likely it is that your dependencies, your

01:24.440 --> 01:29.960
components are open source code, something like 78%, according to a study by Synopsys

01:29.960 --> 01:34.440
last year, 78% of code in a typical product code base.

01:34.440 --> 01:36.460
That could be a container image.

01:36.460 --> 01:38.040
That could be software in a phone.

01:38.040 --> 01:39.440
That could be or a car.

01:39.440 --> 01:43.960
78% on average is preexisting open source code.

01:43.960 --> 01:49.520
That last 22% is the part that, you know, the company put its name on and whatever.

01:49.520 --> 01:55.080
But every and 97% of code bases somewhere contain open source software.

01:55.080 --> 02:00.140
And 85% of code bases contain open source that is more than four years out of date.

02:00.140 --> 02:04.000
The comparable for this and log for shell, by the way, were the number of companies who

02:04.000 --> 02:07.760
claimed we're not vulnerable to the log for J problem, because we're still on version

02:07.760 --> 02:09.720
1.x rather than 2.x.

02:09.720 --> 02:14.160
Don't worry, which had been out of support, out of any updates for five years.

02:14.160 --> 02:20.360
So this is kind of a disaster, but fixing this requires thinking about systematically

02:20.360 --> 02:22.840
what does the software supply chain look like.

02:22.840 --> 02:27.640
And this is highly simplified, and in a way, this is only what happens at one node of a

02:27.640 --> 02:28.860
chain, right?

02:28.860 --> 02:35.560
But within a given software lifecycle, you've got the developer writing, you know, code

02:35.560 --> 02:41.040
from their head or in partnership with Copilot now, I guess, into an IDE that then goes into

02:41.040 --> 02:46.160
a build system and pulls in dependencies and then creates packages and pushes them out

02:46.160 --> 02:49.140
to a consumer of sorts, right?

02:49.140 --> 02:55.000
Who could be another developer who then repeats that process and just uses that input as dependencies.

02:55.000 --> 02:59.020
And there's at least eight, and there's probably a lot more, but at least eight kind of major

02:59.020 --> 03:05.840
opportunities to take advantage of some default biases and assumptions and, frankly, just

03:05.840 --> 03:10.960
things we forgot to close up in the course of this development process.

03:10.960 --> 03:16.040
Everything from bypassing code review to compromising the source control system to modifying code

03:16.040 --> 03:20.500
after it's come through source code and into build to compromising the build platform to

03:20.500 --> 03:27.320
using a bad dependency to bypassing CI CD entirely, which we all know happens, to compromising

03:27.320 --> 03:31.080
the package repo to using a bad package as a consumer.

03:31.080 --> 03:36.920
So all each of those has had examples of compromise in the last few years that has caused major

03:36.920 --> 03:40.360
breaches in and data loss out there.

03:40.360 --> 03:45.000
And of course, we all, I don't know if any of you were on the front lines of fighting

03:45.000 --> 03:53.400
this fire over the winter holiday of 2021 into 2022, but it ruined a lot of people's

03:53.400 --> 03:56.680
holidays when log4shell hit.

03:56.680 --> 04:01.120
And by the way, I want to refer to the vulnerability and the breach and the remediation as the

04:01.120 --> 04:05.800
log4shell problem, not the log4j problem, because the log4j developers don't deserve

04:05.800 --> 04:10.360
to have their brand of their project turned into exhibit A in what's broken about open

04:10.360 --> 04:11.360
source.

04:11.360 --> 04:12.840
They were actually, it's great software.

04:12.840 --> 04:14.200
They're all professional developers.

04:14.200 --> 04:15.440
Let's give them some credit.

04:15.440 --> 04:18.880
There's a bunch of contributing factors we'll walk through, but it was really the log4shell

04:18.880 --> 04:19.880
breach.

04:19.880 --> 04:25.680
And what happened in the course of about six weeks is you went from a researcher for Alibaba

04:25.680 --> 04:31.880
in China finding a vulnerability out of the ordinary course of due diligence work that

04:31.880 --> 04:38.640
he was doing, reporting it appropriately through the Apache software foundation processes,

04:38.640 --> 04:45.760
and that leading to the very first CVE, starting from November 24th all the way to January

04:45.760 --> 04:50.880
4th and January 10th, so about six weeks, where you have governments like the UK government

04:50.880 --> 04:58.000
warning people of this major systematic issue, right?

04:58.000 --> 05:02.880
And three more CVEs being discovered of various degrees of intensity, each of them leading

05:02.880 --> 05:09.280
to a subsequent patch, to a subsequent remediation by exhausted IT teams to, I mean, if you talk

05:09.280 --> 05:12.840
to any of the log4j developers, I don't believe any of them are here, but they would talk

05:12.840 --> 05:18.500
about things like getting these demand letters from corporate legal departments asking them

05:18.500 --> 05:25.000
to fax back a signed attestation that they had fixed the holes in log4j and that company's

05:25.000 --> 05:26.000
use.

05:26.000 --> 05:29.480
That was a real relationship, that company was a free rider on top of their code.

05:29.480 --> 05:32.720
So I'm not going to read through each of these steps, I apologize for this, but there was

05:32.720 --> 05:38.640
this incredibly compressed timeline where people were intensely stressed, where really

05:38.640 --> 05:43.320
the goodwill that we show as open source developers by putting our code out there and the fair

05:43.320 --> 05:48.200
warning that we give people to use it at your own risk was substantially attacked, right?

05:48.200 --> 05:53.300
It was substantially, all these misconceptions that companies have about underlying open

05:53.300 --> 05:58.320
source code and the degree to which they take advantage of it kind of came to bear.

05:58.320 --> 06:02.440
And so it raised a bunch of questions amongst folks who perhaps hadn't thought about this

06:02.440 --> 06:03.440
before.

06:03.440 --> 06:07.480
Is open source software's generally good reputation for security?

06:07.480 --> 06:09.280
Is it well deserved?

06:09.280 --> 06:13.160
Does this demonstrate deep and pervasive issues, technical issues, across how we consume and

06:13.160 --> 06:14.740
develop open source code?

06:14.740 --> 06:18.780
Do these issues extend to the sustainability model for open source itself?

06:18.780 --> 06:22.240
Can we really depend upon so many, quote, volunteers, right?

06:22.240 --> 06:26.840
I mean, think about it, we don't depend upon volunteers to build bridges and highways to

06:26.840 --> 06:29.640
maintain our electrical grid, right?

06:29.640 --> 06:35.240
How do we depend upon volunteers to maintain our critical infrastructure that everything

06:35.240 --> 06:36.240
runs on, right?

06:36.240 --> 06:40.600
And of course, it wasn't just like us as technologists asking these questions of each other, it was

06:40.600 --> 06:42.760
like compliance and risk officers.

06:42.760 --> 06:46.000
It was the cybersecurity insurance industry.

06:46.000 --> 06:51.000
It was the European Union and the White House and UK's NCSC and other government agencies

06:51.000 --> 06:54.760
kind of all challenging us, do we know what we're doing?

06:54.760 --> 06:59.720
And one interesting report, and it is worth your time to read, it's about 49 pages, came

06:59.720 --> 07:02.640
out about six months after the fact.

07:02.640 --> 07:07.840
What happened was the US government convened a group of experts from across industry and

07:07.840 --> 07:12.720
had them go and talk to the Log4j developers, talk to other open source experts, talk to

07:12.720 --> 07:17.480
lots and lots of open source foundations, and try to ask what went on, what contributed

07:17.480 --> 07:18.560
to this?

07:18.560 --> 07:24.120
And it was modeled after, you know, when a plane crashes and the government will convene

07:24.120 --> 07:29.200
for many of them, like a study group, to answer, well, why did this plane crash, other than,

07:29.200 --> 07:32.240
of course, sudden loss of altitude.

07:32.240 --> 07:34.840
You know, what were the underlying root causes to this plane crash?

07:34.840 --> 07:37.320
And so this was modeled after the very same thing.

07:37.320 --> 07:41.720
And it's a great report to read, I think, because it also comes up with some recommendations

07:41.720 --> 07:44.840
for how potentially to prevent the next one.

07:44.840 --> 07:50.960
And I'll walk through a couple of the conclusions, they said, you know, a focused review of the

07:50.960 --> 07:56.720
Log4j code could have identified the unintended functionality that led to the problem.

07:56.720 --> 08:00.400
Understand the bug, the original big bug was in a portion of code that had been contributed

08:00.400 --> 08:07.680
to Log4j years and years earlier by a company that wanted to support LDAP lookups in real

08:07.680 --> 08:11.600
time during the logging process, which seems like an extraordinarily bad idea to me, but,

08:11.600 --> 08:14.000
okay, I'm not an enterprise IT.

08:14.000 --> 08:17.000
So they had added this functionality and then kind of left.

08:17.000 --> 08:19.320
They kind of didn't stick around to maintain it.

08:19.320 --> 08:23.520
They didn't really do a due diligence into the security of its own code.

08:23.520 --> 08:28.080
And the other Log4j developers just kind of kept it around because they didn't get many

08:28.080 --> 08:29.240
bug reports on it.

08:29.240 --> 08:31.000
It wasn't really a problem.

08:31.000 --> 08:35.840
So it was kind of this forgotten portion of the code.

08:35.840 --> 08:40.680
So part of it was if they had had security resources to look at every line of code that

08:40.680 --> 08:44.120
they were shipping out, rather than just the core stuff, which they were pretty diligent

08:44.120 --> 08:48.600
about, they might have discovered this bug.

08:48.600 --> 08:53.520
It might also have been discovered if the developers themselves had developed, had adopted

08:53.520 --> 08:58.760
certain secure coding practices consistent with how certain other organizations kind

08:58.760 --> 09:00.880
of define how those processes should work.

09:00.880 --> 09:05.120
If they'd had design reviews that focused on security and reducing kind of the surface

09:05.120 --> 09:09.740
area, the attack surface, sorry, for problems.

09:09.740 --> 09:13.880
If they'd used threat models to understand, hey, we really should try to make sure we're

09:13.880 --> 09:19.840
better protected against people using through the user generated input.

09:19.840 --> 09:23.460
When you're a logging engine, you're dealing with a ton of user generated input.

09:23.460 --> 09:27.120
If you're parsing that for things like format strings, which is what they were doing in

09:27.120 --> 09:29.960
this, that's potentially very dangerous.

09:29.960 --> 09:33.640
That's something we've known kind of since some of the earliest CVEs out there.

09:33.640 --> 09:36.960
And then finally, if they had had proper security audits.

09:36.960 --> 09:41.240
And so in answering that and trying to generalize from it, and it's always dangerous to generalize

09:41.240 --> 09:45.600
from a single example, but they found that the only way to reduce the likelihood of risk

09:45.600 --> 09:49.800
to the entire ecosystem caused by these kind of vulnerabilities and other widely used open

09:49.800 --> 09:55.440
source code was to ensure that as much code as possible is developed pursuant to standardized

09:55.440 --> 09:57.080
secure coding practices.

09:57.080 --> 10:02.640
Now that kind of sounds like, well, if only the pilots had had better training or if only

10:02.640 --> 10:07.000
the planes had been maintained better, then we wouldn't have had these problems.

10:07.000 --> 10:10.840
It seems a little bit like hindsight is 20-20.

10:10.840 --> 10:16.200
But they did acknowledge that the volunteer based model of open source would need many

10:16.200 --> 10:20.520
more resources than they have to be able to make this possible on average.

10:20.520 --> 10:25.920
I mean, you've all heard the aphorism, which is called Linus's law, but it was coined by

10:25.920 --> 10:27.240
Eric Raymond.

10:27.240 --> 10:32.520
Linus has disavowed the law, actually, that says with enough eyeballs, all bugs are shallow.

10:32.520 --> 10:36.880
But what was missing from that quote was eyeballs per line of code.

10:36.880 --> 10:41.680
And I would argue that even in some of the most open source projects, we don't have enough

10:41.680 --> 10:43.560
eyeballs per line of code.

10:43.560 --> 10:49.960
And anything we do that divides that list, such as forks, for example, only takes us

10:49.960 --> 10:53.880
further away from having enough eyeballs to review code.

10:53.880 --> 10:58.480
There's lots that I can go into about it's not really just a supply chain security story.

10:58.480 --> 11:02.920
It was kind of a supply chain story because of just how pervasive Log4J was.

11:02.920 --> 11:08.280
It was a bug that affected everything from the iTunes store to people badging in with

11:08.280 --> 11:13.720
security kind of like badges to all sorts of like embedded systems and the like.

11:13.720 --> 11:15.400
Log4J was kind of everywhere.

11:15.400 --> 11:19.400
And because it was everywhere, it was in a whole lot of places that people didn't have

11:19.400 --> 11:21.520
the tools to even go and discover.

11:21.520 --> 11:26.980
Often it was compiled into JAR files, so you couldn't even just, you know, do a directory

11:26.980 --> 11:29.960
listing and grep through it to find Log4J.jar.

11:29.960 --> 11:32.440
You actually had to interrogate the development process.

11:32.440 --> 11:37.680
And without things like S-bombs, which appropriately the U.S. government has focused on kind of,

11:37.680 --> 11:41.940
you know, saying this is an important thing to have, without a tool like that, a lot of

11:41.940 --> 11:45.760
enterprises were left scrambling to figure out if they were vulnerable, which versions

11:45.760 --> 11:46.760
they were running.

11:46.760 --> 11:50.640
And then, as I mentioned, making ludicrous claims like we're not vulnerable because we're

11:50.640 --> 11:55.440
way on an old version of Log4J, or asking completely disinterested third parties like

11:55.440 --> 11:59.600
the Log4J developers themselves to attest that they're not vulnerable, right?

11:59.600 --> 12:02.720
It was kind of crazy.

12:02.720 --> 12:08.200
Moving on, part of this as well is trying to understand the motivations of developers

12:08.200 --> 12:13.760
on an open source project, which, again, they took a look at, but I think they could have

12:13.760 --> 12:15.900
pursued this even a little bit further.

12:15.900 --> 12:19.760
When you work on an open source project, your primary motivation, well, okay, first off,

12:19.760 --> 12:22.440
you probably all start as a user of the software.

12:22.440 --> 12:26.040
Basically your first step into an open source project was not to write it from scratch.

12:26.040 --> 12:29.680
Maybe it is, but in either case, you have some utility, something you want to use it

12:29.680 --> 12:30.680
for.

12:30.680 --> 12:33.480
So your first interest is get it running, and get it running correctly.

12:33.480 --> 12:35.480
And so you're going to, like, be fixing bugs.

12:35.480 --> 12:38.040
You're going to be adding features here and there, right?

12:38.040 --> 12:44.220
But adding things that help make the software more secure, very rarely do they turn into

12:44.220 --> 12:45.920
immediate benefit for you.

12:45.920 --> 12:50.260
It's often a thing that's hard to convince your manager is worth doing, right, because

12:50.260 --> 12:54.680
it doesn't necessarily affect what the manager sees in terms of, like, the feature set and

12:54.680 --> 12:57.780
the code, or hey, it's now fit for purpose or whatever.

12:57.780 --> 13:02.840
So there's a lot of sympathy that we can have for positions taken by, like, folks like Ben,

13:02.840 --> 13:09.120
who wrote the cyber resilience act, who was up here yesterday kind of defending what was

13:09.120 --> 13:13.320
written in the act, to say, well, maybe there are other forces that need to come into play

13:13.320 --> 13:19.120
to help support those kinds of outcomes, right, to act as a forcing function for it if it

13:19.120 --> 13:21.680
wouldn't otherwise be there.

13:21.680 --> 13:26.000
But it's really hard to measure the return on that benefit independently.

13:26.000 --> 13:31.080
And if you can't measure the ROI, it tends to get disincentive.

13:31.080 --> 13:35.840
So as a way to illustrate this, particularly to Log4J, you know, I've had conversations

13:35.840 --> 13:39.760
with the mirror Montezari, who some of you might know, who's with Ostiff, who's here.

13:39.760 --> 13:45.520
We've kind of asked, hey, what would it have taken to do a proper third party code review

13:45.520 --> 13:48.760
for security of the Log4J code base, right?

13:48.760 --> 13:51.520
Just as an independent thing, looking at the number of lines of code in there.

13:51.520 --> 13:55.720
And the estimate we came back was $50,000 to $100,000, depending on how deep you wanted

13:55.720 --> 13:56.720
to get.

13:56.720 --> 14:02.040
Let's say, and one of those would have found all four of those CVEs, possibly more, and

14:02.040 --> 14:06.040
with a little bit more money, generously, let's say, another $50,000 to $100,000, you

14:06.040 --> 14:10.640
could have funded the fixes for those bugs and coordinated a disclosure process such

14:10.640 --> 14:15.080
that everybody got, or a lot of people would get updated, and then you publish the release.

14:15.080 --> 14:18.920
And it wouldn't have been this mad scramble taking place over, between Christmas and New

14:18.920 --> 14:20.160
Year's for a lot of folks.

14:20.160 --> 14:25.960
So $200,000, which is beyond what I think any of the Log4J developers had in their back

14:25.960 --> 14:26.960
pocket.

14:26.960 --> 14:31.080
It's beyond what I think even, you know, the eight or ten of them together would have individually

14:31.080 --> 14:35.800
been able to put together, or convince their employers to put in as a, as a, as a chunk

14:35.800 --> 14:37.720
of cash.

14:37.720 --> 14:44.080
But it was far less than the negative impact that that breach had on society, right?

14:44.080 --> 14:47.600
I mean, it's hard, no one's actually sat and tried to calculate how much, and when they've

14:47.600 --> 14:52.800
started they've come back with billions of dollars in lost productivity, in breaches,

14:52.800 --> 14:53.800
in other things.

14:53.800 --> 14:59.600
So, so like trying to play that back and do hindsight, you know, 20-20, that kind of thing,

14:59.600 --> 15:01.760
could we have discovered this and fixed it?

15:01.760 --> 15:07.680
You know, could we find the next one and spend $200,000 and fix that from being, from being

15:07.680 --> 15:08.680
likely to happen?

15:08.680 --> 15:13.160
I don't think I could give you the one that that's likely to be, but what if I could give

15:13.160 --> 15:19.400
you a list of 200 projects, each of which probably had a greater than 1% chance, based

15:19.400 --> 15:25.640
on their criticality, as you can measure from how often these codes, code bases are dependent

15:25.640 --> 15:27.960
upon by other, other, other packages.

15:27.960 --> 15:32.360
There's lots of data sources for that, and we at the OpenSSF have developed something

15:32.360 --> 15:35.160
called the criticality index that'll find that.

15:35.160 --> 15:40.480
What if we could find this list of 200 projects based on criticality, based on how well they

15:40.480 --> 15:46.040
score by some objective measure of risk, and I'll get into this in a little bit.

15:46.040 --> 15:50.640
Could I give you that list of 200 and could that likely, I mean more than 50% chance,

15:50.640 --> 15:51.920
prevent the next log for J?

15:51.920 --> 15:53.280
I would wager yes.

15:53.280 --> 15:57.120
And that $40 million, again, is more than any open source foundation has to be able

15:57.120 --> 15:58.840
to spend on this kind of work.

15:58.840 --> 16:02.440
Even all the foundations together collectively probably couldn't spend that, and this is

16:02.440 --> 16:07.240
the kind of thing you probably have to do each year in order to have that kind of impact.

16:07.240 --> 16:12.920
But $40 million is, I don't mean to sound blasé about it, but frankly pocket change

16:12.920 --> 16:17.280
for a lot of governments, especially if we got governments to work together on this,

16:17.280 --> 16:22.440
or the insurance industry to work together, or say many of the sectors who use this software

16:22.440 --> 16:24.880
without lifting a finger to contribute back.

16:24.880 --> 16:28.680
If we pooled these kinds of funds, we could have an impact like that.

16:28.680 --> 16:29.960
Some people just want to watch the world burn.

16:29.960 --> 16:33.060
I had to throw in this obligatory slide, of course.

16:33.060 --> 16:38.760
But I want to kind of push forward this theory of change then around, you know, because it's

16:38.760 --> 16:42.560
not just about spending money on specific interventions like that.

16:42.560 --> 16:48.940
I'll come back to that in a little bit, how we might rally those kinds of funds and focus

16:48.940 --> 16:49.940
on that kind of work.

16:49.940 --> 16:51.880
And what we're doing is the open SSF to have it.

16:51.880 --> 16:57.300
But I want to also put forward, it's actually not just about a matter of spending money.

16:57.300 --> 17:05.040
It's not just a matter of, you know, a mandate from a government to get an open source software

17:05.040 --> 17:09.000
to be more secure, to get our processes and the supply chain to be more secure.

17:09.000 --> 17:12.680
There's a culture change that has to happen as well.

17:12.680 --> 17:14.640
People are often very resistant to change.

17:14.640 --> 17:19.020
When your CI system is running and you're able to put out, you know, a new release and

17:19.020 --> 17:24.560
turn the crank, and a few hours after issuing the, initiating, you know, accepting a pull

17:24.560 --> 17:26.160
request, you've got a binary.

17:26.160 --> 17:28.000
Like, you kind of don't want to mess it up.

17:28.000 --> 17:29.120
You don't want to change it.

17:29.120 --> 17:33.360
And especially the older we get, the more resistant we are to having to learn a new

17:33.360 --> 17:36.680
system or change, especially if there seems to be no benefit.

17:36.680 --> 17:42.360
But this is not unlike other times over the last 30 years that we've taken an insecure

17:42.360 --> 17:45.040
paradigm and made it more secure.

17:45.040 --> 17:50.000
And my general theory is something called carrots, defaults, and sticks.

17:50.000 --> 17:54.680
And the best example I can come up with this is how we went from a completely unencrypted

17:54.680 --> 18:01.080
web where browsers and servers talked clear text HTTP that could be sniffed by anybody

18:01.080 --> 18:05.160
between browser and server and got to the point where today, I mean, somebody might

18:05.160 --> 18:08.860
know the number, it was like 95% of web traffic is HTTPS.

18:08.860 --> 18:12.720
It's actually probably 99% now based on what's happening recently with browsers.

18:12.720 --> 18:16.960
But it didn't start with the browser maker saying, right, on April 1st, we're going to

18:16.960 --> 18:21.880
cut off or send these warning signs about unencrypted access at the beginning of the

18:21.880 --> 18:23.080
TLS era.

18:23.080 --> 18:24.560
It started with incentives.

18:24.560 --> 18:25.820
It started with carrots.

18:25.820 --> 18:29.840
It started by having that little green key that would show up in the location bar on

18:29.840 --> 18:31.080
a browser.

18:31.080 --> 18:34.600
It might start by certain folks saying, well, this is something that should be used for

18:34.600 --> 18:40.800
banking websites or for e-commerce websites or, you know, hosted email sites or that kind

18:40.800 --> 18:41.840
of thing.

18:41.840 --> 18:46.320
And that got about 15% of the web traffic getting encrypted out there.

18:46.320 --> 18:47.960
But it started the flat line.

18:47.960 --> 18:52.680
And then a bunch of people got together and realized, you know, we don't actually, it

18:52.680 --> 18:56.880
doesn't have to be this hard to get a TLS certificate and install it in the right place.

18:56.880 --> 18:58.000
We can automate this.

18:58.000 --> 19:04.420
We can automate demonstrating that you have domain control over this domain name.

19:04.420 --> 19:08.600
And if you do, then to give you a short-lived TLS certificate that can automatically be

19:08.600 --> 19:10.640
installed in the right place in the web server.

19:10.640 --> 19:13.320
And that service was called Let's Encrypt.

19:13.320 --> 19:19.160
And it is now, I mean, for the last 10 years, it's been at the point where you can automatically,

19:19.160 --> 19:27.000
when you install Apache, when you install a web server and install a, you know, the

19:27.000 --> 19:30.920
TLS kind of version of that or a TLS profile, it will automatically set up a fetch tool

19:30.920 --> 19:33.080
that's encrypt for a domain name you give it.

19:33.080 --> 19:36.560
And it's like automated, automatable out of the box, right?

19:36.560 --> 19:44.080
And that is what got us from 15% of the web being encrypted to about 75%.

19:44.080 --> 19:48.520
And at that point, about five, six years ago is when the web browser maker said, right,

19:48.520 --> 19:50.600
it's time for us to bring up the tail.

19:50.600 --> 19:52.920
And that's where I talk about sticks.

19:52.920 --> 19:58.800
And to finally get the laggards, the legacy sites, the folks who probably don't care about

19:58.800 --> 20:02.320
it, even though who probably even haven't updated their web server in five years or

20:02.320 --> 20:07.480
ten or whatever, to finally get off the duff and use Let's Encrypt or some other technique.

20:07.480 --> 20:12.440
And they did that by making it progressively harder and harder for you to access a non-encrypted

20:12.440 --> 20:19.360
website through Firefox, through Chrome, through, you know, MSIE, through other browsers.

20:19.360 --> 20:22.000
And they kind of talked amongst themselves how to do that.

20:22.000 --> 20:26.040
They tried not to piss people off, but you kind of have to piss some people off to do

20:26.040 --> 20:27.040
that.

20:27.040 --> 20:31.320
And as long as you just kind of progressively roll through, you can kind of bring people

20:31.320 --> 20:32.320
along.

20:32.320 --> 20:34.520
And there's some who will just, you know, forever be pissed off.

20:34.520 --> 20:39.000
But that's like the tail end of an adoption curve, right, is this kind of concepts of

20:39.000 --> 20:40.000
sticks.

20:40.000 --> 20:44.440
And we think about the same thing when it comes to things like S-bombs or signing artifacts

20:44.440 --> 20:51.320
in the supply chain or software at a station levels, which I'll get into a bit.

20:51.320 --> 20:54.440
But when we think about how to get adoption of some of these security paradigms, it's

20:54.440 --> 20:58.520
got to be through this three-step kind of process.

20:58.520 --> 21:03.320
We can't just jump directly to sticks, which is kind of what the European Union Cyber Resiliency

21:03.320 --> 21:04.800
Act attempts to do.

21:04.800 --> 21:10.120
And I will say I think the CRA is a backlash to the Silicon Valley move fast and break

21:10.120 --> 21:15.040
things kind of paradigm, this concept that open source software is some sort of reflection

21:15.040 --> 21:17.820
of that or connected to that and that we're just as reckless.

21:17.820 --> 21:20.280
But none of you all are Mark Zuckerberg, thankfully.

21:20.280 --> 21:24.160
None of you all, I think, take that degree of recklessness as a badge of honor.

21:24.160 --> 21:29.240
I think we're all just completely strapped for the amount of time that we'd really like

21:29.240 --> 21:32.120
to spend on making the software as secure as possible.

21:32.120 --> 21:33.120
And we need help.

21:33.120 --> 21:34.720
We need defaults.

21:34.720 --> 21:39.240
And we need, by the way, what's always worked in open source software as a duocracy, which

21:39.240 --> 21:44.040
is people showing up and doing the work if that's what their primary interest is about,

21:44.040 --> 21:45.040
right?

21:45.040 --> 21:48.240
If somebody can sit on stage here and say, it's absolutely essential that this French

21:48.240 --> 21:53.920
nuclear power plant only run open source software that has been certified against a whole bunch

21:53.920 --> 21:59.400
of cybersecurity requirements, it's on them to do that work, not on the log4j developers

21:59.400 --> 22:01.280
or others.

22:01.280 --> 22:04.600
So this is where OpenSSF comes in.

22:04.600 --> 22:11.080
We were started in 2020 kind of as a result of a small kind of gathering that had been

22:11.080 --> 22:16.680
hosted on the West Coast, people working on software projects that had to do with enhancing

22:16.680 --> 22:21.540
the software development processes in the open source community to be a bit more secure.

22:21.540 --> 22:28.400
It was a mix of a bunch of different pieces of software, suggestions of protocols, building

22:28.400 --> 22:34.000
on some of the SBOM work that had been actually championed first by the licensing community,

22:34.000 --> 22:38.360
by the software licensing community, this is in particular a standard called SPDX for

22:38.360 --> 22:39.640
SBOMs.

22:39.640 --> 22:43.600
But they kind of realized that collectively what they were doing was building tools that

22:43.600 --> 22:47.960
would help try to measure risk in open source and what does that mean?

22:47.960 --> 22:52.520
It means measuring the likelihood that there will be a new undiscovered vulnerability in

22:52.520 --> 22:57.500
this component and the impact that that would have downstream, right?

22:57.500 --> 22:58.500
Measurement is essential.

22:58.500 --> 23:02.720
If we can't measure whether we're improving the overall risk in that chain and the collective

23:02.720 --> 23:06.320
risk in our use of that software, we're not going to know whether the interventions that

23:06.320 --> 23:08.480
we're trying are actually meaningful.

23:08.480 --> 23:10.000
So you've got to measure it.

23:10.000 --> 23:15.040
You've got to then think about this sequence of carrots and defaults and sticks to eventually

23:15.040 --> 23:18.040
get this stuff adopted if it's any good, right?

23:18.040 --> 23:22.800
And then finally as part of this culture change, are there things that we should be learning

23:22.800 --> 23:29.480
as open source developers, things that we should be thinking about as a professional

23:29.480 --> 23:34.800
type of operation, like as a diligence of care, as something that as engineers and that

23:34.800 --> 23:39.880
term used to have to go and take a certification exam to call yourself an engineer, right?

23:39.880 --> 23:45.120
And that instilled a sense of professionalism in that industry that led to bridges that

23:45.120 --> 23:48.120
didn't fall down when you hired an engineer to design it.

23:48.120 --> 23:52.760
We need a little bit of the same professionalism in software development across the board,

23:52.760 --> 23:54.360
not just open source.

23:54.360 --> 23:58.800
And here are a set of resources that might help us from a security point of view be better

23:58.800 --> 23:59.800
developers.

23:59.800 --> 24:02.160
So collectively we want to put these pieces together.

24:02.160 --> 24:07.520
And we've got all sorts of projects in working groups, projects organized by thematically

24:07.520 --> 24:13.600
related working groups, a working group on best practices and documenting those and advocating

24:13.600 --> 24:19.320
for those, a working group on identifying security threats, understanding, you know,

24:19.320 --> 24:23.760
relatively speaking, what are the areas to really worry about in the areas that, you

24:23.760 --> 24:26.600
know, might represent low threat.

24:26.600 --> 24:28.880
How do we think about supply chain integrity?

24:28.880 --> 24:35.520
Like that chart I showed, how do you get those pieces, those opportunities for bugs to be

24:35.520 --> 24:38.840
inserted to just be locked down and hardened?

24:38.840 --> 24:42.920
How do we think about, you know, the CVE system is not great, frankly.

24:42.920 --> 24:43.920
It's nowhere near perfect.

24:43.920 --> 24:47.840
It's not great for trying to automate and understand given this collection of software

24:47.840 --> 24:52.720
I use, where might the vulnerabilities, where are the known vulnerabilities and how easy

24:52.720 --> 24:53.840
is it to remediate them?

24:53.840 --> 24:57.440
Are there known vulnerabilities that just don't matter because I'm not using them?

24:57.440 --> 25:02.240
And so there's an entire working group focused on vulnerability disclosures and on the vulnerability

25:02.240 --> 25:06.160
system that has a bunch of new ideas for this, but also developed content to try to help

25:06.160 --> 25:12.800
developers simply be better at coordinating vulnerability disclosures and updates.

25:12.800 --> 25:17.280
We've got another working group focused on once you've identified those critical projects,

25:17.280 --> 25:20.320
well, securing and identifying critical projects.

25:20.320 --> 25:22.360
And that's where we've defined the criticality score.

25:22.360 --> 25:27.840
We've done some work with Harvard Business School to understand quantitatively how are

25:27.840 --> 25:33.600
things being used by enterprises and where might the next log for JB lurking, so to speak.

25:33.600 --> 25:38.440
And then one of the most important things we've got here is we've pulled together the

25:38.440 --> 25:44.480
architects and the people responsible for product at many of the major security repositories,

25:44.480 --> 25:49.800
NPM, PyPy, Maven Central, because if we're going to get anything improved throughout

25:49.800 --> 25:54.520
the chain, you need to involve the last couple hops of each of the nodes in that chain, which

25:54.520 --> 25:56.800
are the distribution points.

25:56.800 --> 26:00.680
And there are things you can do there to encourage more secure alternatives and eventually have

26:00.680 --> 26:05.000
the stick to say, well, no, we're not going to accept, you know, things like you might

26:05.000 --> 26:10.200
need to enforce two-factor auth for the more popular packages, right, which has been controversial,

26:10.200 --> 26:14.760
to say the least, but is one of those things where it's like somewhere in that adoption

26:14.760 --> 26:19.240
curve we need to start nudging people into a more secure direction.

26:19.240 --> 26:22.120
But all of these pieces work together.

26:22.120 --> 26:26.760
And if you are an open source software maintainer, what I'm going to walk through now is a set

26:26.760 --> 26:30.480
of specific things coming out of the OpenSSF that I'd love you to adopt.

26:30.480 --> 26:34.400
I'm not going to be able to talk about all the features of each, just given time.

26:34.400 --> 26:40.400
But we've come up the very best starting point you can start to consume.

26:40.400 --> 26:45.060
The very first piece of thing that you can get from the OpenSSF are two concise guides,

26:45.060 --> 26:48.480
one that we've developed for evaluating open source code.

26:48.480 --> 26:52.760
When you're out there looking at packages and you're trying to figure out is this community

26:52.760 --> 26:59.120
likely to have processes and is there likely to be an undiscovered vulnerability lurking

26:59.120 --> 27:01.080
in this code that I'm about to use, right?

27:01.080 --> 27:06.160
Is this a well-engineered, well-maintained active community that has adopted the right

27:06.160 --> 27:12.600
practices and the like, or is this a one-off that was developed by one person in a hurry,

27:12.600 --> 27:14.320
thrown up on a repo and not well-maintained?

27:14.320 --> 27:19.400
I mean, we've got some ad hoc cues that we can use that most of us have, but how many

27:19.400 --> 27:25.040
of you use GitHub stars as your basis for deciding whether something is probably secure

27:25.040 --> 27:26.040
enough or not?

27:26.040 --> 27:28.000
I'm going to guess probably too many of you.

27:28.000 --> 27:33.200
So there's a bunch of subjective criteria that you can use.

27:33.200 --> 27:39.000
The flip side of that is if you are a maintainer and you are pushing code out, here are the

27:39.000 --> 27:44.960
signals you can send to your consumers of that software that show that you're taking

27:44.960 --> 27:47.080
this stuff seriously, right?

27:47.080 --> 27:52.640
And it's a bunch of best practices, adopting multi-factor auth, taking the courses on secure

27:52.640 --> 27:58.440
software development, using a specific combination of tools in the CI pipeline, thinking about

27:58.440 --> 28:03.160
how do you get to the point of doing rapid updates without throwing curve balls to your

28:03.160 --> 28:05.880
users because you change APIs all the time?

28:05.880 --> 28:09.720
What's the number one reason people don't update is that they assume, even in minor

28:09.720 --> 28:14.800
point releases, something is going to break because somebody took an API and marked it

28:14.800 --> 28:19.720
not only deprecated but removed it or changed a field that just sends things sideways or

28:19.720 --> 28:23.560
changed behavior in a way that they thought was compatible but was not.

28:23.560 --> 28:26.600
How do you get to the point where you can have more rapid updates and make it easier

28:26.600 --> 28:29.160
for your end users to pick those up?

28:29.160 --> 28:36.800
Now, some of these ideas were elaborated upon in a course that we built within openSSF and

28:36.800 --> 28:40.840
have offered for free now through the Linux Foundation's training department called Secure

28:40.840 --> 28:43.000
Software Development Fundamentals.

28:43.000 --> 28:44.480
This has been translated to Japanese.

28:44.480 --> 28:49.600
It's been translated to a bunch of other languages, Chinese, Arabic, and Hebrew.

28:49.600 --> 28:54.680
And this is 14 to 18 hours worth of content that primarily talks about anti-patterns,

28:54.680 --> 28:55.680
right?

28:55.680 --> 28:58.960
What does it mean to not trust user contributed input?

28:58.960 --> 29:03.920
What are some of the other common gotchas that have led to security vulnerabilities

29:03.920 --> 29:07.920
and breaches that as a most software developers are self-taught.

29:07.920 --> 29:12.960
Some people take courses, but even most university undergraduate level courses on computer science

29:12.960 --> 29:18.400
don't really teach about vulnerabilities and about common mistakes as well as they could.

29:18.400 --> 29:24.160
So this is something we think anybody who is writing code for a living or even for a

29:24.160 --> 29:28.720
hobby and you're giving this to somebody else to run, you should probably take this course.

29:28.720 --> 29:32.920
And the flip side of this is you might want to look and see whether the developers who

29:32.920 --> 29:35.920
are working on a thing you really care about have taken this course.

29:35.920 --> 29:39.680
You can get a badge that certifies you've taken the course, you've answered a basic

29:39.680 --> 29:44.440
quiz, it's not honorous, and it's free, but we hope it's something that helps substantiate

29:44.440 --> 29:45.960
that.

29:45.960 --> 29:50.920
Somebody has a bit more knowledgeable about this than they otherwise would be.

29:50.920 --> 29:53.320
Another part of this is something called the best practices badge.

29:53.320 --> 29:57.640
This is a checklist that's fairly extensive of the things that open source projects can

29:57.640 --> 30:03.280
do to show that they take steps, they have a security team, they distribute things over

30:03.280 --> 30:04.280
HTTPS.

30:04.280 --> 30:08.920
I mean, some of these things that seem pretty basic and each individual one is no guarantee

30:08.920 --> 30:17.160
of its security whole free code, but collectively can represent that this is a project that

30:17.160 --> 30:18.860
takes security more seriously.

30:18.860 --> 30:23.000
And studies have shown that the projects that have better scores tend to have fewer CVEs

30:23.000 --> 30:26.400
over the subsequent months and years.

30:26.400 --> 30:31.000
Now there's an automated tool for those projects because the best practices badge is something

30:31.000 --> 30:34.960
that requires the maintainers to fill out kind of a questionnaire, a checklist.

30:34.960 --> 30:39.720
There's some automation to that, but it's really just used to check the answers that

30:39.720 --> 30:41.040
the maintainers give.

30:41.040 --> 30:46.720
There's a different approach, which is much more of a scanning kind of approach, called

30:46.720 --> 30:51.640
the OpenSSF security scorecards that automatically goes and scans repositories.

30:51.640 --> 30:56.380
It's done a first wave scan of a million different repos, and you can trigger it to

30:56.380 --> 31:02.160
do an updated scan if you've made changes to your repo, but it takes dozens of different

31:02.160 --> 31:03.320
heuristics.

31:03.320 --> 31:09.960
Things like do you have binary artifacts you've checked into your GitHub repo?

31:09.960 --> 31:11.440
That's probably not a great thing.

31:11.440 --> 31:16.360
Storing binaries and repos, I don't know how many of you might disagree, but for reproducibility,

31:16.360 --> 31:21.240
maybe, but use your package manager to get your binary packages, checking it into source

31:21.240 --> 31:27.240
code control, opens the door to things that are not scrutinizable inside your source code

31:27.240 --> 31:28.240
system.

31:28.240 --> 31:33.200
Branch protection, CI tests, do you have the best practices badge?

31:33.200 --> 31:37.600
Have you done code reviews before code is merged, or does everybody just have commit

31:37.600 --> 31:39.000
proofs, right?

31:39.000 --> 31:41.880
Do you have contributors from more than one organization?

31:41.880 --> 31:47.800
Some of this adopts the chaos metrics, which looks at community health, but some of this

31:47.800 --> 31:54.520
as well are things like do your automated tests, do they call fuzzing libraries?

31:54.520 --> 31:56.880
You game a lot of these tests, right?

31:56.880 --> 32:02.600
Again, none of this is proof that your code is defract free, but collectively what this

32:02.600 --> 32:12.800
can do, along with these other kind of measures of risk, is develop a credit score for a project.

32:12.800 --> 32:16.760
The scores in scorecard actually do correlate to lower CVEs.

32:16.760 --> 32:22.000
There was a study done by Sonotype who looked at the projects that had been scored and discovered

32:22.000 --> 32:27.500
that after receiving a score, there's a couple different categories within the security scorecards,

32:27.500 --> 32:32.420
so they really were interested on which of those correlate most strongly to lower number

32:32.420 --> 32:34.300
of CVEs.

32:34.300 --> 32:38.240
That was an interesting outcome, and this is going to be used to refine the security

32:38.240 --> 32:43.920
scorecards continuously over time to have them reflect the changing landscape of some

32:43.920 --> 32:46.600
of the better run projects.

32:46.600 --> 32:51.320
That's a big deal, and it's something that some projects have picked up as a leaderboard

32:51.320 --> 32:53.720
tool.

32:53.720 --> 32:59.480
The Cloud Native Compute Foundation ran a competition recently called the CLO Monitor,

32:59.480 --> 33:04.560
on the sidelines for a month of their main KubeCon event, where they got the maintainers

33:04.560 --> 33:09.920
of the different projects to commit to have a floor on the score.

33:09.920 --> 33:16.160
I think it was six or seven out of ten for all of their projects, and have a competition

33:16.160 --> 33:23.320
between them, and with rewards for the maintainers who got their projects highest on the scorecard.

33:23.320 --> 33:25.720
Really cool to see.

33:25.720 --> 33:27.360
All of that was about measurement.

33:27.360 --> 33:34.280
This next set of things are about tools that help actually harden the software supply chain,

33:34.280 --> 33:35.280
so to speak.

33:35.280 --> 33:38.720
One that you've heard, no doubt, talked about before, so I won't dwell on it too much,

33:38.720 --> 33:40.360
is something called SigStore.

33:40.360 --> 33:43.440
SigStore is a software signing service.

33:43.440 --> 33:47.260
It's a set of software that are clients into that service.

33:47.260 --> 33:52.240
It's a protocol, because it's a certain way of signing it that's an alternative to GPG

33:52.240 --> 33:53.400
signing of code.

33:53.400 --> 33:58.960
It's a recognition that we haven't really signed artifacts to the supply chain, pervasively,

33:58.960 --> 34:00.740
except for at the very end.

34:00.740 --> 34:05.240
When you do an apt-get install, it checks the GPG signatures on each package.

34:05.240 --> 34:12.280
That is helpful, even above and beyond the fact that you're sending stuff over TLS.

34:12.280 --> 34:17.720
The rest of upstream, so often, people are just pulling off of NPM, pulling off of package

34:17.720 --> 34:22.800
hosting, other packages just stored on bare websites, where even validating the hash of

34:22.800 --> 34:28.040
that and fetching it over HTTPS doesn't prove the connection between the developers behind

34:28.040 --> 34:30.360
that code and the binary you have.

34:30.360 --> 34:34.480
There have been examples of people registering NPM packages that are named the same thing

34:34.480 --> 34:40.680
as a GitHub repo, kind of a typo squatting kind of attack, as a way to try to cause you

34:40.680 --> 34:43.600
to inadvertently pick up the wrong piece of code.

34:43.600 --> 34:49.880
Obviously, even sites like GitHub can be hacked, could be compromised, and you don't want your

34:49.880 --> 34:54.520
enterprise to be compromised if GitHub's compromised, frankly.

34:54.520 --> 34:56.840
This is a tool to try to prevent that kind of thing.

34:56.840 --> 35:03.240
It logs all of this to essentially a distributed ledger, a public database, using short-lived

35:03.240 --> 35:09.080
keys, so you don't have to worry, like PGP requires you to, to have private keys that

35:09.080 --> 35:11.760
you battle and keep private for a long time.

35:11.760 --> 35:17.680
Just like Let's Encrypt, this is based on short-lived keys and an easy way to reprovision

35:17.680 --> 35:19.520
those keys.

35:19.520 --> 35:21.400
I won't go into much more depth on that.

35:21.400 --> 35:26.120
There's a few other things I'll point you to, something called Salsa, which is for supply

35:26.120 --> 35:30.520
chain level attestations, basically a way to distinguish between those things in your

35:30.520 --> 35:36.360
chain that are built to a higher degree of rigor than other things that are not.

35:36.360 --> 35:40.280
We've got another, something back on the best practices working group, which is a guide

35:40.280 --> 35:42.920
to coordinated vulnerability disclosure.

35:42.920 --> 35:47.120
The next time there's a team, say they're not associated with Apache, say they're not

35:47.120 --> 35:52.080
associated with a major foundation who discover that they've got a pretty nasty bug and their

35:52.080 --> 35:59.520
code is used pretty widely, well, who do they turn to to understand how to manage a coordinated

35:59.520 --> 36:04.560
disclosure process, how to not get in trouble for keeping something a little bit quiet while

36:04.560 --> 36:09.160
they come up with the right fix, and then how do you evaluate who potentially to notify

36:09.160 --> 36:13.040
ahead of time so that you're upgrading enough of the internet before something becomes more

36:13.040 --> 36:14.240
widely known.

36:14.240 --> 36:17.720
By the way, even if that sounds controversial, like there's some people who say, including

36:17.720 --> 36:21.760
the CRA, like if you know about a bug, you should tell everybody immediately.

36:21.760 --> 36:27.240
Well, does anyone remember the hack that almost brought down the internet, the DNS cache poisoning

36:27.240 --> 36:32.640
bug in Bind, that if that had become widely known before the root name servers had been

36:32.640 --> 36:39.160
updated, would have set us back so far, we would have had to revert to Etsy host files

36:39.160 --> 36:43.560
to be able to connect on the internet again and get started.

36:43.560 --> 36:48.480
The need for coordinated vulnerability disclosure might be somewhat controversial, but has become

36:48.480 --> 36:52.760
much more widely accepted today than ever before.

36:52.760 --> 36:56.560
One thing we're going to do in the OpenSSF is pull this all together into a single dashboard

36:56.560 --> 37:04.280
to understand that risk, understand how open source projects compare apples to apples, and

37:04.280 --> 37:08.520
really as a tool to help the maintainers on those projects get better at what they do.

37:08.520 --> 37:13.680
But also, frankly, if we can help enterprises understand where the risk lies in their use

37:13.680 --> 37:19.760
of code, if they can start making more choices based more on the security of that code than

37:19.760 --> 37:24.080
necessarily what is the most features or the most users, then we can start to, I think,

37:24.080 --> 37:28.000
understand industry in a better direction, somewhere between the carrots and the defaults

37:28.000 --> 37:32.560
kind of step of getting folks to adopt stuff.

37:32.560 --> 37:37.280
I do also want to throw out one of the biggest efforts that we have under the OpenSSF is

37:37.280 --> 37:44.920
this thing called the Alpha Omega project, which is independently funded and staffed,

37:44.920 --> 37:46.320
and it's got two pieces to it.

37:46.320 --> 37:51.120
The Alpha side is going and helping the largest open source foundations out there with the

37:51.120 --> 37:56.520
most critical needs basically develop better security practices, develop security teams,

37:56.520 --> 38:02.920
go and do some proactive third-party audits, but develop this muscle, this capability that

38:02.920 --> 38:03.920
hopefully persists.

38:03.920 --> 38:08.400
We'll go and we'll fund some of these projects for a couple years, and our hope is that at

38:08.400 --> 38:11.680
some point the stakeholders in that community take on that funding themselves.

38:11.680 --> 38:15.720
The companies who are depending upon that see the value of this kind of proactive investment

38:15.720 --> 38:19.240
and continue it forward so we can move on to the next set of projects.

38:19.240 --> 38:23.600
The Omega side of that is trying to set up scanning infrastructure for the most important

38:23.600 --> 38:29.440
10,000 open source code bases to look for new kinds of vulnerabilities, to ask, in theory,

38:29.440 --> 38:33.840
this Gindi LDAP bug in Log4J that led to this thing, is it novel?

38:33.840 --> 38:38.000
If it's novel, can we systematically scan for other projects that might be vulnerable

38:38.000 --> 38:39.880
to the same thing?

38:39.880 --> 38:45.920
In some cases, could we even submit proactive pull requests to go and close those?

38:45.920 --> 38:49.520
An example of another organization that has done this recently, I don't know if folks

38:49.520 --> 38:57.360
saw this announcement by Trellix last week, where they went and discovered 60,000, 61,000

38:57.360 --> 39:02.920
open source projects that used the Python tar file module in an insecure way.

39:02.920 --> 39:09.160
This is actually an old CVE from 2007 that the CPython devs have refused to fix because

39:09.160 --> 39:13.560
of a claim that the only way to fix it would be to break POSIX, so we can have that debate

39:13.560 --> 39:14.560
some other time.

39:14.560 --> 39:19.280
They went and found 61,000 projects that have a vulnerability because they used it unsafely.

39:19.280 --> 39:21.640
They didn't sanitize inputs to it.

39:21.640 --> 39:30.080
They went and proactively issued 61,000 pull requests on those projects to fix this code.

39:30.080 --> 39:33.160
Doing this at scale is tremendously hard, but they did it.

39:33.160 --> 39:37.200
So far, after a month and a half of having those pull requests up, do you want to guess

39:37.200 --> 39:40.640
how many projects have actually accepted that pull request?

39:40.640 --> 39:44.640
Really push the button to make their project more secure?

39:44.640 --> 39:46.920
1,000.

39:46.920 --> 39:48.440
We still have a culture problem here.

39:48.440 --> 39:52.440
We still have an incentives problem, even when you've given them this gift.

39:52.440 --> 39:55.640
It might not happen.

39:55.640 --> 39:57.840
We're really towards the end of time.

39:57.840 --> 40:03.160
I just want to say we've recognized that, as the point I made earlier, you've got to

40:03.160 --> 40:04.400
show up.

40:04.400 --> 40:07.800
If you're an organization that cares about increasing the security of code, you've got

40:07.800 --> 40:12.320
to be prepared to invest time and ultimately money to make that happen.

40:12.320 --> 40:16.760
You cannot demand that open source developers simply be better.

40:16.760 --> 40:20.360
You've got to go and help them do that and spend that in.

40:20.360 --> 40:24.800
One of the things we've done at the OpenSSF is, over the last year, we developed an overarching

40:24.800 --> 40:30.320
plan to go and address 10 systematic weaknesses in open source and put together essentially

40:30.320 --> 40:36.200
business plans for each of them that would call for some funding to pay for the core

40:36.200 --> 40:40.160
of a project on the presumption that we could leverage volunteers around the periphery to

40:40.160 --> 40:41.640
try and have some of this impact.

40:41.640 --> 40:44.000
I won't go into detail of what that is too much.

40:44.000 --> 40:46.020
We call it the security mobilization plan.

40:46.020 --> 40:52.680
It includes things like $40 million to go and close security holes and some other things.

40:52.680 --> 40:59.160
It includes setting up an emergency response team for development teams that are understaffed

40:59.160 --> 41:04.720
who find a vulnerability to going and doing new scanning, to driving adoption of SigStore

41:04.720 --> 41:05.720
and other standards.

41:05.720 --> 41:07.880
It's pretty comprehensive.

41:07.880 --> 41:12.360
It might seem like $150 million, which is the number we came up with after saying, what

41:12.360 --> 41:16.880
could we do that would be lean, that would be low-hanging fruit but actually have a big

41:16.880 --> 41:18.440
impact.

41:18.440 --> 41:20.600
We came up with this two-year number of 150.

41:20.600 --> 41:21.800
It might sound like a lot of money.

41:21.800 --> 41:23.720
It's certainly more than the Linux Foundation has.

41:23.720 --> 41:28.160
It's more than any of the other major open source foundations or even frankly Google

41:28.160 --> 41:32.960
and Microsoft have to spend on this, arguably.

41:32.960 --> 41:36.760
There's a larger number out there that I want to focus on, which is $700 million, which

41:36.760 --> 41:42.360
is the fine that the US Federal Trade Commission levied on Equifax for the 2007 data breach

41:42.360 --> 41:48.080
caused in part by their use of unpatched open source software, Apache Struts.

41:48.080 --> 41:53.200
To the industry, making the case that we collectively could pool our funds to go do this should

41:53.200 --> 41:54.600
be easy.

41:54.600 --> 41:58.400
We've been out there trying to do it, have these conversations, doing it at a time when

41:58.400 --> 42:02.800
the economic headwinds have not been in our favor, but still the kinds of conversations

42:02.800 --> 42:05.240
we're having are very positive.

42:05.240 --> 42:10.360
Things like seeing the Sovereign Tech Fund in Germany pop up and be able to fund not

42:10.360 --> 42:13.840
just some improvements in open source code but security enhancements and the like has

42:13.840 --> 42:16.120
been really positive to see.

42:16.120 --> 42:20.160
It should be a model for other countries to go and do this, but frankly, insurance companies

42:20.160 --> 42:25.400
as well as banks, as well as all these other industries that have benefited from open source

42:25.400 --> 42:28.040
software and haven't put things really in.

42:28.040 --> 42:31.560
Again, we're kind of out of time, so I won't go too much into depth.

42:31.560 --> 42:36.680
I do want to emphasize tooling around the SBOM space is an important part of this as

42:36.680 --> 42:42.320
well and being able to paint this overarching picture about how SBOMs, signed artifacts,

42:42.320 --> 42:46.760
software level attestations, and all these other things could have a positive impact,

42:46.760 --> 42:51.120
but we've got to show up and not just tell projects to adopt this, but weave it into

42:51.120 --> 42:56.040
the development tools as defaults so we can bring industry along.

42:56.040 --> 42:58.800
We've launched this with US government back in May.

42:58.800 --> 43:01.720
We had a similar meeting in Japan in July.

43:01.720 --> 43:09.120
We've had conversations in Singapore and with people in other countries, and hopefully we'll

43:09.120 --> 43:11.760
see something here in Europe along the same lines.

43:11.760 --> 43:18.120
But let me just wrap up by saying there are attacks on the integrity of open source software

43:18.120 --> 43:22.480
that are increasingly disruptive and require us to work together to do things a little

43:22.480 --> 43:24.360
bit different than we have before.

43:24.360 --> 43:28.880
It's not that we were reckless or careless or didn't care about security, most of us

43:28.880 --> 43:29.880
at least.

43:29.880 --> 43:33.920
There's some open source projects that definitely have been problems, but there's simply more

43:33.920 --> 43:37.880
that we can do and more that people who care about this and are starting to use open source

43:37.880 --> 43:43.720
software in French nuclear power plants can do to help this space be better.

43:43.720 --> 43:46.920
There's some specific steps, as I've talked about, and that's kind of why we're here at

43:46.920 --> 43:52.520
the OpenSSF, and we're here to help, but we also need your help as developers.

43:52.520 --> 43:57.920
It'd be very easy to see what we do as being the enterprises trying to make open source

43:57.920 --> 44:04.540
boring and make it all about checklists, and I'll concede that, but we're also here to

44:04.540 --> 44:08.940
try to say if we're going to shift the landscape, how do we work with the open source community

44:08.940 --> 44:10.300
to do that?

44:10.300 --> 44:15.200
Because we are part of the open source community, how we collectively take some action to make

44:15.200 --> 44:18.640
it less likely that our next winter holidays will be ruined.

44:18.640 --> 44:28.360
And with that, thank you.

44:28.360 --> 44:32.640
I think I left about 22 seconds for questions.

44:32.640 --> 44:35.000
Okay.

44:35.000 --> 44:39.320
Five minutes.

44:39.320 --> 44:47.960
Okay, so we've got about five minutes for questions.

44:47.960 --> 44:51.080
So let me start by reading one question online.

44:51.080 --> 44:57.640
There was a question whether OpenSSF allows for anonymous reporting, which could be without

44:57.640 --> 45:03.920
disclosing the reporter, because that would be useful for companies fearing backlash or

45:03.920 --> 45:05.880
high expectations regarding what they have to do.

45:05.880 --> 45:09.680
So why bother reporting if they're just going to get into trouble?

45:09.680 --> 45:11.920
Why not just keep it not release anything?

45:11.920 --> 45:17.440
So making it possible to report anonymously would possibly improve that.

45:17.440 --> 45:21.600
So the question is about anonymous reporting of bugs, and would that be helpful?

45:21.600 --> 45:26.520
Well, I will submit, open source software has benefited tremendously by the fact that

45:26.520 --> 45:30.760
you aren't badging in to GitHub with your national ID, right?

45:30.760 --> 45:32.880
You are able to be pseudonymous.

45:32.880 --> 45:36.880
And you can use Satoshi Nakamoto as a famous example of that, whatever, right?

45:36.880 --> 45:41.000
But most of us, or many of us, have probably created login IDs that have nothing to do

45:41.000 --> 45:42.880
with our real name, right?

45:42.880 --> 45:47.000
And open source software is one of the last remaining places where you can actually productively

45:47.000 --> 45:51.040
collaborate with people who aren't fully identifying who they are, right?

45:51.040 --> 45:54.160
You're basing it on their quality of their contribution.

45:54.160 --> 45:56.720
And that's a really essential thing to try to preserve.

45:56.720 --> 46:01.160
And whether it's in reporting bugs or even collaborating on code, we should fight to

46:01.160 --> 46:05.800
preserve the right to be pseudonymous, or even anonymous, if you want to call it that,

46:05.800 --> 46:09.600
in the development of code and in the fixing, reporting of bugs and the fixing of bugs.

46:09.600 --> 46:14.320
So I'm committed to trying to make sure we don't get to know your developer kinds of

46:14.320 --> 46:19.760
rules like some countries have started to call for.

46:19.760 --> 46:21.080
Thanks for the really interesting talk.

46:21.080 --> 46:25.480
I have a question about the economics of your proposed solution.

46:25.480 --> 46:31.080
It's not that you can pay developers out of the blue to do these tasks.

46:31.080 --> 46:33.720
You have to pull them away from other work.

46:33.720 --> 46:40.240
So you have to pay them actually more to let all the other work rest and focus on security.

46:40.240 --> 46:42.560
So this requires a major shift.

46:42.560 --> 46:44.800
Have you factored this into your proposal?

46:44.800 --> 46:49.080
No, I haven't thought about having to pay not just for the work that we're doing, but

46:49.080 --> 46:52.440
paying for work that wouldn't be done because we're paying people to do the work.

46:52.440 --> 46:56.120
I think most of the time developers aren't able to work on open source code because they

46:56.120 --> 46:59.200
have to work on proprietary code to pay the bills.

46:59.200 --> 47:03.360
And so I think there's a lot of capacity out there for us if we do have funds to be able

47:03.360 --> 47:05.800
to pay for the kind of work that needs to be done.

47:05.800 --> 47:10.360
I also don't think we're talking about taking away from other software development work

47:10.360 --> 47:12.880
that's about adding features or fixing bugs.

47:12.880 --> 47:19.160
This is about bringing new types of organizations like the software auditor community to look

47:19.160 --> 47:21.920
at to find new bugs.

47:21.920 --> 47:24.120
So it's not a big deal.

47:24.120 --> 47:27.800
And frankly, $150 million, even if that were all spent on software developers, would be

47:27.800 --> 47:31.480
a drop in the bucket compared to the total amount that is spent on developer salaries

47:31.480 --> 47:32.480
out there.

47:32.480 --> 47:34.720
So that isn't where I'm at.

47:34.720 --> 47:35.720
But it's a good question.

47:35.720 --> 47:36.720
Thank you for that.

47:36.720 --> 47:42.520
Do you have more questions from the public?

47:42.520 --> 47:53.040
There was one question in the chat about how is the OpenSSL collaborating with OWASP?

47:53.040 --> 47:56.560
Is that a collaboration there or not?

47:56.560 --> 48:01.960
So there's a question in chat on how is the OpenSSL collaborating with OWASP.

48:01.960 --> 48:06.760
So Andrew Van Der Stock, who's the executive director of OWASP, is on our board.

48:06.760 --> 48:11.960
There's a lot that OWASP does in terms of education and certification and community

48:11.960 --> 48:14.000
building that absolutely is essential.

48:14.000 --> 48:17.440
And so we look for ways to work together and we'd like to avoid overlap with what they

48:17.440 --> 48:19.480
do.

48:19.480 --> 48:21.920
But yeah, that's about it.

48:21.920 --> 48:26.840
We're very complimentary to their efforts and I think they think the same.

48:26.840 --> 48:29.920
Okay.

48:29.920 --> 48:36.800
Anybody else?

48:36.800 --> 48:44.240
Hello.

48:44.240 --> 48:46.000
We are in Europe here.

48:46.000 --> 48:51.080
You have spoken about different conferences all over the world in Singapore.

48:51.080 --> 48:54.920
But do you have something in Europe?

48:54.920 --> 48:57.440
We've had lots of conversations in Europe.

48:57.440 --> 49:00.720
There are many OSPOs starting in Europe who are interested in this.

49:00.720 --> 49:05.920
And I do think OSPOs are an interesting lever point in being able to get standards adopted

49:05.920 --> 49:11.400
around security, being able to present measures of risk to be thinking about all these kinds

49:11.400 --> 49:12.400
of things.

49:12.400 --> 49:17.000
So have had interesting conversations that way, have not had the kind of full-throated

49:17.000 --> 49:21.600
engagement around this that we've seen with the United States and with some other countries.

49:21.600 --> 49:23.680
So I would like to see more.

49:23.680 --> 49:27.240
But frankly, even those other countries haven't yet put money into this.

49:27.240 --> 49:30.620
They're kind of waiting for certain political cycles to make their way through.

49:30.620 --> 49:32.120
But I know we've inspired some action.

49:32.120 --> 49:36.840
Again, I do want to cite the sovereign tech fund out of Germany as not specifically a

49:36.840 --> 49:40.760
security fund, but the right kind of thing for these countries to be doing.

49:40.760 --> 49:43.360
So anyways, thank you for the question.

49:43.360 --> 49:44.360
Anything else?

49:44.360 --> 49:45.920
That's exactly how much time we've had.

49:45.920 --> 49:48.520
So thank you again, Brian.

49:48.520 --> 49:49.520
Thanks all.

49:49.520 --> 50:05.820
Over and out.

50:05.820 --> 50:14.500
Thank you.
