WEBVTT

00:00.000 --> 00:12.040
Hello, everyone. I'm Marco Castelluccio. Thank you for being here to listen to my talk.

00:12.040 --> 00:20.160
I'm an engineer manager at Mozilla. I've been at Mozilla for almost 10 years now. I've been

00:20.160 --> 00:26.320
I started as a contributor, then an intern, then I was hired, and I've been here for almost

00:26.320 --> 00:33.520
10 years. I started working on some funny projects like writing a Java VM in JavaScript,

00:33.520 --> 00:39.240
and then more recently I started focusing on using machine learning and data mining

00:39.240 --> 00:51.400
techniques to improve developer efficiency, which has also been the subject of my PhD.

00:51.400 --> 00:58.600
During this talk, I will show you how we will all be out of our job in a few years. Joking.

00:58.600 --> 01:06.640
I will just take you through our journey of how we incrementally built features based

01:06.640 --> 01:16.080
on machine learning for improving software engineering, one on top of each other.

01:16.080 --> 01:26.600
I'm the father of two, Luna and Nika. And before we start with the presentation, I wanted

01:26.600 --> 01:34.320
to explain a little why we need to do all these complex machine learning things on top

01:34.320 --> 01:42.920
of bugs, CI, patches, et cetera, et cetera. Firefox is a very complex software. It's a

01:42.920 --> 01:52.240
browser. We have hundreds of bug reports and feature requests open per day. We have 108

01:52.240 --> 01:57.560
million bug reports at this time, which is almost the price of a one bedroom apartment

01:57.560 --> 02:06.520
in London. We release every four weeks with thousands of changes. And during 2022, we

02:06.520 --> 02:13.520
had 13 major releases and 45 million minor releases. As you can see, we even sometimes

02:13.520 --> 02:26.720
party when we reach a certain number of bugs. As I said, Firefox is one of the biggest software

02:26.720 --> 02:34.000
in the world. We have a lot of legacy. Netscape was open sourced 25 years ago. A few days

02:34.000 --> 02:43.520
ago we celebrated the 25th birthday. Over time we had 800,000 commits made by 9,000 unique

02:43.520 --> 02:51.320
contributors representing 25 million lines of code. We had 37,000 commits only last year

02:51.320 --> 03:00.600
by 1,000 unique contributors. Not all of them are paid. Many of them are volunteers.

03:00.600 --> 03:05.440
And this is a list of the languages that we use. As you can see, we use many of them.

03:05.440 --> 03:11.200
We have C, C++, and Rust for low level things. Rust is gaining ground and is probably going

03:11.200 --> 03:19.720
to overcome C soon. We use JavaScript for front end and for tests. And we use Python

03:19.720 --> 03:28.000
for CI and build system. But we have many more. So if anybody is interested in contributing,

03:28.000 --> 03:39.000
you have many options to choose from. But let's see. So as I said, the complexity is

03:39.000 --> 03:47.120
really large. We have thousands and thousands of bugs. And we need some way to control the

03:47.120 --> 03:53.760
quality, to increase the visibility into the quality of the software. And we cannot do

03:53.760 --> 04:00.400
that if the bugs are left uncontrolled. One of the first problems that we had was that

04:00.400 --> 04:06.600
there is no way to differentiate between defects and feature requests. We call them bugs on

04:06.600 --> 04:12.480
Bugzilla. But they are actually just reports. Many of them are defects. Many of them are

04:12.480 --> 04:19.880
actually just feature requests. And so at the time we had no way to measure quality.

04:19.880 --> 04:26.360
We had no way to tell in this release we have 100 bugs. In this other release we had 50.

04:26.360 --> 04:32.660
So this release is better than the previous. And so we need a way to make this differentiation

04:32.660 --> 04:37.000
in order to measure the quality. And it was also hard to improve workflows if we had no

04:37.000 --> 04:42.960
way to differentiate between them. So we thought of introducing a new type field. This might

04:42.960 --> 04:50.160
seem simple. It's just choice between defect, enhancement, and task. But in practice when

04:50.160 --> 04:57.640
you have 9,000 unique contributors, some of them not paid, it's not easy to enforce a

04:57.640 --> 05:05.160
change like this. And we also had another problem. We have 100 million bugs. How if

05:05.160 --> 05:12.040
we just introduced this type, it's not going to help us at all until we reach a mass of

05:12.040 --> 05:19.520
bugs that we change. So if we just introduced it at this time, it will only start to be

05:19.520 --> 05:25.520
useful six months from now. So we thought how do we set the field for existing bugs

05:25.520 --> 05:32.680
so that this actually becomes useful from day one. And we thought of using machine learning.

05:32.680 --> 05:40.760
So we collected a large data set. I'm not sure it can be considered large nowadays.

05:40.760 --> 05:51.600
With 2,000 manually labeled bugs, a few of us labeled independently. And then we shared

05:51.600 --> 05:57.400
the labeling so that we were consistent. And we had 9,000 labeled with some heuristics

05:57.400 --> 06:03.240
based on fields that were already present in Baxilla. Then we, using the fields from

06:03.240 --> 06:12.080
Baxilla and the title and comment through an NLP pipeline, we trained an XGB boost model.

06:12.080 --> 06:21.960
And we achieved accuracy that we deemed good enough to be used on production. And this

06:21.960 --> 06:28.820
is how the bug bug project started. It was just a way to differentiate between defects

06:28.820 --> 06:36.160
and non-defects on Baxilla. We saw it worked. And then we decided, we thought, what if we

06:36.160 --> 06:43.720
extend this to something else? What is the next big problem that we have on Baxilla?

06:43.720 --> 06:53.360
And it was assigning components. Again, we have lots of bugs, millions of, 100,000s of

06:53.360 --> 06:59.200
bugs. We need a way to split them in groups so that the right team sees them, so that

06:59.200 --> 07:04.600
the right people see them. And the faster we do it, the faster we can fix them. At the

07:04.600 --> 07:09.560
time it was manually done by volunteers and developers. So you can see a screenshot here,

07:09.560 --> 07:21.080
a product and component, PDF viewer. In this case, we didn't need to manually create a

07:21.080 --> 07:29.640
dataset because all of the 1 million bugs were already manually split into groups by

07:29.640 --> 07:37.480
volunteers and developers in the past. So we had, in this case, a very large dataset,

07:37.480 --> 07:44.800
two decades worth of bugs. The problem here was that we had to roll back the bug to the

07:44.800 --> 07:51.840
initial state because otherwise, by training the model on the final state of the bug, we

07:51.840 --> 07:57.480
would have used future data to predict the past. And it was not possible, of course.

07:57.480 --> 08:02.520
So we rolled back the history of the bug to the beginning. We also reduced the number

08:02.520 --> 08:07.840
of components because, again, with the Firefox scale, we have 100,000s of components. Many

08:07.840 --> 08:13.240
of them are no longer actually maintained and no longer relevant. So we reduced them

08:13.240 --> 08:21.040
to a smaller subset. And, again, we had the same kind of architecture to train the model.

08:21.040 --> 08:30.840
With a small tweak, we didn't have perfect accuracy, and so we needed a way to choose

08:30.840 --> 08:39.720
confidence and recall. So pay the price of lower quality but catching more bugs or catching

08:39.720 --> 08:44.480
fewer bugs but be precise more time. So we can control this easily with a confidence

08:44.480 --> 08:50.920
level that is output by the model, which allows us to sometime be more aggressive, sometime

08:50.920 --> 08:58.120
be less aggressive. But at least we can have a minimum level of quality that we enforce.

08:58.120 --> 09:04.040
The average time to assign a bug then went from one week to a few seconds. Over time,

09:04.040 --> 09:12.240
we auto classified 20,000 bugs. And since it worked, we also extended it to webcompat.com,

09:12.240 --> 09:19.080
which is another yet another bug reporting system that we have at Mozilla, which if you

09:19.080 --> 09:23.980
find the web compatibility bugs, please go there and file them because it's pretty important.

09:23.980 --> 09:29.760
And you can see here an action of the bot moving the bug to, again, the Firefox PDF

09:29.760 --> 09:35.720
viewer component. Maybe I should have used another example just for fun.

09:35.720 --> 09:43.360
Now we had something working, and it was starting to become promising. But we needed to make

09:43.360 --> 09:48.080
it better. We needed to have a better architecture for the machine learning side of things. We

09:48.080 --> 09:53.000
needed to retrain the models. We needed to collect new data. We needed to make sure that

09:53.000 --> 10:00.480
whenever a new component comes in, we retrain the model with the new components. If a component

10:00.480 --> 10:05.760
stops being used, we need to remove it from the data set and things like that.

10:05.760 --> 10:12.240
So we built over time a very complex architecture. I won't go into too many details because it

10:12.240 --> 10:23.240
will take too long. But maybe if somebody has questions later, we can go into that.

10:23.240 --> 10:31.360
And then with the architecture now, it was easier to build new models. So we even had

10:31.360 --> 10:43.480
contributors building models just all by themselves. In particular, there was a contributor, Aayush,

10:43.480 --> 10:48.880
which helped us build a model to root out spam from Bugzilla.

10:48.880 --> 10:54.960
So it seems weird, but yes, we do have spam on Bugzilla as well. People are trying to

10:54.960 --> 11:01.120
get links to their websites into Bugzilla because they think the search engine will

11:01.120 --> 11:06.360
index them. It's not actually the case. We tell them all the time, but they keep doing

11:06.360 --> 11:15.560
it anyway. We have university students. Bugzilla is probably the most studied bug tracking

11:15.560 --> 11:24.400
system in research. And we have many university students from many countries that use Bugzilla

11:24.400 --> 11:35.160
as a playing field. Many times we even contact the universities and professors asking them

11:35.160 --> 11:44.600
if we can help them give more relevant topics to students, et cetera. But they keep filing

11:44.600 --> 11:49.440
bugs. And this contributor maybe was from one of these schools, was tired of it and

11:49.440 --> 11:55.960
helped us build a model. And the results were pretty good. I'll show you a few examples

11:55.960 --> 12:05.720
of bugs that were caught by the model. So this one was, if you look just at the first

12:05.720 --> 12:11.680
comment of the bug, it looks like a legit bug. But then the person created a second

12:11.680 --> 12:21.760
comment with a link to their website. And it was pretty clear that it was spam. This

12:21.760 --> 12:29.520
one is another example. This is actually a legit bug. It's not spam. Maybe it's not so

12:29.520 --> 12:37.440
usable as a bug report, but it was not spam. And then somebody else, a spammer, took exactly

12:37.440 --> 12:45.560
the same contents, created a new bug, injecting the link to their website in the bug report.

12:45.560 --> 12:50.560
And somehow, I don't know how the model was able to detect that it was spam. It's funny

12:50.560 --> 12:57.240
because you can see that when you file a bug on Bugzilla, Bugzilla will automatically insert

12:57.240 --> 13:05.280
the user agent so that we have more information as possible to fix bug. But in this case,

13:05.280 --> 13:11.920
he was copying the contents of the other bug. So we have two user agents. And they're even

13:11.920 --> 13:22.080
on different platforms, one on Mac and one on... Ah, he was using Chrome, actually.

13:22.080 --> 13:29.520
Okay. So we were done with bugs. Well, we are not done with the bugs. We will have plenty

13:29.520 --> 13:37.560
of things to do in the future forever. But we were happy enough with bugs. And we thought,

13:37.560 --> 13:47.080
what can we improve next? One of the topics that we were focusing on at the time was testing

13:47.080 --> 13:52.640
and the cost associated to testing. We were experimenting with code coverage, trying to

13:52.640 --> 14:02.880
collect code coverage to select relevant tests to run on a given patch. But it was pretty

14:02.880 --> 14:10.600
complex for various reasons. So we thought maybe we can apply machine learning here as

14:10.600 --> 14:17.600
well. But before we go into that, let me explain a bit about RCI because it's a little complex.

14:17.600 --> 14:25.000
So we have three branches, three repositories, which all kind of share the same code, Firefox.

14:25.000 --> 14:34.480
We have Tri, which is on-demand CI. We have Autoland, which is the repository where patches

14:34.480 --> 14:40.400
land after they've been reviewed and approved. And we have Mozilla Central, which is the

14:40.400 --> 14:50.040
actual repository where Firefox source code lives and from which we build Firefox nightly.

14:50.040 --> 14:56.680
On Tri, we run whatever the user wants. On Autoland, we run a subset of tests. At the

14:56.680 --> 15:04.100
time, it was kind of random, what we decided to run. And on Mozilla Central, we run everything.

15:04.100 --> 15:08.760
To give you an idea, on Tri, we will have hundreds of pushes per day. On Autoland, the

15:08.760 --> 15:16.200
same. And on Mozilla Central, we have only three or four. And it's restricted only to

15:16.200 --> 15:24.960
certain people that have the necessary permissions since you can build Firefox nightly from there.

15:24.960 --> 15:34.720
And it's going to be shipped to everyone. The scale here is similar to the bug case.

15:34.720 --> 15:43.280
We have 100,000 unique test files. We have around 150 unique test configurations. So

15:43.280 --> 15:51.160
combinations of operating systems, high-level Firefox configurations. So old style engine

15:51.160 --> 15:57.160
versus new style engine, certain graphics engine versus another graphics engine, et

15:57.160 --> 16:05.120
cetera, et cetera. We have debug builds versus optimized builds. We have ASAN, T-SAN, code

16:05.120 --> 16:11.600
coverage, et cetera, et cetera. Of course, the matrix is huge. And you get to 150 configurations.

16:11.600 --> 16:18.760
We have more than 300 pushes per day by developers. And the average push takes 1,500 hours if

16:18.760 --> 16:24.880
you were to run it all at the same, all one after the other. It takes 300 machine years

16:24.880 --> 16:32.880
per month. And we run around 1 million machines per, we use 100 million machines per month

16:32.880 --> 16:39.920
to run these tests. If you were to run all of the tests, you would need to run 2.0, all

16:39.920 --> 16:44.920
of the tests in all of the configurations, you would need to run around 2.3 billion test

16:44.920 --> 16:55.440
files per day, which is, of course, unfeasible. And this is a view of our tree herder, which

16:55.440 --> 17:03.680
is the user interface for Mozilla test results. You can see that it is almost unreadable.

17:03.680 --> 17:11.560
Likely the green stuff is good. The orange stuff is probably not good. You can see that

17:11.560 --> 17:19.240
we have lots of tests. And we spend a lot of money to run these tests. So what we wanted

17:19.240 --> 17:24.760
to do, we wanted to reduce the machine time spent to run the tests. We wanted to reduce

17:24.760 --> 17:31.160
the end-to-end time so that developers, when they push, they get a result, yes or no, your

17:31.160 --> 17:36.880
patch is good or not, quickly. And we also wanted to reduce the cognitive overload for

17:36.880 --> 17:47.160
developers. Looking at a page like this, what is it? It's impossible to understand. Also,

17:47.160 --> 17:56.720
to give you an obvious example, if you have, if you're changing the Linux version of Firefox,

17:56.720 --> 18:03.560
I don't know, you're touching GTK, you don't need to run Windows tests. At the time, we

18:03.560 --> 18:09.560
were doing that. At the time, if you touched GTK code, we were running Android, Windows,

18:09.560 --> 18:18.680
Mac. That was totally useless. And the traditional way of running tests on browsers doesn't really

18:18.680 --> 18:24.720
work. You cannot run everything on all of the pushes. Otherwise, you will have a huge

18:24.720 --> 18:31.440
bill from the cloud provider. So we couldn't use coverage because of some technical reasons.

18:31.440 --> 18:41.320
We thought, what if we use machine learning? What if we extend bug bug to also learn patches

18:41.320 --> 18:53.760
and tests? So the first part was to use machines to try to parse this information and try to

18:53.760 --> 18:59.480
understand what exactly failed. It might seem like an easy task if you have one under tests

18:59.480 --> 19:07.000
or ten tests, but when you have two billion tests, you have lots of intermittent filling

19:07.000 --> 19:14.680
tests. These tests fail randomly. They are not always the same. Every week, we see 150

19:14.680 --> 19:22.120
new intermittent tests coming in. It's impossible to, it's not easy to automatically say if

19:22.120 --> 19:28.600
a failure is actually a failure or if it is an intermittent. Not even developers are able

19:28.600 --> 19:34.680
to do that sometimes. Also, not all of the tests are run on all of the pushes. So if

19:34.680 --> 19:44.400
I push my patch and a test doesn't run, but runs later on another patch, and it fails,

19:44.400 --> 19:52.880
I don't know if it was my fault or somebody else's fault. And so we have sheriffs, people

19:52.880 --> 20:01.480
that are only focused, whose main focus is watching the CI, and they are pretty experienced

20:01.480 --> 20:09.560
at doing that. Probably better than most developers. But human errors still exist. Even if we have

20:09.560 --> 20:15.960
their annotations, it's pretty hard to be sure about the results. You can see a meme

20:15.960 --> 20:27.760
that some sheriffs created. Flaky tests are the infamous intermittent filling tests.

20:27.760 --> 20:35.400
So the first step, the second step, after we implemented some heuristics to try to understand

20:35.400 --> 20:44.040
the failures due to a given patch, was to analyze patches. We didn't have readily available

20:44.040 --> 20:52.520
tools, at least not fast enough for the amount of data that we are talking about. We just

20:52.520 --> 21:01.440
used Mercurial for authorship info. Who is the author of the push? Who is the reviewer?

21:01.440 --> 21:07.040
When was it pushed? Et cetera, et cetera. And we created a couple of projects written

21:07.040 --> 21:13.040
in Rust to parse patches efficiently and to analyze source code. The second one was actually

21:13.040 --> 21:26.560
a research partnership with the Polytech clinical ditoreno. And the machine learning model itself,

21:26.560 --> 21:33.320
it's not a multilabel model, as one might think, where each test is a label. It would

21:33.320 --> 21:41.480
be too large with the number of tests that we have. The model is simplified. The input

21:41.480 --> 21:50.160
is the tappel test and patch. And the label is just fail, not fail. So the features actually

21:50.160 --> 21:57.080
come from both the test, the patch, and the link between the test and the patch. So,

21:57.080 --> 22:02.520
for example, the pass failures, when the same files were touched, the distance from the

22:02.520 --> 22:10.180
source files to the test files in the tree, how often source files were modified together

22:10.180 --> 22:15.760
with test files. Of course, if they're modified together, probably they are somehow linked.

22:15.760 --> 22:21.000
Maybe you need to fix the test. And so when you push your patch, you also fix the test.

22:21.000 --> 22:29.800
This is a clear link. But even then, we have lots of test redundancies. So we use the frequent

22:29.800 --> 22:38.680
item set mining to try to understand which tests are redundant and remove them from the

22:38.680 --> 22:49.600
set of tests that are selected to run. And this was pretty successful as well. So now

22:49.600 --> 22:58.440
we had architecture to train models on bugs, to train models on patches and tests. The

22:58.440 --> 23:09.120
next step was to reuse what we built for patches to also try to predict defects. This is actually

23:09.120 --> 23:15.520
still in experimental phase. It's kind of a research project. So if anybody is interested

23:15.520 --> 23:22.960
in collaborating with us on this topic, we would be happy to do so. I will just show

23:22.960 --> 23:30.760
you a few things that we have done in the space for now. So the goals are to reduce

23:30.760 --> 23:37.800
the regressions by detecting the patches that reviewers should focus on more than others,

23:37.800 --> 23:44.920
to reduce the time spent by reviewers on less risky patches, and to when we detect that

23:44.920 --> 23:51.800
the patch is risky, trigger some risk control operations. For example, I don't know, running

23:51.800 --> 23:57.800
tests more comprehensively in dispatches and things like this. Of course, the model is

23:57.800 --> 24:04.920
just an evaluation of the risk. It's not actually going to tell us if there is a bug or not.

24:04.920 --> 24:17.080
And it will never replace a real reviewer who can actually review the patch more precisely.

24:17.080 --> 24:23.960
The first step was again build the dataset. It is not easy to know which patches cause

24:23.960 --> 24:29.920
regressions. It's actually impossible at this time. There are some algorithms that are used

24:29.920 --> 24:38.320
in research. The most famous one is SZZ. But we had some answers that it was not so good.

24:38.320 --> 24:44.640
So we started here again introducing a change in the process that we have. We introduced

24:44.640 --> 24:54.520
a new field, which is called Regressed By, so that developers, QA users, can specify

24:54.520 --> 25:00.760
what caused a given regression. So when they file a bug, if they know what caused it, they

25:00.760 --> 25:06.840
can specify it here. If they don't know what caused it, we have a few tools that we built

25:06.840 --> 25:16.400
over time to automatically download the builds from RCI that we showed earlier. Automatically

25:16.400 --> 25:22.400
download the builds from the past and run a bisection to try to find what the cause

25:22.400 --> 25:30.040
is for the given bug. With this, we managed to build a pretty large dataset, 5,000 links

25:30.040 --> 25:39.520
between bug introducing and bug fixing commits. Actually, commit sets. And then these amounts

25:39.520 --> 25:46.760
to 24,000 commits. And then we were able, with this dataset, to evaluate the current

25:46.760 --> 25:52.720
algorithms that are presented in the literature. And as we thought, they're not working well

25:52.720 --> 26:03.840
at all. So this is one of the areas of improvement for research.

26:03.840 --> 26:13.640
One of the improvements that we tried to apply to SZZ was to improve the blame algorithm.

26:13.640 --> 26:19.640
If you're more familiar with Mercurial annotate algorithm, to try to, instead of looking at

26:19.640 --> 26:30.600
lines splitting changes by words and tokens, so you can see past changes by token instead

26:30.600 --> 26:37.680
of by line. This is a visualization from the Linux kernel. This is going to give you a

26:37.680 --> 26:44.560
much more precise view of what changed in the past. For example, it will skip over tab

26:44.560 --> 26:52.680
only changes, white space only changes, and things like that. If you add an if, your code

26:52.680 --> 26:57.640
will be in tandem more. But you're not actually changing everything inside. You're changing

26:57.640 --> 27:06.160
only the if. This actually improved the results, but it was not enough to get to an acceptable

27:06.160 --> 27:11.800
level of accuracy. But it's nice, and we can actually use it in the IDE. We're not doing

27:11.800 --> 27:19.160
it yet, but we will, to give more information to users, because developers use annotate

27:19.160 --> 27:27.200
and git blame a lot. And this is a UI that is a work in progress

27:27.200 --> 27:34.420
for analyzing the risk of a patch. This is a screenshot from our code review tool. So

27:34.420 --> 27:39.080
we are showing the result of the algorithm with the confidence. So in this case, it was

27:39.080 --> 27:45.760
a risky patch with 79% confidence. And we give a few explanations to the developers.

27:45.760 --> 27:51.720
This is one of the most important things. Developers do not always trust developers

27:51.720 --> 27:58.040
like any other user, do not always trust results from machine learning. And so you need to

27:58.040 --> 28:09.360
give them an explanation. And this is another part of the output of our tool. This is again

28:09.360 --> 28:16.160
on our code review tool. We are showing on the functions that are being changed by the

28:16.160 --> 28:25.480
patch if the function is risky or not, and which bugs in the past were involved in this

28:25.480 --> 28:32.360
problem. So developers can try to see if the patch is reintroducing a previously fixed

28:32.360 --> 28:39.880
bug. And they can also know what kind of side effects there are when you make changes to

28:39.880 --> 28:53.760
a given area of the code. Now, we did a lot of stuff for developers.

28:53.760 --> 28:59.080
We trained models for bugs. We trained models for patches. We trained models for tests.

28:59.080 --> 29:06.640
We trained models to predict the facts. Now I'm going to go to a slightly different topic,

29:06.640 --> 29:15.240
even though it's connected. Privacy friendly translations. So we're working on introducing

29:15.240 --> 29:23.240
translations in Firefox. The subtitle was actually translated automatically using Firefox

29:23.240 --> 29:32.320
Translate, which you can use nowadays. The idea is that translation models improved a

29:32.320 --> 29:39.680
lot in recent times. Current cloud-based services do not offer the privacy guarantees that we

29:39.680 --> 29:47.480
like to offer in Firefox. They are closed source. They are not privacy preserving. So

29:47.480 --> 29:53.280
we started a project. It was funded by the European Union to investigate client-side

29:53.280 --> 30:01.760
private translation capabilities in Firefox itself. It is currently available as an add-on

30:01.760 --> 30:06.360
that you can install in Firefox. We support many European languages, and we are working

30:06.360 --> 30:13.120
on supporting even more. We are going to also work on supporting non-European languages

30:13.120 --> 30:23.880
like Chinese, Korean, Japanese, et cetera. And in this case, we use machine learning

30:23.880 --> 30:30.320
on the client side to perform the translation. So your data never leaves your Firefox. The

30:30.320 --> 30:38.640
models are downloaded from our servers, but they run locally on your machine. So the contents

30:38.640 --> 30:44.080
of the web page that you're looking at will never go to Google being or whatever. They

30:44.080 --> 30:51.520
will be translated locally on your machine. We use a few open data sets. Luckily, we have

30:51.520 --> 30:58.280
lots of them from past research. Not all of them have good quality, but many of them have.

30:58.280 --> 31:03.680
But we are looking for more. So if you have suggestions for data sets that we can use,

31:03.680 --> 31:13.520
please let us know. On the data sets, we perform some basic data cleaning, and we use machine

31:13.520 --> 31:21.600
learning-based techniques to clean the data, to remove bad sentence pairs that we believe

31:21.600 --> 31:27.600
are bad. Of course, the data sets that I showed before are open, but sometimes they are just

31:27.600 --> 31:38.480
crawled from the web, so they contain all sorts of bad sentences. Also, HTML tags and

31:38.480 --> 31:42.640
stuff like that, we need to clean them up. Otherwise, the translations will learn to

31:42.640 --> 31:49.960
translate HTML tags. And we use some techniques to increase the size of the data set automatically,

31:49.960 --> 31:56.080
like back translations, translating sentences from one language to the other, and back translating

31:56.080 --> 32:04.240
it in order to increase the size of the data sets.

32:04.240 --> 32:16.400
So we trained a large model on cloud machines, which is pretty large. You can see it's around

32:16.400 --> 32:22.440
800 megabytes. So every language pair, you would need to download 800 megabytes, and

32:22.440 --> 32:33.200
it is super slow. So we can only use that on cloud. So we use some techniques in order

32:33.200 --> 32:40.040
to reduce the size of these models and to make them faster. We use knowledge distillation,

32:40.040 --> 32:47.800
basically using the model, the large model that we trained as a trainer for a student

32:47.800 --> 32:53.640
model, which is much smaller. So you can see that from 800 megabytes, we got 216. I think

32:53.640 --> 32:58.120
now we're around 5, 6, something like that. So it's much smaller, and you can actually

32:58.120 --> 33:04.320
download it on demand from our servers. And we use quantization for further compression

33:04.320 --> 33:14.080
and perf improvements, so moving the data from the model from float 32 to int 8.

33:14.080 --> 33:21.400
Then we compiled the machine translation engine to WebAssembly in order to be able to use

33:21.400 --> 33:29.040
it inside Firefox. We introduced some SIMD extensions into WebAssembly and into Firefox

33:29.040 --> 33:36.200
in order to be able to be even faster when translating, even though we translate a bit

33:36.200 --> 33:47.560
at a time. So it's pretty fast. And the engines are downloaded and updated on demand.

33:47.560 --> 34:08.720
Let me show you a demo.

34:08.720 --> 34:25.920
So you can see the, my Firefox is in Italian, but you can see that it automatically detected

34:25.920 --> 34:33.560
that the page is in French, and it is suggesting me to translate it to Italian. I will change

34:33.560 --> 35:00.920
it to English. Oh, fuck.

35:00.920 --> 35:09.400
So it is downloading the model. Now it's translating. So while it was translating, you already saw

35:09.400 --> 35:13.920
the contents of the first part of the page was already translated, so it's super quick

35:13.920 --> 35:21.040
in the end. And the translation seems to be pretty good. I don't speak French, but I think

35:21.040 --> 35:34.920
it makes sense. You can also use it from the toolbar. So you can choose a language and

35:34.920 --> 35:58.040
translate it to another. Let's do Italian to French. It works.

35:58.040 --> 36:21.800
All right. So if you know any dataset that we can use,

36:21.800 --> 36:26.520
in addition to the ones that we already use, or if you're interested in building a new

36:26.520 --> 36:30.800
great feature in Firefox, or if you want to add support for your language or improving

36:30.800 --> 36:36.120
support for your language, come and talk to us at our booth. We would be really happy

36:36.120 --> 36:43.120
if you could help us. And before we come to an end, let me show you how far we've come.

36:43.120 --> 36:50.200
The dogs have grown, and we have learned that it is possible to tame the complexity of a

36:50.200 --> 36:57.560
large scale software. It is possible to use the past history of development to support

36:57.560 --> 37:04.440
the future of development. And it is possible to use machine learning in a privacy friendly

37:04.440 --> 37:09.760
way and in the open. What else could we do with the data and the

37:09.760 --> 37:15.440
tools that we have at our disposal? I don't know. I'm looking forward to know. I'm looking

37:15.440 --> 37:31.440
forward to see what other wild ideas you and us at Mozilla can come up with. Thank you.

37:31.440 --> 37:36.640
Thank you very much, Madhka, for the amazing talk. Now we're open for questions. If anyone

37:36.640 --> 37:41.560
would like to make a question, please raise your hand so you can take the microphone.

37:41.560 --> 37:53.760
Questions, questions, questions? Hands up. There. Okay, okay. I'm sorry. I'm learning.

37:53.760 --> 38:20.480
I'm new to this. I'm coming up. Hello. I have actually two questions. First question is

38:20.480 --> 38:24.880
have you actually think about the idea to use this mechanism to automatically translate

38:24.880 --> 38:36.880
interface of Mozilla products? Sorry? Testing? Yes. Yeah. So the question is have you think

38:36.880 --> 38:43.440
about mechanism of automatically translating the interface of Mozilla Firefox products

38:43.440 --> 38:48.400
or maybe documentation you already have, like MDN, because it's still a demand to translate

38:48.400 --> 39:13.000
this stuff? I'm sorry. I'm not hearing well. Can you maybe come closer? From here? Okay.

39:13.000 --> 39:19.520
Now it's better? Yes. Okay. So my question is have you tried to use this mechanism of

39:19.520 --> 39:24.960
automatic translation to use this translation for existing interface you have in the products

39:24.960 --> 39:30.760
and especially also documentation part? Because it's kind of vital part when you need to translate

39:30.760 --> 39:34.440
new functionality or you have to translate something new in interface, you need the help

39:34.440 --> 39:39.440
of translator. But if you already know how to translate new stuff, so that means you

39:39.440 --> 39:45.240
already have a dataset, you can actually automatically translate new parts of interface without translator.

39:45.240 --> 39:52.000
Yes. So it is definitely something that could be used to help translators do their job.

39:52.000 --> 39:57.400
We could translate parts of the interface automatically and of course there will always

39:57.400 --> 40:01.920
be some review from actual translator to make sure that the translation makes sense in the

40:01.920 --> 40:08.440
context, especially because Firefox UI sometimes you have very short text and it needs to make

40:08.440 --> 40:12.560
sense. But yes, it's definitely something that we have considered. And actually one

40:12.560 --> 40:18.560
of the datasets that we use from the list, it's not possible to see from the slide, but

40:18.560 --> 40:28.000
it's called Mozilla L10N and they are sentence pairs from our browser UI. People are actually

40:28.000 --> 40:37.240
using it in research for automating translations. Does anyone have any other question? Please

40:37.240 --> 40:48.760
raise your hands if you have any other questions to Marcum. Okay. If not, thank you very much

40:48.760 --> 41:09.400
again, Marcum. Thank you.
