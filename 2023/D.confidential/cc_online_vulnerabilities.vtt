WEBVTT

00:00.000 --> 00:18.560
Hello, everyone.

00:18.560 --> 00:22.960
I am Egole Feuver, a PhD student at the University of Manchester.

00:22.960 --> 00:28.080
In this talk, I will present the result of my research on compartment interface vulnerabilities,

00:28.080 --> 00:31.600
a work that will appear in NDSS 23.

00:31.600 --> 00:40.560
This is the result of a collaboration between Manchester, Bucharest, Rice, and Unicraft.io.

00:40.560 --> 00:46.840
Before starting to talk about interface vulnerabilities, let me bring a little bit of necessary background.

00:46.840 --> 00:52.400
And a very important notion in this work is compartmentalization.

00:52.400 --> 00:57.040
Compartmentalization is about decomposing software into lesser privileged components, such that

00:57.040 --> 01:00.760
components only have access to what they need to do their job.

01:00.760 --> 01:06.200
Compartmentalization is not particularly something new, so let me illustrate it with a real-world

01:06.200 --> 01:08.480
example, web servers.

01:08.480 --> 01:13.720
Typically, web servers are composed of components that do, on the one hand, privileged things

01:13.720 --> 01:18.800
like listening to port 80, and on the other hand, of other components that perform risky

01:18.800 --> 01:22.600
operations like parsing network-provided data.

01:22.600 --> 01:27.680
If we have these two components in the same process, then this process has to be root,

01:27.680 --> 01:33.120
and that's problematic, because if an attacker manages to compromise the network-facing component,

01:33.120 --> 01:37.640
for example, then it will immediately own the root process.

01:37.640 --> 01:42.840
So what people do in practice is decomposing or compartmentalizing the server into two

01:42.840 --> 01:48.400
entities in separate processes, the master, which is privileged and not exposed to risky

01:48.400 --> 01:54.200
operations, and the worker, which is deprivileged and exposed to network data.

01:54.200 --> 01:57.120
Both entities then communicate over shared memory.

01:57.120 --> 02:02.520
Thus, if the worker gets compromised, it will not be able to perform privileged operations

02:02.520 --> 02:04.640
and will remain contained.

02:04.640 --> 02:10.000
Recently, we have seen really nice advances in the field of compartmentalization.

02:10.000 --> 02:14.920
People have been taking more fine grain, more arbitrary, and more automatic approaches to

02:14.920 --> 02:16.800
compartmentalization.

02:16.800 --> 02:22.520
And what these work do is taking arbitrary applications, identifying a particular component

02:22.520 --> 02:29.960
that may be untrusted or risky, or trusted and critical, and compartmentalizing it automatically

02:29.960 --> 02:32.280
or semi-automatically.

02:32.280 --> 02:36.960
The granularity of the component can be very variable, ranging from libraries to blocks

02:36.960 --> 02:38.600
of code.

02:38.600 --> 02:43.160
Notice that I'm talking about compartments here and not processes, as the isolation technology

02:43.160 --> 02:45.320
too is very variable.

02:45.320 --> 02:48.080
In short, the goal of these works is quite ambitious.

02:48.080 --> 02:53.720
It's about compartmentalizing legacy software with a low engineering effort and a low performance

02:53.720 --> 02:55.120
cost.

02:55.120 --> 03:00.480
Unfortunately, as we're highlighting in this work, things are not as easy as they might

03:00.480 --> 03:01.800
seem.

03:01.800 --> 03:07.680
And privileged-separated software, cross-component interfaces are the attack surface.

03:07.680 --> 03:11.880
And there, all sorts of things can go wrong security-wise.

03:11.880 --> 03:14.280
Let me give you a few examples.

03:14.280 --> 03:18.800
Let's say we have two compartments, one on the left, malicious, and the other one on

03:18.800 --> 03:22.160
the right, trusted, protecting some secret.

03:22.160 --> 03:27.400
The compartmentalization mechanism guarantees us that compartment one cannot access compartment

03:27.400 --> 03:30.840
two's memory directly, so that doesn't work.

03:30.840 --> 03:35.880
However, compartment one is still able to do legitimate API calls to compartment two

03:35.880 --> 03:40.220
with, for example, an invalid pointer.

03:40.220 --> 03:44.880
If compartment two doesn't validate the pointer, it will risk exploitation.

03:44.880 --> 03:50.680
Another example is the usage of corrupted indexing information, for example, a size,

03:50.680 --> 03:54.040
index, or bounce, as is done in this function.

03:54.040 --> 03:59.460
Another one is the usage of a corrupted object, such as a tempered file pointer.

03:59.460 --> 04:04.840
And there are many others which will go through partially in the next slide.

04:04.840 --> 04:10.080
In this work, we unify all of these vulnerabilities under the concept of compartment interface

04:10.080 --> 04:13.280
vulnerabilities, or SIVs.

04:13.280 --> 04:18.280
SIVs encompass traditional confused deputies, IAGO attacks, which are SIVs specific for

04:18.280 --> 04:25.440
the system called API, and their references under influence, and probably many others.

04:25.440 --> 04:30.800
They are all attacks revolving around misuse of a legitimate interface.

04:30.800 --> 04:35.880
SIVs are very common when compartmentalizing and modified applications, as we further highlight

04:35.880 --> 04:37.520
in this talk.

04:37.520 --> 04:42.320
They affect all compartmentalization framework because they are a fundamental part of the

04:42.320 --> 04:44.720
problem of privilege separation.

04:44.720 --> 04:51.760
To put it in more precise words, we define SIVs as the set of vulnerabilities that arise

04:51.760 --> 04:58.520
due to lack of or improper control in data flow validation at compartment boundaries.

04:58.520 --> 05:05.200
We observe three classes of SIVs, data leakages, data corruption, and temporal violations.

05:05.200 --> 05:09.440
Within data leakages, we differentiate between address leakages, which can be leveraged to

05:09.440 --> 05:14.580
de-randomize compartments and mount further attacks, and compartment confidential data

05:14.580 --> 05:18.760
leakages, which result in information disclosure.

05:18.760 --> 05:23.640
Both are due to data oversharing and sharing of uninitialized memory.

05:23.640 --> 05:29.040
We have already illustrated a range of data corruption attacks in the previous slide,

05:29.040 --> 05:33.640
but generally they are bound to happen in situations where interface crossing data is

05:33.640 --> 05:36.560
used without appropriate sanitization.

05:36.560 --> 05:40.440
They can affect control as well as non-control data.

05:40.440 --> 05:47.200
Finally, temporal violations include vulnerabilities like expectation of API usage ordering, usage

05:47.200 --> 05:53.200
of corrupted synchronization primitives, or shared memory time of check to time of use.

05:53.200 --> 05:57.720
Temporal violations are usually caused by a wide range of behaviors, including missing

05:57.720 --> 06:03.720
copies, double fetches, and generally lack of enforcement of API semantics.

06:03.720 --> 06:08.880
This is a broad and succinct overview, but the paper provides a full taxonomy, including

06:08.880 --> 06:12.720
an analysis of existing defenses.

06:12.720 --> 06:18.200
So having observed and characterized the problem, we asked a few questions.

06:18.200 --> 06:22.160
How many SIVs are there at legacy imported APIs?

06:22.160 --> 06:25.160
Are all APIs similarly affected by SIVs?

06:25.160 --> 06:30.080
For example, taking library API generally versus module APIs generally, do we observe

06:30.080 --> 06:32.600
systematic differences?

06:32.600 --> 06:36.160
How hard are these SIVs to address when compartmentalizing?

06:36.160 --> 06:38.000
And finally, how bad are they?

06:38.000 --> 06:42.920
If for some reason you don't fix one of them or just decide to not fix them at all, what

06:42.920 --> 06:49.240
is the impact on the guarantees that compartmentalization can give to you?

06:49.240 --> 06:53.840
We believe that it is really critical to understand these points to be able to provide countermeasures

06:53.840 --> 06:58.000
that are adequate, systematic, and usable.

06:58.000 --> 07:03.400
And so the approach that we take in this work to answer these questions is to design a tool,

07:03.400 --> 07:08.400
and more particularly a fuzzer, specialized to detect SIVs at arbitrary interfaces, and

07:08.400 --> 07:10.960
we call this tool Confuzz.

07:10.960 --> 07:16.200
Then we apply Confuzz at scale to a range of applications and interfaces to gather a

07:16.200 --> 07:18.800
dataset of real-world SIVs.

07:18.800 --> 07:25.520
Finally, we study, systematize, patternize the resulting dataset to extract numerous

07:25.520 --> 07:29.520
insights on the problem of SIVs in compartmentalization.

07:29.520 --> 07:33.840
In the next slides, I will give a quick overview of Confuzz before focusing on the dataset

07:33.840 --> 07:36.680
and insights.

07:36.680 --> 07:40.560
So let me give you a high-level overview of the fuzzer first.

07:40.560 --> 07:46.720
Taking unmodified applications, we instrument them to intercept cross-compartment calls.

07:46.720 --> 07:52.480
These are freely defined, for example, a particular library boundary or an internal component

07:52.480 --> 07:54.280
interface.

07:54.280 --> 08:00.560
We based our prototype on dynamic binary instrumentation using Intel PIN, but also explored other

08:00.560 --> 08:04.760
instrumentation approaches, for example, LLVM-based.

08:04.760 --> 08:10.680
The interface between the trusted and untrusted components is automatically detected using

08:10.680 --> 08:13.440
binary debug information.

08:13.440 --> 08:19.360
Our fuzzing monitor then drives the exploration by ordering mutations of the dataflow to simulate

08:19.360 --> 08:24.660
attacks from the malicious compartment to the trusted compartment.

08:24.660 --> 08:29.240
The workload used to drive the program is application-specific, for example, benchmark

08:29.240 --> 08:32.800
tools, test suites, custom workloads, etc.

08:32.800 --> 08:36.320
You could even plug another fuzzer like OSS fuzz there.

08:36.320 --> 08:41.760
Finally, the fuzzer automatically triages and stores crash reports.

08:41.760 --> 08:48.120
That includes deduplicating, reproducing, minimizing, etc.

08:48.120 --> 08:52.320
The paper provides much greater details on these technical matters, and I would be happy

08:52.320 --> 08:55.320
to elaborate if you have questions.

08:55.320 --> 09:00.680
Using Confuzz, we gathered a substantial dataset that we carefully dissected.

09:00.680 --> 09:05.520
Here you can see the paper's big table that summarizes the dataset.

09:05.520 --> 09:07.680
Let's have a closer look at it.

09:07.680 --> 09:15.700
Overall, we applied Confuzz to 25 applications and 36 APIs for a total of 39 scenarios.

09:15.700 --> 09:21.760
We considered a selection of library APIs, module APIs, and internal component APIs,

09:21.760 --> 09:26.400
trying to focus on scenarios that make sense in popular software.

09:26.400 --> 09:32.600
In fact, 16 of these scenarios have been previously considered by about 12 studies in the literature,

09:32.600 --> 09:35.760
and the attacks that we find apply to them as well.

09:35.760 --> 09:40.560
In total, we find 629 SIFs.

09:40.560 --> 09:46.600
We classify these SIFs in five impact classes, read impact, write impact, execution, memory

09:46.600 --> 09:51.560
allocator corruption, and null-pointing reference.

09:51.560 --> 09:56.440
With this data, the first questions that we try to answer are how many SIFs are there

09:56.440 --> 10:04.040
at legacy or unmodified arbitrary APIs, and are all APIs or codes similarly affected?

10:04.040 --> 10:09.480
And looking into this, we quickly confirm that SIFs are absolutely widespread among

10:09.480 --> 10:12.320
unmodified APIs or code.

10:12.320 --> 10:17.640
Having said that, we also highlighted significant disparities of prevalence among scenarios,

10:17.640 --> 10:20.040
and that's the really interesting part.

10:20.040 --> 10:26.080
For example, we observed variations of SIF counts from 0 to 105 across APIs.

10:26.080 --> 10:27.440
That's quite significant.

10:27.440 --> 10:32.120
Take a look at this plot, which represents for each scenario, the number of vulnerable

10:32.120 --> 10:35.520
API endpoints versus non-vulnerable.

10:35.520 --> 10:41.480
It clearly shows that SIF prevalence among applications and APIs is very heterogeneous.

10:41.480 --> 10:48.560
We have large and almost totally SIF-free APIs, and small and fully vulnerable APIs.

10:48.560 --> 10:55.840
In fact, we show an entire absence of correlation between API size and SIF count in this dataset.

10:55.840 --> 11:03.380
So while clearly, yes, SIFs are widespread, no, not all APIs are similarly affected.

11:03.380 --> 11:09.600
This motivates us to look into the patterns and effects that influence these observations.

11:09.600 --> 11:15.580
And doing so, we observe recurring API design patterns that result in SIFs.

11:15.580 --> 11:20.720
This really comforts us in the idea that the presence of SIFs is influenced by structural

11:20.720 --> 11:26.900
properties of the API, rather than API size or quantity of shared data.

11:26.900 --> 11:32.040
In this talk, I will present one of these patterns, but there are more in the paper.

11:32.040 --> 11:36.160
And the particular pattern I want to go through concerns modular APIs.

11:36.160 --> 11:42.680
Indeed, we notice that modular or module APIs are the most SIF-vulnerable interfaces in

11:42.680 --> 11:44.280
our study.

11:44.280 --> 11:50.440
On average, we observe that module APIs feature more SIFs and worse SIFs than any other class

11:50.440 --> 11:52.160
of APIs.

11:52.160 --> 11:56.200
And looking at the structure of these interfaces, it makes sense.

11:56.200 --> 12:01.720
Unlike library APIs, module APIs must be very generic and yield high performance.

12:01.720 --> 12:07.400
As a consequence, we have patterns with the application exposing its core internals and

12:07.400 --> 12:12.400
its core state to the module to achieve their generosity and performance.

12:12.400 --> 12:17.440
But this results in a much larger attack surface exposed to the module.

12:17.440 --> 12:23.120
Take the example of this data structure exposed to potential malicious modules by the Apache

12:23.120 --> 12:25.040
HttpD core.

12:25.040 --> 12:32.560
It is very complex with over 75 fields, 60% of which point us, referencing core data structures

12:32.560 --> 12:37.600
like memory pools, connection state structures, or mutexes.

12:37.600 --> 12:45.940
What we observe with this pattern is a somewhat counterintuitive thing.

12:45.940 --> 12:52.520
Security is not always good for compartmentalization, and in many cases, it can even be counterproductive.

12:52.520 --> 12:57.280
This is only one of the patterns that we highlight, and there are more in the paper.

12:57.280 --> 13:04.000
Now having shown that SIFs are widespread but affecting applications unequally or APIs,

13:04.000 --> 13:07.080
let's look at their concrete security impact.

13:07.080 --> 13:11.040
And the first thing that we confirm is that they are quite impactful.

13:11.040 --> 13:18.920
In fact, over 75% of scenarios present in our dataset show at least one right vulnerability.

13:18.920 --> 13:25.040
And worse than that, about 70% of right and read and 50% of executed vulnerabilities

13:25.040 --> 13:33.900
are arbitrary, which means that when the attacker controls a right or read primitive, then they

13:33.900 --> 13:37.320
are likely to be able to read and write anywhere.

13:37.320 --> 13:42.240
And while only a smaller proportion of these scenarios have execution impact, it is likely

13:42.240 --> 13:47.920
that read and write primitives will be combinable to achieve execution capabilities.

13:47.920 --> 13:53.000
In this talk, I will be concretely illustrating this impact with practical scenarios and real-world

13:53.000 --> 13:59.540
SIFs taken from the dataset where we demonstrate key extraction from a protected OpenSSL.

13:59.540 --> 14:03.680
Once again here, we show more details in the paper.

14:03.680 --> 14:10.200
So here we assume a scenario with two compartments where the goal is to isolate OpenSSL.

14:10.200 --> 14:15.320
For example, from a compromised web server engine exon.

14:15.320 --> 14:21.280
Isolating OpenSSL or part of OpenSSL is a popular application of compartmentalization,

14:21.280 --> 14:23.840
both in the literature and in the industry.

14:23.840 --> 14:31.160
Thus here, the compartment interface and therefore the attack surface is the OpenSSL public API.

14:31.160 --> 14:37.280
Unfortunately, we find several SIFs that enable for read, write and execution impact.

14:37.280 --> 14:43.080
Take this option setting primitive, for example, which is part of the OpenSSL public API.

14:43.080 --> 14:49.360
It dereferences an interface crossing pointer, sets it and returns it, clearly resulting

14:49.360 --> 14:52.480
in an arbitrary read and write oracle.

14:52.480 --> 14:57.360
Any attacker that can compromise the application's control flow will likely be able to extract

14:57.360 --> 14:59.440
SSL keys easily.

14:59.440 --> 15:05.120
Thus, clearly if the API is not carefully enough sanitized, the benefits will be pretty

15:05.120 --> 15:09.960
low at most a form of weak hardening.

15:09.960 --> 15:15.160
Now you could tell me that it's not a good idea to protect at the public API anyways

15:15.160 --> 15:21.600
and that we should rather choose the OpenSSL internal key API that's much smaller.

15:21.600 --> 15:23.120
So let's take a look at it.

15:23.120 --> 15:28.200
This time we have engine ex and most of OpenSSL in the untrusted compartment.

15:28.200 --> 15:33.560
While we have the small key handling part of OpenSSL together with the keys in the protected

15:33.560 --> 15:34.560
compartment.

15:34.560 --> 15:38.920
Unfortunately, here too we find several SIFs.

15:38.920 --> 15:42.440
Take a look at this function of the internal key API, for example.

15:42.440 --> 15:47.440
I only put the signature for simplicity's sake because the function is implemented in

15:47.440 --> 15:49.800
per generated assembly.

15:49.800 --> 15:56.080
You can manipulate the in pointer to point to the key that you cannot directly access

15:56.080 --> 16:00.600
encrypt with a known key and then decrypt to get the secret.

16:00.600 --> 16:05.920
Hence, here again, attackers that can manage to compromise the application are likely to

16:05.920 --> 16:09.520
be able to easily extract the key.

16:09.520 --> 16:14.520
Unfortunately here, fixing this SIFs requires to make the components stateful, which is

16:14.520 --> 16:17.120
a fairly drastic design change.

16:17.120 --> 16:24.000
Overall, through these two examples, I showed how existing OpenSSL isolation strategies

16:24.000 --> 16:30.240
collapse when confronted to SIFs and how important they are security wise.

16:30.240 --> 16:33.920
To conclude this talk, let's take a quick look at countermeasures.

16:33.920 --> 16:35.560
How do we tackle SIFs?

16:35.560 --> 16:38.160
Overall, we see two ways.

16:38.160 --> 16:43.000
First, making progress on automatic and systematic countermeasures.

16:43.000 --> 16:47.760
Our paper highlights the limitations as part of our SIF taxonomy.

16:47.760 --> 16:54.360
Second, learning from our study of patterns, we also believe that software component APIs

16:54.360 --> 17:00.640
should be designed to feature low compartmentalization complexity in the first place.

17:00.640 --> 17:04.160
We provide a set of guidelines to achieve this.

17:04.160 --> 17:08.360
The two approaches are complementary.

17:08.360 --> 17:14.280
Even in the presence of countermeasures, well-designed APIs are wishable as the first point is known

17:14.280 --> 17:16.880
to be fundamentally harder.

17:16.880 --> 17:21.000
I will not have enough time to go over all the guidelines, but let me try to give you

17:21.000 --> 17:23.360
the gist of them.

17:23.360 --> 17:28.840
First, not every interface is a good boundary for privilege separation.

17:28.840 --> 17:33.080
Maybe a particular API doesn't fit privilege separation, and that's fine.

17:33.080 --> 17:36.080
In this case, it will be hard to harden anyways.

17:36.080 --> 17:41.800
Second, we recommend that major attention should be dedicated to reducing the complexity

17:41.800 --> 17:47.200
of interface crossing objects, avoiding, for example, sharing of resource handle, system

17:47.200 --> 17:52.280
resource handles, complex tracks, synchronization primitives, etc.

17:52.280 --> 17:56.000
If this is not possible, it should bring us back to the first point.

17:56.000 --> 18:00.400
The interface is probably not the right point to compartmentalize, for example, because

18:00.400 --> 18:03.160
components are too deeply entangled.

18:03.160 --> 18:09.840
Third, compartmentalizable components should enforce API semantics to be safe, for example,

18:09.840 --> 18:12.720
securing or concurrency support.

18:12.720 --> 18:18.560
Under distrust scenarios, it is not acceptable anymore to assume that the caller will respect

18:18.560 --> 18:21.680
them or face the consequences.

18:21.680 --> 18:25.480
We are slowly coming towards the end of this talk, so let me summarize the key points that

18:25.480 --> 18:27.760
I wanted to make.

18:27.760 --> 18:34.160
Civs should be at the center of every compartmentalization approach, and you will likely not achieve

18:34.160 --> 18:37.880
tangible security benefits without considering them.

18:37.880 --> 18:43.440
API design patterns influence the presence of Civs and their severity.

18:43.440 --> 18:48.120
Overall, it's not so much about the size of the API, it's about the complexity of

18:48.120 --> 18:51.040
API crossing objects.

18:51.040 --> 18:54.120
Addressing Civs is not just a matter of writing a few checks.

18:54.120 --> 19:01.280
In fact, strong solutions often require refactoring the API.

19:01.280 --> 19:09.200
Because compartmentalizing apps goes much further than just setting and enforcing bounds.

19:09.200 --> 19:13.440
We want this work to be an appeal for more research towards addressing the problem of

19:13.440 --> 19:20.040
Civs, systematically finding them, addressing them, or telling you what interface make good

19:20.040 --> 19:23.160
compartmentalization boundaries.

19:23.160 --> 19:27.460
If you are interested in this work, I invite you to check out our paper and the code and

19:27.460 --> 19:29.520
data set of confuzz.

19:29.520 --> 19:32.680
I will now be more than happy to take questions.

19:32.680 --> 19:33.680
Thank you.

19:33.680 --> 20:01.360
Okay.

20:01.360 --> 20:10.280
Thank you, Hugo, for this very accessible talk on this important topic of securing interfaces.

20:10.280 --> 20:14.000
One question maybe that I can start with is something that you brought up yourself as

20:14.000 --> 20:15.000
well.

20:15.000 --> 20:21.480
You say it's more about compartmentalization, but it also applies obviously to TEs.

20:21.480 --> 20:24.640
Can you comment a bit on that?

20:24.640 --> 20:26.240
Is that something you consider?

20:26.240 --> 20:32.000
Confuzz, your physics could be extended to something like Gramine?

20:32.000 --> 20:37.120
Actually, so maybe there are two different parts.

20:37.120 --> 20:42.960
I think the conceptual part about compartment interface vulnerabilities, maybe we could

20:42.960 --> 20:48.640
remove the compartment out of compartment interface vulnerabilities and just get interface

20:48.640 --> 20:49.800
vulnerabilities.

20:49.800 --> 20:55.560
I think it has also been described by other works previously, notably some of the work

20:55.560 --> 20:56.560
that you did, Joe.

20:56.560 --> 21:00.080
I think that applies to TEs really, really well.

21:00.080 --> 21:07.920
I think it's just a generic problem about interfaces and that fully applies to TEs.

21:07.920 --> 21:15.600
Regarding the fuzzer, from a very technical point of view, I think that it might need

21:15.600 --> 21:23.560
some adaptation to be run on existing TE software, but it's absolutely feasible.

21:23.560 --> 21:27.240
And yeah, I think that it could apply there as well.

21:27.240 --> 21:32.360
We didn't really explore it because obviously at some point we needed to restrict the scope

21:32.360 --> 21:34.800
of what we're doing, but I think it...

21:34.800 --> 21:36.240
That makes sense.

21:36.240 --> 21:43.520
So following up on that as well, I think you mentioned in your slides, one of the technologies

21:43.520 --> 21:47.880
that you could use for compartmentalization is not only TEs, it's also something like

21:47.880 --> 21:55.840
SHERRI, which uses capabilities, and I'm wondering, TEs are not great in these vulnerabilities

21:55.840 --> 22:00.440
because you have these confused deputy attacks that you explained also where you have a pointer

22:00.440 --> 22:02.560
that you essentially can dereference.

22:02.560 --> 22:10.360
And with SHERRI, with capabilities, you have native mitigations for many of those capabilities,

22:10.360 --> 22:13.400
I think were made with the idea of avoiding confused deputies.

22:13.400 --> 22:18.400
So can you comment a bit on what the underlying technology can mean for the vulnerability

22:18.400 --> 22:21.320
of compartmentalization essentially?

22:21.320 --> 22:25.440
So I'm not sure if I can...

22:25.440 --> 22:29.080
I don't think I can share my screen, but maybe I can.

22:29.080 --> 22:30.080
No, no.

22:30.080 --> 22:32.800
But you can put a link maybe in the...

22:32.800 --> 22:33.800
Yeah.

22:33.800 --> 22:34.800
... for people.

22:34.800 --> 22:39.520
So actually in the paper, we did talk about this, so I'm just gonna...

22:39.520 --> 22:43.160
I don't think I can share my screen, but maybe I can.

22:43.160 --> 22:45.720
Oh, my God, I'm sorry.

22:45.720 --> 22:47.400
I'm sorry, I just broke everything.

22:47.400 --> 22:49.120
I just posted the link.

22:49.120 --> 22:52.960
I don't know if I triggered something terrible, but...

22:52.960 --> 22:54.200
I think I see the link.

22:54.200 --> 22:57.040
I think you unmuted the tab or something.

22:57.040 --> 22:59.640
So the paper goes in in case of that.

22:59.640 --> 23:02.880
Can you summarize maybe in the minute that remains?

23:02.880 --> 23:04.520
Absolutely, yes.

23:04.520 --> 23:11.040
So SHERRI provides some features that, as you said, are really nice in addressing some

23:11.040 --> 23:18.560
of the spatial part of the compartment interface spectrum, of the CF spectrum.

23:18.560 --> 23:20.640
It does not solve everything.

23:20.640 --> 23:22.840
It's not magic.

23:22.840 --> 23:27.520
Many of the leakage issues remain.

23:27.520 --> 23:34.200
Many of the temporal issues remain as well, because to some extent, they are a little

23:34.200 --> 23:40.360
bit more high level than just spatial things on memory.

23:40.360 --> 23:42.080
So they still apply.

23:42.080 --> 23:48.360
For example, the issues with ordering of interface calls.

23:48.360 --> 23:53.920
If you have an interface that has some ordering expectations, for example, calling function

23:53.920 --> 24:00.280
one before function two, and you don't respect that, SHERRI is not necessarily going to help

24:00.280 --> 24:02.720
you.

24:02.720 --> 24:03.920
So this is going to remain.

24:03.920 --> 24:10.920
So it does address part of it, but it's not everything.
