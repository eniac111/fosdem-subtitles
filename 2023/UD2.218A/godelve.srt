1
0:00:00.000 --> 0:00:09.120
Okay, thank you.

2
0:00:09.120 --> 0:00:11.360
We have two traditions here in the Go Dev Room.

3
0:00:11.360 --> 0:00:14.400
That is that we start with a state of Go and then it's around lunchtime.

4
0:00:14.400 --> 0:00:18.220
We always have the next state, which is the state of Delve.

5
0:00:18.220 --> 0:00:20.640
So let's all get into Delve.

6
0:00:20.640 --> 0:00:29.880
Let's go debugging.

7
0:00:29.880 --> 0:00:32.360
You might be muted to that me quickly.

8
0:00:32.360 --> 0:00:33.840
There is a switch on there.

9
0:00:33.840 --> 0:00:34.840
Test.

10
0:00:34.840 --> 0:00:35.840
Good?

11
0:00:35.840 --> 0:00:36.840
Perfect.

12
0:00:36.840 --> 0:00:37.840
All right, let's try this again.

13
0:00:37.840 --> 0:00:38.840
Hello, everybody.

14
0:00:38.840 --> 0:00:40.960
My name is Derek Parker.

15
0:00:40.960 --> 0:00:49.240
I am the author of Delve and I continue to maintain the project along with my lead co-maintainer,

16
0:00:49.240 --> 0:00:53.440
Alessandro, who is also in the crowd today.

17
0:00:53.440 --> 0:01:00.840
And as mentioned, it's been kind of a tradition here at Bosdom to piggyback on the state

18
0:01:00.840 --> 0:01:03.240
of Go and talk about the state of Delve.

19
0:01:03.240 --> 0:01:06.400
So this talk will be kind of a two-parter.

20
0:01:06.400 --> 0:01:11.040
I'll start with the state of Delve and then I'll go into the main talk, which is debugging

21
0:01:11.040 --> 0:01:12.760
Go programs with eBPF.

22
0:01:12.760 --> 0:01:20.400
Now if you're unfamiliar with what eBPF is as a technology, fret not.

23
0:01:20.400 --> 0:01:25.960
I will go in and kind of explain it in more detail throughout the course of the talk as

24
0:01:25.960 --> 0:01:30.800
we kind of get into the real meat of everything.

25
0:01:30.800 --> 0:01:34.320
So just to introduce myself a little bit more, again, my name is Derek Parker.

26
0:01:34.320 --> 0:01:38.040
I'm a senior software engineer at Red Hat.

27
0:01:38.040 --> 0:01:42.100
If you would like to follow me, I am Dirk the Daring on Twitter.

28
0:01:42.100 --> 0:01:48.960
And at Red Hat I work on Delve and Go itself.

29
0:01:48.960 --> 0:01:54.920
So the first thing that I want to start and talk about is the state of Delve.

30
0:01:54.920 --> 0:02:02.560
So what I'll go through is essentially what's changed since the last Bosdom and actually

31
0:02:02.560 --> 0:02:04.800
since the last in-person Bosdom.

32
0:02:04.800 --> 0:02:10.840
So I was actually here in 2020 presenting a different talk before the world ended.

33
0:02:10.840 --> 0:02:16.980
And I'm happy to be here again in person with everybody and being able to kind of talk and

34
0:02:16.980 --> 0:02:18.760
catch up and present these things.

35
0:02:18.760 --> 0:02:21.760
So thanks everybody for coming and for attending this talk.

36
0:02:21.760 --> 0:02:30.440
I really appreciate it.

37
0:02:30.440 --> 0:02:34.880
So one of the big milestones that I kind of want to call out is that Delve turns nine

38
0:02:34.880 --> 0:02:36.400
this year.

39
0:02:36.400 --> 0:02:40.400
So to celebrate that on the count of three, everybody in the room, we're going to sing

40
0:02:40.400 --> 0:02:41.400
happy birthday.

41
0:02:41.400 --> 0:02:45.180
One, two, I'm just kidding.

42
0:02:45.180 --> 0:02:46.880
Maybe next year for the 10th anniversary.

43
0:02:46.880 --> 0:02:49.480
I'll hold that off for a little bit.

44
0:02:49.480 --> 0:02:55.560
But the Delve project was started in 2014.

45
0:02:55.560 --> 0:02:59.320
And yeah, it turns nine still going strong.

46
0:02:59.320 --> 0:03:03.880
And I appreciate everybody who uses it, contributes to it.

47
0:03:03.880 --> 0:03:07.240
It's just really fantastic to see.

48
0:03:07.240 --> 0:03:13.720
So I'll go into some statistics a little bit about what's happened in the last couple of

49
0:03:13.720 --> 0:03:14.720
years.

50
0:03:14.720 --> 0:03:19.240
So as far as in-person FOSDAM, we've done 18 different releases.

51
0:03:19.240 --> 0:03:27.480
Now the way we do releases of Delve is somewhat scheduled, somewhat ad hoc.

52
0:03:27.480 --> 0:03:35.800
So we always produce a new release when the first release candidate of the new Go version

53
0:03:35.800 --> 0:03:36.800
comes out.

54
0:03:36.800 --> 0:03:43.200
So anytime a new Go version comes out, we ensure that the day that it's released, you

55
0:03:43.200 --> 0:03:44.200
can debug it.

56
0:03:44.200 --> 0:03:47.680
Once you compile your code, do everything, you have a debugger that's going to work with

57
0:03:47.680 --> 0:03:49.880
that version.

58
0:03:49.880 --> 0:03:53.840
And then aside from that, we have kind of minor releases that come out throughout the

59
0:03:53.840 --> 0:03:54.840
year.

60
0:03:54.840 --> 0:04:00.680
And in between the releases, the fixed bugs add new features, things like that.

61
0:04:00.680 --> 0:04:07.760
So within that time frame, we've added support for numerous different Go versions.

62
0:04:07.760 --> 0:04:10.880
So 114 all the way through 120.

63
0:04:10.880 --> 0:04:14.920
And as I mentioned, 120 was just released the other day.

64
0:04:14.920 --> 0:04:17.800
We've supported it since the first RC.

65
0:04:17.800 --> 0:04:24.600
So you always have a debugger to kind of go through your code even before the official

66
0:04:24.600 --> 0:04:28.880
release actually comes out.

67
0:04:28.880 --> 0:04:33.400
During that time, we've also added four new operating system and architecture combinations.

68
0:04:33.400 --> 0:04:40.240
So with Delve, we strive to enable you to debug on any operating system and architecture

69
0:04:40.240 --> 0:04:42.800
that Go itself supports.

70
0:04:42.800 --> 0:04:46.960
We're getting closer and closer to that goal with each passing release.

71
0:04:46.960 --> 0:04:51.880
So I'm proud to say, you know, within the last few years, we added support for four

72
0:04:51.880 --> 0:04:54.560
new platforms.

73
0:04:54.560 --> 0:05:02.520
And there's a few more already in the works, and we'll be releasing later this year.

74
0:05:02.520 --> 0:05:07.480
So I want to call out a few major new features that have been developed.

75
0:05:07.480 --> 0:05:14.760
The first is we've integrated a DAP server into Delve, which is probably not something

76
0:05:14.760 --> 0:05:19.880
that's super relevant to everybody here unless you're like the author of like an editor or

77
0:05:19.880 --> 0:05:20.960
something like that.

78
0:05:20.960 --> 0:05:23.160
It's really for editor integration.

79
0:05:23.160 --> 0:05:31.200
But from a user's perspective, it really improves the usability of Delve within editors, such

80
0:05:31.200 --> 0:05:35.200
as VS Code and things like that.

81
0:05:35.200 --> 0:05:42.200
We've added support for Apple Silicon, and that happened, you know, really quickly once

82
0:05:42.200 --> 0:05:48.400
we were able to kind of get our hands on the hardware and everything like that.

83
0:05:48.400 --> 0:05:51.320
We added the ability to generate core dumps from running processes.

84
0:05:51.320 --> 0:05:56.600
So while you're in a debug session, you can ad hoc, generate a core dump, save that away,

85
0:05:56.600 --> 0:06:00.920
and use that, debug it later.

86
0:06:00.920 --> 0:06:05.120
We've added support for hardware watch points, which I think is a really, really cool feature.

87
0:06:05.120 --> 0:06:13.800
And kind of difficult to do with Go due to some kind of internal things of how Go kind

88
0:06:13.800 --> 0:06:18.760
of looks at the stack and changes stack and stuff like changes Go routine stacks as the

89
0:06:18.760 --> 0:06:20.640
stack grows, things like that.

90
0:06:20.640 --> 0:06:24.000
But we were able to implement them and get them working.

91
0:06:24.000 --> 0:06:29.120
So if you're unaware of what hardware watch points are, it's a really cool feature where

92
0:06:29.120 --> 0:06:34.200
you can say like, I want to watch this particular variable or this particular address and memory,

93
0:06:34.200 --> 0:06:38.840
and I want to know, I want the debugger to stop any time that value is read or changed,

94
0:06:38.840 --> 0:06:39.840
right?

95
0:06:39.840 --> 0:06:45.520
So it's, you're basically just saying like, telling the debugger what you want to do and

96
0:06:45.520 --> 0:06:47.800
letting it do the heavy lifting for you.

97
0:06:47.800 --> 0:06:51.160
Really cool feature.

98
0:06:51.160 --> 0:06:56.280
And as was just shown in the previous talk, we've improved some of the filtering and grouping

99
0:06:56.280 --> 0:06:57.800
for Go routine output.

100
0:06:57.800 --> 0:07:01.720
So you can filter by label, you can filter by all different kinds of things.

101
0:07:01.720 --> 0:07:07.320
So in massively concurrent and parallel programs where you might have tons and tons of different

102
0:07:07.320 --> 0:07:14.500
Go routines, we've improved a lot of the introspection on that and being able to kind of filter out

103
0:07:14.500 --> 0:07:19.080
and get the information that you really need.

104
0:07:19.080 --> 0:07:22.360
We've also added an experimental EBPF-based tracing backend.

105
0:07:22.360 --> 0:07:26.840
So that's what I'm going to be talking about today.

106
0:07:26.840 --> 0:07:29.680
And we also added support for debug info find.

107
0:07:29.680 --> 0:07:34.080
So this is really cool for a lot of operating systems where maybe you're debugging a package

108
0:07:34.080 --> 0:07:39.960
that you installed via your package manager and the like the dwarf, the debug information

109
0:07:39.960 --> 0:07:41.480
is not included with the binary.

110
0:07:41.480 --> 0:07:44.040
Maybe it's in a different package or something like that.

111
0:07:44.040 --> 0:07:48.360
We've integrated with debug info find to be able to automatically download those debug

112
0:07:48.360 --> 0:07:54.440
packages for you so that you can have a fruitful and successful debugging session.

113
0:07:54.440 --> 0:07:56.040
And there's also been a lot more.

114
0:07:56.040 --> 0:08:00.760
If you want a look at all of the details, go ahead and check out the changelog and the

115
0:08:00.760 --> 0:08:01.760
repo.

116
0:08:01.760 --> 0:08:03.560
It'll detail all of the changes that we've made.

117
0:08:03.560 --> 0:08:12.120
Next thing I want to talk about is a few little upcoming features that I want to tease.

118
0:08:12.120 --> 0:08:17.520
So one of the biggest ones is we're working on support for two new architectures.

119
0:08:17.520 --> 0:08:23.200
So PowerPC 64LE and S390X.

120
0:08:23.200 --> 0:08:29.300
My colleague Alejandro is working on the PowerPC 64LE port and he's in the crowd as well.

121
0:08:29.300 --> 0:08:34.680
So thank you for your work on that.

122
0:08:34.680 --> 0:08:37.320
We're looking at some more improvements to the EBPF tracing backend.

123
0:08:37.320 --> 0:08:42.520
I'll go into some more detail on that as well during this talk.

124
0:08:42.520 --> 0:08:48.000
We're also working on the ability to debug multiple processes simultaneously.

125
0:08:48.000 --> 0:08:53.440
My co-maintainer Alejandro is working on that and we're hoping to land that pretty

126
0:08:53.440 --> 0:08:54.440
soon.

127
0:08:54.440 --> 0:09:00.160
So that would be like if your process forks or anything like that creates new child processes,

128
0:09:00.160 --> 0:09:05.400
you can debug all of them within a single session.

129
0:09:05.400 --> 0:09:09.360
Another thing that we want to work on this year is improved function call support across

130
0:09:09.360 --> 0:09:10.360
architectures.

131
0:09:10.360 --> 0:09:15.680
So that was a big feature that landed in Delve as well, the ability to call a function while

132
0:09:15.680 --> 0:09:18.360
you're debugging your program.

133
0:09:18.360 --> 0:09:20.720
It's very architecture specific.

134
0:09:20.720 --> 0:09:24.960
So one of the things that we want to do throughout this year is improve support for that across

135
0:09:24.960 --> 0:09:27.600
different architectures.

136
0:09:27.600 --> 0:09:28.960
And there's tons more.

137
0:09:28.960 --> 0:09:35.640
We're always working on new things and we also always try to gather community feedback

138
0:09:35.640 --> 0:09:37.240
and user feedback and stuff like that.

139
0:09:37.240 --> 0:09:44.280
So since I'm here and other maintainers of Delve are here, if you want to come and tell

140
0:09:44.280 --> 0:09:47.200
us something that you would like us to implement or something that you would like to focus

141
0:09:47.200 --> 0:09:52.440
on, feel free to come chat with us.

142
0:09:52.440 --> 0:09:58.600
So now with that said and done, I want to move on to the real portion of this talk which

143
0:09:58.600 --> 0:10:03.440
is debugging and tracing Go programs with EBPF.

144
0:10:03.440 --> 0:10:09.720
Now it's really cool that this talk comes after the talk right before because I think

145
0:10:09.720 --> 0:10:13.960
like the tracing feature in Delve is somewhat underutilized.

146
0:10:13.960 --> 0:10:18.640
And I think it's really good for debugging concurrent programs and seeing the interactions

147
0:10:18.640 --> 0:10:21.940
between Go routines as your program is actually running.

148
0:10:21.940 --> 0:10:29.240
So if you're unfamiliar with what tracing is, I'll show a little demo, but essentially

149
0:10:29.240 --> 0:10:34.120
what we're talking about here is instead of going into a full on debug session, what you're

150
0:10:34.120 --> 0:10:36.280
really doing is kind of like spying on your program.

151
0:10:36.280 --> 0:10:40.480
So if you're familiar with S trace, it's the same concept except for the functions that

152
0:10:40.480 --> 0:10:44.560
you're writing as opposed to the interactions with the kernel, right, like the system calls

153
0:10:44.560 --> 0:10:45.880
and things like that.

154
0:10:45.880 --> 0:10:52.400
So you can kind of spy and see like what functions are being executed, what are their inputs,

155
0:10:52.400 --> 0:10:58.040
what are the outputs, what Go routines are executing that function, so on and so forth.

156
0:10:58.040 --> 0:11:08.920
So to show a little demo of it real quick, let me increase my screen size a little bit.

157
0:11:08.920 --> 0:11:15.880
It may still be hard for folks in the back to see, but hopefully that's good enough.

158
0:11:15.880 --> 0:11:20.680
So what I've done here is instead of typing everything directly on the console, I've created

159
0:11:20.680 --> 0:11:25.320
a little makefile just so that you can see kind of the commands up there and they don't

160
0:11:25.320 --> 0:11:26.880
disappear as I run them.

161
0:11:26.880 --> 0:11:30.640
But the first thing that we're going to do is we're just going to run a simple trace.

162
0:11:30.640 --> 0:11:36.520
So to do this, we use the trace subcommand of Delve and what you provide to it as an

163
0:11:36.520 --> 0:11:43.640
argument is a regular expression and what Delve will do internally is set a trace point

164
0:11:43.640 --> 0:11:45.860
on any function that matches that regular expression.

165
0:11:45.860 --> 0:11:53.160
So you can do something like main.star to trace anything in the main package, extrapolate

166
0:11:53.160 --> 0:11:56.900
that out to any other package, and it's a really cool feature.

167
0:11:56.900 --> 0:12:03.680
So just to kind of show how it works, we can go here and say make trace and we see the

168
0:12:03.680 --> 0:12:04.680
output there.

169
0:12:04.680 --> 0:12:10.520
So to explain the output a little bit, you have like the single line or the single arrow

170
0:12:10.520 --> 0:12:15.140
is the call, the double arrow is the return.

171
0:12:15.140 --> 0:12:20.960
You can see there it labels what go routine is running and calling that function.

172
0:12:20.960 --> 0:12:25.380
You can see the arguments to that function and then you can also see the return value.

173
0:12:25.380 --> 0:12:29.260
So again, really cool and useful for like if you have a bunch of different go routines,

174
0:12:29.260 --> 0:12:34.360
you can kind of see the interactions of them and see what go routines are doing at any

175
0:12:34.360 --> 0:12:36.240
given time.

176
0:12:36.240 --> 0:12:42.320
Another option that you can do is you can say if you pass the stack flag and give it

177
0:12:42.320 --> 0:12:46.680
an argument, you can get a stack trace any time one of the trace points are hit.

178
0:12:46.680 --> 0:12:55.520
So if we say trace with stack, you see we get kind of a similar output but we get a

179
0:12:55.520 --> 0:12:56.520
stack trace as well.

180
0:12:56.520 --> 0:13:03.040
So you can kind of see a little bit more detailed information as your program is being traced.

181
0:13:03.040 --> 0:13:14.400
So, the real like meat of this talk is how we improve the tracing back end to make it

182
0:13:14.400 --> 0:13:22.040
more efficient because what you, especially when you're doing something like tracing and

183
0:13:22.040 --> 0:13:25.440
things like that, the lower overhead the better, right?

184
0:13:25.440 --> 0:13:30.440
We don't want to make your program run significantly slower because that's just going to frustrate

185
0:13:30.440 --> 0:13:33.920
you and it's going to take longer to get to root cause analysis which is what you're really

186
0:13:33.920 --> 0:13:36.120
trying to do if you're using a debugger in the first place.

187
0:13:36.120 --> 0:13:41.620
So we'll talk about quickly how things are currently implemented and then how we can

188
0:13:41.620 --> 0:13:44.760
improve upon that using eBPF.

189
0:13:44.760 --> 0:13:52.780
So right now, Delve uses, or traditionally Delve uses Ptrace syscall to implement the

190
0:13:52.780 --> 0:13:53.940
tracing back end.

191
0:13:53.940 --> 0:13:59.560
It's how Ptrace is useful for, like it's used by pretty much every debugger, every kind

192
0:13:59.560 --> 0:14:01.040
of tool like this.

193
0:14:01.040 --> 0:14:04.240
Delve is no exception.

194
0:14:04.240 --> 0:14:08.360
And if you look at the man page, it'll explain a little bit more about what it is, but it

195
0:14:08.360 --> 0:14:12.400
essentially allows you to control the execution of another process and kind of examine the

196
0:14:12.400 --> 0:14:16.080
state of it, memory and things like that.

197
0:14:16.080 --> 0:14:19.400
So the problem is Ptrace is slow.

198
0:14:19.400 --> 0:14:22.560
And it can be very slow.

199
0:14:22.560 --> 0:14:29.920
So I ran some tests kind of a while ago when I was implementing the first iteration of

200
0:14:29.920 --> 0:14:32.160
this eBPF back end.

201
0:14:32.160 --> 0:14:39.720
And I measured a simple program execution that executed in 23.7 microseconds.

202
0:14:39.720 --> 0:14:44.080
And then the overhead with the Ptrace base tracing, the traditional base tracing, it

203
0:14:44.080 --> 0:14:45.560
went up to 2.3 seconds.

204
0:14:45.560 --> 0:14:48.840
So that's several orders of magnitude of overhead, right?

205
0:14:48.840 --> 0:14:51.600
Which is definitely not what you want.

206
0:14:51.600 --> 0:14:59.040
But why is Ptrace so slow?

207
0:14:59.040 --> 0:15:04.200
So part of the reason is syscall overhead.

208
0:15:04.200 --> 0:15:07.680
We have to, you know, Ptrace is a syscall.

209
0:15:07.680 --> 0:15:12.320
So whenever you invoke a syscall, you trap into the kernel, you switch context, right?

210
0:15:12.320 --> 0:15:19.840
So that has its own kind of overhead, which can be pretty significant.

211
0:15:19.840 --> 0:15:23.760
And as I mentioned, the user space kernel context switching, the overhead of that can

212
0:15:23.760 --> 0:15:26.400
be really expensive.

213
0:15:26.400 --> 0:15:34.840
And it's amplified by the fact that Ptrace is in a sense very like directed.

214
0:15:34.840 --> 0:15:42.760
So when we're tracing these functions, we often have to make multiple Ptrace calls per

215
0:15:42.760 --> 0:15:45.560
like function entry and function exit.

216
0:15:45.560 --> 0:15:50.000
So if you think about it, we need to read the registers, we need to read all of the

217
0:15:50.000 --> 0:15:54.840
different like function arguments that are there.

218
0:15:54.840 --> 0:15:56.680
There's a bunch of different things that we need to do.

219
0:15:56.680 --> 0:16:01.760
So it kind of balloons up really, really quickly where we get into this situation where we're

220
0:16:01.760 --> 0:16:06.400
doing a ton of these user space kernel context switching per every time you hit one of these

221
0:16:06.400 --> 0:16:11.480
trace points.

222
0:16:11.480 --> 0:16:17.100
And on top of that, all of these operations have to happen twice per function, right?

223
0:16:17.100 --> 0:16:19.000
So the entry and the exit.

224
0:16:19.000 --> 0:16:25.200
So it's a lot of overhead, a lot of context switching, essentially a lot of unnecessary

225
0:16:25.200 --> 0:16:31.560
work and a lot of work that just slows down your program and adds a lot of overhead.

226
0:16:31.560 --> 0:16:40.920
So the way that we can improve upon this and work around this is by using eBPF.

227
0:16:40.920 --> 0:16:47.000
So eBPF is a lot more efficient, a lot quicker to do this kind of work.

228
0:16:47.000 --> 0:16:54.760
So with the same test, again, as I mentioned before, the original program, 23 microseconds

229
0:16:54.760 --> 0:16:58.520
with Ptrace, 2.3 actual seconds.

230
0:16:58.520 --> 0:17:04.560
And with the eBPF-based tracing, we have like 683 microseconds, which is still measurable

231
0:17:04.560 --> 0:17:11.320
overhead but significantly less than the traditional method of doing it.

232
0:17:11.320 --> 0:17:17.120
So I've been talking about this technology a lot, eBPF, eBPF, eBPF, right?

233
0:17:17.120 --> 0:17:20.360
But what actually is it?

234
0:17:20.360 --> 0:17:29.480
So eBPF is a technology that enables the kernel to run sandbox programs directly.

235
0:17:29.480 --> 0:17:35.920
So eBPF programs are written primarily in like a limited C. I'll get into some of the

236
0:17:35.920 --> 0:17:39.640
limitations later.

237
0:17:39.640 --> 0:17:44.840
But it gets compiled to a bytecode, loaded into the kernel where it's executed and jitted

238
0:17:44.840 --> 0:17:48.240
as it's ran.

239
0:17:48.240 --> 0:17:53.200
And it has a lot of use cases, observability, networking, debugging, and a lot more.

240
0:17:53.200 --> 0:17:54.880
So you'll hear a lot about eBPF.

241
0:17:54.880 --> 0:18:00.360
I'm sure a lot of folks in this room have already heard of it in some shape or another.

242
0:18:00.360 --> 0:18:07.560
Typically it started as a technology for networking and kind of ballooned from there.

243
0:18:07.560 --> 0:18:16.400
So originally it was like BPF, which is Berkeley packet filtering, and it came into extended

244
0:18:16.400 --> 0:18:17.400
Berkeley packet filtering.

245
0:18:17.400 --> 0:18:19.680
And now the acronym doesn't really mean anything anymore.

246
0:18:19.680 --> 0:18:25.440
eBPF is just eBPF because it's way more than just what it originally was.

247
0:18:25.440 --> 0:18:29.360
And the cool thing is these programs that are loaded into the kernel, they can be triggered

248
0:18:29.360 --> 0:18:30.520
by certain events.

249
0:18:30.520 --> 0:18:34.760
And I'll talk about how we can trigger those events ourselves.

250
0:18:34.760 --> 0:18:41.720
But they run in response to something happening.

251
0:18:41.720 --> 0:18:48.240
So why is eBPF so fast in comparison to the way that we're traditionally doing things?

252
0:18:48.240 --> 0:18:52.560
The first thing is these eBPF programs run in the kernel.

253
0:18:52.560 --> 0:18:59.440
So there's a lot less context switching overhead.

254
0:18:59.440 --> 0:19:02.960
We're already in the kernel, so we don't have to keep asking the kernel for more and more

255
0:19:02.960 --> 0:19:08.240
and more and more information to get what we actually want.

256
0:19:08.240 --> 0:19:12.560
Relative to traditional syscall and a bunch of syscalls, the context switching is a lot

257
0:19:12.560 --> 0:19:15.580
cheaper.

258
0:19:15.580 --> 0:19:23.500
You get small targeted programs that, again, execute really quickly and can do everything

259
0:19:23.500 --> 0:19:29.080
that you need or want to do in essentially one shot.

260
0:19:29.080 --> 0:19:33.960
And a single program can execute many tasks that we would traditionally use multiple ptrace

261
0:19:33.960 --> 0:19:34.960
calls for.

262
0:19:34.960 --> 0:19:40.920
So you can, like, you have access to the current registers.

263
0:19:40.920 --> 0:19:47.720
You can read memory and a lot of other things like that.

264
0:19:47.720 --> 0:19:54.120
Now when I was looking to implement this back end, I had a few requirements that I wanted

265
0:19:54.120 --> 0:19:59.840
to make sure can be satisfied with this eBPF-based approach.

266
0:19:59.840 --> 0:20:03.840
So the first one was the ability to trace arbitrary functions, right?

267
0:20:03.840 --> 0:20:07.320
As a user, you just want to say, I want to trace everything in the main package.

268
0:20:07.320 --> 0:20:12.840
Or I want to trace this specific function or whatever.

269
0:20:12.840 --> 0:20:17.320
This new back end had to be able to satisfy that requirement as well.

270
0:20:17.320 --> 0:20:23.800
We had to be able to retrieve the go routine ID from within the eBPF program.

271
0:20:23.800 --> 0:20:27.240
We had to be able to read function input arguments.

272
0:20:27.240 --> 0:20:33.800
And we had to be able to read function return arguments.

273
0:20:33.800 --> 0:20:39.320
Now let's talk a little bit about tracing arbitrary functions.

274
0:20:39.320 --> 0:20:46.120
So just as a little bit of background, how Delve uses eBPF from the go side of things

275
0:20:46.120 --> 0:20:48.720
is we use the cilium eBPF package.

276
0:20:48.720 --> 0:20:55.040
There's a few other go-based eBPF packages out there.

277
0:20:55.040 --> 0:20:58.960
Originally it was implemented, I implemented using one from Aqua security but ended up

278
0:20:58.960 --> 0:21:04.400
switching to cilium for a few various different reasons.

279
0:21:04.400 --> 0:21:09.520
But the first thing that we need to do when we're tracing these arbitrary functions is

280
0:21:09.520 --> 0:21:14.600
we need to first load the eBPF program into the kernel so that we can start triggering

281
0:21:14.600 --> 0:21:17.200
it with some of these events.

282
0:21:17.200 --> 0:21:22.880
Once we've loaded the eBPF program, we attach UProbes to each symbol.

283
0:21:22.880 --> 0:21:27.120
And this slide is actually a little bit outdated because we don't actually use URepProbes.

284
0:21:27.120 --> 0:21:35.720
So UProbes can kind of be attached arbitrarily to different addresses and things like that

285
0:21:35.720 --> 0:21:36.720
within the binary.

286
0:21:36.720 --> 0:21:44.200
URepProbes are typically used to hook into the return of a function, which seems like

287
0:21:44.200 --> 0:21:46.120
something that would be super, super useful.

288
0:21:46.120 --> 0:21:47.240
And in theory it is.

289
0:21:47.240 --> 0:21:52.760
But with go it doesn't work very well because of how go manages go routine stacks.

290
0:21:52.760 --> 0:22:04.760
So when go has to inspect the stack, it kind of reads up the stack to unwind it a little

291
0:22:04.760 --> 0:22:05.860
bit.

292
0:22:05.860 --> 0:22:08.800
And if it sees anything that doesn't look right, it'll panic.

293
0:22:08.800 --> 0:22:17.080
So URepProbes work by overwriting the return address of the function that we're trying

294
0:22:17.080 --> 0:22:19.500
to probe.

295
0:22:19.500 --> 0:22:25.160
And so go notices that during its runtime work and kind of freaks out.

296
0:22:25.160 --> 0:22:27.240
So we just use UProbes.

297
0:22:27.240 --> 0:22:32.240
And again, we want to do as much in the kernel as possible to limit overhead.

298
0:22:32.240 --> 0:22:38.800
And we have to communicate function argument and return values to the eBPF program and

299
0:22:38.800 --> 0:22:42.600
get those values back from the eBPF program.

300
0:22:42.600 --> 0:22:44.200
So first we load it.

301
0:22:44.200 --> 0:22:48.080
So first thing we have to do is write the eBPF program.

302
0:22:48.080 --> 0:22:50.880
Second thing, compile the program and generate some helpers.

303
0:22:50.880 --> 0:22:54.100
So this is kind of what the Cilium package helps us with.

304
0:22:54.100 --> 0:22:56.420
And then we have to load the programs in the kernel.

305
0:22:56.420 --> 0:22:58.200
So these are actually links.

306
0:22:58.200 --> 0:22:59.680
I'll publish these slides.

307
0:22:59.680 --> 0:23:02.520
You can kind of follow along at home.

308
0:23:02.520 --> 0:23:05.660
But I'll show a little bit of the code here.

309
0:23:05.660 --> 0:23:16.040
So this is an example of the eBPF program that we use written in like C basically.

310
0:23:16.040 --> 0:23:22.080
And we have access to a bunch of different eBPF based data structures, like maps, ring

311
0:23:22.080 --> 0:23:23.600
buffers.

312
0:23:23.600 --> 0:23:26.960
And these are just different ways to be able to communicate with the eBPF program running

313
0:23:26.960 --> 0:23:32.180
in the kernel and the Go program that's running in user space.

314
0:23:32.180 --> 0:23:35.480
So I won't go through all of this exhaustively for time.

315
0:23:35.480 --> 0:23:41.100
But again, if you want to look at it yourself, go ahead and follow the link.

316
0:23:41.100 --> 0:23:46.080
So the second thing that we have to do is go ahead and actually compile this eBPF program

317
0:23:46.080 --> 0:23:48.160
and make it usable from Go.

318
0:23:48.160 --> 0:23:53.760
So the Cilium eBPF package has a really nice helper that you can just use with Go generate

319
0:23:53.760 --> 0:23:57.880
to be able to compile the object file that is your eBPF program.

320
0:23:57.880 --> 0:24:01.840
And it generates a bunch of helpers for you that you can call to be able to load it and

321
0:24:01.840 --> 0:24:06.020
interact with that eBPF program.

322
0:24:06.020 --> 0:24:12.280
And then finally, we have to load the eBPF program into the kernel.

323
0:24:12.280 --> 0:24:19.760
So again, the Cilium eBPF library has a ton of helpers to be able to facilitate that.

324
0:24:19.760 --> 0:24:27.920
So we open up the executable that represents the process that we're debugging.

325
0:24:27.920 --> 0:24:32.440
We call this helper that the package generated for us.

326
0:24:32.440 --> 0:24:38.560
And then we initialize some of the things that we need to do, like the ring buffer and

327
0:24:38.560 --> 0:24:44.880
the map data structure that we use to pass values back and forth.

328
0:24:44.880 --> 0:24:49.540
The next thing we have to do is attach our UProbes.

329
0:24:49.540 --> 0:24:52.360
So first we find an offset to attach to.

330
0:24:52.360 --> 0:24:55.080
We attach the probe to that offset.

331
0:24:55.080 --> 0:24:56.880
And then we go from there.

332
0:24:56.880 --> 0:25:06.160
So we have a little helper here to take an address within the program to an offset.

333
0:25:06.160 --> 0:25:16.420
And the offset is just like an offset within the binary itself as it's loaded into memory.

334
0:25:16.420 --> 0:25:19.720
And then from there, we attach our probe.

335
0:25:19.720 --> 0:25:24.840
And it's as simple as the executable that we opened earlier.

336
0:25:24.840 --> 0:25:29.560
We have that attached to this eBPF context here.

337
0:25:29.560 --> 0:25:36.080
And we just call this UProbe method and pass it the offset and the PID.

338
0:25:36.080 --> 0:25:44.120
So the next thing about this is you pass along the PID so that this eBPF program is constrained

339
0:25:44.120 --> 0:25:46.360
to just the process that you're trying to debug.

340
0:25:46.360 --> 0:25:50.340
Because these programs that you load in are actually global.

341
0:25:50.340 --> 0:25:59.840
So they're not really by themselves attached to any specific process.

342
0:25:59.840 --> 0:26:04.040
Then from there, we need to actually communicate with this program.

343
0:26:04.040 --> 0:26:07.800
So we need to store function parameter information.

344
0:26:07.800 --> 0:26:11.600
And then we need to communicate that information with the program.

345
0:26:11.600 --> 0:26:16.040
Now I won't go too much into the code in this for the sake of time.

346
0:26:16.040 --> 0:26:24.760
But essentially, we need to tell the eBPF program all of the function argument information,

347
0:26:24.760 --> 0:26:29.240
the return value information, where they're located, are they on the stack, are they in

348
0:26:29.240 --> 0:26:34.860
registers, and let it know where to find it so that it can read all of this information

349
0:26:34.860 --> 0:26:39.720
and send it back to the user space program.

350
0:26:39.720 --> 0:26:45.320
When we want to get the data back, we use a ring buffer to, again, communicate between

351
0:26:45.320 --> 0:26:49.040
user space and our program running in kernel space.

352
0:26:49.040 --> 0:26:52.840
And essentially, it's just a stream of all of the information coming back.

353
0:26:52.840 --> 0:26:56.840
So all of the information that's being read and picked up by the eBPF program.

354
0:26:56.840 --> 0:27:03.440
And then that's ultimately what gets displayed to you as we run the trace command.

355
0:27:03.440 --> 0:27:09.480
So I'll go through another quick demo of actually using the eBPF backend.

356
0:27:09.480 --> 0:27:16.540
So all you have to do to enable it for now is just add dash dash eBPF to the trace command.

357
0:27:16.540 --> 0:27:26.000
So if I run our make command here, nobody look at my password.

358
0:27:26.000 --> 0:27:27.980
We see that the trace happens.

359
0:27:27.980 --> 0:27:31.900
And from here, you can't really tell that it's significantly faster.

360
0:27:31.900 --> 0:27:34.020
But the output is a little bit different.

361
0:27:34.020 --> 0:27:39.040
As I mentioned, this is still kind of like an experimental work in progress backend.

362
0:27:39.040 --> 0:27:41.340
So some of the output is a little bit different.

363
0:27:41.340 --> 0:27:48.180
And it doesn't have exact parity with the traditional more established tracing backend.

364
0:27:48.180 --> 0:27:50.580
But you can see it works.

365
0:27:50.580 --> 0:27:54.920
You see the arguments, the return values, and everything like that.

366
0:27:54.920 --> 0:27:59.540
And this is all happening with significantly less overhead.

367
0:27:59.540 --> 0:28:02.880
So a few downsides of the eBPF approach.

368
0:28:02.880 --> 0:28:07.900
The programs are written in a constrained version of C, so you're not writing go.

369
0:28:07.900 --> 0:28:10.420
You end up having to fight the verifier a lot.

370
0:28:10.420 --> 0:28:14.380
If you don't know what that means, that's great for you.

371
0:28:14.380 --> 0:28:18.580
Congratulations.

372
0:28:18.580 --> 0:28:23.580
There's a lot of constraints on stack sizes and stuff like that within eBPF programs,

373
0:28:23.580 --> 0:28:27.980
which is going to be kind of gnarly to deal with.

374
0:28:27.980 --> 0:28:33.500
It's different to write some control flow, like loops and stuff like that.

375
0:28:33.500 --> 0:28:37.820
And as I mentioned, URep probes do not play well with go programs at all.

376
0:28:37.820 --> 0:28:38.940
Do not use them.

377
0:28:38.940 --> 0:28:41.500
Do not try.

378
0:28:41.500 --> 0:28:42.500
And that's it.

379
0:28:42.500 --> 0:28:43.500
Thank you very much.

380
0:28:43.500 --> 0:28:44.500
Thank you.

381
0:28:44.500 --> 0:28:45.580
Unfortunately, we do not have time for questions.

382
0:28:45.580 --> 0:28:58.820
But if you see them in the hallway track, you can always ask him any questions, improvements,

383
0:28:58.820 --> 0:28:59.820
bug fixes, et cetera.

384
0:28:59.820 --> 0:29:16.500
If you leave, it's better to do so on this side.

385
0:29:16.500 --> 0:29:18.020
You may pause the stage.

386
0:29:18.020 --> 0:29:22.180
And there is also a swag table diagram.

387
0:29:22.180 --> 0:29:30.180
It's looking pretty easy.

