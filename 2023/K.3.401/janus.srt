1
0:00:00.000 --> 0:00:10.060
Okay, I'll start because the 10 minutes apply to me as well even though I wear this nice

2
0:00:10.060 --> 0:00:11.060
blue shirt.

3
0:00:11.060 --> 0:00:14.000
So please sit down and I'll start right away.

4
0:00:14.000 --> 0:00:18.940
So I'll be talking about social audio applications that you may want to re-implement with Janus.

5
0:00:18.940 --> 0:00:23.680
If you want quick slides about me, nobody cares.

6
0:00:23.680 --> 0:00:24.680
What is social audio?

7
0:00:24.680 --> 0:00:29.920
It's basically whenever you have something that is primarily audio and not strictly video

8
0:00:29.920 --> 0:00:31.840
as part of their form of communication.

9
0:00:31.840 --> 0:00:36.360
So whether it is messages or podcasts or virtual audio rooms or stuff like that, you may have

10
0:00:36.360 --> 0:00:40.480
heard about stuff like Clubhouse, Twitter Spaces, Reddy Talk.

11
0:00:40.480 --> 0:00:42.160
They are all examples of social audio.

12
0:00:42.160 --> 0:00:46.520
So people talking with each other, maybe they take turns and then they broadcast to a very

13
0:00:46.520 --> 0:00:47.880
large audience.

14
0:00:47.880 --> 0:00:51.400
And of course it does seem like a very good fit for WebRTC, especially for the real-time

15
0:00:51.400 --> 0:00:52.880
kind of participation.

16
0:00:52.880 --> 0:00:56.880
And you didn't hear about me because I don't know if there is any secrets about that, but

17
0:00:56.880 --> 0:01:02.400
actually Twitter Spaces uses Janus for the live part and then they distribute it somehow

18
0:01:02.400 --> 0:01:03.900
else.

19
0:01:03.900 --> 0:01:05.820
And how do they usually work?

20
0:01:05.820 --> 0:01:08.640
So as I said, they are typically live conversations.

21
0:01:08.640 --> 0:01:12.840
So you have a limited number of people that talk to each other, exchange ideas, they take

22
0:01:12.840 --> 0:01:13.840
turns.

23
0:01:13.840 --> 0:01:17.820
So it's not always the same people talking for two hours like a podcast, for instance.

24
0:01:17.820 --> 0:01:22.160
And then you may have possibly thousands of attendees, like for instance, anytime Elon

25
0:01:22.160 --> 0:01:27.040
Musk speaks in a Twitter Space, there's a million of people listening, let's say, things

26
0:01:27.040 --> 0:01:28.240
like that.

27
0:01:28.240 --> 0:01:31.800
And there are of course different challenges to tackle because for the live conversation

28
0:01:31.800 --> 0:01:36.340
part it needs of course to be real-time because it needs to be something that happens as fast

29
0:01:36.340 --> 0:01:37.640
as possible.

30
0:01:37.640 --> 0:01:41.920
For the distribution to the audience, you may want a bit of latency maybe okay and this

31
0:01:41.920 --> 0:01:46.640
is why for instance they take advantage of CDNs or stuff like that most of the times.

32
0:01:46.640 --> 0:01:51.020
But of course there's a problem that of course the more latency you have for the audience,

33
0:01:51.020 --> 0:01:54.460
if somebody from the audience needs to come into the conversation there may be a bit of

34
0:01:54.460 --> 0:01:55.860
latency there.

35
0:01:55.860 --> 0:01:58.240
And so that's something that needs to be taken into account.

36
0:01:58.240 --> 0:02:03.320
And so you may want to use WebRTC for everything but then there's scalability issues at play

37
0:02:03.320 --> 0:02:04.320
there.

38
0:02:04.320 --> 0:02:08.400
And so I wanted to check whether or not Janus, which is the WebRTC server that I work on

39
0:02:08.400 --> 0:02:10.500
for a living, could be used for the job.

40
0:02:10.500 --> 0:02:13.560
And I came up with a few potential ideas.

41
0:02:13.560 --> 0:02:16.740
And one of those may be relying on the audio bridge plugin.

42
0:02:16.740 --> 0:02:20.060
The audio bridge is basically an audio mixer that lives within Janus.

43
0:02:20.060 --> 0:02:23.560
So you have multiple people connected to the audio bridge plugin.

44
0:02:23.560 --> 0:02:27.940
They create a single pair connection that the audio bridge mixes all the audio streams

45
0:02:27.940 --> 0:02:32.380
so that you send one stream, you receive one stream that contains the audio of everybody

46
0:02:32.380 --> 0:02:34.200
involved except you.

47
0:02:34.200 --> 0:02:39.760
Which is really nice because for instance it's easy to bring C pinpoints in if you want

48
0:02:39.760 --> 0:02:41.760
using the plain RTP functionality.

49
0:02:41.760 --> 0:02:47.320
You can play jingles for instance you have your own show, your own context that you want

50
0:02:47.320 --> 0:02:51.480
to play something in there or maybe as an iPad from another conversation.

51
0:02:51.480 --> 0:02:56.040
If you do stereo mixing which you support you can use spatial positioning of participants

52
0:02:56.040 --> 0:02:58.400
to make it easier to understand for people.

53
0:02:58.400 --> 0:03:02.020
And of course this takes care of the live conversation but we want to make it available

54
0:03:02.020 --> 0:03:05.060
to other people as well so to a wider audience.

55
0:03:05.060 --> 0:03:08.600
And so what you can do is take advantage of RTP for worders which is basically an easy

56
0:03:08.600 --> 0:03:13.360
way by which the audio bridge plugin sends a plain RTP stream towards an address that

57
0:03:13.360 --> 0:03:17.320
you specify containing the mix that is being mixed there.

58
0:03:17.320 --> 0:03:20.840
And the nice feature in the audio bridge plugin is that you can also tag participants so that

59
0:03:20.840 --> 0:03:26.040
you may say don't send me a mix of all participants but only the ones that I tag in a specific

60
0:03:26.040 --> 0:03:27.040
group.

61
0:03:27.040 --> 0:03:30.700
For instance this one may be a technician so those two need to hear the technician who

62
0:03:30.700 --> 0:03:34.560
gives tips but all the attendees only need to hear those two.

63
0:03:34.560 --> 0:03:36.320
That's basically the main idea.

64
0:03:36.320 --> 0:03:40.560
And of course whatever happens in here is basically handling a mixed stream.

65
0:03:40.560 --> 0:03:45.160
So there may be a script here that sends this mix to Icecast to make a very simple example

66
0:03:45.160 --> 0:03:50.240
or to YouTube Live for audio or to whatever platform you want to use as a CDN for distributing

67
0:03:50.240 --> 0:03:52.620
the audio if it's not WebRTC.

68
0:03:52.620 --> 0:03:55.140
If you want to use WebRTC you can use something like this.

69
0:03:55.140 --> 0:03:59.400
So you have your active participants connected to the audio bridge they are talking to each

70
0:03:59.400 --> 0:04:00.400
other.

71
0:04:00.400 --> 0:04:04.440
You're RTP for word to the streaming plugin which is the plugin in Janus that takes care

72
0:04:04.440 --> 0:04:07.440
of broadcasting RTP to a wider audience.

73
0:04:07.440 --> 0:04:11.580
And then the streaming plugin is what distributes the audio which is the greatest advantage

74
0:04:11.580 --> 0:04:15.560
that you don't have to perform specific mixing for these participants.

75
0:04:15.560 --> 0:04:17.960
They are already receiving a mix of the stream.

76
0:04:17.960 --> 0:04:22.780
All people connected to the audio bridge instead have a dedicated context for mixing because

77
0:04:22.780 --> 0:04:24.800
they need to receive everybody except them.

78
0:04:24.800 --> 0:04:27.560
So it's not the same audio for all of them.

79
0:04:27.560 --> 0:04:33.880
And whenever you want somebody from the listeners to join in the conversation they mute the

80
0:04:33.880 --> 0:04:34.880
streaming parts.

81
0:04:34.880 --> 0:04:38.680
When they join the audio bridge temporarily they become active participants that everybody

82
0:04:38.680 --> 0:04:42.340
else can listen to because they are now mixed in the audio bridge.

83
0:04:42.340 --> 0:04:46.920
And of course for scalability purposes you can just RTP for word to multiple streaming

84
0:04:46.920 --> 0:04:50.220
plugin instances on multiple different instances of Janus.

85
0:04:50.220 --> 0:04:51.980
How you distribute it is entirely up to you.

86
0:04:51.980 --> 0:04:54.920
You can use a tree based distribution however you want.

87
0:04:54.920 --> 0:05:00.000
And you can also take advantage maybe of Multicast because of course if it's just a plain RTP

88
0:05:00.000 --> 0:05:03.420
stream that you are for wording if you for word it on a Multicast group then multiple

89
0:05:03.420 --> 0:05:08.440
Janus instances can all pull from that Multicast group that same mix of audio and can distribute

90
0:05:08.440 --> 0:05:10.140
it more efficiently.

91
0:05:10.140 --> 0:05:14.420
And one added value is that using this approach if you want you can also do something like

92
0:05:14.420 --> 0:05:15.660
interpreter services.

93
0:05:15.660 --> 0:05:18.800
You have two different audio bridge rooms for different rooms.

94
0:05:18.800 --> 0:05:22.280
You have the speaker join the room of their language and you have an interpreter on the

95
0:05:22.280 --> 0:05:23.460
other room.

96
0:05:23.460 --> 0:05:28.040
And then you distribute those two streams separately and then you allow the audience

97
0:05:28.040 --> 0:05:33.040
to listen maybe to the English channel or the French channel and depending on the language

98
0:05:33.040 --> 0:05:37.360
you will speak in you will hear the translator or the actual speaker on either one.

99
0:05:37.360 --> 0:05:42.040
So which makes little sense for an actual social audio application if we want it's maybe

100
0:05:42.040 --> 0:05:47.520
more for a conversational scenario but it's still a good side effect of that.

101
0:05:47.520 --> 0:05:51.680
If instead you don't want to mix in Janus for a few reasons because you don't want to

102
0:05:51.680 --> 0:05:56.520
terminate audio there mixing a CPU intensive or whatever you may want to use the SFU approach

103
0:05:56.520 --> 0:06:01.920
instead which means that participants in the conversation now need to establish maybe one

104
0:06:01.920 --> 0:06:05.720
single peer connection not necessarily more than one but they are exchanging multiple

105
0:06:05.720 --> 0:06:06.720
audio streams.

106
0:06:06.720 --> 0:06:11.080
So they are sending their own and they are receiving as many as there are other participants

107
0:06:11.080 --> 0:06:12.880
in the room.

108
0:06:12.880 --> 0:06:18.400
And you can still externalize this conversation via RTP for worders as before but now audio

109
0:06:18.400 --> 0:06:23.040
is not mixed so you have different audio streams for each of the participants there.

110
0:06:23.040 --> 0:06:27.200
So if you have three participants in the conversation each of them is sending one and receiving

111
0:06:27.200 --> 0:06:31.880
two and you have a separate component that is receiving the three different audio streams

112
0:06:31.880 --> 0:06:32.880
from the different participants.

113
0:06:32.880 --> 0:06:38.200
And so if you want to distribute something via regular CDN that requires a single audio

114
0:06:38.200 --> 0:06:39.320
stream to distribute.

115
0:06:39.320 --> 0:06:44.880
And so that component receiving RTP for worders needs to act a bit like a mixer acting live

116
0:06:44.880 --> 0:06:45.880
basically.

117
0:06:45.880 --> 0:06:50.000
So and once this happens so once you have a mix there everything is pretty much as the

118
0:06:50.000 --> 0:06:55.000
example as I made before you have a mixed stream you can distribute it via CDN or via

119
0:06:55.000 --> 0:07:00.240
Janus as we said before if you don't want to mix for the attendee as well you want something

120
0:07:00.240 --> 0:07:03.240
closer to a regular webinar or something like this.

121
0:07:03.240 --> 0:07:06.600
You can still do that but then you have to take do you have to use that approach that

122
0:07:06.600 --> 0:07:11.080
I was talking about for wording to the streaming plugin for each of the different participants.

123
0:07:11.080 --> 0:07:16.200
And so something like you have the presenter set contributing audio to the video room this

124
0:07:16.200 --> 0:07:21.960
becomes an audio broadcast for that specific presenter in the streaming plugin and people

125
0:07:21.960 --> 0:07:25.020
listen to that participant over there.

126
0:07:25.020 --> 0:07:30.960
You can again involve multiple streaming plugin instances if needed so that you can widen

127
0:07:30.960 --> 0:07:32.960
the audience if you want.

128
0:07:32.960 --> 0:07:36.360
But again if you have multiple participants speaking you have to do the same for each

129
0:07:36.360 --> 0:07:41.040
of them because otherwise of course since the audio is not mixed you would only listen

130
0:07:41.040 --> 0:07:45.900
to one single participant which means that the audience need to create subscriptions

131
0:07:45.900 --> 0:07:50.460
for more than one participant at any given time and of course you have to make this dynamic

132
0:07:50.460 --> 0:07:54.880
in case there's presenters that come and go basically which is what is expected in a social

133
0:07:54.880 --> 0:07:56.720
audio kind of application.

134
0:07:56.720 --> 0:08:01.960
Which means that it's probably easier to do something like this where you still do some

135
0:08:01.960 --> 0:08:07.720
sort of you keep the audio conversation using an SFU for WebRTC participant because it gives

136
0:08:07.720 --> 0:08:12.640
a better audio quality between each of them maybe but then for distributing the conversation

137
0:08:12.640 --> 0:08:17.420
it's okay to mix it and so even mix it for WebRTC usage so that you distribute a single

138
0:08:17.420 --> 0:08:20.640
audio stream instead which makes which makes sense.

139
0:08:20.640 --> 0:08:24.320
But again if you want to do that that works for instance this is what we do for our virtual

140
0:08:24.320 --> 0:08:31.520
event platform for meetings so that definitely works anyway and again you can also do this

141
0:08:31.520 --> 0:08:36.160
sort of multicast distribution if you want to take advantage of a wider distribution

142
0:08:36.160 --> 0:08:37.560
of the media.

143
0:08:37.560 --> 0:08:42.360
And if I spoke too fast which is very likely I did write a blog post about this which goes

144
0:08:42.360 --> 0:08:47.740
a bit more in detail and explains things a bit more precisely than I did right now and

145
0:08:47.740 --> 0:08:52.120
I think I managed to stay on time and these are some references so you can find me on

146
0:08:52.120 --> 0:08:57.400
Mastodon mainly I'm still on Twitter but who knows for how long and that's the blog post

147
0:08:57.400 --> 0:09:00.960
that I was mentioning before so that's all thank you.

148
0:09:00.960 --> 0:09:14.560
Okay there's time maybe for one or two questions if anybody is curious so I don't know if you

149
0:09:14.560 --> 0:09:15.560
have any.

150
0:09:15.560 --> 0:09:16.560
Okay.

151
0:09:16.560 --> 0:09:25.800
So any ability to do like energy level like to say which user are more important or less

152
0:09:25.800 --> 0:09:30.200
important when you are making the mix in this region.

153
0:09:30.200 --> 0:09:34.480
Not specifically in the audio bridge but this is something that you can enforce at the application

154
0:09:34.480 --> 0:09:38.920
level if you want so for instance you may decide that some users always need to be there

155
0:09:38.920 --> 0:09:44.760
and some users so for instance you may have the concept of the actual presenters and panelists

156
0:09:44.760 --> 0:09:49.080
that come and go for instance this is more of an application level context than the mixing

157
0:09:49.080 --> 0:09:52.640
context as far as mixing is concerned you just mix.

158
0:09:52.640 --> 0:10:02.680
Yeah exactly so any other question or can we move to Sagu?

159
0:10:02.680 --> 0:10:04.480
Okay then.

160
0:10:04.480 --> 0:10:15.520
Thank you very much.

