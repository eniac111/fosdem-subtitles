1
0:00:00.000 --> 0:00:21.680
I'm here, thanks. Yes, hello, good morning and nice day for Fostem. Hope you had a nice

2
0:00:21.680 --> 0:00:33.040
evening. Yes, let's start with the talk matrix RTC matrix beyond instant messaging. Let's

3
0:00:33.040 --> 0:00:37.600
get that. So first of all, what is matrix? Maybe we have some redundancy a little bit

4
0:00:37.600 --> 0:00:42.960
here but for the sake of the recording I might repeat some of what Matthew already showed

5
0:00:42.960 --> 0:00:50.880
us. So basically the idea is an open and federated secure and decentralized real-time communication

6
0:00:50.880 --> 0:00:57.600
network and the use cases are many fold. So the obvious one is of course an interoperable chat

7
0:00:57.600 --> 0:01:02.960
but we are also aiming for voice over IP applications or even VR applications but

8
0:01:02.960 --> 0:01:11.280
you can also think of something like IoT data. And this is, so most of those use cases you're

9
0:01:11.280 --> 0:01:17.040
quite familiar with and what's the well-known event layer. So for chat for instance you have a store

10
0:01:17.040 --> 0:01:25.280
and forward semantics. However, the cool thing about matrix is that it is constructed such a way

11
0:01:25.280 --> 0:01:32.000
that it is decentralized, it is federated and what's for me pretty cool and important is it's

12
0:01:32.000 --> 0:01:38.240
replicated and end-to-end encrypted. So for instance if you're a client and one of those hosts here

13
0:01:38.240 --> 0:01:42.400
and you're attaching to one home server and you're joining a room from another home server,

14
0:01:42.400 --> 0:01:47.280
at that moment the room's replicated and everything is end-to-end encrypted. This is pretty cool.

15
0:01:47.280 --> 0:01:51.440
It's like a git clone, something like that, similar with an automatically

16
0:01:52.320 --> 0:01:57.120
synchronization mechanism on top of it. I'm quite sure that you're very familiar with it.

17
0:01:57.120 --> 0:02:02.080
You could also summarize that matrix is a distributed real-time database and I can

18
0:02:02.080 --> 0:02:08.240
recommend this talk here from my colleague Andy. It's a very nice overview of the specifics here.

19
0:02:08.240 --> 0:02:14.960
On the other side, this talk today is about matrix RTC and now what is the definition of matrix RTC?

20
0:02:14.960 --> 0:02:22.320
What's it? So basically it's the world first decentralized federated real-time channel or

21
0:02:22.320 --> 0:02:29.760
communication platform and it's backed in MSC 341 and MSC 3898 and it's depicted here what basically

22
0:02:29.760 --> 0:02:36.080
the idea is. From a client perspective you have a peer-to-peer semantics and we don't have a store

23
0:02:36.080 --> 0:02:43.360
or persistency in it but you can exchange data with a low latency and a low jitter from one

24
0:02:43.360 --> 0:02:50.080
client to the other. Another interesting thing here is that the business logic is owned by the

25
0:02:50.080 --> 0:02:58.240
clients. In most recent RTC platforms or video conferencing platforms you have something like

26
0:02:58.240 --> 0:03:03.600
an SFU and an application server and here the idea really is the business logic is

27
0:03:03.600 --> 0:03:11.360
in the clients. Let's have a look at some use cases. So the most obvious of course is video

28
0:03:11.360 --> 0:03:18.720
conferencing. This is what everybody would assume when you talk about RTC. But we can also have the

29
0:03:18.720 --> 0:03:24.400
embedded version here so let's just take a normal matrix client and put a widget into it and then

30
0:03:24.400 --> 0:03:30.720
have audio video conferencing or go to the VR world or the matrix interpretation of the meta

31
0:03:30.720 --> 0:03:36.320
words which is called third room. Everything can be realized using matrix RTC.

32
0:03:39.200 --> 0:03:43.360
And the cool thing here is that you can also think about a hybrid use case. So for instance

33
0:03:43.360 --> 0:03:49.920
imagine we have a whiteboard like we have this here. So we can use for fast UX the matrix RTC

34
0:03:49.920 --> 0:03:54.640
layer such when I make a stroke now that it's more or less immediately at the other whiteboards

35
0:03:54.640 --> 0:04:01.600
but for persistency we can just use the room, the distributed database.

36
0:04:05.840 --> 0:04:11.360
So what are the base building blocks which we use to create matrix RTC? So first of all of course

37
0:04:11.360 --> 0:04:16.880
we need something like a real-time communication framework and the obvious choice at the current

38
0:04:16.880 --> 0:04:21.920
point in time is web RTC because it has a quite good adoption. It's in all the web browsers and

39
0:04:21.920 --> 0:04:27.520
there are a lot of a lot of SDKs around we can use but going forward maybe you can also think

40
0:04:27.520 --> 0:04:33.520
something like web transport or web codecs to replace it. So we are not mandating web RTC but

41
0:04:33.520 --> 0:04:40.160
for the time being that is of course the framework to use. Then for the signaling that's quite

42
0:04:40.160 --> 0:04:45.760
obvious that we use matrix for iterates and then to make it scale you might optionally also want to

43
0:04:45.760 --> 0:04:52.880
use a back-end component, a focus. This could either be an MCU or an SFU.

44
0:04:57.120 --> 0:05:02.560
So now as I stated the back-end component is optional. Let's have a look on start

45
0:05:02.560 --> 0:05:08.160
matrix RTC without an back-end component. So having a look at the connection models.

46
0:05:08.160 --> 0:05:12.560
So the obvious and the simplest one to start with is peer-to-peer right? That's just easy. You create

47
0:05:12.560 --> 0:05:17.520
a peer connection and then you have a data layer and then you can play around with matrix RTC.

48
0:05:19.200 --> 0:05:25.440
It's getting a little bit more complicated if you want to have an RTC session with more than two

49
0:05:25.440 --> 0:05:32.400
people so then we spin up a full mesh and then it really depends on the use case how many people

50
0:05:32.400 --> 0:05:38.720
can join. If you have a look maybe at the use case of a video conference then you would need to

51
0:05:38.720 --> 0:05:45.600
distribute N minus one media uplinks and downlinks which is then limited by your internet connection

52
0:05:45.600 --> 0:05:52.000
and if you have at least in Germany an average DSL connection it would scale to up to five to eight

53
0:05:52.000 --> 0:05:58.480
participants. This is something we are currently using in Element Call. So Element Call at the

54
0:05:58.480 --> 0:06:03.280
current point in time is based on this full mesh setup or was we have some news today.

55
0:06:03.280 --> 0:06:14.000
The vision which also really scales and would allow a large scale RTC sessions is what we call

56
0:06:14.000 --> 0:06:19.760
cascaded selective forwarding units and it's depicted here. So what you would have, you would

57
0:06:19.760 --> 0:06:26.160
have a selective forwarding unit alongside with your home server. It's optional but you can have

58
0:06:26.160 --> 0:06:37.040
it and by this we then would allow further scaling and can really, using the cascading concept

59
0:06:37.040 --> 0:06:44.000
to dynamically crawl to any size. We have to test it but that's the theory so far.

60
0:06:46.000 --> 0:06:53.120
The signaling here of course is also carried out over matrix and for the specifics for the SFU

61
0:06:53.120 --> 0:07:00.640
we have this MSC3898 which handles then all the magic of the cascading and so on and so forth.

62
0:07:02.400 --> 0:07:08.960
From a setup perspective if you want to scale large network and large RTC network the idea is

63
0:07:08.960 --> 0:07:13.520
that you place the SFUs as close as you can to your customers or to your clients

64
0:07:14.400 --> 0:07:20.320
and to ensure a proper internet. So this ensures a proper internet connection with low jitter,

65
0:07:20.320 --> 0:07:26.240
low packet loss and then you have the SFUs placed in a strong network center and have a

66
0:07:26.240 --> 0:07:32.480
good interconnection and by this setup you have, yeah, that's the best you can do in terms of

67
0:07:33.600 --> 0:07:34.480
media quality.

68
0:07:34.480 --> 0:07:49.600
So what we did, we started with an SFU which is capable to speak the matrix flavor of RTC.

69
0:07:50.720 --> 0:07:56.160
It's a prototype which was handed over from Sean from the inventor of the PINEstack

70
0:07:56.160 --> 0:08:03.440
and it's a Golang based WebRTC implementation. We added the matrix bits to it, we wrote a lot of it.

71
0:08:04.560 --> 0:08:09.120
It's early stage but we have support for audio channels, we have support for video channels

72
0:08:09.760 --> 0:08:15.600
and screen sharing and on top of that recently we also added so-called simulcast support.

73
0:08:16.320 --> 0:08:22.720
Simulcast is, as you can imagine, that maybe you have to go step back. So in the full mesh mode you

74
0:08:22.720 --> 0:08:28.880
have a literally a peer-to-peer connection to each of those clients and by adding some signaling you

75
0:08:28.880 --> 0:08:35.280
can, the receiver can tell the sender, oh I'm struggling with a network connection, can you

76
0:08:35.280 --> 0:08:40.880
please adapt your network bandwidth from the encoding side. This is a little bit harder if

77
0:08:40.880 --> 0:08:47.920
you're having a central point, an SFU, so here the trick is that the sender will provide several

78
0:08:47.920 --> 0:08:54.080
or media quality levels and then on the SFU the client can decide which one to choose,

79
0:08:54.080 --> 0:08:59.520
low quality, mid quality and high quality and this is called simulcast and we already have

80
0:08:59.520 --> 0:09:04.000
basic support for simulcast in our selective forwarding unit.

81
0:09:07.840 --> 0:09:13.920
Matrix is known for privacy and end-to-end encryption and in the full mesh setup of

82
0:09:13.920 --> 0:09:18.560
MatrixRTC that's quite easy because you have the transport layer which ensures end-to-end encryption.

83
0:09:19.920 --> 0:09:26.400
But if you terminate a peer connection on an SFU the transport layer is of course terminated

84
0:09:27.440 --> 0:09:33.360
and hence we need media encryption and this is the missing part here. So using insertable streams

85
0:09:33.360 --> 0:09:39.280
we need going forward to implement end-to-end encryption on the client side that such that

86
0:09:39.280 --> 0:09:44.160
the media is encrypted on the client sendover and then it's not an issue on the SFU.

87
0:09:47.200 --> 0:09:53.680
For this specific topic MatrixRTC and cascaded FOCI or selective forwarding units

88
0:09:53.680 --> 0:10:01.360
we have later a dedicated talk from my colleague Szymon, it's the in-depth talk cascaded FOCI,

89
0:10:01.360 --> 0:10:09.520
it will be in this room, not in this room, it will be online at 2 pm this day.

90
0:10:12.800 --> 0:10:18.080
So now we have an idea of what the vision of MatrixRTC is and what we can do with it, we have

91
0:10:18.960 --> 0:10:25.920
seen so far the use cases. Let's come back to element call, I think we demonstrated it last year.

92
0:10:25.920 --> 0:10:34.320
Yes, very early. Very early and after one year you could imagine something happened.

93
0:10:36.800 --> 0:10:41.520
So first recap, what's element called? So initially it was developed on a green field

94
0:10:42.080 --> 0:10:45.840
as a single page application and the cool story here it's just a matrix client.

95
0:10:46.960 --> 0:10:51.600
It's not for chat, it's a matrix client and the implementation was using the full

96
0:10:51.600 --> 0:10:56.800
mesh so without a backend component. So what's new? So after this year, first of all in our

97
0:10:57.440 --> 0:11:02.400
site or not site project, our partner project Hydrogen we also have call support right now

98
0:11:02.400 --> 0:11:18.420
and it's also working in Drop

99
0:11:18.420 --> 0:11:23.940
Call. We have a group call experience, we just press the group call button and we have dedicated

100
0:11:23.940 --> 0:11:30.200
video rooms which is pretty cool. So the semantic of this room is that when you click on this room

101
0:11:30.200 --> 0:11:41.880
you're asked to join the conference immediately. The question is how to embed element call into a

102
0:11:41.880 --> 0:11:48.360
matrix client in general. So in theory you could just implement the MSCs but that would be very

103
0:11:48.360 --> 0:11:54.200
expensive because then you need to implement in each platform, expensive in terms of engineering

104
0:11:54.200 --> 0:12:04.840
bandwidth. So all requirements are one implementation which fits all and the idea is that we embed

105
0:12:04.840 --> 0:12:11.240
element call or the embedded element call needs to share the same underlying matrix client and room

106
0:12:11.240 --> 0:12:17.880
in order to not waste resources or to have device proliferation. So the idea is quite obvious,

107
0:12:17.880 --> 0:12:25.640
let's use a widget for it. Also a short recap on widgets. What is a widget? A widget is basically

108
0:12:26.200 --> 0:12:32.760
an application living in a matrix room. It's simply an embedded iframe and it's a small

109
0:12:32.760 --> 0:12:44.840
form factor web application, HTML, JavaScript. The widget is embedded within a room and can

110
0:12:44.840 --> 0:12:49.480
communicate with matrix clients and therefore from the matrix client through the widget API.

111
0:12:51.480 --> 0:13:00.440
And this widget API is a defined post message API basically. A widget is able to request permissions

112
0:13:01.400 --> 0:13:09.400
to perform actions on the user's behalf, something like posting into a room, receiving specific event

113
0:13:09.400 --> 0:13:17.560
types and so on and so forth. To have a more easier way of approaching widgets, we also have

114
0:13:17.560 --> 0:13:24.760
a widget SDK which is written in JavaScript and TypeScript. It's basically a web app.

115
0:13:26.840 --> 0:13:31.480
And now here we have an overview about element call and the various flavors. So in the single

116
0:13:31.480 --> 0:13:37.400
page application mode, it's just the matrix client using the client server API and in the

117
0:13:37.400 --> 0:13:42.440
widget mode we're going through the widget API over the underlying matrix client and then to the

118
0:13:42.440 --> 0:13:50.040
host server. The abstraction layer client server API versus widget is really thin. So from a

119
0:13:50.040 --> 0:13:58.600
development perspective that was really easy to implement. Yeah, so the solution is it's just a

120
0:13:58.600 --> 0:14:05.080
widget. It's WebRTC in a web view and this is the nice thing. So the whole WebRTC stack to implement

121
0:14:05.080 --> 0:14:10.680
on various platforms is quite painful. But if you can just a WebView where this is included for free,

122
0:14:10.680 --> 0:14:17.400
that's a thing. We needed to extend the widget API to add some missing bits, specifically where

123
0:14:17.400 --> 0:14:25.480
the 2D vice messages and to access the turn server, also spec'd in the MSCs. And this whole concept we

124
0:14:25.480 --> 0:14:30.360
call Matroska embedding where we have a WebView hosting widgets and the various clients and that

125
0:14:30.360 --> 0:14:35.160
could be a web client but it could also be the native clients like the iOS and the Android items.

126
0:14:35.880 --> 0:14:39.560
And hence we have the solution, one implementation that fits all.

127
0:14:45.080 --> 0:14:46.120
Let's have a demo, right?

128
0:14:46.120 --> 0:15:01.400
So what you see here basically is just the desktop application of Element, Element Nightly.

129
0:15:02.200 --> 0:15:07.480
On the left hand side you can see the various rooms with various flavors. So here this is a

130
0:15:07.480 --> 0:15:12.440
general room and here's already a conference started. So if you press it you will join it.

131
0:15:12.440 --> 0:15:18.840
And at the top here we have a so-called video room and if you join it, you're directly prompted

132
0:15:18.840 --> 0:15:27.720
to join a conference. And what you can also see here is a chat. So let's join it.

133
0:15:27.720 --> 0:15:42.920
Hello, I erased the volume here. So, hi Enrico, hi Simon. Yeah, welcome to Fostem.

134
0:15:44.120 --> 0:15:53.000
What we can do here right now is that we have various flavors. So we have a new layout here

135
0:15:53.000 --> 0:16:01.640
which we call large grid design. And you can change the tile sizes. And I also added here

136
0:16:01.640 --> 0:16:06.840
some debug information and you can see that the small video on the top left receives the

137
0:16:06.840 --> 0:16:16.920
low-quality stream whereas the large tile on the bottom receives the mid-quality stream.

138
0:16:16.920 --> 0:16:35.000
Hey Dave. Hello. So, now we want to carry out an experiment. I have a QR code here.

139
0:16:37.560 --> 0:16:46.200
Hopefully I find it. And I encourage everybody to join the call and to crash our SFU. Let's

140
0:16:46.200 --> 0:16:52.680
low test it. Sorry. With Chrome?

141
0:16:59.480 --> 0:17:00.200
Yeah, yeah, I really do.

142
0:17:09.160 --> 0:17:12.760
It's the resolution of the projector, good enough. We'll put the URL in the

143
0:17:12.760 --> 0:17:19.000
frame. So let's see.

144
0:17:19.000 --> 0:17:25.240
Let's see.

145
0:17:25.240 --> 0:17:39.160
I'm getting video from Ben Key. Refresh. So of course if it's not working then we can blame the

146
0:17:39.160 --> 0:18:00.760
Wi-Fi here, right? It's slightly unhappy now.

147
0:18:00.760 --> 0:18:08.440
I don't know.

148
0:18:11.960 --> 0:18:14.440
Oh no, no, no. It's recovering. It's recovering.

149
0:18:20.360 --> 0:18:28.200
So we plan a second demo later the day with the talk from Shimon. So yeah,

150
0:18:28.200 --> 0:18:31.400
but so how many do we have?

151
0:18:37.240 --> 0:18:39.880
Depends.

152
0:18:51.080 --> 0:18:54.280
Okay, let's say I leave it in the background, play around with it.

153
0:18:54.280 --> 0:18:57.080
And we go back to the talk.

154
0:19:05.160 --> 0:19:15.240
Okay, so what's next in the matrix RTC ecosystem? Of course we want to implement the whiteboard,

155
0:19:15.240 --> 0:19:22.120
at least the hybrid version of the whiteboard. Then the very important thing really is to start

156
0:19:22.120 --> 0:19:28.600
with the insertable streams to also have the end-to-end encryption in case of using the SFU.

157
0:19:30.040 --> 0:19:37.400
With respect to the selective forwarding units, we need to implement the focus selection logic.

158
0:19:37.400 --> 0:19:41.560
So if you remember the graph where we had the, or the picture where we had the

159
0:19:42.440 --> 0:19:48.200
home servers alongside the SFU's alongside with the home servers. We sketched out a nice

160
0:19:48.200 --> 0:19:52.760
algorithm where you can automatically choose the right one. And this is something we need to

161
0:19:52.760 --> 0:19:58.440
implement right now. Yeah, and then obviously the cascading. This has not started the implementation,

162
0:19:58.440 --> 0:20:06.440
but yeah, we need to carry out. On the simulcast layer, we also have some optimizations in mind.

163
0:20:07.240 --> 0:20:13.320
For instance, I think it's only a good idea to upload your video to the SFU. If on the other

164
0:20:13.320 --> 0:20:19.160
side someone consumes this video stream. So this is an optimization we can add. And I think also the

165
0:20:20.040 --> 0:20:24.360
the switching point where when you change the layer from high quality to low quality,

166
0:20:24.360 --> 0:20:31.160
there's also some room for improvement. On top of that, we need to care a little bit more about

167
0:20:31.160 --> 0:20:37.880
network bandwidth rate control. This is an important thing we need here, such that the SFU

168
0:20:37.880 --> 0:20:43.480
also feeds back information back to the client, such that the client is then in a good position

169
0:20:43.480 --> 0:20:52.040
to adapt the local video or audio encoders. And finally, we want to extend the call support in

170
0:20:52.040 --> 0:21:00.440
hydrogen and add the SFU bits to it. And now maybe some of you are wondering a little bit

171
0:21:00.440 --> 0:21:12.520
why Matthew is sitting here with his classes. Yeah, and now let's head over. So what we have

172
0:21:12.520 --> 0:21:17.800
so far seen was the obvious use case for matrix RTC, which is a video conferencing solution.

173
0:21:18.360 --> 0:21:25.000
But I told you earlier that we also have something like the metaverse interpretation of matrix.

174
0:21:25.000 --> 0:21:32.520
We call it third room. Yeah, and in a half minute. Yeah, any questions though on the

175
0:21:32.520 --> 0:21:36.760
florians? Yeah, the short Q&A part.

176
0:21:41.800 --> 0:21:43.480
Hopefully this thing is gonna work.

177
0:21:46.280 --> 0:21:49.560
Apologies for being the idiot with a VR headset on.

178
0:21:49.560 --> 0:21:56.120
I'm going to start streaming in a second. So I wanted to talk about third room,

179
0:21:56.120 --> 0:22:03.640
which is the social collaboration platform that we have built on top of matrix. And I'm going to

180
0:22:03.640 --> 0:22:10.680
slightly mess around with trying to get this to work at the wrong resolution, because it's going

181
0:22:10.680 --> 0:22:19.640
to let crack if it's not on the right res. How do you change the resolution these days in macOS?

182
0:22:20.520 --> 0:22:29.960
Anybody know how to actually change the refresh rate? Advanced? That's not helpful.

183
0:22:29.960 --> 0:22:34.840
So

184
0:22:48.520 --> 0:22:53.160
that's not me. Yeah, and is that your fault that it's live streaming?

185
0:22:54.440 --> 0:22:59.240
Oh, it's the wrong one. Thank you. Too many dev rooms. You should play the using the same one.

186
0:22:59.240 --> 0:23:01.240
And 2001.

187
0:23:03.160 --> 0:23:06.520
Online dev room. No, it's not the online dev room. Normal dev room.

188
0:23:12.760 --> 0:23:17.880
I can't spell matrix. This is going well. That one. Right. Thank you.

189
0:23:17.880 --> 0:23:28.200
Okay. Are we sure that looks totally squashed? That's literally what I'm trying to fix right now.

190
0:23:32.200 --> 0:23:35.800
How can it be to actually set a resolution on this thing these days?

191
0:23:35.800 --> 0:23:39.240
How about I press that button where we're going to go to.

192
0:23:43.080 --> 0:23:46.280
Yeah, so it's gone to four by three, but it wants to do four by three everywhere,

193
0:23:46.280 --> 0:23:49.880
but it's not four by three. It's 16 by nine. Let's go to that.

194
0:23:53.400 --> 0:23:57.560
So I'm coming in on the stream. All right, just check this. It'll be worth it. Don't worry.

195
0:24:03.320 --> 0:24:09.960
On the plus side, the Oculus thing kicks in, which is good. Right. Yeah, this is looking good.

196
0:24:09.960 --> 0:24:20.920
Yeah. So let me actually bring up third room. So the point of third room is that it's a tiny team.

197
0:24:20.920 --> 0:24:22.520
It's sorry.

198
0:24:29.080 --> 0:24:37.080
Okay. Hi, everybody. Welcome to my talk on third room, which is a project,

199
0:24:37.080 --> 0:24:44.920
a tiny project done by three people, Robert and AJ. AJ also famous for doing Cine as matrix client,

200
0:24:45.560 --> 0:24:51.480
which is trying to show people that matrix is way more than chat and VoIP. I know that it's cool to

201
0:24:51.480 --> 0:24:57.240
look at 3D stuff these days and go, don't like 3D. But honestly, I think this is incredibly

202
0:24:57.240 --> 0:25:01.880
interesting in showing the potential of what we have to build on top of matrix today. Now,

203
0:25:01.880 --> 0:25:08.360
the way it works is that you've got hydrogen SDK going and basically providing a plain old matrix

204
0:25:08.360 --> 0:25:16.440
client. And if I jump into this room here, which is hash presentation on thirdroom.io, if people

205
0:25:16.440 --> 0:25:23.640
want to play along at home, feel free to come and jump in and heckle my presentation. And you can

206
0:25:23.640 --> 0:25:30.200
see that this is a virtual world going and sitting in browser. If I pull up the frame rate, which is

207
0:25:30.200 --> 0:25:34.760
obviously control shift s, you can see it's actually going at 60 frames a second. I'm ending

208
0:25:34.760 --> 0:25:43.000
you're stuck in the floor. It's running at 60 frames a second in browser at 1080p, as we all

209
0:25:43.000 --> 0:25:51.080
just saw, which is pretty impressive for a fairly complicated scene that we have going on here. And

210
0:25:51.080 --> 0:25:58.280
the way that thirdroom works is quite unusual. And it's properly multi threaded in browser.

211
0:25:58.280 --> 0:26:03.480
It's using an entirely new game engine that the team basically put together. And I should

212
0:26:03.480 --> 0:26:07.880
hasten to add, I've basically been encouraging people rather than actually working on this,

213
0:26:08.600 --> 0:26:13.800
Robertson and Sam Fran. And so it'll be cruel and unusual to get him to do this and talk.

214
0:26:15.400 --> 0:26:19.320
And I've even got some slides here. And it's showing the scripting that is built in that

215
0:26:19.320 --> 0:26:23.960
I'll talk about in a minute. Now, the interesting thing is that we're using

216
0:26:23.960 --> 0:26:30.200
shadow raid buffers to go and share data between the main thread and a bunch of worker threads

217
0:26:30.200 --> 0:26:34.440
using post message between these and then the atomic APIs in the browser, so that you can

218
0:26:34.440 --> 0:26:39.640
actually have probable multiple threads in order to have the rendering thread running completely

219
0:26:39.640 --> 0:26:44.600
independently from the gaming thread that does physics and the main thread that does react and

220
0:26:44.600 --> 0:26:53.400
does hydrogen is with embedded hydrogen in the react app here, as well as matrix. So if I go

221
0:26:53.400 --> 0:27:01.160
into the next slide, here are the main threads, we've got react, matrix and web RTC happening.

222
0:27:01.160 --> 0:27:04.280
And we have spatial audio in here. So if I actually unmute myself,

223
0:27:05.640 --> 0:27:08.520
I've got first for myself on my own talk, that's annoying. Let me

224
0:27:09.960 --> 0:27:14.840
pause that. I'm still out there somewhere. You want to come over and say something to me?

225
0:27:14.840 --> 0:27:17.640
Somebody else. I'll go over to you. Say something.

226
0:27:17.640 --> 0:27:23.480
You hear me? Yeah, okay. So if we had headphones on at this point, and I turn this way and you say

227
0:27:23.480 --> 0:27:28.680
something, it's coming out the left speaker and you have to believe me and look the other way.

228
0:27:28.680 --> 0:27:32.440
And it's coming out. Honestly, it helps the immersive experience massively that we're

229
0:27:32.440 --> 0:27:36.120
going using spatial audio to go and position where things are here.

230
0:27:36.920 --> 0:27:40.920
Whilst we're wandering around here, you can see that we've got at the moment, generic avatars.

231
0:27:41.720 --> 0:27:46.360
But if you walk around a bit, you can see her moon walking backwards for whatever reason.

232
0:27:46.360 --> 0:27:51.800
I'm sure you can also go forwards. There we go. And fly for that matter. And

233
0:27:53.240 --> 0:27:57.400
so the B button lets you fly in this, so you can go and jump around like so.

234
0:27:58.520 --> 0:28:05.560
And so you're spoiling my talk. So if we go down here, then on the game thread, we've got

235
0:28:05.560 --> 0:28:10.360
a bunch of rust. We have the ability to run arbitrary WebAssembly scripts, which are sitting

236
0:28:10.360 --> 0:28:15.400
in a sandbox, which allows you to basically add any arbitrary functionality into the world.

237
0:28:15.400 --> 0:28:19.640
From a pure matrix perspective, this is probably the most exciting thing here.

238
0:28:19.640 --> 0:28:26.040
Now, if you remember, I'll see in Merck scripting, the ability to run arbitrary scripts on your IRC

239
0:28:26.040 --> 0:28:31.480
client, this is effectively allowing you to define bots and arbitrary functionality and matrix,

240
0:28:31.480 --> 0:28:37.880
which run inside your client, inside the sandbox, and the actual data is stored in your room.

241
0:28:37.880 --> 0:28:46.920
Now, this whole thing is a matrix room. If I go and hit enter, then you can see a bunch of users

242
0:28:46.920 --> 0:28:53.720
there. I can say, hello world. And if I go back to my element client, and if I literally join

243
0:28:53.720 --> 0:29:02.440
presentation on thirdroom.io for matrix.org, then you can see, I'm then saying, here. And I can say,

244
0:29:02.440 --> 0:29:13.000
here to you too. And hopefully, hang on. Well, we've got traffic running one way.

245
0:29:14.040 --> 0:29:19.880
Interesting. Well, we should be seeing messages coming into the room as well, because it is,

246
0:29:19.880 --> 0:29:25.720
oh, there we go. It's just a plain old hydrogen overlay that is being rented in React for the

247
0:29:25.720 --> 0:29:32.840
contents of the room. Now, the actual geometry of the room, if we start flying around some more,

248
0:29:33.400 --> 0:29:38.520
looks like this is actually a big GLTF or a single GLTF asset. This thing is just sitting

249
0:29:38.520 --> 0:29:43.720
in the media repository in the room. It's just a file that is GLTF, the transfer format for openGL,

250
0:29:43.720 --> 0:29:49.320
that has been uploaded there, and also any scripts in the room, like the one which is executing the,

251
0:29:49.320 --> 0:29:56.040
let me press on the buttons here. Again, there's a bit of, I think, JavaScript, using the quick JS

252
0:29:56.680 --> 0:30:00.920
engine that has gone and compiled down the JavaScript to WebAssembly in real time. It's

253
0:30:00.920 --> 0:30:05.160
pretty cool that you literally write it in JavaScript, and then the engine sucks it up,

254
0:30:05.160 --> 0:30:09.480
turns it into Wasm, and runs it within that sandbox. So you could argue it's a little bit

255
0:30:09.480 --> 0:30:13.960
perverse to be taking JavaScript, compiling it to WebAssembly, and then running it from within a

256
0:30:13.960 --> 0:30:19.960
JavaScript environment. But it gives you a hell of a lot more safety than you would if we were just,

257
0:30:19.960 --> 0:30:26.760
I don't know, having random blobs of JavaScript running here. On the render thread, we are using

258
0:30:26.760 --> 0:30:35.960
WebGL2, and we're using FreeJS to manage the actual driving of WebGL. But the scene itself is

259
0:30:35.960 --> 0:30:43.880
the scene itself is managed using a really cool technology called BitECS that was actually created

260
0:30:43.880 --> 0:30:49.240
by Nate, one of the developers, before he started working on, before they started working on Third

261
0:30:49.240 --> 0:30:57.400
Room. And BitECS is a entity component system where you basically track the state of the world,

262
0:30:57.400 --> 0:31:03.880
the objects that exist within it, their transformations, and it's done with arrays

263
0:31:03.880 --> 0:31:08.680
in JavaScript. And it turns out that if you stretch your arrays intelligently enough in JavaScript,

264
0:31:08.680 --> 0:31:13.960
you can get as good as WebAssembly performance. And it's one of the other secrets to the crazy

265
0:31:13.960 --> 0:31:19.960
performance that we have here. So this isn't an scene graph API under the hood, like a frame,

266
0:31:19.960 --> 0:31:29.320
if anybody ever played with a frame, instead, it's using the BitECS. Then another thing which

267
0:31:29.320 --> 0:31:35.640
is interesting here is that everything is triple buffered. So in a kind of traditional game engine,

268
0:31:35.640 --> 0:31:41.160
you just have one sort of buffer that you write data into and the renderer reads it out,

269
0:31:41.160 --> 0:31:46.360
and you have some kind of locking system to make sure that it doesn't collide. Whereas here, we

270
0:31:46.360 --> 0:31:52.120
have lot three data structures, letting things go as rapidly as possible with the various different

271
0:31:52.120 --> 0:31:58.760
bits of the engine writing into these shared triple buffer as a shared array buffer, which

272
0:31:58.760 --> 0:32:03.240
is then juggled effectively between the various different threads. And it means that the render

273
0:32:03.240 --> 0:32:09.240
thread can run at the native speed of whatever device, which is particularly useful if it's a

274
0:32:09.240 --> 0:32:14.680
less powered device than my MacBook Pro here. And then the game engine that is actually rendering

275
0:32:14.680 --> 0:32:19.800
what's going on can go at its own speed. So you totally decouple the two, and you get as high a

276
0:32:19.800 --> 0:32:26.280
frame rate as you can. And I think that oh, yeah, and finally, lots of fun stuff going on with

277
0:32:26.280 --> 0:32:33.640
optimization pipeline. Particularly the textures have been highly compressed using these fun

278
0:32:33.640 --> 0:32:40.280
codecs, I think it's called universal basis, format from Binomial and KTX. And one of the things

279
0:32:40.280 --> 0:32:47.000
we've done to cheat to bootstrap third room is to build a pipeline from unity, where you can take

280
0:32:47.000 --> 0:32:52.360
existing unity assets like this scene here is one that we bought off a unity asset store, and then

281
0:32:52.360 --> 0:32:58.520
export it as proper open standardized jotf somewhat liberating the contents from the slightly

282
0:32:58.520 --> 0:33:05.800
proprietary world of unity in order to get content in more rapidly, and then compress it down. And

283
0:33:05.800 --> 0:33:11.480
there are lots of fun things like the has instancing support built in. So if you start

284
0:33:11.480 --> 0:33:16.760
generating lots of objects like the physics engine here, I know going to create a whole bunch of

285
0:33:16.760 --> 0:33:21.080
objects and attack the various people who are wandering around in here. I'm sure they love me

286
0:33:21.080 --> 0:33:26.520
for it. And then this is basically just the same jotf asset. What are you doing?

287
0:33:28.840 --> 0:33:35.800
Going and being created multiple times, all the textures are sprouted. So there's just one great

288
0:33:35.800 --> 0:33:43.880
big thing. There's also some really interesting extensions to GL that we've contributed by the

289
0:33:43.880 --> 0:33:51.480
chronos group. And particularly, if you look at if we grab one of these miracles, which many use for

290
0:33:51.480 --> 0:33:56.280
debugging purposes, let's grab that one. And if I run around with it, while I fly around with it,

291
0:33:56.280 --> 0:34:03.480
you should see that the reflection changes. There we go. If I go between zones there, it's not

292
0:34:03.480 --> 0:34:07.480
it needs to be tuned a bit. But basically, rather than ray tracing, which would be incredibly

293
0:34:08.520 --> 0:34:12.680
time consuming, instead, we have lots of different probes hanging around the scene

294
0:34:12.680 --> 0:34:19.800
that allow you to I'm hitting myself in the face with the ball. A common problem. But as you run

295
0:34:19.800 --> 0:34:24.840
around, you can see the reflection changes. It's pretty nasty if you do it rapidly. But if you're

296
0:34:24.840 --> 0:34:29.800
doing it more slowly like this, and it's a quite a subtle but nice effect. And it's even better

297
0:34:29.800 --> 0:34:35.960
when it's on not perfect miracles. If you look at say, Dave, if you walk backwards, if you can hear

298
0:34:35.960 --> 0:34:40.840
me, or go into light or out of the light, then you'll actually see a fairly subtle shadowing

299
0:34:40.840 --> 0:34:45.560
effect as it's gone and figured out where the shadows are there. Right, it's good to see all

300
0:34:45.560 --> 0:34:51.880
the people running around in here. So what else can I show you one of the so we're going to launch

301
0:34:51.880 --> 0:34:56.920
some tech preview to this next week. And this is the first time anybody has seen tech preview two

302
0:34:56.920 --> 0:35:02.520
and I have 10 minutes left. And tech preview one is sort of what we've been looking at here,

303
0:35:02.520 --> 0:35:06.760
except it didn't have scripting, we've already shown some of the scripting here. But one of the

304
0:35:06.760 --> 0:35:15.960
big things that have been added and let's pray that this thing works is web VR. So hopefully, if I

305
0:35:17.720 --> 0:35:24.840
go to the Oculus streaming thing, which I had a second ago, I should have possibly cleaned this

306
0:35:24.840 --> 0:35:34.120
up first. Of course, it stopped working. Well, I get this thing back in again. And everything is

307
0:35:34.120 --> 0:35:39.640
going wrong. Apparently, I've got to recalibrate the entire thing. So I apologize, apologize for

308
0:35:39.640 --> 0:35:45.480
using proprietary technology, but unfortunately, there aren't any open source headsets which do

309
0:35:45.480 --> 0:35:56.920
the trick yet. And we go. And let me try to cast this up. And unfortunately, it takes ages for the

310
0:35:56.920 --> 0:36:09.480
screen casting to kick in for some reason. But I'll go as quick as I can. Bump and cast and computer

311
0:36:10.120 --> 0:36:19.400
go. Right. So WebXR is a really cool technology. It's been there for ages now since about 2017,

312
0:36:19.400 --> 0:36:27.880
built into browsers like Firefox and Chrome, obviously. And also, interestingly, the browser,

313
0:36:27.880 --> 0:36:33.080
the Oculus Quest like this or Quest Pro has built into it, which is based on Chromium.

314
0:36:34.520 --> 0:36:38.600
It has awful screen casting support, as you can see, that I started at screen casting and

315
0:36:38.600 --> 0:36:42.760
something is happening in the depths of Facebook, trying to figure out how to actually get this

316
0:36:42.760 --> 0:36:47.160
onto the screen here. But hopefully, it will come through. I've got internet connectivity. Here it

317
0:36:47.160 --> 0:36:54.600
is. Thank God. And I can start talking. And I apologize for I'm going to focus on oh, very

318
0:36:54.600 --> 0:36:58.600
interesting. So I'm going to focus on flooring rather than embarrassing everybody else.

319
0:36:59.720 --> 0:37:06.040
But let's just use a stationary boundary. Confirm. Right. So the browser here sits there.

320
0:37:06.760 --> 0:37:12.920
I'm not going to update this right now. But here is third room. And if I continue into third room,

321
0:37:12.920 --> 0:37:19.320
as guests, you can see this is just a static boring web browser just sitting here. Worth

322
0:37:19.320 --> 0:37:26.920
noting that third room uses OIDC entirely. So this thing here is actually a skinned key cloak.

323
0:37:26.920 --> 0:37:30.040
I'm going to say I'm not a bot. I'm not going to bother giving myself a name.

324
0:37:31.240 --> 0:37:34.200
And then capture failed. Brilliant. Thanks, Google.

325
0:37:34.200 --> 0:37:43.880
I'm going to have to type in third room except caffeine and stress means my ability to use a

326
0:37:43.880 --> 0:37:49.160
stupid keyboard like this is going to be fun. Okay, back to third room here is a streaming. Okay.

327
0:37:50.120 --> 0:37:55.160
Okay, brilliant. Let's go to login. Go out third room continues guests.

328
0:37:56.840 --> 0:38:00.920
This time hope that it's not gonna make me pick stupid things right good continue.

329
0:38:00.920 --> 0:38:08.120
You accept the T's and C's. Honestly, the using key cloak for this is really, really fun.

330
0:38:10.120 --> 0:38:15.720
And very anticlimactically, we end up with eventually want to look connectivity.

331
0:38:16.440 --> 0:38:25.480
A 2d version of third room just sitting right here. So isn't it amazing? By the way, that just

332
0:38:25.480 --> 0:38:33.800
loaded from index DB local storage. But the fun thing is hopefully, come on, you can do it.

333
0:38:33.800 --> 0:38:38.280
You can see it's actually struggling quite a lot. And this bit if I press the old X button,

334
0:38:39.000 --> 0:38:43.880
there, that's I have to close the welcome to third room dialogue. It is

335
0:38:45.880 --> 0:38:51.640
come on, and to XR. Thank God for that. Then I can see flooring Hello,

336
0:38:51.640 --> 0:38:58.120
Florian. But more excitingly, hopefully, if I stay in the right place, there we go. You can see that

337
0:38:58.120 --> 0:39:04.040
I'm actually in the third room environment right now. And this is genuinely cool. This is running

338
0:39:04.040 --> 0:39:11.960
at 90 frames a second for me right now. And if I go and press some buttons to create some Oh, God,

339
0:39:13.960 --> 0:39:19.320
some crates like massive crates, let me get rid of that. You can see it's actually hooked up to

340
0:39:19.320 --> 0:39:24.200
the normal physics engine. So I can go and pull that and I can confusingly throw it into the

341
0:39:24.200 --> 0:39:31.080
audience, which is no way surreal to be going and flipping back and forth. And then back in the

342
0:39:31.080 --> 0:39:37.800
normal world again. At the moment, we've just got basic things like the joystick and hung up,

343
0:39:38.360 --> 0:39:44.440
hooked up to it. It's got a kinematic controller. And I'm running out of Oh, no, thank you, Florian.

344
0:39:44.440 --> 0:39:53.880
Um, what else can I show you? You can jump, we can spawn more objects. I can go up to that glitter

345
0:39:53.880 --> 0:40:00.360
globe and sorry, mirror ball, except it's running faster than I can run after it. That's awkward.

346
0:40:01.560 --> 0:40:05.240
And theoretically, if I was a little bit closer to the bloody thing, I'd be able to grab it and

347
0:40:05.240 --> 0:40:12.600
pick it up, etc. So this is pretty cool. Honestly, it's as good as the native non web VR and closed

348
0:40:12.600 --> 0:40:19.880
stuff that Facebook or meta horizons does. And the entire thing is open. And I built on the

349
0:40:19.880 --> 0:40:25.400
surgery mentioned how am I doing for time three minutes in which case I will very quickly go and

350
0:40:25.400 --> 0:40:34.200
sorry, thanks. I will start looking at random overseas, go back into this and just look at some

351
0:40:34.200 --> 0:40:38.920
other things we've done. In fact, this one is really cool. Let's just flip into this one,

352
0:40:38.920 --> 0:40:43.240
because this is a really complicated bit of wasm. It's actually an audio reactive widget,

353
0:40:44.200 --> 0:40:49.560
which is setting here, as you can see, as I yell at it, it goes and changes size. And this is a

354
0:40:49.560 --> 0:40:54.200
whole bunch of C code that has been compiled down to wasm to show how you can have interactive

355
0:40:54.200 --> 0:41:03.320
things sitting inside the scene. Another example is slightly less exciting new chat box echo service.

356
0:41:03.320 --> 0:41:10.680
So if I go into here, and say, Hello, and then do echo, hello with a slash command, it says hello

357
0:41:10.680 --> 0:41:15.720
back to me. Now the echo that's happening down there is actually being done from the widget API

358
0:41:15.720 --> 0:41:22.920
of matrix going into WebAssembly, talking to I think a JavaScript service, and then echoes back.

359
0:41:22.920 --> 0:41:26.360
And you can see we have a slight bug sometimes with scripting where it loads two worlds at the

360
0:41:26.360 --> 0:41:31.560
same time. And that's pretty surreal. That's what happens if London got combined with miles.

361
0:41:31.560 --> 0:41:43.960
So, final thing here, I was going to show you, oh, yeah, is this guy, which is a bit silly, but fun

362
0:41:43.960 --> 0:41:48.680
anyway. And this time, I'll remember to refresh as fun as it is to have the scenes combined. So you

363
0:41:48.680 --> 0:41:55.400
might recognize this from a certain film. And if we actually look at the script for this particular

364
0:41:55.400 --> 0:42:01.000
room, if I can figure how to get out of full screen mode, the script here is again, just sitting in

365
0:42:01.000 --> 0:42:06.360
the media repository, it's a little bit of JavaScript, to use the Web Scene Graph API,

366
0:42:06.360 --> 0:42:10.280
which is a new API that we've created. We hope it will become a W3 standard for

367
0:42:10.280 --> 0:42:15.160
manipulating scene graphs. It looks a lot like DOM. You basically get a node by name, the TV,

368
0:42:15.160 --> 0:42:19.720
and then every frame, you'd see if the TV is being pressed, and if it is, then you enable the matrix

369
0:42:19.720 --> 0:42:24.760
material. And the end result is if I go here, and I click on the TV, then predictably enough,

370
0:42:24.760 --> 0:42:30.040
you end up in a matrix style world. And I've got it in third person view, which is also new with

371
0:42:30.040 --> 0:42:34.440
tech preview two, and click back and forth. This is super early, but you can imagine this is

372
0:42:34.440 --> 0:42:38.920
basically a platform for doing any kind of real time collaborative app could be Figma on this,

373
0:42:38.920 --> 0:42:44.120
it could be multiplayer blender, it could be a game, it could be digital twins, it could be,

374
0:42:44.120 --> 0:42:50.440
I don't know, smart cities, GIS applications, it's as powerful and as flexible as the web,

375
0:42:50.440 --> 0:43:02.280
but for real time. Thank you very much. And we have no time for questions.

376
0:43:13.800 --> 0:43:19.080
It will be coming in the next release after tech preview two. I mean, the hard bit of actually

377
0:43:19.080 --> 0:43:23.800
rigging up the engine and doing all the inverse kinematics. And if you run around with the current

378
0:43:23.800 --> 0:43:29.480
avatars, you can now trip over things, which is very important. But suffice to say, we're focusing

379
0:43:29.480 --> 0:43:34.200
on the engine rather than the assets. And also, this is at a point where people can start

380
0:43:34.200 --> 0:43:39.800
contributing things. So if you've got amazing assets, if they support the mixamo rig, then they

381
0:43:39.800 --> 0:43:52.280
should just drop straight in. Cool.

