WEBVTT

00:00.000 --> 00:11.280
Okay, then we continue with music with the next talk which is Become a Rockstar using

00:11.280 --> 00:12.280
3n.2 software.

00:12.280 --> 00:13.280
Please welcome Lorenzo.

00:13.280 --> 00:14.280
Thank you.

00:14.280 --> 00:15.280
Thank you very much.

00:15.280 --> 00:23.120
And it's going to be a hard job following up a guy that brought a synthesizer and an

00:23.120 --> 00:24.120
amplifier.

00:24.120 --> 00:27.720
I didn't bring anything to the table, so you'll just have to endure me talking about it.

00:27.720 --> 00:29.240
I hope it's fine anyway.

00:29.240 --> 00:33.040
And first of all, this is my first talk in open media and I already feel like a fraud

00:33.040 --> 00:36.560
because clickbait alert, I'm not a rockstar at all.

00:36.560 --> 00:39.280
I mean, this is an image that I got from Spotify last month.

00:39.280 --> 00:41.080
I got two listeners last month.

00:41.080 --> 00:42.280
One of those was me.

00:42.280 --> 00:45.960
So I think on average, you need a bit more than that.

00:45.960 --> 00:48.280
We actually call the rockstar, but it doesn't really matter.

00:48.280 --> 00:52.880
I had a lot of fun in the past few years just playing with music and open source.

00:52.880 --> 00:58.320
I mean, and I had to use this for something rather than just show them around the home.

00:58.320 --> 01:01.120
And for a living, of course, I don't do any music at all.

01:01.120 --> 01:04.720
I'm just a hobbyist musician and that's what I've been talking about today.

01:04.720 --> 01:06.680
In the real world, I am a WebRTC developer.

01:06.680 --> 01:10.560
I'm, for instance, involved in some of the things that Dan mentioned in his previous

01:10.560 --> 01:11.640
talk.

01:11.640 --> 01:17.480
I love a lot hard rock, metal, orchestral music, symphonic music when they work together

01:17.480 --> 01:18.480
as well.

01:18.480 --> 01:21.920
And this is something that I've been trying to do in my own music as well.

01:21.920 --> 01:24.280
And here you can find some links if you want to get in touch.

01:24.280 --> 01:28.280
For instance, you can get in touch on Mastodon, a couple of links to my music as well.

01:28.280 --> 01:29.880
And so on and so forth.

01:29.880 --> 01:33.920
And this is just a very basic and completely out of order table of content.

01:33.920 --> 01:37.960
So I talk about a few different things and I will not follow this order because I will

01:37.960 --> 01:43.120
mostly follow the order by which I learned how to do things with music and Linux in the

01:43.120 --> 01:44.120
first place.

01:44.120 --> 01:50.280
So how I tried to dip my toes into a few different things and how I eventually learned how to

01:50.280 --> 01:53.160
do some more complex things in the process.

01:53.160 --> 01:58.040
And of course, it will be a very, if you pass the term, a very dumb presentation because

01:58.040 --> 01:59.640
I will only scratch the surface.

01:59.640 --> 02:03.520
I'll try to introduce several different concepts.

02:03.520 --> 02:07.920
And really just to tickle your interest enough so that maybe you have your own guitar getting

02:07.920 --> 02:09.120
dusted home.

02:09.120 --> 02:13.160
You don't know how to get it started with, for instance, using your laptop to do some

02:13.160 --> 02:17.400
music and maybe this presentation will tickle your interest and you start doing something.

02:17.400 --> 02:21.040
And besides, there is a very good chance that I'll say something dumb as well.

02:21.040 --> 02:22.280
Or maybe something incorrect.

02:22.280 --> 02:24.200
So if I do, please bear with me.

02:24.200 --> 02:28.320
It's really a high level presentation and something that's really meant as an introduction,

02:28.320 --> 02:32.200
not really something that goes very much in detail.

02:32.200 --> 02:37.460
And when I first started learning about all this, I was really surprised by how mature,

02:37.460 --> 02:42.200
for instance, Linux and the audio ecosystems was to actually do music production on those

02:42.200 --> 02:47.880
machines because you always assumed the world around was Linux is not good enough to do

02:47.880 --> 02:48.880
real time music.

02:48.880 --> 02:51.480
You have to use Windows or MacOS or whatever.

02:51.480 --> 02:54.840
And I disagree with that because especially when I started with Jack at the time, I found

02:54.840 --> 02:57.600
a very interesting ecosystem to do things.

02:57.600 --> 03:02.820
And especially I really loved the port based approach that allowed you not to use monolithic

03:02.820 --> 03:07.200
applications to do things, but you have different applications that you can just connect arbitrarily

03:07.200 --> 03:08.800
any way you want.

03:08.800 --> 03:13.720
Possibly use the same source for multiple to connect to multiple applications, implement

03:13.720 --> 03:18.840
very complex workflows and all in real time and very low latency, which was really amazing.

03:18.840 --> 03:24.080
And the fact that you can have all these different applications to talking to each other means

03:24.080 --> 03:28.680
that you also often have a lot of different applications implementing more or less the

03:28.680 --> 03:29.680
same requirements.

03:29.680 --> 03:34.600
So you will have different synthesizers or different ways of implementing effects for

03:34.600 --> 03:36.280
your guitars and so on.

03:36.280 --> 03:40.960
And often they don't really need to be a substitution for one or the other.

03:40.960 --> 03:45.240
Maybe for one genre, it's better to use some applications, for some others, it's better

03:45.240 --> 03:46.240
using others.

03:46.240 --> 03:50.960
It's really up to your preference and how you like to work with music.

03:50.960 --> 03:55.840
And some tools may make sense more than others in that sense.

03:55.840 --> 04:00.800
And it's probably useless to make this distinction right now because we just had a very interesting

04:00.800 --> 04:05.040
presentation by Ernst who explained a bit what MIDI signals are.

04:05.040 --> 04:11.160
So when we talk about music production, especially on Linux and Jack, you do have to know basically

04:11.160 --> 04:15.420
that you have audio signals, so a sound that is that has already been processed, record

04:15.420 --> 04:20.600
or something, a waveform of some sort, and MIDI signals that just carry information that

04:20.600 --> 04:22.800
is then used to produce sounds.

04:22.800 --> 04:26.760
And so of course these two can go through very different workflows.

04:26.760 --> 04:32.480
Different applications can handle just one or both or maybe none at all.

04:32.480 --> 04:36.360
What's really important though is, again, how you can actually have different applications

04:36.360 --> 04:38.280
that you connect arbitrarily on your own way.

04:38.280 --> 04:42.720
And that was at the very basis of how Jack was conceived at the very beginning.

04:42.720 --> 04:47.880
And Jack, a few years ago, was really the way to do very low latency audio on Linux

04:47.880 --> 04:48.880
systems.

04:48.880 --> 04:53.160
The downside of that, it was that it was a bit complex to set up and manage.

04:53.160 --> 04:57.680
And luckily, and we've seen a presentation by wind this morning, PyPaw has made this

04:57.680 --> 04:58.680
so much simpler.

04:58.680 --> 05:00.720
So I was a bit skeptical at the beginning.

05:00.720 --> 05:05.480
I just jumped the wagon a couple of weeks ago.

05:05.480 --> 05:11.240
And basically, PyPaw comes with an implementation of Jack that basically hides all the complex.

05:11.240 --> 05:15.320
I mean, the applications stick, they're still using Jack, but in practice you are using

05:15.320 --> 05:20.760
PyPaw instead, which means that you can start using also applications that were not specifically

05:20.760 --> 05:26.240
conceived for Jack purposes and work on them together while you work on music production

05:26.240 --> 05:27.600
of some sort.

05:27.600 --> 05:31.520
And all of these small boxes that you see over there are basically different processes.

05:31.520 --> 05:36.480
And you see that some of them have inputs, some of them have outputs, either one or both,

05:36.480 --> 05:37.800
these sort of things.

05:37.800 --> 05:41.880
And this is what allows you to basically just arbitrarily connect different applications

05:41.880 --> 05:47.440
to each other to, again, create more complex workflows that you can get out of what a single

05:47.440 --> 05:48.640
application can do.

05:48.640 --> 05:51.280
And I'll show a couple of practical examples in a minute.

05:51.280 --> 05:56.240
So let's assume that you have that home guitar getting dusted home and now you want to get

05:56.240 --> 05:57.240
some noise.

05:57.240 --> 05:59.640
You want to connect it to your laptop and do something.

05:59.640 --> 06:04.720
So what you don't do is, of course, just plug it in the microphone slot because that will

06:04.720 --> 06:06.080
cause problems.

06:06.080 --> 06:08.760
What you need is some sort of an audio interface instead.

06:08.760 --> 06:14.360
So something like an external sound card that has some inputs that do accept your instrument

06:14.360 --> 06:15.680
instead.

06:15.680 --> 06:21.440
And often these interfaces come with USB interfaces and so are very easy to plug.

06:21.440 --> 06:25.080
Your operating system will very likely recognize them out of the box.

06:25.080 --> 06:30.080
And they will be available as a system capture and so as one of these boxes that we saw over

06:30.080 --> 06:31.080
there.

06:31.080 --> 06:34.240
So something that you can connect to something else.

06:34.240 --> 06:37.560
And the one that I have at home, and spoiler alert, it didn't come with the cat.

06:37.560 --> 06:40.960
The cat came with something else.

06:40.960 --> 06:47.120
I personally bought this Focusrite Scarlett Solo because it's quite inexpensive.

06:47.120 --> 06:52.800
It's very common among hobbyists because it already provides decent enough quality for

06:52.800 --> 06:53.920
recording at home.

06:53.920 --> 06:56.920
It's very flexible and I really like it a lot.

06:56.920 --> 07:00.880
And basically, the one that I bought basically comes with two separate inputs.

07:00.880 --> 07:05.320
So it has a USB interface so it recognizes an external USB sound card by the operating

07:05.320 --> 07:06.720
system.

07:06.720 --> 07:11.240
And mine in particular, I think later versions changed this a bit, but it comes with one

07:11.240 --> 07:16.240
input that is XLR, the typical cable that you use for microphones, for instance.

07:16.240 --> 07:20.760
And another one is the cable that the typical guitar jack slot.

07:20.760 --> 07:25.200
And since it's two different inputs, when you connect it to the operating system, the

07:25.200 --> 07:29.280
box that you see, which may have this name or entirely different name depending on what

07:29.280 --> 07:33.920
you're using, shows two different channels, which means that depending on where you are

07:33.920 --> 07:38.720
actually plugging what you want to plug, it will come out of one of those two different

07:38.720 --> 07:42.880
channels for what you want to do, which opens the door to a lot of different things that

07:42.880 --> 07:43.880
you can do.

07:43.880 --> 07:49.000
Because for instance, I could plug my guitar directly into this external sound card.

07:49.000 --> 07:54.480
In this case, I'm plugging it into the jack slot, that's chapter number two, which means

07:54.480 --> 07:57.120
that I can then use this chapter number two to do something.

07:57.120 --> 08:02.320
The dumbest thing that I can do is just connect it to the playback system so that I hear what

08:02.320 --> 08:05.840
I'm playing just unencoded.

08:05.840 --> 08:08.160
So I don't hear any effects.

08:08.160 --> 08:11.840
It's just the raw sound of the guitar, but it's something that I can do.

08:11.840 --> 08:15.640
Of course, I can do something more interesting and we'll show an example later.

08:15.640 --> 08:19.680
Or maybe you have a very good amplifier at home and a very good microphone.

08:19.680 --> 08:23.680
You put the microphone in front of the amplifier.

08:23.680 --> 08:30.760
You connect it to the first slot and what you get on your laptop is an already distorted,

08:30.760 --> 08:34.360
for instance, sound of your guitar out of your amplifier.

08:34.360 --> 08:38.040
Or maybe you can use them both at the same time, which is what I do often for classical

08:38.040 --> 08:44.920
and acoustic guitars, for instance, where I attach both the pickup of the guitar, whether

08:44.920 --> 08:50.240
it's integrated or added, and I put the microphone in front of the guitar just so that I capture

08:50.240 --> 08:52.160
different frequencies, different sounds.

08:52.160 --> 08:56.080
And together they give me a more full sound than they would give me individually.

08:56.080 --> 09:00.960
I mean, again, it's just very simple examples that show you that before you couldn't do

09:00.960 --> 09:05.880
anything with an external sound card like this, now you have ways to put your instrument

09:05.880 --> 09:11.440
and get it part of a workflow in your own laptop and do something cool.

09:11.440 --> 09:14.240
One cool thing that you could do, for instance, is just launch Gita Rix.

09:14.240 --> 09:20.600
Gita Rix is a very complex and effective guitar simulator, basically.

09:20.600 --> 09:25.200
So it has different beats that you can, it's very configurable, so you can create your

09:25.200 --> 09:31.000
own configuration, you can choose the different beats, how you want your amplifier to look

09:31.000 --> 09:32.000
like.

09:32.000 --> 09:34.720
I'm really stupid in that sense, so I never really tried to do it myself.

09:34.720 --> 09:39.600
I work a lot with presets shared by the community, but if you are savvy enough, you can just

09:39.600 --> 09:44.640
do things on your own to create, to really shape your own sound so that the guitar sounds

09:44.640 --> 09:47.960
exactly how you want it to sound like.

09:47.960 --> 09:52.520
And when you launch Gita Rix, it basically spawns two different boxes as far as jack

09:52.520 --> 09:57.560
or slash pipe, where I'm, again, when I'm seeing jack, you can assume I'm also just

09:57.560 --> 10:01.840
implying pipe or usage as a consequence.

10:01.840 --> 10:05.840
Basically it comes with two different boxes, one as an amplifier and one for effects.

10:05.840 --> 10:11.600
And then it means that since we had the jack in my Scarlett Focusrite was capture number

10:11.600 --> 10:16.080
two, I connect that to the amplifier, I connect the amplifier to the effects, I connect the

10:16.080 --> 10:20.280
effects to whatever I want, playback, something that records it.

10:20.280 --> 10:21.520
It's really that simple.

10:21.520 --> 10:28.360
So you have already created a workflow out of that beat that you managed to capture thanks

10:28.360 --> 10:30.800
to the external audio interface.

10:30.800 --> 10:35.040
Another application that I love a lot as a guitar player is Raka Raka, I'm not sure if

10:35.040 --> 10:40.440
I'm pronouncing it correctly or not, which is not a guitar amplifier simulator as Gita

10:40.440 --> 10:41.520
Rix sees.

10:41.520 --> 10:45.360
It's basically a pedal board simulator instead.

10:45.360 --> 10:48.960
So it has a lot of different effects that you can use and combine.

10:48.960 --> 10:52.640
You can, it also comes with a lot of different presets.

10:52.640 --> 10:56.720
I particularly love the clean sounds that you can get out of Raka Raka.

10:56.720 --> 11:01.320
And again, similar approach, you connect your, whatever capture where you add your guitar

11:01.320 --> 11:04.120
on to Raka Raka and then the output of that.

11:04.120 --> 11:09.600
So the processed sound of the guitar will, it's something that you can end up using.

11:09.600 --> 11:15.240
You can do something more complex or in some cases also dumbed by just possibly using both

11:15.240 --> 11:17.320
Gita Rix and Raka Raka at the same time.

11:17.320 --> 11:19.120
So putting them one after the other.

11:19.120 --> 11:23.480
This is a very simple example and probably doesn't make sense to have the effects box

11:23.480 --> 11:24.520
in between there.

11:24.520 --> 11:30.160
But this is a similar approach is what I use, for instance, myself in one of the songs because

11:30.160 --> 11:34.480
I had an effect that I liked in Gita Rix, but I also need the sustainer effect in Raka

11:34.480 --> 11:35.480
Raka as well.

11:35.480 --> 11:38.640
So I basically just chained them in my workflow.

11:38.640 --> 11:43.200
I plugged my guitar in the sound card that Gita Rix distorted and then Raka Raka do some

11:43.200 --> 11:47.560
more things with the sound before I actually used it for something.

11:47.560 --> 11:51.840
And again, this is just very simple examples that are meant to show you how easy it is

11:51.840 --> 11:57.280
to create a workflow using different applications out of sounds that you have access to, to

11:57.280 --> 12:00.240
do some interesting and really cool things.

12:00.240 --> 12:05.720
And so let's assume that basically now we managed to get a decent sound.

12:05.720 --> 12:10.560
Now we just want to record something because we want to either write the song or whatever.

12:10.560 --> 12:14.440
And of course, if you want to do something very simple, so just record the sounds and

12:14.440 --> 12:20.560
then use them somewhere else, you can use any tool that is actually able of consuming

12:20.560 --> 12:21.560
these sources.

12:21.560 --> 12:25.560
And so Audacity or Gstreamer come to mind, but there's so many more.

12:25.560 --> 12:31.280
If you want to do something more complex, maybe work to write a song no matter how complex

12:31.280 --> 12:35.680
it is, you'll want to work within some sort of a project instead.

12:35.680 --> 12:40.200
So maybe in an application that is capable of handling multiple tracks at the same time

12:40.200 --> 12:45.120
and that maybe can add different filters to all these tracks that you're having.

12:45.120 --> 12:50.520
So because you need a compressor on one or maybe reverb on some tracks or you need equalization

12:50.520 --> 12:52.400
or something like this.

12:52.400 --> 12:56.320
And this is the kind of application that you use a digital audio workstation for.

12:56.320 --> 12:59.200
And DAB is a short term for that.

12:59.200 --> 13:03.560
And mostly because these kinds of applications are specifically conceived to do exactly that.

13:03.560 --> 13:10.080
So possibly record things in real time or use existing assets, edit and produce, although

13:10.080 --> 13:15.440
these are different audio files in different ways, they often support media as well.

13:15.440 --> 13:20.040
And especially most of them have a modular nature that allows you to use existing models

13:20.040 --> 13:27.160
that are part of the open source ecosystem to add different effects to any of those tracks,

13:27.160 --> 13:31.280
either as a whole, for instance, a filter that applies to multiple tracks at the same

13:31.280 --> 13:35.680
time or just one of them and so on and so forth, because you may want equalization,

13:35.680 --> 13:36.680
compression.

13:36.680 --> 13:42.680
I mean, whatever is part of the usual audio editing process in a regular music studio,

13:42.680 --> 13:46.640
if you want, is something that a digital audio workstation can provide for you.

13:46.640 --> 13:50.560
So if you're ever heard, for instance, of Pro Tools and stuff like this, this is exactly

13:50.560 --> 13:54.720
what a digital audio workstation can do for you.

13:54.720 --> 14:00.240
And the one that I personally use is called Dardour, which is a very powerful component.

14:00.240 --> 14:03.320
I personally use this because it was the first one I stumbled upon.

14:03.320 --> 14:07.240
I fell in love with it at the time and I just kept on learning.

14:07.240 --> 14:10.440
But again, there are more than that you can use out there.

14:10.440 --> 14:15.280
There's Kootractor, there's Reaper, which is not open source, but it's also very used

14:15.280 --> 14:19.560
in the open source applications as well.

14:19.560 --> 14:24.160
And one thing that you'll notice when you start using an application like this is that

14:24.160 --> 14:29.520
the boxes in that graph that I showed, for instance, on Jack or Pipe, are going to explode

14:29.520 --> 14:33.720
because a digital audio workstation is going to handle a lot of tracks and those tracks

14:33.720 --> 14:36.240
are going to be connected to a lot of things.

14:36.240 --> 14:39.560
And so you'll see a huge amount of connections out there.

14:39.560 --> 14:44.120
And luckily for you, you don't really have to create those connections on your own because

14:44.120 --> 14:46.080
otherwise you will go crazy.

14:46.080 --> 14:51.800
Often it's the digital audio workstation that does this for you and there are easier ways

14:51.800 --> 14:57.200
to change those connections if you need to from the user interfaces or all those applications.

14:57.200 --> 15:02.000
And most importantly, this shows that no matter how monolithic now this application can look

15:02.000 --> 15:06.600
like, it's still able to communicate with all those external applications that we mentioned.

15:06.600 --> 15:11.120
So you can still have, for instance, another session open, a guitar rig session open, you

15:11.120 --> 15:16.400
connect your guitar to guitar rigs and then you connect your guitar rigs to that in order

15:16.400 --> 15:18.160
for it to record it.

15:18.160 --> 15:21.760
Or maybe you have guitar rigs as a plugin so that you just record the clean sound and

15:21.760 --> 15:26.760
then you have it processed in different ways any time that you need it, these sort of things.

15:26.760 --> 15:31.440
And so let's assume that we have now bass and guitars.

15:31.440 --> 15:35.320
I am assuming that bass and guitars you can process them pretty much the same way.

15:35.320 --> 15:38.240
I'm sure that there are bass players that will disagree with me.

15:38.240 --> 15:40.360
The concept is like this.

15:40.360 --> 15:42.480
Let's say that you now need drums.

15:42.480 --> 15:45.120
And let's assume that you're like me.

15:45.120 --> 15:46.360
I'm a WebRTC developer.

15:46.360 --> 15:47.440
I have no friends.

15:47.440 --> 15:50.200
So I don't have any drummer friend either.

15:50.200 --> 15:52.960
So I have to create a virtual one instead.

15:52.960 --> 15:57.400
So something that plays drums for me because I am at home doing nothing.

15:57.400 --> 16:02.760
And which means that this is the very first good example of a virtual instrument.

16:02.760 --> 16:08.000
So I need to write the drum parts somehow and then I need to sequence them somehow,

16:08.000 --> 16:10.680
which means that the drum parts will be the instructions.

16:10.680 --> 16:14.880
So what I want to be played and then something will actually translate them to a kick sound

16:14.880 --> 16:17.440
as an air sound, this sort of things.

16:17.440 --> 16:21.880
And of course you can just play right the MIDI manually or use something like Mero's

16:21.880 --> 16:23.120
as we've seen.

16:23.120 --> 16:26.960
What I found out that is for drums it's much easier to work with a pattern based instead

16:26.960 --> 16:32.440
mostly because of the reach mechanism of the instrument and the fact that you can often

16:32.440 --> 16:37.640
do some repetitions, maybe some variations and then just play a bit with those instead.

16:37.640 --> 16:42.400
And personally I like hydrogen a lot in that sense because it's basically it allows you

16:42.400 --> 16:44.160
to create multiple patterns.

16:44.160 --> 16:47.200
For instance, it has all the different parts of a drum.

16:47.200 --> 16:52.720
You can say within the context of a measure play this there at this, this, this, and this

16:52.720 --> 16:54.840
point, a kick here and here and here.

16:54.840 --> 16:56.160
You create different patterns.

16:56.160 --> 17:00.980
You specify the sequence of those patterns or even some patterns in parallel if you use

17:00.980 --> 17:04.480
some patterns just to create variations, this sort of things.

17:04.480 --> 17:09.800
And then you basically hydrogen plays drums for you out of what you just wrote basically.

17:09.800 --> 17:14.860
And while hydrogen comes with its own sounds, which is really cool, I personally just use

17:14.860 --> 17:18.760
hydrogen to write the parts but then use drum gizmo to actually render them mostly because

17:18.760 --> 17:24.880
drum gizmo is probably the most advanced drum renderer that is out there because it's basically

17:24.880 --> 17:30.680
a lot of drum keys that were captured and recorded by professional drummers.

17:30.680 --> 17:37.800
They created samples and then using drum gizmo you can replay them also using, I mean, I'm

17:37.800 --> 17:41.600
not even going to try and explain how drum gizmo works because it's very complex but

17:41.600 --> 17:46.160
it's, suffice it to say that it has so many channels that it's the best way to actually

17:46.160 --> 17:51.560
get drum sounds out there and also work with them within the mixing process.

17:51.560 --> 17:57.960
Which means that from a Jack perspective I just use hydrogen to generate the drum parts

17:57.960 --> 18:02.840
and then I connect the MIDI output of hydrogen to drum gizmo and then whatever drum gizmo

18:02.840 --> 18:06.880
generates I use within the context of my own application.

18:06.880 --> 18:09.160
That's basically how it works.

18:09.160 --> 18:13.480
And now that we've dipped our toe in the MIDI world, what can we do with other instruments?

18:13.480 --> 18:18.880
Because maybe we want a keyboard background, a pad or a piano solo or even a full orchestra

18:18.880 --> 18:22.080
behind our music.

18:22.080 --> 18:25.920
And again, this is what MIDI is for because basically we don't have access to a whole

18:25.920 --> 18:30.280
orchestra because I don't have 30,000 euros to pay a lot of players.

18:30.280 --> 18:35.120
So what I do is I just sketch and write the notes for all the different instruments that

18:35.120 --> 18:40.160
are involved and then those notes, that information will be translated to actual sounds.

18:40.160 --> 18:44.960
So something will be played by something that simulates strings, something else will simulate

18:44.960 --> 18:48.720
a trumpet, these sort of things.

18:48.720 --> 18:50.800
And of course these notes can come from different places.

18:50.800 --> 18:55.640
It can come from an hardware keyboard as we saw in the previous presentation with Melrose

18:55.640 --> 18:58.040
or it can come from something that you wrote.

18:58.040 --> 19:01.120
For instance using Melrose or other approaches.

19:01.120 --> 19:05.480
And I am not a keyboard player but I did buy this small tiny thing over here that again

19:05.480 --> 19:07.040
is just plug and play.

19:07.040 --> 19:12.600
You plug it in there, it becomes a MIDI input that you can use for different things.

19:12.600 --> 19:16.920
And once you have it, you can have a lot of different ways of rendering MIDI sounds.

19:16.920 --> 19:21.080
Sound fonts are historically the oldest and easiest way to do that.

19:21.080 --> 19:25.520
And the Q-seam, thanks to FluidSimt, is one of the most popular ways to actually play

19:25.520 --> 19:26.520
them.

19:26.520 --> 19:31.280
You can use a sound font from somewhere that contains all the sounds that are associated

19:31.280 --> 19:33.280
to different instruments.

19:33.280 --> 19:38.240
And then for instance you just connect your keyboard to FluidSimt using the MIDI part

19:38.240 --> 19:43.560
and that eventually gets generated to actual sounds that you can then use for something

19:43.560 --> 19:44.880
else.

19:44.880 --> 19:48.360
If you don't want to use sound fonts, maybe you want to use a synthesizer instead.

19:48.360 --> 19:49.560
There's plenty of those as well.

19:49.560 --> 19:52.760
I use Yoshimi a lot but there's also Zina's effects.

19:52.760 --> 19:59.280
That's a very complex name but they share a lot of code because Yoshimi was actually

19:59.280 --> 20:00.280
a fork of death.

20:00.280 --> 20:03.320
There is Surge which is also another excellent synthesizer.

20:03.320 --> 20:06.240
So in that case there is no sound bank they start from.

20:06.240 --> 20:09.400
They actually generate the sound depending on what you want to do.

20:09.400 --> 20:15.880
And again I'm dumb so I never aim at creating my own synthesized sounds but if you know

20:15.880 --> 20:18.560
more about that it's something that you can do.

20:18.560 --> 20:20.160
And again it works pretty much the same way.

20:20.160 --> 20:24.480
You can connect your keyboard to Yoshimi and Yoshimi you can directly connect the sound

20:24.480 --> 20:25.480
to that as well.

20:25.480 --> 20:29.520
And in this example I also wanted to highlight the fact that again you can connect the same

20:29.520 --> 20:31.000
source to multiple things.

20:31.000 --> 20:36.360
So in this example I'm connecting my keyboard to both Yoshimi and that sound from the application

20:36.360 --> 20:37.640
that I showed before.

20:37.640 --> 20:42.960
So that whatever I play sounds both like a synthesizer and a piano at the same time.

20:42.960 --> 20:50.560
Okay I'll just fly over the slides so for some files are also very interesting to do

20:50.560 --> 20:51.560
the same thing.

20:51.560 --> 20:56.600
You can use Windows VSTs over there as well via LinVST for instance.

20:56.600 --> 21:01.040
If you want to write music you can use Lillipone, Melrose, NuScore which I personally like a

21:01.040 --> 21:02.040
lot.

21:02.040 --> 21:05.360
If you don't know music notation you can use piano rolls.

21:05.360 --> 21:09.800
And if you want to then publish this you can there's a lot of places where you can publish

21:09.800 --> 21:13.600
your music but what I really encourage to do however you publish your music make sure

21:13.600 --> 21:16.840
that you engage the community in order to exchange information.

21:16.840 --> 21:22.240
So for instance I use a lot Linux musicians and the main author of Linux musicians is

21:22.240 --> 21:23.240
there as well.

21:23.240 --> 21:27.320
He asked me to tell you there's a lot of stickers that you can get from here if you want.

21:27.320 --> 21:31.160
It's an excellent place to get in touch with other musicians working in the open source

21:31.160 --> 21:32.840
space so that you exchange ideas.

21:32.840 --> 21:34.960
You publish a piece they give you advice.

21:34.960 --> 21:36.480
It's an excellent place to learn.

21:36.480 --> 21:40.360
You may want to add video like I did with my Viking Metal cover of All You Want For

21:40.360 --> 21:46.000
Christmas is by Mariah Carey and that's a fun watch if you want to see it.

21:46.000 --> 21:52.040
I talked also a bit about WebRTC used for musicians as well which in a previous presentation

21:52.040 --> 21:55.400
that you may want to look at and then that's basically it.

21:55.400 --> 21:58.560
These are again my contacts if you want to have a look at that.

21:58.560 --> 22:03.560
Unfortunately I didn't speak fast enough.

22:03.560 --> 22:10.560
I have a question for the wall.

22:10.560 --> 22:11.560
Question?

22:11.560 --> 22:12.560
Yeah.

22:12.560 --> 22:13.560
Thanks for the presentation.

22:13.560 --> 22:14.560
Oh no thank you.

22:14.560 --> 22:22.560
One basic question for the audio chain slides that you showed.

22:22.560 --> 22:23.560
Yeah.

22:23.560 --> 22:29.560
So a bike wire has a GUI content where you can actually do the chain or some other thing.

22:29.560 --> 22:31.560
Yeah basically I personally use.

22:31.560 --> 22:34.280
Oh sorry.

22:34.280 --> 22:39.560
The question was does pipe wire also have the way of showing those different boxes that

22:39.560 --> 22:42.520
you can connect in order to create a workflow.

22:42.520 --> 22:47.920
I personally still use QJAC control which was a front end specifically conceived for

22:47.920 --> 22:54.120
Jack mostly because pipe wire implements Jack as well and so QJAC controls allows you to

22:54.120 --> 22:58.840
create the same connections from the Jack perspective but there are some applications

22:58.840 --> 23:02.140
that are specifically conceived for pipe wire as well.

23:02.140 --> 23:03.320
It really works the same way.

23:03.320 --> 23:07.360
You have these different boxes and you can connect them any way that you want.

23:07.360 --> 23:09.840
And for Jack it's also a GUI or you script it?

23:09.840 --> 23:13.680
No no you can script it if you want but you can definitely use a GUI.

23:13.680 --> 23:15.680
I always use a GUI because otherwise you go crazy.

23:15.680 --> 23:16.680
Any other questions?

23:16.680 --> 23:17.680
I'm not sure which one yesterday is guys.

23:17.680 --> 23:18.680
Any other questions?

23:18.680 --> 23:31.040
Do you have a favorite from the other question?

23:31.040 --> 23:32.040
I'm sorry?

23:32.040 --> 23:38.400
Yeah the one that I use since I work a lot with metal the one that I prefer is called

23:38.400 --> 23:43.720
the Muldi or Kit which I personally love that one a lot but there are a lot of excellent

23:43.720 --> 23:44.720
tools out there.

23:44.720 --> 23:45.720
Good job.

23:45.720 --> 23:46.720
Thank you.

23:46.720 --> 23:49.440
Have you used the YABRIDGE?

23:49.440 --> 23:50.440
Which one sorry?

23:50.440 --> 23:52.440
Have you used YABRIDGE for Windows VSTs?

23:52.440 --> 23:53.440
YABRIDGE.

23:53.440 --> 24:00.760
No for Windows VSTs the one that I use the most are some free VSTs by Spitfire Audio

24:00.760 --> 24:02.720
the Spitfire Labs Audio.

24:02.720 --> 24:06.720
They have a lot of free different VSTs that are very interesting and experimental sounds

24:06.720 --> 24:08.400
and those are the ones that I like the most.

24:08.400 --> 24:12.720
I used it when I used it for YABRIDGE but that's the easiest way to use Windows VSTs.

24:12.720 --> 24:14.440
Yeah there are different ways.

24:14.440 --> 24:21.920
So LinVST is the one that I found to be the easiest but you can use DSSI, VOs for instance

24:21.920 --> 24:25.520
is another way to do that but there are different approaches.

24:25.520 --> 24:30.760
Personally the one that worked consistently for me was LinVST that's just why I used it.

24:30.760 --> 24:31.760
Sorry.

24:31.760 --> 24:38.040
If I install pipewire can I get rid of full-soudier?

24:38.040 --> 24:42.200
Yeah I know because pipewire is basically a replacement for both Full-soudier and Jack

24:42.200 --> 24:45.480
even though it's compliant with both of them so you can just...

24:45.480 --> 24:48.360
I can just play a video almost differently too.

24:48.360 --> 24:51.640
Yeah exactly while you record your guitar which is something that you couldn't do before

24:51.640 --> 24:57.080
and besides pipewire also does an excellent thing for instance with just playing Jack

24:57.080 --> 25:01.160
I couldn't attach two different audio interfaces to my computer.

25:01.160 --> 25:03.640
I had to choose one or use Zita to add another.

25:03.640 --> 25:09.640
Instead with pipewire I can plug as many as I want and they all appear which is great.

25:09.640 --> 25:16.360
I think I have to...

25:16.360 --> 25:18.360
Yeah, yeah, I'll come outside in a second.

25:18.360 --> 25:19.360
Yeah, sure.

25:19.360 --> 25:43.480
I'm going to go to the

25:43.480 --> 25:50.480
room.

25:50.480 --> 25:53.480
I'll just come and talk in a second because I think I should

25:53.480 --> 25:54.480
wait for him.

25:54.480 --> 25:56.480
Sorry, thank you.

25:56.480 --> 25:57.480
Sorry, no worries.

25:57.480 --> 25:58.480
Sorry, no worries.

25:58.480 --> 25:59.480
Sorry, sorry, sorry.

25:59.480 --> 26:00.480
Sorry, sorry, sorry.

26:00.480 --> 26:01.480
Sorry, sorry, sorry.

26:01.480 --> 26:14.480
Sorry, sorry.
