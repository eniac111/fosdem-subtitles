1
0:00:00.000 --> 0:00:13.760
So welcome to my talk about Trixity, one matrix SDK for almost everything.

2
0:00:13.760 --> 0:00:20.700
I added written in Kotlin a few days ago, so maybe there are some Kotlin fanboys here.

3
0:00:20.700 --> 0:00:24.400
Yeah, let me first introduce myself.

4
0:00:24.400 --> 0:00:30.240
I am Benedict and my friends often see me as a kid when it comes to data prediction

5
0:00:30.240 --> 0:00:31.720
and data security.

6
0:00:31.720 --> 0:00:39.480
But I convinced them to come to Matrix anyhow, so I have 20 users, family and friends on

7
0:00:39.480 --> 0:00:42.480
my own Matrix home server.

8
0:00:42.480 --> 0:00:48.960
My first contact with Matrix was four to five years ago and I gained a lot of experience

9
0:00:48.960 --> 0:00:51.800
with it since then.

10
0:00:51.800 --> 0:00:59.960
And so much I founded Connect2X and this is just a company that is developing a Timmy

11
0:00:59.960 --> 0:01:06.340
and that is a TI messenger for the medical health sector in Germany.

12
0:01:06.340 --> 0:01:08.360
Now let's start with Trixity.

13
0:01:08.360 --> 0:01:19.080
Trixity is a Matrix SDK and it is for developing clients, bots, app servers and servers.

14
0:01:19.080 --> 0:01:27.280
It is multi-platform capable, so everyone thinks Kotlin is JVM only, it is not.

15
0:01:27.280 --> 0:01:30.880
You can compile it to JS and you can compile it to native.

16
0:01:30.880 --> 0:01:33.580
That's important for iOS.

17
0:01:33.580 --> 0:01:39.560
So we all have that target with Trixity.

18
0:01:39.560 --> 0:01:46.960
And it's also developed test-driven, so we have a high test coverage and it is licensed

19
0:01:46.960 --> 0:01:51.720
under the Apache 2 license.

20
0:01:51.720 --> 0:01:55.400
You may wonder why another SDK?

21
0:01:55.400 --> 0:02:03.720
So back in January 2020 there were only a few multi-platform SDKs to choose from.

22
0:02:03.720 --> 0:02:12.080
If I remember correctly there was the Matrix Rust SDK but it was in a very early stage.

23
0:02:12.080 --> 0:02:21.560
And there was the Dart SDK but very likely this forces you to use Flutter in the UI,

24
0:02:21.560 --> 0:02:28.160
so there isn't a real free choice which UI framework you want to use, especially when

25
0:02:28.160 --> 0:02:35.880
you want to use native UI technologies, for example on Android Compose or on iOS Swift.

26
0:02:35.880 --> 0:02:43.760
Additionally, most SDKs didn't have a very strict typing of events and the rest endpoints.

27
0:02:43.760 --> 0:02:48.080
And also the extensibility was a bit limited.

28
0:02:48.080 --> 0:02:54.520
Even if the next point is not that important, SDKs were really bound to its purpose.

29
0:02:54.520 --> 0:03:00.280
So you've had an SDK for a client, for a server, for a bot and so on.

30
0:03:00.280 --> 0:03:10.760
So you have to learn a new SDK for each purpose of application for Matrix.

31
0:03:10.760 --> 0:03:12.400
Why I chose Kotlin?

32
0:03:12.400 --> 0:03:19.320
Chose Kotlin because it is a statically typed language which compiles, as I mentioned, to

33
0:03:19.320 --> 0:03:21.600
JVM, JS and native.

34
0:03:21.600 --> 0:03:24.440
And you don't need bindings.

35
0:03:24.440 --> 0:03:32.160
Like in Rust, when you use JS you get JS, you don't need to make bindings over Wasm

36
0:03:32.160 --> 0:03:33.520
or something.

37
0:03:33.520 --> 0:03:39.840
And on native you can just call it from your Swift or Objective-C code in Xcode and have

38
0:03:39.840 --> 0:03:42.840
access to Trixity.

39
0:03:42.840 --> 0:03:51.320
Moreover, besides shared common code, it is possible to write platform specific code.

40
0:03:51.320 --> 0:03:56.080
You just define a common interface and depending on the platform, the actual implementation

41
0:03:56.080 --> 0:03:58.040
can be different.

42
0:03:58.040 --> 0:04:03.960
This way you have access to platform specific APIs and libraries which can be very helpful

43
0:04:03.960 --> 0:04:08.880
when implementing encryption like AES for attachments.

44
0:04:08.880 --> 0:04:13.880
So you have on each platform can you use the native encryption algorithms the platform

45
0:04:13.880 --> 0:04:16.680
gives you already.

46
0:04:16.680 --> 0:04:23.360
And last but not least, you can define your own domain specific language.

47
0:04:23.360 --> 0:04:26.640
You will see later what I did with that.

48
0:04:26.640 --> 0:04:29.920
So let's start with the core of Trixity.

49
0:04:29.920 --> 0:04:38.440
The core contains all basic data structures of the spec and its serialization algorithms.

50
0:04:38.440 --> 0:04:43.920
This includes events, identifiers like user IDs, event IDs and so on.

51
0:04:43.920 --> 0:04:51.720
And other things like cross signing keys, device keys.

52
0:04:51.720 --> 0:04:58.720
One goal of developing Trixity was the ability to add custom events which are strictly typed.

53
0:04:58.720 --> 0:05:05.160
So this is achieved by mapping event types to just a serializer.

54
0:05:05.160 --> 0:05:13.880
In this example we add a new type of M.PumPumCAD with this of the Kotlin type CAD event content

55
0:05:13.880 --> 0:05:19.560
so you have access to all fields of this CAD event content and don't have to mess around

56
0:05:19.560 --> 0:05:23.680
with the JSON.

57
0:05:23.680 --> 0:05:28.200
The next layer of Trixity is the API layer.

58
0:05:28.200 --> 0:05:34.240
Each API has its model which defines all endpoints of the API.

59
0:05:34.240 --> 0:05:42.040
The actual client and server implementation just use these endpoints and so as a consequence

60
0:05:42.040 --> 0:05:44.640
there is no need to define things twice.

61
0:05:44.640 --> 0:05:46.880
They are using the same Kotlin object.

62
0:05:46.880 --> 0:05:52.000
So a Kotlin object represents an endpoint on the matrix side.

63
0:05:52.000 --> 0:05:56.160
A Kotlin class, not Kotlin object, sorry.

64
0:05:56.160 --> 0:06:00.940
The best way to show this to you is with an example.

65
0:06:00.940 --> 0:06:04.240
This example is the endpoint leave room.

66
0:06:04.240 --> 0:06:08.960
You just implement matrix endpoint, give him the types.

67
0:06:08.960 --> 0:06:17.200
And in this case unit is the response so we don't get a JSON as response, just a headed

68
0:06:17.200 --> 0:06:20.680
HTTP OK or an empty JSON.

69
0:06:20.680 --> 0:06:28.200
And you can also define a request, a URL, HTTP method and all that.

70
0:06:28.200 --> 0:06:40.920
And you can use this to call, to use a client, matrix client on the client side to call these

71
0:06:40.920 --> 0:06:41.920
endpoints.

72
0:06:41.920 --> 0:06:46.840
So you create a leave room object, a request and you get the response.

73
0:06:46.840 --> 0:06:48.840
That's all on the client side.

74
0:06:48.840 --> 0:06:52.540
And the same thing on the server side.

75
0:06:52.540 --> 0:06:59.400
So you define an endpoint, give it the type you expect as a request and in the context

76
0:06:59.400 --> 0:07:07.000
object you have access to the request and can answer with the response.

77
0:07:07.000 --> 0:07:11.920
To make it a bit more easier for developers there is a bit of abstraction on top of that

78
0:07:11.920 --> 0:07:15.800
so you can also just call leave room.

79
0:07:15.800 --> 0:07:20.600
So you don't have to know which endpoint are there existing.

80
0:07:20.600 --> 0:07:26.720
You just type point on your IDE and see OK there's a leave room, I can leave a room.

81
0:07:26.720 --> 0:07:32.120
And the same on the server side so you just need to implement an interface and see all

82
0:07:32.120 --> 0:07:40.880
your endpoints you have to implement to be a fully featured matrix server API.

83
0:07:40.880 --> 0:07:46.200
Regardless of the API there is Trixity Arm and Trixity Crypto.

84
0:07:46.200 --> 0:07:51.800
Trixity Arm is just a wrapper for Lib Arm as mentioned a platform independent implementation

85
0:07:51.800 --> 0:07:58.920
doesn't need to worry about the actual platform specific implementations.

86
0:07:58.920 --> 0:08:08.760
So you have when you use Trixity Arm you don't need to know how Lib Arm is accessed.

87
0:08:08.760 --> 0:08:17.360
So on the JVM I use JNA, on JS this is done via Wasm and on native just C interrupt from

88
0:08:17.360 --> 0:08:20.880
Kotlin.

89
0:08:20.880 --> 0:08:26.920
Lib Arm is also packaged into Trixity Arm so as a developer you doesn't need to ship

90
0:08:26.920 --> 0:08:36.120
the build C library and it is just loaded automatically so you just you don't need to

91
0:08:36.120 --> 0:08:42.520
init your encryption like in other libraries it's just loaded.

92
0:08:42.520 --> 0:08:50.440
My plan is to migrate that to Wodosemic but currently UniFFI we heard of that in another

93
0:08:50.440 --> 0:08:54.860
talk does not support Wasm targets.

94
0:08:54.860 --> 0:09:03.440
So currently I can Wodosemic just only use in Kotlin JVM and native but I also want to

95
0:09:03.440 --> 0:09:09.320
use JavaScript so this project is currently on ice.

96
0:09:09.320 --> 0:09:14.440
Trixity Crypto currently implements the key management and allows to decrypt and encrypt

97
0:09:14.440 --> 0:09:21.880
events and in the future it will be more so you can reuse the completely complete crypto

98
0:09:21.880 --> 0:09:28.760
stuff for example in app services.

99
0:09:28.760 --> 0:09:36.760
Trixity Client allows you to, oh sorry, the most abstract layer are Trixity Client and

100
0:09:36.760 --> 0:09:40.120
Trixity App Service.

101
0:09:40.120 --> 0:09:45.120
While Trixity App Service is still very basic and does not have a persistent layer, Trixity

102
0:09:45.120 --> 0:09:50.120
Client allows you to choose which database and which media store implementation you want

103
0:09:50.120 --> 0:09:51.960
to use.

104
0:09:51.960 --> 0:09:57.720
And on top of that there is something that isn't released yet, we are not sure how to

105
0:09:57.720 --> 0:10:03.960
release because we have to make money with our company.

106
0:10:03.960 --> 0:10:11.600
It is Trixity Messenger, this is just the view model representation of a messenger so

107
0:10:11.600 --> 0:10:20.160
you only have to implement thin UI layer where when the user clicks a button the UI send

108
0:10:20.160 --> 0:10:26.520
this to the view model and the view model says okay send a message or go to this room

109
0:10:26.520 --> 0:10:29.080
or any other stuff.

110
0:10:29.080 --> 0:10:40.640
And with this approach we have implemented an iOS client in a few weeks with one person.

111
0:10:40.640 --> 0:10:45.960
So Trixity Client allows you to implement a nearly fully featured matrix client or bot.

112
0:10:45.960 --> 0:10:55.860
So if you were at the matrix Rust SDK talk you can just use their representation and

113
0:10:55.860 --> 0:10:58.680
instead of Rust you write colon.

114
0:10:58.680 --> 0:11:05.560
So everything that matrix Rust SDK does also does Trixity.

115
0:11:05.560 --> 0:11:13.000
Some features like sliding zoom aren't there because we want to follow the stable matrix

116
0:11:13.000 --> 0:11:19.200
specs so we doesn't implement any MSCs.

117
0:11:19.200 --> 0:11:25.840
So we have all the E2E features, the exchangeability data stores and media stores, we have a lot

118
0:11:25.840 --> 0:11:31.800
of reactive cache on top of that notification, thumbnail generation, all that stuff you need

119
0:11:31.800 --> 0:11:36.100
to implement a client.

120
0:11:36.100 --> 0:11:45.840
There are already some media store wrappers that we implemented for all targets expect

121
0:11:45.840 --> 0:11:47.680
browsers.

122
0:11:47.680 --> 0:11:54.920
We just use the file system and on browsers we just use index.db.

123
0:11:54.920 --> 0:11:59.440
Next I want to talk about how I accidentally created a cache.

124
0:11:59.440 --> 0:12:06.720
So on the left side you see the relation between the UI, Trixity and the storage layer.

125
0:12:06.720 --> 0:12:11.480
And because reactive UIs are really common I want Trixity to give the UI access to the

126
0:12:11.480 --> 0:12:13.840
data in a reactive way.

127
0:12:13.840 --> 0:12:20.560
So if anything changes the UI should immediately know about this.

128
0:12:20.560 --> 0:12:29.560
But the question is how, on the one hand there are a few databases which support listeners

129
0:12:29.560 --> 0:12:37.400
to react to changes to the database but on the other hand this would limit support for

130
0:12:37.400 --> 0:12:42.920
multiple supported databases because finding a common interface for listeners would be

131
0:12:42.920 --> 0:12:44.080
hard.

132
0:12:44.080 --> 0:12:50.960
So I started implementing an intermediate layer based on Kotlin flows.

133
0:12:50.960 --> 0:12:56.560
A flow in Kotlin is a reactive data structure so you have a producer on the one side and

134
0:12:56.560 --> 0:12:59.600
a consumer on the other side.

135
0:12:59.600 --> 0:13:08.760
So if the producer changes anything the consumers immediately know about that.

136
0:13:08.760 --> 0:13:15.360
And what does this intermediate layer, it talks to a very thin database layer which

137
0:13:15.360 --> 0:13:21.440
only knows about save, read and delete data.

138
0:13:21.440 --> 0:13:29.360
And if someone wants data from this layer it just reads it from the database or if someone

139
0:13:29.360 --> 0:13:35.960
changes something in this layer it just writes it to the database.

140
0:13:35.960 --> 0:13:41.640
And the values are kept in this layer as long as they are subscribed from anyone.

141
0:13:41.640 --> 0:13:48.560
So this means that if anyone else subscribes to a value he will immediately get the current

142
0:13:48.560 --> 0:13:53.640
value because there is no additional database call needed because it is persisted in the

143
0:13:53.640 --> 0:13:56.000
intermediate layer.

144
0:13:56.000 --> 0:14:01.440
This goes so far that even if there are no subscribers anymore I just keep the value

145
0:14:01.440 --> 0:14:03.680
a bit longer in this layer.

146
0:14:03.680 --> 0:14:11.400
So if someone asks for a value for example 10 seconds later and the value is distorted

147
0:14:11.400 --> 0:14:20.960
he gets the value and there is no database call needed.

148
0:14:20.960 --> 0:14:28.000
And you can now guess what I implemented, it's just cache.

149
0:14:28.000 --> 0:14:32.760
So as you see with this cache everything in Trickity is reactive.

150
0:14:32.760 --> 0:14:39.240
These are just a few examples so you can just get all users or check if a user can invite

151
0:14:39.240 --> 0:14:40.400
another one.

152
0:14:40.400 --> 0:14:50.920
You immediately get the notification if anything has changed.

153
0:14:50.920 --> 0:14:57.760
As mentioned the database layer is really thin so we implemented many database layers.

154
0:14:57.760 --> 0:15:04.080
So SQL based one via Xposed for JVM based targets.

155
0:15:04.080 --> 0:15:11.480
We implemented one with Realm that can be also used on native targets like iOS and for

156
0:15:11.480 --> 0:15:16.760
browsers we have IndexedDB.

157
0:15:16.760 --> 0:15:24.120
So most of the data changes when a Zinc is processed, most of the data changes when a

158
0:15:24.120 --> 0:15:33.800
Zinc is processed so it is way more performant to make a large transaction around the Zinc.

159
0:15:33.800 --> 0:15:40.600
So you don't have a transaction every time the cache writes something into the database.

160
0:15:40.600 --> 0:15:45.960
Trickity just spends a large transaction around Zinc so you have thousands of writes in one

161
0:15:45.960 --> 0:15:48.520
transaction.

162
0:15:48.520 --> 0:15:56.600
So everything is fine, no, then there was Realm and Realm is just a really fast database

163
0:15:56.600 --> 0:16:02.640
but Realm only allows one write transaction at the time.

164
0:16:02.640 --> 0:16:08.920
So if another one wants to write to the database he needs to wait until the first transaction

165
0:16:08.920 --> 0:16:11.160
ended.

166
0:16:11.160 --> 0:16:20.200
And the problem is that while the Zinc is running it may be needed that we have to wait

167
0:16:20.200 --> 0:16:25.160
for outdated keys to be updated to decrypt on stuff.

168
0:16:25.160 --> 0:16:31.760
So if the outdated keys part of Trickity want to write something in the database he needs

169
0:16:31.760 --> 0:16:36.480
to wait until the Zinc is ended but the Zinc waits for the keys to be updated so we have

170
0:16:36.480 --> 0:16:40.980
a deadlock there.

171
0:16:40.980 --> 0:16:46.400
This is one of the reasons why I introduced ASIMC transactions.

172
0:16:46.400 --> 0:16:52.600
The other reason was that most of the time the Zinc processing as I find out with some

173
0:16:52.600 --> 0:16:57.120
benchmark was wasted due to writing to the database.

174
0:16:57.120 --> 0:17:04.340
So processing ASIMC takes a long time because there are so many I.O. operations that the

175
0:17:04.340 --> 0:17:10.280
user have to wait until all operations are done.

176
0:17:10.280 --> 0:17:19.240
So what does ASIMC transaction Trickity mean that all changes to the database are collected

177
0:17:19.240 --> 0:17:21.800
and processed in the background.

178
0:17:21.800 --> 0:17:29.800
So database operations are decoupled from the cache layer and they are just written

179
0:17:29.800 --> 0:17:31.160
in the background.

180
0:17:31.160 --> 0:17:37.020
If everything fails it is raw baked but that's irrelevant in the normal use case.

181
0:17:37.020 --> 0:17:45.080
So we can process even more Zincs at the same time as if we would wait that the transaction

182
0:17:45.080 --> 0:17:47.960
has finished.

183
0:17:47.960 --> 0:17:50.960
And this gave Trickity a huge performance boost.

184
0:17:50.960 --> 0:17:58.760
Actually I released it last week.

185
0:17:58.760 --> 0:18:04.620
I wrote an integration test which just fails if it is not 50% faster.

186
0:18:04.620 --> 0:18:11.080
So it is always green until now.

187
0:18:11.080 --> 0:18:15.700
The next thing I did completely different in Trickity are timelines.

188
0:18:15.700 --> 0:18:22.020
So normally Zims are sent as fragment from the server to the client.

189
0:18:22.020 --> 0:18:29.520
So one fragment contains a few timeline events and if there is a gap you get a token so you

190
0:18:29.520 --> 0:18:34.240
know as a client okay there is a gap I need to fetch to fill that gap and so on.

191
0:18:34.240 --> 0:18:41.120
And these fragments normally are saved as is to the database in clients.

192
0:18:41.120 --> 0:18:45.760
In Trickity I use another approach.

193
0:18:45.760 --> 0:18:51.560
There I have each timeline event pointing to each other and if there is a gap the timeline

194
0:18:51.560 --> 0:18:56.240
event knows about this.

195
0:18:56.240 --> 0:19:05.160
So this allows Trickity to again benefit from cotton flows.

196
0:19:05.160 --> 0:19:11.840
So we have a producer that is the room starting from a timeline event and a subscriber who

197
0:19:11.840 --> 0:19:15.320
wants the next timeline event to fill its timeline.

198
0:19:15.320 --> 0:19:24.060
So this allows us to go really fast through the timeline and build the timeline under

199
0:19:24.060 --> 0:19:31.840
the top and it makes it easier to fill the gaps because we don't have another layer,

200
0:19:31.840 --> 0:19:37.480
fragments we just have timeline events.

201
0:19:37.480 --> 0:19:42.440
And this way it is also possible to very easy connect upgraded rooms.

202
0:19:42.440 --> 0:19:49.340
So that one I released yesterday I think or two days ago.

203
0:19:49.340 --> 0:19:55.400
So the timeline event just shows through another timeline in another room.

204
0:19:55.400 --> 0:20:01.640
So timelines with room upgrades are invisible for users of Trickity.

205
0:20:01.640 --> 0:20:07.120
You just get an infinite timeline until you reach the oldest room and the first timeline

206
0:20:07.120 --> 0:20:10.880
event.

207
0:20:10.880 --> 0:20:14.160
And finally a small example.

208
0:20:14.160 --> 0:20:20.360
So if you want to write a bot that's a good start to use Trickity just to get a feeling

209
0:20:20.360 --> 0:20:22.880
about it how it works.

210
0:20:22.880 --> 0:20:29.420
You can just call get timeline events from now on and what this does is it subscribe

211
0:20:29.420 --> 0:20:35.720
to the flow that I mentioned which builds the timeline and waits until the timeline

212
0:20:35.720 --> 0:20:39.240
event is decrypted because the timeline itself also is a flow.

213
0:20:39.240 --> 0:20:47.400
So if everything changes it is redacted or there's a reaction or a replacement the timeline

214
0:20:47.400 --> 0:20:48.960
event flow changes.

215
0:20:48.960 --> 0:20:56.240
So this get timeline events from now on just wraps it down so you get a timeline event

216
0:20:56.240 --> 0:20:58.320
that is decrypted.

217
0:20:58.320 --> 0:21:04.540
And you can see we can just check what type it has and when we have checked the type we

218
0:21:04.540 --> 0:21:07.080
have access to body.

219
0:21:07.080 --> 0:21:10.840
And then we have send message.

220
0:21:10.840 --> 0:21:15.320
So when you call send message you don't have to worry about if the room is encrypted or

221
0:21:15.320 --> 0:21:16.320
not.

222
0:21:16.320 --> 0:21:22.520
You can just use the DSL that I created to write text messages in image messages and

223
0:21:22.520 --> 0:21:24.140
so on and so on.

224
0:21:24.140 --> 0:21:26.700
And you can also form relations with that.

225
0:21:26.700 --> 0:21:34.560
So you can say like here yeah this is a reply to the timeline event I just got.

226
0:21:34.560 --> 0:21:40.120
And this has extensible events in mind so if in the future there are other content blogs

227
0:21:40.120 --> 0:21:50.000
that are added we can just extend the DSL and you can very very intuitive write your

228
0:21:50.000 --> 0:21:57.520
content with Trixity into an event and into an extensible event.

229
0:21:57.520 --> 0:22:02.960
So here are some projects that are using Trixity and that I know about.

230
0:22:02.960 --> 0:22:07.440
There is Spotify bot, a manza bot.

231
0:22:07.440 --> 0:22:13.480
Someone has created some extensions to better use it for bots and so on.

232
0:22:13.480 --> 0:22:16.480
And there is Trixity examples.

233
0:22:16.480 --> 0:22:17.480
That is from me.

234
0:22:17.480 --> 0:22:23.200
This is just a ping bot part of it you saw here.

235
0:22:23.200 --> 0:22:24.920
It is e2e enabled.

236
0:22:24.920 --> 0:22:32.680
You can just run it in your browser on your Linux machine or on your iOS client or via

237
0:22:32.680 --> 0:22:35.480
the JVM on Android.

238
0:22:35.480 --> 0:22:39.960
And there is also Timmy Messenger that is our messenger from our company but it is not

239
0:22:39.960 --> 0:22:40.960
open source yet.

240
0:22:40.960 --> 0:22:45.920
We plan to but we don't know how because licensing.

241
0:22:45.920 --> 0:22:48.480
Here.

242
0:22:48.480 --> 0:22:54.040
Just try it out and come to me if you have questions.

243
0:22:54.040 --> 0:22:55.480
I am a bit around.

244
0:22:55.480 --> 0:22:57.760
This is the matrix room.

245
0:22:57.760 --> 0:22:59.960
This is my matrix ID.

246
0:22:59.960 --> 0:23:07.160
And if we have time, I just can show you a small demo, I think.

247
0:23:07.160 --> 0:23:11.920
I made a small performance comparison.

248
0:23:11.920 --> 0:23:19.000
It is not representative because it just runs once on my machine and there was no warm up

249
0:23:19.000 --> 0:23:23.480
or multiple runs.

250
0:23:23.480 --> 0:23:29.360
On the left side you see our Timmy client but basically it is just using Trixity.

251
0:23:29.360 --> 0:23:33.920
On the right side there is Element and in the middle is Fluffy Jet.

252
0:23:33.920 --> 0:23:38.000
And now you can give me your bets who is the fastest.

253
0:23:38.000 --> 0:23:41.960
Let's see.

254
0:23:41.960 --> 0:23:46.040
When the red zoom comes, the response from the server reached the client.

255
0:23:46.040 --> 0:23:51.360
So I just looked into the synapse logs when the response was sent.

256
0:23:51.360 --> 0:23:57.120
So we just wait a few seconds and then we see who is first.

257
0:23:57.120 --> 0:24:00.400
And you can look into opening rooms because we have this caching.

258
0:24:00.400 --> 0:24:06.040
It is very fast in our client but I must say Fluffy Jet is also very fast regarding opening

259
0:24:06.040 --> 0:24:07.200
rooms.

260
0:24:07.200 --> 0:24:17.640
So oh, Trixity was fastest and we can open rooms and you see open rooms is also a lot

261
0:24:17.640 --> 0:24:21.120
faster than on Element.

262
0:24:21.120 --> 0:24:29.200
And there was Fluffy Jet and Fluffy Jet also is very fast.

263
0:24:29.200 --> 0:24:36.840
I also have a desktop demo but there, Naiko is the fastest.

264
0:24:36.840 --> 0:24:39.840
This is Naiko, this is Timmy, Element on the web.

265
0:24:39.840 --> 0:24:47.360
It's a bit hard this comparison because Element runs in the web and does not have the mighty

266
0:24:47.360 --> 0:24:53.320
threading other clients have so Naiko just three seconds.

267
0:24:53.320 --> 0:25:01.080
I can just chat around and the next is Timmy on the top left side.

268
0:25:01.080 --> 0:25:06.440
Also very fast opening rooms and switching rooms because it is cached all the time and

269
0:25:06.440 --> 0:25:07.440
events.

270
0:25:07.440 --> 0:25:12.960
Then there was Element and I think also Fluffy Jet.

271
0:25:12.960 --> 0:25:14.800
Yeah, Fluffy Jet also.

272
0:25:14.800 --> 0:25:16.480
Yeah, okay.

273
0:25:16.480 --> 0:25:17.480
That was my talk.

274
0:25:17.480 --> 0:25:18.480
Thank you.

275
0:25:18.480 --> 0:25:19.480
Questions?

276
0:25:19.480 --> 0:25:20.480
Yeah.

277
0:25:20.480 --> 0:25:36.680
How do you prevent data loss with your ASIC transactions?

278
0:25:36.680 --> 0:25:39.840
The transactions are run each after.

279
0:25:39.840 --> 0:25:46.440
So if one transaction fails, the other transactions are just run and you can, the next thing starts

280
0:25:46.440 --> 0:25:47.440
with the old token.

281
0:25:47.440 --> 0:25:53.440
What happens if say your battery runs out whilst a bunch of transactions are queued?

282
0:25:53.440 --> 0:25:55.040
Sorry, sorry, I didn't answer.

283
0:25:55.040 --> 0:25:59.040
If your battery runs out when all those transactions are queued so they haven't been written to

284
0:25:59.040 --> 0:26:00.040
the database?

285
0:26:00.040 --> 0:26:01.920
Yeah, then they are gone.

286
0:26:01.920 --> 0:26:05.840
Your client have to do the work again but mostly this doesn't happen.

287
0:26:05.840 --> 0:26:12.320
If you close your client, all transactions are written that are just opened but it depends

288
0:26:12.320 --> 0:26:18.320
on your platform if it is killed hardly or he at Trixity have a bit time to write the

289
0:26:18.320 --> 0:26:20.280
transactions back to the database.

290
0:26:20.280 --> 0:26:22.920
But it's still very fast to write.

291
0:26:22.920 --> 0:26:29.880
So it's just a bit snappier on mobile devices which are not that fast.

292
0:26:29.880 --> 0:26:37.620
Like my smartphone from 2016, Element, I can't run Element on that because it's too slow.

293
0:26:37.620 --> 0:26:42.800
Then sending messages, 10 seconds later the message is, oh, okay, yes, yes, now we send

294
0:26:42.800 --> 0:26:43.800
the message.

295
0:26:43.800 --> 0:26:50.000
I don't have this problem because Zooms are just faster than the slow IO writing to the

296
0:26:50.000 --> 0:26:57.440
database we have on old smartphones, for example.

297
0:26:57.440 --> 0:26:58.440
Another question.

298
0:26:58.440 --> 0:27:09.600
I go for a domain specific language over just changing together methods to say add a new

299
0:27:09.600 --> 0:27:10.600
continent block.

300
0:27:10.600 --> 0:27:11.600
Is there any benefits to that, DSL?

301
0:27:11.600 --> 0:27:12.600
It's nice to write.

302
0:27:12.600 --> 0:27:13.600
I like DSLs.

303
0:27:13.600 --> 0:27:23.280
In Kotlin we have them all over the language and it feels very intuitive because your IDE

304
0:27:23.280 --> 0:27:31.760
gives you suggestions what methods there are and it's a lot easier to read, I think.

305
0:27:31.760 --> 0:27:35.560
Do the character.

306
0:27:35.560 --> 0:27:36.560
Yeah.

307
0:27:36.560 --> 0:27:40.560
There's Rust and there's Kotlin.

308
0:27:40.560 --> 0:27:52.560
Is there any way to minimize the amount of things that the user has to learn to use all

309
0:27:52.560 --> 0:27:53.560
the time?

310
0:27:53.560 --> 0:27:54.560
I didn't understand the question acoustically.

311
0:27:54.560 --> 0:27:55.560
There's a lot of language learning to make any progress.

312
0:27:55.560 --> 0:28:12.080
Is there any effort to unify this or towards Rust maybe?

313
0:28:12.080 --> 0:28:16.360
To be honest, I don't like Rust.

314
0:28:16.360 --> 0:28:24.240
I just like a higher level of implementing stuff so I didn't spoke with the matrix Rust

315
0:28:24.240 --> 0:28:25.240
team.

316
0:28:25.240 --> 0:28:26.240
I think we are done with the time.

317
0:28:26.240 --> 0:28:27.240
The last question from the audience would be that we can open the windows and the doors

318
0:28:27.240 --> 0:28:28.240
a bit to get more air in.

319
0:28:28.240 --> 0:28:29.240
Thank you very much.

320
0:28:29.240 --> 0:28:46.400
Thank you very much.

