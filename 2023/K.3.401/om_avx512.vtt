WEBVTT

00:00.000 --> 00:08.240
We'll talk about AVX-512 in FFmpeg.

00:08.240 --> 00:12.440
He's also the co-organizer of this bedroom.

00:12.440 --> 00:15.000
Please welcome Kirano.

00:15.000 --> 00:24.280
So yes, I'm going to be talking about AVX-512 in FFmpeg.

00:24.280 --> 00:25.280
What is AVX-512?

00:25.280 --> 00:28.880
AVX stands for Advanced Vector Extensions.

00:28.880 --> 00:32.160
There'll be a lot of acronyms and jargon, unfortunately, in this one.

00:32.160 --> 00:35.360
But I will try and explain all of them.

00:35.360 --> 00:42.640
So AVX-512 is a relatively new single instruction, multiple data instruction set for Intel CPUs

00:42.640 --> 00:48.320
from about 2017 and more recently in the last six months or so with AMD CPUs.

00:48.320 --> 00:54.440
In particular, it has a larger 512-bit register size, many new instructions, which we'll talk

00:54.440 --> 00:56.440
about in a minute.

00:56.440 --> 00:58.920
Top masks, we'll talk about in a minute.

00:58.920 --> 01:00.160
Comparisons, which are quite new.

01:00.160 --> 01:03.600
And also lots of other things that are not so interesting in multimedia.

01:03.600 --> 01:08.880
Cryptography, neural networks, and I'm sure there are other people at FOSDEM who could

01:08.880 --> 01:11.180
talk a lot more about these kind of things.

01:11.180 --> 01:15.280
As I mentioned, lots of fancy words, but the thing to bear in mind is in FFmpeg, high

01:15.280 --> 01:17.320
schoolers have gone and written assembly.

01:17.320 --> 01:20.040
This is heavily jargon-centric.

01:20.040 --> 01:24.480
It sounds complicated, but actually quite a big, reasonable chunk of assembly in FFmpeg

01:24.480 --> 01:28.320
has been written by people who are in high school.

01:28.320 --> 01:29.320
Why is this relevant now?

01:29.320 --> 01:34.200
So yeah, I have mentioned AVX-512 has been around since 2017.

01:34.200 --> 01:36.840
So why it's 2023?

01:36.840 --> 01:42.120
Well, Skylake was the first CPU generation from Intel to have AVX-512 support, but it

01:42.120 --> 01:45.560
had very large performance throttling when you use them.

01:45.560 --> 01:51.360
So your effective CPU capability speed went down quite dramatically.

01:51.360 --> 01:56.400
And so this was fine if you were doing high performance computing in academia, for example,

01:56.400 --> 02:00.760
like Fluid Dynamics, where you were using these instructions 100% of the time.

02:00.760 --> 02:01.760
That was fine.

02:01.760 --> 02:06.520
But in multimedia is a mixture of assembly and C code, where you're not necessarily always

02:06.520 --> 02:07.680
using these instructions.

02:07.680 --> 02:13.600
So this relative remains unused for the last couple of years.

02:13.600 --> 02:17.000
You could still use these new instructions, though, with the smaller register sizes.

02:17.000 --> 02:20.760
And I'll show an example of this later.

02:20.760 --> 02:25.880
The first Intel CPUs not to have throttling were the Ice Lake 10th and 11th Gen Intel

02:25.880 --> 02:26.880
CPUs.

02:26.880 --> 02:29.300
They were the first to have no throttling.

02:29.300 --> 02:37.080
And this meant these ZMM-based instructions could be first-class citizens.

02:37.080 --> 02:38.400
How to get started?

02:38.400 --> 02:42.960
One of the tricky things as well in the last few years has been actually getting access

02:42.960 --> 02:44.280
to devices that have this.

02:44.280 --> 02:47.160
And unfortunately, Intel have not made it easy.

02:47.160 --> 02:51.800
From their 12th generation CPUs have actually removed support in consumer equipment.

02:51.800 --> 02:57.000
It's still available on AMD, Zen 4 CPUs, though.

02:57.000 --> 03:01.520
And if using the cloud is your kind of thing, available also from many cloud providers in

03:01.520 --> 03:04.640
the server CPU range, such as AWS or others.

03:04.640 --> 03:08.960
Personally, I think the easiest way is to buy an 11th generation Intel NUC.

03:08.960 --> 03:09.960
That's what I did for FMPG.

03:09.960 --> 03:13.040
I bought two of them for the project and host them.

03:13.040 --> 03:14.040
It's the easiest way.

03:14.040 --> 03:16.360
It's only a few hundred euros.

03:16.360 --> 03:18.640
It's quiet if it's under your desk.

03:18.640 --> 03:19.640
And that's the easiest way to get started.

03:19.640 --> 03:24.720
You get a full AVX-512 stack.

03:24.720 --> 03:29.960
So let's look at some of the existing work in multimedia that's using AVX-512.

03:29.960 --> 03:33.280
And probably most importantly, we had a sort of introduction from J.V.

03:33.280 --> 03:36.240
earlier today, the David project, which is an AV-1 decoder.

03:36.240 --> 03:42.120
This added AVX-512 support, I think a year or two ago.

03:42.120 --> 03:48.880
It's particularly beneficial in AV-1 because AV-1 has large block sizes, sort of in comparison

03:48.880 --> 03:53.760
to more traditional standards, traditional codecs like H.264 and others, which are smaller.

03:53.760 --> 03:57.760
So AVX-512 in David gave, I think, 10% to 20% overall.

03:57.760 --> 03:59.520
So not just the functions themselves.

03:59.520 --> 04:03.760
The overall decode performance was improved.

04:03.760 --> 04:06.720
And it's actually been a running topic, which is quite interesting.

04:06.720 --> 04:13.200
AVX-264 today is an FFmpeg that we use and David and also we use this classic FFmpeg X264 approach

04:13.200 --> 04:21.080
to assembly, which is no intrinsics, no inline assembly, no special SIMD sort of libraries

04:21.080 --> 04:22.240
to make life easier.

04:22.240 --> 04:26.080
It's raw assembly language.

04:26.080 --> 04:28.640
And I'll show some examples of that.

04:28.640 --> 04:33.400
And also we don't also compile them in and force you to have a particular CPU generation.

04:33.400 --> 04:35.560
I know this is quite controversial.

04:35.560 --> 04:37.840
I think it's MongoDB, for example.

04:37.840 --> 04:42.680
They forced one year a particular CPU generation and this was super controversial because not

04:42.680 --> 04:44.680
everybody had that.

04:44.680 --> 04:49.400
So what we do in FFmpeg is we detect CPU capabilities and I'll show the function in a minute.

04:49.400 --> 04:50.600
And then we use function pointers.

04:50.600 --> 04:54.160
So we set them once at the beginning and therefore the overhead of doing that measurement is

04:54.160 --> 04:58.120
done once, but doing the capabilities is checked once.

04:58.120 --> 05:01.640
And then those function pointers are executed after that.

05:01.640 --> 05:08.120
And unfortunately, though, on Intel, there's a very messy Venn diagram of capabilities.

05:08.120 --> 05:12.520
But in practice, we really, so far, they may change their mind, but care about these kind

05:12.520 --> 05:13.520
of two things.

05:13.520 --> 05:17.720
So these are the CPU flags you get in FFmpeg.

05:17.720 --> 05:23.840
There are others, but the AVX-512 related ones are broadly speaking legacy Skylake and the

05:23.840 --> 05:26.240
newer ICL I put in bold for Icelake.

05:26.240 --> 05:31.040
But you can see there are actually a lot of different subcategories in there.

05:31.040 --> 05:34.080
But in practice, it's at the moment one or the other.

05:34.080 --> 05:39.400
But as I mentioned, Intel are very keen on adding and removing features and possibly

05:39.400 --> 05:44.120
even charging your subscription for certain features is one of their new ideas.

05:44.120 --> 05:49.680
So it could be that newer additions to this are subscription based or you buy and pay

05:49.680 --> 05:52.920
for it later or something much more complicated.

05:52.920 --> 05:58.400
So who knows?

05:58.400 --> 06:02.640
So I guess unfortunately, there's some sort of dependency in explaining a few of the topics

06:02.640 --> 06:06.480
and some of the benefits without explaining some of the backstory.

06:06.480 --> 06:13.200
So historically, in old AVX, you had all the 256-bit registers.

06:13.200 --> 06:16.280
And these were split in practice into lanes.

06:16.280 --> 06:20.800
So in practice, you've got 228-bit lanes.

06:20.800 --> 06:24.160
And instructions, broadly speaking, operated in these lanes.

06:24.160 --> 06:29.840
So if you ran in a structure and it worked on data and it was actually quite difficult,

06:29.840 --> 06:34.720
it was possible but difficult to move data between these lanes.

06:34.720 --> 06:41.200
And it's one of the historical limitations on existing AVX and AVX2 code that we have

06:41.200 --> 06:47.800
in FMPG is lane crossing and all sorts of trickery that essentially cost CPU cycles

06:47.800 --> 06:49.400
to take up this time.

06:49.400 --> 06:54.680
Sorry, that takes time to compensate for the lanes.

06:54.680 --> 06:57.640
I have to talk a bit about K-mask registers as well.

06:57.640 --> 07:02.920
So AVX-512 has this new set of registers called K-masks, K0 to K7.

07:02.920 --> 07:07.560
And this allows a destination register to remain unchanged.

07:07.560 --> 07:12.400
So for example, underneath, you could have an addition but actually have a simple case

07:12.400 --> 07:15.760
and you wouldn't, obviously, you could just add zero and it's unchanged.

07:15.760 --> 07:21.160
But you could actually use the K-masks to say, actually, I don't want addition to be

07:21.160 --> 07:22.160
applied to these elements.

07:22.160 --> 07:25.000
I want this to be a pure pass-through.

07:25.000 --> 07:28.920
Or you could even force some of the elements to zero if you wanted to.

07:28.920 --> 07:32.520
There's a specific, I think it's a flag that lets you do that.

07:32.520 --> 07:36.000
And there's a whole set of new instructions to go and manipulate these K-mask registers.

07:36.000 --> 07:43.240
And certainly David, in particular, makes good use of K-masks.

07:43.240 --> 07:47.360
So now that I've sort of explained some of the back story, I think it's fair to say one

07:47.360 --> 07:52.960
of the most important instructions, if not the most important instruction, is a shuffle

07:52.960 --> 07:55.200
in multimedia.

07:55.200 --> 07:56.200
Also known as permutes.

07:56.200 --> 07:58.720
And there might be a technical difference between a shuffle and a permute.

07:58.720 --> 07:59.720
Someone might be able to correct me.

07:59.720 --> 08:02.160
That might be some mathematical difference.

08:02.160 --> 08:06.880
But these are the most important or one of the most important instructions in multimedia.

08:06.880 --> 08:13.200
And as you can see on the right, basically, it lets you, shuffles let you have various

08:13.200 --> 08:17.000
bits of data and rearrange them in any way that you want, duplicate them, as you can

08:17.000 --> 08:22.360
see, or even set individual elements to zero.

08:22.360 --> 08:29.120
And this is, for example, famously one use case of this is in the ZigZagScan of FFmpeg,

08:29.120 --> 08:32.720
which groups a larger coefficient in a block together.

08:32.720 --> 08:36.720
But the way that that's done is via a ZigZagScan.

08:36.720 --> 08:40.920
The thing about VPIRM B, which is the new AVX-512 instruction, is it lets you cross

08:40.920 --> 08:41.920
a lane.

08:41.920 --> 08:44.200
This wasn't something that was possible in before.

08:44.200 --> 08:49.120
And as I'll show you later, this makes things substantially faster in many cases.

08:49.120 --> 08:54.720
PSHAF B, probably one of the most commonly used instructions in all of open source multimedia.

08:54.720 --> 09:01.120
You do git grep, PSHAF B. There will be a huge, you know, that your screen will be full

09:01.120 --> 09:02.120
of PSHAF Bs.

09:02.120 --> 09:06.840
They'll be used everywhere in open source multimedia.

09:06.840 --> 09:10.520
PSHAF B had a kind of useful benefit that if you set the index to minus one, you had

09:10.520 --> 09:13.280
a automatically did a zeroing out.

09:13.280 --> 09:14.720
With VPIRM B, this isn't the case.

09:14.720 --> 09:18.160
You have to actually use a K-Masks to do that.

09:18.160 --> 09:20.720
So that just makes things slightly more complicated.

09:20.720 --> 09:26.240
There's all sorts of other interesting permutes that AVX-512 offers.

09:26.240 --> 09:28.960
I think David also again makes good use of this VPIRM 2B.

09:28.960 --> 09:32.640
So you can actually not just have one set of data, you can actually permute from two

09:32.640 --> 09:33.640
different registers.

09:33.640 --> 09:38.320
So you could have IJK, et cetera, et cetera, in a different register and your output could

09:38.320 --> 09:40.260
be a mixture of both of those.

09:40.260 --> 09:44.080
So that's kind of interesting.

09:44.080 --> 09:46.080
Variable shifts.

09:46.080 --> 09:48.740
You have now variable right shifts.

09:48.740 --> 09:56.160
So I've given the example of a VPSRLVW, logical right shift, and VPSLVW, variable left shift

09:56.160 --> 09:57.520
logical.

09:57.520 --> 10:01.080
Big letter soup, quite confusing.

10:01.080 --> 10:04.440
In effect, when writing this slide, I misspelt the word shift.

10:04.440 --> 10:08.240
You can have a think about how that may have been spelt.

10:08.240 --> 10:11.920
Thankfully the rehearsals will pick this up.

10:11.920 --> 10:15.560
But this word soup is exceptionally confusing both when writing slides and writing code,

10:15.560 --> 10:17.040
it seems.

10:17.040 --> 10:23.480
So historically to do variable shifts, so if you want to take off just a step back,

10:23.480 --> 10:28.360
take an element and shift each element by a different amount, this was quite complicated.

10:28.360 --> 10:33.040
There's various bits of trickery, various idioms that people use to try and emulate

10:33.040 --> 10:34.800
that, but they had limitations.

10:34.800 --> 10:39.600
I think for example, you were not shifting by zero, possibly wasn't allowed in one of

10:39.600 --> 10:42.560
the various bits of trickery.

10:42.560 --> 10:46.760
And so if you needed a zero shift, you had to do it a different way, et cetera, et cetera.

10:46.760 --> 10:51.160
But now you have this variable shift and it's all usable.

10:51.160 --> 10:55.240
Particularly on the left shift, the naive way of doing an emulated left shift is just

10:55.240 --> 10:59.280
to multiply, but these instructions are actually faster than to multiply, so there's still

10:59.280 --> 11:01.280
some benefit.

11:01.280 --> 11:09.960
VP turn log D, this is a, I think no presentation about AVX 512 could not fail to mention VP

11:09.960 --> 11:13.800
turn log D. This instruction is literally a kitchen sink.

11:13.800 --> 11:17.240
It's quite remarkable in what it can actually do.

11:17.240 --> 11:22.040
You can literally program a truth table within an individual instruction itself, and in theory

11:22.040 --> 11:25.120
could replace up to eight different instructions.

11:25.120 --> 11:31.800
So you could do a whole presentation on VP turn log D, so I thought it would be best

11:31.800 --> 11:36.240
to try and pick one of the simplest ones, which is a ternary operation.

11:36.240 --> 11:42.180
So this is a bitwise equivalent to the C ternary operation.

11:42.180 --> 11:48.720
So in each register, each bit is iterated through, and you can see, for example, one,

11:48.720 --> 11:52.360
the ternary operation, so if that bit set chooses this or versus this, and you can see

11:52.360 --> 11:54.400
the output of that is that.

11:54.400 --> 11:59.480
And so essentially it's a bitwise operation of ZM zero, ZM zero is equal to ZM zero, question

11:59.480 --> 12:03.480
mark, ZM one, ZM two, but on a bitwise level.

12:03.480 --> 12:07.000
And there's all sorts of other interesting things you can do, and this article's very

12:07.000 --> 12:08.000
good.

12:08.000 --> 12:13.120
So there's all sorts of interesting things you can do, bit selects, all sorts of various

12:13.120 --> 12:18.560
different operations that you can do, multiple XORs, for example.

12:18.560 --> 12:22.780
So yeah, also very interesting.

12:22.780 --> 12:24.640
So let's look at a real world example.

12:24.640 --> 12:26.120
I don't know how well you can see that.

12:26.120 --> 12:29.600
I was hoping the dark mode would actually make life easier, but maybe it's made things

12:29.600 --> 12:30.600
worse.

12:30.600 --> 12:33.480
But I'll talk about some of the, how's it going, mouse?

12:33.480 --> 12:34.720
Is it a mouse?

12:34.720 --> 12:37.560
No, you can't, because the mouse on the Mac is dark.

12:37.560 --> 12:41.800
But anyway, this is V210, Inc.

12:41.800 --> 12:45.360
It's probably one of the most simplest assembly functions in FMPEG, but what it does is it

12:45.360 --> 12:50.600
takes three 8-bit samples from different memory locations.

12:50.600 --> 12:55.360
Sort of as part of its work extends to 10 bits and then packs those three 10-bit words

12:55.360 --> 12:58.080
into 32 bits.

12:58.080 --> 13:03.220
So what's interesting in this function is we're already starting to do lane crossing

13:03.220 --> 13:04.580
that wasn't possible before.

13:04.580 --> 13:11.360
So we load the Y samples, so the Luma samples, into the lower 256 bits.

13:11.360 --> 13:17.880
We do the U section of the chroma into the third or the second if zero indexed portion

13:17.880 --> 13:19.400
of the register.

13:19.400 --> 13:31.480
And then equally the same for the V. And then we do one, excuse me, and then one single

13:31.480 --> 13:35.680
V perm B can rearrange all of that in one go.

13:35.680 --> 13:41.160
This was a lot more complicated back in the olden days.

13:41.160 --> 13:46.040
P MAD sub SW is some trickery that unfortunately is not going to be enough time to explain,

13:46.040 --> 13:51.000
but eventually is a multiply and add and we use that to emulate a shift.

13:51.000 --> 13:57.920
And then the, but then for the second element in the three elements we need to do a D word

13:57.920 --> 14:01.800
shift because it actually spans the middle.

14:01.800 --> 14:06.680
So then, but therefore then we have sort of conflicting bits in each register.

14:06.680 --> 14:07.960
How do we do a bit selection?

14:07.960 --> 14:14.340
And this was quite a, I think it's a two or three even operand two, three different instructions

14:14.340 --> 14:16.160
in the previous code.

14:16.160 --> 14:24.160
And this can now be done in a single VP turn log B. So essentially C turnery B or A. So

14:24.160 --> 14:29.640
if bit C is set, choose the bit from B or choose it from A otherwise.

14:29.640 --> 14:34.160
And you'll see in a second that actually provides quite a big, well certainly a measurable speed

14:34.160 --> 14:37.200
improvement.

14:37.200 --> 14:38.200
So these are the benchmarks.

14:38.200 --> 14:44.000
So this is a, so I wanted to show a bit about how you can get benefits from AVX 512 even

14:44.000 --> 14:47.680
on the older hardware with the shorter existing registers.

14:47.680 --> 14:49.040
These are not scientifically benchmarked.

14:49.040 --> 14:51.280
I just ran them yesterday.

14:51.280 --> 14:55.360
When you do benchmarking you should run them 10 or 100 of times, average them, do standard

14:55.360 --> 14:56.360
deviations, et cetera.

14:56.360 --> 15:05.960
But just for the simple case, you can see that the C code versus the AVX2 code is around

15:05.960 --> 15:06.960
10 times faster.

15:06.960 --> 15:10.720
And you can see just by replacing, I think it's a set of two or three different P ANDs

15:10.720 --> 15:17.560
or various Boolean functions, you can get a measurable increase just with a small, just

15:17.560 --> 15:24.200
with one instruction replacing three, even on the older YM registers.

15:24.200 --> 15:27.240
The way the big gains come are on Ice Lake.

15:27.240 --> 15:34.760
You can see the C code versus the AVX 512 ICL.

15:34.760 --> 15:35.760
There's a huge difference.

15:35.760 --> 15:44.240
So by using VPIRMB and the ZMM, you can already make the legacy AVX 512 twice as fast.

15:44.240 --> 15:48.400
And if something was 10 times faster, that now becomes 20 times faster.

15:48.400 --> 15:51.840
And I often have to say that's not a multiply, that's a times.

15:51.840 --> 15:54.400
So it's massive improvement.

15:54.400 --> 15:58.680
This was code that could, if you have a large resolution file, take up an entire CPU call

15:58.680 --> 16:02.440
and now it takes essentially 5% of a call.

16:02.440 --> 16:06.000
It's really tiny.

16:06.000 --> 16:09.600
What AVX 512 code is next?

16:09.600 --> 16:14.040
Anything really that's line-based or frame-based such as filtering or scaling, I think the

16:14.040 --> 16:18.160
next thing we're working on is deinterlacing.

16:18.160 --> 16:19.160
Anything involving comparisons.

16:19.160 --> 16:22.080
I haven't really talked about comparisons, but there are bits of code that often need

16:22.080 --> 16:25.280
to do comparisons.

16:25.280 --> 16:28.120
That's going to be an obvious place for AVX 512.

16:28.120 --> 16:35.040
Lots of places that do triple Boolean, multiple XORs or multiple XORs and ANDs.

16:35.040 --> 16:39.720
And I think it's almost always as possible to replace that with a VP-10 log D.

16:39.720 --> 16:45.040
Likewise, in the code base, there's various different idioms and trickery to try and emulate

16:45.040 --> 16:48.120
a variable left shift and right shift.

16:48.120 --> 16:51.080
Or multiplies for the left shifts and trickery for the right shifts.

16:51.080 --> 16:56.800
This could be used with the word suit, the sort of letter suit instructions to try and

16:56.800 --> 16:59.760
reproduce that.

16:59.760 --> 17:01.800
Intel provides an official manual to all of this.

17:01.800 --> 17:05.920
It's very verbose, which is great in many cases because it provides really precise detail

17:05.920 --> 17:07.720
of how the instructions work.

17:07.720 --> 17:09.960
But unfortunately, it's not at all approachable.

17:09.960 --> 17:13.560
There are a few websites that try and simplify things.

17:13.560 --> 17:17.080
I think this website on officedaytime.com is some kind of Japanese website, but it's

17:17.080 --> 17:18.080
in English.

17:18.080 --> 17:25.920
It tries to group all the instructions in some kind of logical ordering, and that makes

17:25.920 --> 17:29.600
it a lot simpler to understand.

17:29.600 --> 17:30.600
Any questions?

17:30.600 --> 17:32.440
Hopefully, I'll be able to answer them.

17:32.440 --> 17:35.600
But thankfully, at Fostem, there's always somebody with more knowledge than you in the

17:35.600 --> 17:36.600
room.

17:36.600 --> 17:43.600
I don't know where they are, but I did see them at one point.

17:43.600 --> 17:44.600
Thanks.

17:44.600 --> 17:45.600
Any questions?

17:45.600 --> 17:46.600
Yes?

17:46.600 --> 17:53.600
Regarding the direct assembly writings of AV-X5 film, there's about 7,000 instructions

17:53.600 --> 17:57.600
for the AV-X5 film.

17:57.600 --> 18:05.240
One, if you choose the direct assembly, then you essentially might miss out on potential

18:05.240 --> 18:10.240
instruction scheduling between different architectures.

18:10.240 --> 18:15.960
You compile this might schedule better, you might get performance benefit in the future.

18:15.960 --> 18:20.680
But then you have to ship a binary for each version.

18:20.680 --> 18:21.680
Sorry, repeat the question.

18:21.680 --> 18:25.680
You have to write in physics, that's what I'm saying.

18:25.680 --> 18:28.160
In order to...

18:28.160 --> 18:33.160
The question is, it's the classic question, can the compiler do a better job than the

18:33.160 --> 18:35.480
human question?

18:35.480 --> 18:40.680
In David, certainly the register allocation has not been very good in compilers historically.

18:40.680 --> 18:42.440
David has got its own...

18:42.440 --> 18:48.080
David has shown this quite dramatically, because it has its own custom ABI internally.

18:48.080 --> 18:51.760
You wouldn't be able to do that with the compiler, like come up with your own internal ABI between

18:51.760 --> 18:52.760
functions.

18:52.760 --> 18:59.840
So there's certainly 10% plus on the individual function speed gains versus doing it in intrinsics.

18:59.840 --> 19:05.480
Some bits of some instructions are not available in intrinsics, like always.

19:05.480 --> 19:07.480
It's a compromise.

19:07.480 --> 19:12.040
Overall, it's been the way in FM-PEG-X264 for the last 10 years.

19:12.040 --> 19:16.920
And I think all intrinsics and inline assembly is banned, and there's only one or two bits

19:16.920 --> 19:21.920
left and there's a very good reason why it needs to be there.

19:21.920 --> 19:24.520
I have a mixed experience about this.

19:24.520 --> 19:26.400
I agree on the...

19:26.400 --> 19:31.400
Ideally, assembly is better, but we had some code in intrinsics, we compiled it with the

19:31.400 --> 19:37.960
latest clunk, 15, and we saw a 15 to 20% speed increase, just for you compiling.

19:37.960 --> 19:40.320
But did you try writing it to begin with?

19:40.320 --> 19:42.320
Yes, it was in...

19:42.320 --> 19:47.440
Write it originally in assembly and compare.

19:47.440 --> 19:49.440
It wouldn't be much...

19:49.440 --> 19:58.080
So for example, some of the bit twizzling in there, for example, a compiler would never

19:58.080 --> 20:00.040
really have the understanding to do...

20:00.040 --> 20:04.520
In fact, I did try chatGPT, and chatGPT at least understood a few of the concepts.

20:04.520 --> 20:08.600
It was quite interesting, because not quite out of a day job, but it is...

20:08.600 --> 20:12.280
I did ask chatGPT to write this function, actually, just to see what...

20:12.280 --> 20:14.400
And it did have some vague idea what was going on.

20:14.400 --> 20:17.120
It didn't need to be helped, which is quite interesting.

20:17.120 --> 20:18.120
Yep.

20:18.120 --> 20:25.160
Is there any collaboration between the multimedia of the people who write the products and

20:25.160 --> 20:32.720
the guys writing the compiler, who tell them, look, perhaps you could target certain patterns?

20:32.720 --> 20:37.360
So the question is, is there collaboration between people writing the compilers and multimedia

20:37.360 --> 20:38.360
community?

20:38.360 --> 20:41.800
Yes, in ARM in particular, I think...

20:41.800 --> 20:42.800
Is Martin here?

20:42.800 --> 20:47.720
No, Martin is not here, but Martin spends a lot of time talking to the compiler community

20:47.720 --> 20:55.520
and the linker community on mostly miscompilations, is more his thing.

20:55.520 --> 21:00.440
And I think there is also some sharing of mostly around the C code, if the C code is

21:00.440 --> 21:06.480
badly miscompiled or thought about the wrong...

21:06.480 --> 21:09.920
This sort of thought of the wrong approach, because you could see actually this...

21:09.920 --> 21:13.480
And in some cases, in some versions of the compiler will really do a bad job on the C,

21:13.480 --> 21:14.480
and it can be 40...

21:14.480 --> 21:16.000
The assembly can be 40 times faster.

21:16.000 --> 21:20.800
I don't know if that's something you can really trust if one day you change compiler version

21:20.800 --> 21:31.000
and a function that you thought was immeasurable is now 40 times slower than it is.

21:31.000 --> 21:34.320
And then the question from the internet is, did you have the occasion to look at ARMVA

21:34.320 --> 21:36.640
SVE vector instructions for a firm peg?

21:36.640 --> 21:40.440
Wow, there's a surprise for this person, because the next speaker is going to be talking about

21:40.440 --> 21:41.440
this entire topic.

21:41.440 --> 21:42.440
Where is the next speaker?

21:42.440 --> 21:43.440
Is he here?

21:43.440 --> 21:44.440
He's over there.

21:44.440 --> 21:47.880
And the next speaker here, Remy, will be talking about this entire topic.

21:47.880 --> 21:50.560
Another question in the room?

21:50.560 --> 21:51.560
There's one there.

21:51.560 --> 21:59.560
Yeah, I was wondering, so obviously the runtime CPU capability detection and dispatching of

21:59.560 --> 22:05.560
the right function is desirable, but I don't think it's necessarily contradictory to having

22:05.560 --> 22:06.560
some amount of abstraction.

22:06.560 --> 22:16.920
Have you, for instance, looked into the highway library that is being used in some places

22:16.920 --> 22:25.720
that is trying to provide some kind of abstraction while still allowing to do runtime dispatch?

22:25.720 --> 22:31.200
So the question was, have you looked into some of the abstraction libraries like Highway

22:31.200 --> 22:36.440
that's trying to do a sort of compromise between runtime dispatch and abstraction?

22:36.440 --> 22:40.760
I think this question was already answered, I think, two presentations ago.

22:40.760 --> 22:43.080
Not with Highway, but I think with a different SIMD library.

22:43.080 --> 22:49.800
But there have been various approaches, LibOil, SIMDEasy, various different approaches.

22:49.800 --> 22:57.280
And again, the result from certainly a firm peg x264, David, has been righted by hand.

22:57.280 --> 23:03.320
It's written once, and you know almost certainly that it's going to be usable for a long time.

23:03.320 --> 23:07.360
I didn't really talk about it, but the abstraction, there is a lightweight abstraction layer in

23:07.360 --> 23:13.440
x264 and FMpeg to try and basically to handle 32-bit, 64-bit, and to handle other things

23:13.440 --> 23:17.520
like the different ABI cores.

23:17.520 --> 23:23.200
The abstraction layer kind of handles some of the future proofing in that respect.

23:23.200 --> 23:27.240
But that's a, well, there's a blog post online from Ronald if he's here, but he's not here.

23:27.240 --> 23:30.440
He explains some of this.

23:30.440 --> 23:32.640
It's another presentation in itself, unfortunately.

23:32.640 --> 23:35.600
I have a question.

23:35.600 --> 23:42.880
For your benchmark, do you know which optimization the C code was compiled with?

23:42.880 --> 23:48.600
Question was, for the benchmark, what optimizations were the C code compiled with?

23:48.600 --> 23:53.120
GCC-003.

23:53.120 --> 23:59.520
Doing versions of GCC in FMpeg test suite, there's all sorts, I think from GCC, there's

23:59.520 --> 24:05.120
a whole range depending on the build OS, but from 4 to 12, I think.

24:05.120 --> 24:06.720
And then maybe some people test nightly.

24:06.720 --> 24:08.760
I think Martin certainly tests nightly for ARM.

24:08.760 --> 24:11.160
I don't know if anyone tests nightly on x86.

24:11.160 --> 24:13.680
Some are LVM as well.

24:13.680 --> 24:18.000
But again, I would be very surprised if the compiler would be able to come up with something

24:18.000 --> 24:25.240
because, like, what a human wrote, because this is involving bit properties of the actual

24:25.240 --> 24:32.960
packing and actually the trick with PMADSW is a kind of trick to try and do a multiply

24:32.960 --> 24:35.600
and a zeroing at the same time.

24:35.600 --> 24:41.960
And it probably doesn't have the level of thinking to understand the bit patterns internally.

24:41.960 --> 24:44.680
Something like chat GPT might one day, which would be quite interesting.

24:44.680 --> 24:46.240
But I don't think the compiler does.

24:46.240 --> 24:48.240
Last question.

24:48.240 --> 24:52.240
I'm just going to follow up on what you said.

24:52.240 --> 24:57.600
If you have a small algorithm, a small function like 10, 100 clients maybe, writing in assembly

24:57.600 --> 24:58.600
might be easy.

24:58.600 --> 25:04.800
But if you have a huge function, like a filter, a variance filter, or something, a GCT, writing

25:04.800 --> 25:07.440
directly in assembly might take a long time.

25:07.440 --> 25:13.600
That's why originally we write it in C and then we try to write it in easy, intrinsic.

25:13.600 --> 25:22.560
So the question is a longer function might take a longer time to write in assembly compared

25:22.560 --> 25:24.360
to C or intrinsic.

25:24.360 --> 25:29.760
Yes, but there are DCTs in FMPEG, but they're macroed.

25:29.760 --> 25:33.720
There's steps of macros to try and help that.

25:33.720 --> 25:37.720
Again the abstraction layer also adds, I think, macros on top of what the normal assembler

25:37.720 --> 25:40.320
does in terms of macros.

25:40.320 --> 25:42.720
The blog post explains, but swap is kind of interesting.

25:42.720 --> 25:47.280
It lets you swap registers, but then continue with them and the layer just handles all of

25:47.280 --> 25:49.680
that internally.

25:49.680 --> 25:51.640
There's also just macros for clipping.

25:51.640 --> 25:55.320
I think it was on the example, but clip, don't worry about this.

25:55.320 --> 25:56.840
But clip is an example.

25:56.840 --> 26:01.600
So clipUB is a macro and on the right target set it will go and use the right clipping

26:01.600 --> 26:03.400
functions if they're available, for example.

26:03.400 --> 26:06.520
And there's a bunch of these, I think transpose, butterfly.

26:06.520 --> 26:09.400
There's a few others like that.

26:09.400 --> 26:10.400
Thank you, Kiawan.

26:10.400 --> 26:18.200
Thank you.
