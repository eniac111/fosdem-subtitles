WEBVTT

00:00.000 --> 00:10.060
Okay, I'll start because the 10 minutes apply to me as well even though I wear this nice

00:10.060 --> 00:11.060
blue shirt.

00:11.060 --> 00:14.000
So please sit down and I'll start right away.

00:14.000 --> 00:18.940
So I'll be talking about social audio applications that you may want to re-implement with Janus.

00:18.940 --> 00:23.680
If you want quick slides about me, nobody cares.

00:23.680 --> 00:24.680
What is social audio?

00:24.680 --> 00:29.920
It's basically whenever you have something that is primarily audio and not strictly video

00:29.920 --> 00:31.840
as part of their form of communication.

00:31.840 --> 00:36.360
So whether it is messages or podcasts or virtual audio rooms or stuff like that, you may have

00:36.360 --> 00:40.480
heard about stuff like Clubhouse, Twitter Spaces, Reddy Talk.

00:40.480 --> 00:42.160
They are all examples of social audio.

00:42.160 --> 00:46.520
So people talking with each other, maybe they take turns and then they broadcast to a very

00:46.520 --> 00:47.880
large audience.

00:47.880 --> 00:51.400
And of course it does seem like a very good fit for WebRTC, especially for the real-time

00:51.400 --> 00:52.880
kind of participation.

00:52.880 --> 00:56.880
And you didn't hear about me because I don't know if there is any secrets about that, but

00:56.880 --> 01:02.400
actually Twitter Spaces uses Janus for the live part and then they distribute it somehow

01:02.400 --> 01:03.900
else.

01:03.900 --> 01:05.820
And how do they usually work?

01:05.820 --> 01:08.640
So as I said, they are typically live conversations.

01:08.640 --> 01:12.840
So you have a limited number of people that talk to each other, exchange ideas, they take

01:12.840 --> 01:13.840
turns.

01:13.840 --> 01:17.820
So it's not always the same people talking for two hours like a podcast, for instance.

01:17.820 --> 01:22.160
And then you may have possibly thousands of attendees, like for instance, anytime Elon

01:22.160 --> 01:27.040
Musk speaks in a Twitter Space, there's a million of people listening, let's say, things

01:27.040 --> 01:28.240
like that.

01:28.240 --> 01:31.800
And there are of course different challenges to tackle because for the live conversation

01:31.800 --> 01:36.340
part it needs of course to be real-time because it needs to be something that happens as fast

01:36.340 --> 01:37.640
as possible.

01:37.640 --> 01:41.920
For the distribution to the audience, you may want a bit of latency maybe okay and this

01:41.920 --> 01:46.640
is why for instance they take advantage of CDNs or stuff like that most of the times.

01:46.640 --> 01:51.020
But of course there's a problem that of course the more latency you have for the audience,

01:51.020 --> 01:54.460
if somebody from the audience needs to come into the conversation there may be a bit of

01:54.460 --> 01:55.860
latency there.

01:55.860 --> 01:58.240
And so that's something that needs to be taken into account.

01:58.240 --> 02:03.320
And so you may want to use WebRTC for everything but then there's scalability issues at play

02:03.320 --> 02:04.320
there.

02:04.320 --> 02:08.400
And so I wanted to check whether or not Janus, which is the WebRTC server that I work on

02:08.400 --> 02:10.500
for a living, could be used for the job.

02:10.500 --> 02:13.560
And I came up with a few potential ideas.

02:13.560 --> 02:16.740
And one of those may be relying on the audio bridge plugin.

02:16.740 --> 02:20.060
The audio bridge is basically an audio mixer that lives within Janus.

02:20.060 --> 02:23.560
So you have multiple people connected to the audio bridge plugin.

02:23.560 --> 02:27.940
They create a single pair connection that the audio bridge mixes all the audio streams

02:27.940 --> 02:32.380
so that you send one stream, you receive one stream that contains the audio of everybody

02:32.380 --> 02:34.200
involved except you.

02:34.200 --> 02:39.760
Which is really nice because for instance it's easy to bring C pinpoints in if you want

02:39.760 --> 02:41.760
using the plain RTP functionality.

02:41.760 --> 02:47.320
You can play jingles for instance you have your own show, your own context that you want

02:47.320 --> 02:51.480
to play something in there or maybe as an iPad from another conversation.

02:51.480 --> 02:56.040
If you do stereo mixing which you support you can use spatial positioning of participants

02:56.040 --> 02:58.400
to make it easier to understand for people.

02:58.400 --> 03:02.020
And of course this takes care of the live conversation but we want to make it available

03:02.020 --> 03:05.060
to other people as well so to a wider audience.

03:05.060 --> 03:08.600
And so what you can do is take advantage of RTP for worders which is basically an easy

03:08.600 --> 03:13.360
way by which the audio bridge plugin sends a plain RTP stream towards an address that

03:13.360 --> 03:17.320
you specify containing the mix that is being mixed there.

03:17.320 --> 03:20.840
And the nice feature in the audio bridge plugin is that you can also tag participants so that

03:20.840 --> 03:26.040
you may say don't send me a mix of all participants but only the ones that I tag in a specific

03:26.040 --> 03:27.040
group.

03:27.040 --> 03:30.700
For instance this one may be a technician so those two need to hear the technician who

03:30.700 --> 03:34.560
gives tips but all the attendees only need to hear those two.

03:34.560 --> 03:36.320
That's basically the main idea.

03:36.320 --> 03:40.560
And of course whatever happens in here is basically handling a mixed stream.

03:40.560 --> 03:45.160
So there may be a script here that sends this mix to Icecast to make a very simple example

03:45.160 --> 03:50.240
or to YouTube Live for audio or to whatever platform you want to use as a CDN for distributing

03:50.240 --> 03:52.620
the audio if it's not WebRTC.

03:52.620 --> 03:55.140
If you want to use WebRTC you can use something like this.

03:55.140 --> 03:59.400
So you have your active participants connected to the audio bridge they are talking to each

03:59.400 --> 04:00.400
other.

04:00.400 --> 04:04.440
You're RTP for word to the streaming plugin which is the plugin in Janus that takes care

04:04.440 --> 04:07.440
of broadcasting RTP to a wider audience.

04:07.440 --> 04:11.580
And then the streaming plugin is what distributes the audio which is the greatest advantage

04:11.580 --> 04:15.560
that you don't have to perform specific mixing for these participants.

04:15.560 --> 04:17.960
They are already receiving a mix of the stream.

04:17.960 --> 04:22.780
All people connected to the audio bridge instead have a dedicated context for mixing because

04:22.780 --> 04:24.800
they need to receive everybody except them.

04:24.800 --> 04:27.560
So it's not the same audio for all of them.

04:27.560 --> 04:33.880
And whenever you want somebody from the listeners to join in the conversation they mute the

04:33.880 --> 04:34.880
streaming parts.

04:34.880 --> 04:38.680
When they join the audio bridge temporarily they become active participants that everybody

04:38.680 --> 04:42.340
else can listen to because they are now mixed in the audio bridge.

04:42.340 --> 04:46.920
And of course for scalability purposes you can just RTP for word to multiple streaming

04:46.920 --> 04:50.220
plugin instances on multiple different instances of Janus.

04:50.220 --> 04:51.980
How you distribute it is entirely up to you.

04:51.980 --> 04:54.920
You can use a tree based distribution however you want.

04:54.920 --> 05:00.000
And you can also take advantage maybe of Multicast because of course if it's just a plain RTP

05:00.000 --> 05:03.420
stream that you are for wording if you for word it on a Multicast group then multiple

05:03.420 --> 05:08.440
Janus instances can all pull from that Multicast group that same mix of audio and can distribute

05:08.440 --> 05:10.140
it more efficiently.

05:10.140 --> 05:14.420
And one added value is that using this approach if you want you can also do something like

05:14.420 --> 05:15.660
interpreter services.

05:15.660 --> 05:18.800
You have two different audio bridge rooms for different rooms.

05:18.800 --> 05:22.280
You have the speaker join the room of their language and you have an interpreter on the

05:22.280 --> 05:23.460
other room.

05:23.460 --> 05:28.040
And then you distribute those two streams separately and then you allow the audience

05:28.040 --> 05:33.040
to listen maybe to the English channel or the French channel and depending on the language

05:33.040 --> 05:37.360
you will speak in you will hear the translator or the actual speaker on either one.

05:37.360 --> 05:42.040
So which makes little sense for an actual social audio application if we want it's maybe

05:42.040 --> 05:47.520
more for a conversational scenario but it's still a good side effect of that.

05:47.520 --> 05:51.680
If instead you don't want to mix in Janus for a few reasons because you don't want to

05:51.680 --> 05:56.520
terminate audio there mixing a CPU intensive or whatever you may want to use the SFU approach

05:56.520 --> 06:01.920
instead which means that participants in the conversation now need to establish maybe one

06:01.920 --> 06:05.720
single peer connection not necessarily more than one but they are exchanging multiple

06:05.720 --> 06:06.720
audio streams.

06:06.720 --> 06:11.080
So they are sending their own and they are receiving as many as there are other participants

06:11.080 --> 06:12.880
in the room.

06:12.880 --> 06:18.400
And you can still externalize this conversation via RTP for worders as before but now audio

06:18.400 --> 06:23.040
is not mixed so you have different audio streams for each of the participants there.

06:23.040 --> 06:27.200
So if you have three participants in the conversation each of them is sending one and receiving

06:27.200 --> 06:31.880
two and you have a separate component that is receiving the three different audio streams

06:31.880 --> 06:32.880
from the different participants.

06:32.880 --> 06:38.200
And so if you want to distribute something via regular CDN that requires a single audio

06:38.200 --> 06:39.320
stream to distribute.

06:39.320 --> 06:44.880
And so that component receiving RTP for worders needs to act a bit like a mixer acting live

06:44.880 --> 06:45.880
basically.

06:45.880 --> 06:50.000
So and once this happens so once you have a mix there everything is pretty much as the

06:50.000 --> 06:55.000
example as I made before you have a mixed stream you can distribute it via CDN or via

06:55.000 --> 07:00.240
Janus as we said before if you don't want to mix for the attendee as well you want something

07:00.240 --> 07:03.240
closer to a regular webinar or something like this.

07:03.240 --> 07:06.600
You can still do that but then you have to take do you have to use that approach that

07:06.600 --> 07:11.080
I was talking about for wording to the streaming plugin for each of the different participants.

07:11.080 --> 07:16.200
And so something like you have the presenter set contributing audio to the video room this

07:16.200 --> 07:21.960
becomes an audio broadcast for that specific presenter in the streaming plugin and people

07:21.960 --> 07:25.020
listen to that participant over there.

07:25.020 --> 07:30.960
You can again involve multiple streaming plugin instances if needed so that you can widen

07:30.960 --> 07:32.960
the audience if you want.

07:32.960 --> 07:36.360
But again if you have multiple participants speaking you have to do the same for each

07:36.360 --> 07:41.040
of them because otherwise of course since the audio is not mixed you would only listen

07:41.040 --> 07:45.900
to one single participant which means that the audience need to create subscriptions

07:45.900 --> 07:50.460
for more than one participant at any given time and of course you have to make this dynamic

07:50.460 --> 07:54.880
in case there's presenters that come and go basically which is what is expected in a social

07:54.880 --> 07:56.720
audio kind of application.

07:56.720 --> 08:01.960
Which means that it's probably easier to do something like this where you still do some

08:01.960 --> 08:07.720
sort of you keep the audio conversation using an SFU for WebRTC participant because it gives

08:07.720 --> 08:12.640
a better audio quality between each of them maybe but then for distributing the conversation

08:12.640 --> 08:17.420
it's okay to mix it and so even mix it for WebRTC usage so that you distribute a single

08:17.420 --> 08:20.640
audio stream instead which makes which makes sense.

08:20.640 --> 08:24.320
But again if you want to do that that works for instance this is what we do for our virtual

08:24.320 --> 08:31.520
event platform for meetings so that definitely works anyway and again you can also do this

08:31.520 --> 08:36.160
sort of multicast distribution if you want to take advantage of a wider distribution

08:36.160 --> 08:37.560
of the media.

08:37.560 --> 08:42.360
And if I spoke too fast which is very likely I did write a blog post about this which goes

08:42.360 --> 08:47.740
a bit more in detail and explains things a bit more precisely than I did right now and

08:47.740 --> 08:52.120
I think I managed to stay on time and these are some references so you can find me on

08:52.120 --> 08:57.400
Mastodon mainly I'm still on Twitter but who knows for how long and that's the blog post

08:57.400 --> 09:00.960
that I was mentioning before so that's all thank you.

09:00.960 --> 09:14.560
Okay there's time maybe for one or two questions if anybody is curious so I don't know if you

09:14.560 --> 09:15.560
have any.

09:15.560 --> 09:16.560
Okay.

09:16.560 --> 09:25.800
So any ability to do like energy level like to say which user are more important or less

09:25.800 --> 09:30.200
important when you are making the mix in this region.

09:30.200 --> 09:34.480
Not specifically in the audio bridge but this is something that you can enforce at the application

09:34.480 --> 09:38.920
level if you want so for instance you may decide that some users always need to be there

09:38.920 --> 09:44.760
and some users so for instance you may have the concept of the actual presenters and panelists

09:44.760 --> 09:49.080
that come and go for instance this is more of an application level context than the mixing

09:49.080 --> 09:52.640
context as far as mixing is concerned you just mix.

09:52.640 --> 10:02.680
Yeah exactly so any other question or can we move to Sagu?

10:02.680 --> 10:04.480
Okay then.

10:04.480 --> 10:15.520
Thank you very much.
