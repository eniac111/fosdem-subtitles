1
0:00:00.000 --> 0:00:07.000
So let's start with our next talk.

2
0:00:07.000 --> 0:00:16.000
Sorry we were going a bit late because the project was not running.

3
0:00:16.000 --> 0:00:22.000
We have a brand new TV now.

4
0:00:22.000 --> 0:00:02.000
So the next talk is about high-pile ups is

5
0:00:02.000 --> 0:00:09.000
going to become women.

6
0:00:32.000 --> 0:00:42.000
Just a short talk about box line and current state.

7
0:01:02.000 --> 0:01:26.000
I gave a talk so far ago about power wires and I will just talk a little bit quickly.

8
0:01:26.000 --> 0:01:33.000
So a bit about what it became since last time and what it is.

9
0:01:33.000 --> 0:01:40.000
So it's kind of like a sort of D-Bus or a lot of medium or a core pipeline.

10
0:01:40.000 --> 0:01:49.000
So its functionality is basically show objects in a graph and pass data between them.

11
0:01:49.000 --> 0:01:57.000
So in terms of that we have a section called wire clumber.

12
0:01:57.000 --> 0:02:14.000
We have a couple of services like for example there is a pulse audio service that converts all your clients to barbed wire.

13
0:02:14.000 --> 0:02:20.000
We also have a replacement library to write a jackpot.

14
0:02:20.000 --> 0:02:27.000
The purpose of this is to share all the videos.

15
0:02:27.000 --> 0:02:34.000
So we have video sharing, simple, I'll show you what I made.

16
0:02:34.000 --> 0:02:40.000
But also audio, functionality of the audio.

17
0:02:40.000 --> 0:02:55.000
So you need to do screen sharing in Wayland so you need to pass video from the GPU without touching the CPU to clients.

18
0:02:55.000 --> 0:03:04.000
So memory using file descriptors, stuff like that, zero copy.

19
0:03:04.000 --> 0:03:10.000
So it turned out in the end that it was also going to work for audio.

20
0:03:10.000 --> 0:03:15.000
Audio passing around and then I started working on that.

21
0:03:15.000 --> 0:03:21.000
So the audio part is very much like a jack audio server.

22
0:03:21.000 --> 0:03:25.000
Very simple how it passes the data around.

23
0:03:25.000 --> 0:03:34.000
So that you can build all the existing audio solutions.

24
0:03:34.000 --> 0:03:44.000
So this is the current situation of what we have for audio and video.

25
0:03:44.000 --> 0:03:49.000
So you have the Bluetooth stack with Bluetooth that goes over the e-mails.

26
0:03:49.000 --> 0:04:00.000
There is also the camera now that talks about that to interface with the kernel video for Linux originally.

27
0:04:00.000 --> 0:04:04.000
There is still also the audio stuff.

28
0:04:04.000 --> 0:04:15.000
And then we have the session manager barbed wire there and then the applications that go through.

29
0:04:15.000 --> 0:04:35.000
So it is a replacement for audio server or native or jack lines.

30
0:04:35.000 --> 0:04:46.000
So originally for Wayland screen sharing it was implemented that the motor which is the compositor would expose inside the pipeline graph.

31
0:04:46.000 --> 0:04:56.000
It is called a node which is something, it is like this here it produces a video feed and then you can connect with clients and also that they.

32
0:04:56.000 --> 0:05:10.000
So this is all input process so different process connected to the barbed wire.

33
0:05:10.000 --> 0:05:26.000
So you can branch out, you can mix things and barbed wire make sure that the data flows around.

34
0:05:26.000 --> 0:05:45.000
So for audio support it is like pro audio model like Jack.

35
0:05:45.000 --> 0:05:56.000
So there is one buffer size to the whole graph just like Jack but it is dynamic it can change.

36
0:05:56.000 --> 0:06:10.000
So there is automatic format converted from sources and things.

37
0:06:10.000 --> 0:06:27.000
So with that core layer you can run Jack lines almost with very little translation and with a little server you can run also audio lines.

38
0:06:27.000 --> 0:06:40.000
So it copies basically stuff that was already there to partially from Jack but also from also audio retirement model is also used.

39
0:06:40.000 --> 0:06:51.000
It uses a copy of all the old audio stuff for managing the cards and the mixers and you plug in the headphones that switches things and remembers volume.

40
0:06:51.000 --> 0:07:12.000
It controls the volume styles and all of that that was just copied directly because that piece is very evolved over the years.

41
0:07:12.000 --> 0:07:28.000
So you can run all the Jack clients like that and they will show up like also audio clients which is still up there.

42
0:07:28.000 --> 0:07:51.000
So it was originally started for video with the screen sharing then a little detour to audio but we are actually back now to video and now that it works.

43
0:07:51.000 --> 0:07:58.000
So now we are basically working on the camera capturing stuff.

44
0:07:58.000 --> 0:07:58.000
So traditionally browsers like for WebRPC go directly to video for Linux using IOS

45
0:07:58.000 --> 0:08:08.000
videos and stuff like that.

46
0:08:08.000 --> 0:08:10.000
So it is very difficult to put anything in between there.

47
0:08:10.000 --> 0:08:13.000
This all needs to be rewritten.

48
0:08:13.000 --> 0:08:15.000
This is in the process.

49
0:08:15.000 --> 0:08:17.000
Also newer cameras they need more stuff than what P

50
0:08:17.000 --> 0:08:21.000
eermo gives.

51
0:08:21.000 --> 0:08:24.000
There is a new library called the camera that works to install this.

52
0:08:24.000 --> 0:08:27.000
You can have more about that in your camera.

53
0:08:27.000 --> 0:08:32.000
You can just go directly to video for Linux and walk.

54
0:08:32.000 --> 0:08:34.000
So there is a layer needed.

55
0:08:34.000 --> 0:08:36.000
So we need to rewrite the applications anyway.

56
0:08:36.000 --> 0:08:47.000
So then it is probably going to be written to Piedwars so that we can route the video more flexibly.

57
0:08:47.000 --> 0:09:01.000
So basically Piedwars we can write cameras and you can get them from clients.

58
0:09:01.000 --> 0:09:13.000
So this also means that you can have multiple apps going to the same camera.

59
0:09:13.000 --> 0:09:22.000
So the status currently is it has been in Piedwars for almost two years.

60
0:09:22.000 --> 0:09:32.000
It was API and ABI stable and so far we can make this work.

61
0:09:32.000 --> 0:09:36.000
It was made to default.

62
0:09:36.000 --> 0:09:42.000
We are made against all expectations.

63
0:09:42.000 --> 0:09:45.000
I was a bit afraid that it doesn't work.

64
0:09:45.000 --> 0:09:47.000
That is not expected.

65
0:09:47.000 --> 0:09:49.000
So it became a default.

66
0:09:49.000 --> 0:09:55.000
So for the moment, Jack and Paul saw the feature.

67
0:09:55.000 --> 0:09:58.000
Everything should work as it worked before.

68
0:09:58.000 --> 0:10:07.000
There is a couple of things that are not checked.

69
0:10:07.000 --> 0:10:11.000
There are alternatives to connect multiple Jacks.

70
0:10:11.000 --> 0:10:15.000
All the servers on the network.

71
0:10:15.000 --> 0:10:23.000
It is a very specific implementation.

72
0:10:23.000 --> 0:10:35.000
There are alternatives to the RTP based on which there are more compatible with the hardware.

73
0:10:35.000 --> 0:10:46.000
There are also a bunch of Piedwars that maybe nobody uses.

74
0:10:46.000 --> 0:10:52.000
So right now most of the stores are switching as well or have switched.

75
0:10:52.000 --> 0:10:56.000
I think Debian is getting there.

76
0:10:56.000 --> 0:11:01.000
Wuntu switched for 32.10.

77
0:11:01.000 --> 0:11:05.000
No more pulse audio.

78
0:11:05.000 --> 0:11:08.000
You have to note no more pulse audio.

79
0:11:08.000 --> 0:11:12.000
The only thing that is changed there is the server part.

80
0:11:12.000 --> 0:11:16.000
The client part of pulse audio is still in use.

81
0:11:16.000 --> 0:11:18.000
But it talks to a different server.

82
0:11:18.000 --> 0:11:24.000
It is a re-implementation of the pipeline.

83
0:11:24.000 --> 0:11:50.000
So what are we doing?

84
0:11:50.000 --> 0:11:57.000
If you are on a laptop speaker, you only get it in the right channel.

85
0:11:57.000 --> 0:12:12.000
The right channel is is lapel.

86
0:12:12.000 --> 0:12:20.000
We are trying to work on various things here.

87
0:12:20.000 --> 0:12:24.000
The camera elements, we work on to get it all integrated.

88
0:12:24.000 --> 0:12:30.000
We are going to have a talk about this on Sunday.

89
0:12:30.000 --> 0:12:33.000
It is a whole bunch of things that need to be done.

90
0:12:33.000 --> 0:12:36.000
For example, for the camera, there is also a portal.

91
0:12:36.000 --> 0:12:44.000
We try to hide everything behind the portal that will manage the permissions.

92
0:12:44.000 --> 0:12:46.000
Application can access the camera.

93
0:12:46.000 --> 0:12:57.000
Yes, it is sort of like other computers where you give access to an application.

94
0:12:57.000 --> 0:13:00.000
So that goes through the portal.

95
0:13:00.000 --> 0:13:02.000
We try to route everything to that.

96
0:13:02.000 --> 0:13:06.000
There are lots of applications to be in looking.

97
0:13:06.000 --> 0:13:14.000
For example, in the studio, there is a bit of a test case there for the camera and screen integration.

98
0:13:14.000 --> 0:13:22.000
There are merge requests ready to be merged.

99
0:13:22.000 --> 0:13:39.000
There are some more things.

100
0:13:39.000 --> 0:13:53.000
The result is that if you do a call in one of these browsers in a future version, you can do lots of fun stuff.

101
0:13:53.000 --> 0:13:57.000
You can add filters to the camera.

102
0:13:57.000 --> 0:14:15.000
For example, in the studio, you can do a virtual camera and then you can add that camera.

103
0:14:15.000 --> 0:14:37.000
I am sorry, I have never thought about that.

104
0:14:37.000 --> 0:14:39.000
Repeat the question.

105
0:14:39.000 --> 0:14:45.000
Can you repeat the question for the stream?

106
0:14:45.000 --> 0:15:11.000
The question was, Jack had a network transport and he also allowed compression.

107
0:15:11.000 --> 0:15:15.000
He tried to do the ABS, which is all that can be used.

108
0:15:15.000 --> 0:15:17.000
It is uncompressed.

109
0:15:17.000 --> 0:15:21.000
There are some more facts.

110
0:15:21.000 --> 0:15:23.000
I am just curious.

111
0:15:23.000 --> 0:15:27.000
We have a product that actually uses that component in portfolio.

112
0:15:27.000 --> 0:15:31.000
Since I put it in order, my...

113
0:15:31.000 --> 0:15:33.000
Yes, the green zone.

114
0:15:33.000 --> 0:15:39.000
Yes, following up on that, there is a rock plugin.

115
0:15:39.000 --> 0:15:45.000
The suggestion is that there is a rock plugin.

116
0:15:45.000 --> 0:15:52.000
The rock toolkit is built over the E and also provides network transport.

117
0:15:52.000 --> 0:15:55.000
I do not know, does it do compression?

118
0:15:55.000 --> 0:16:00.000
I do not know.

119
0:16:00.000 --> 0:16:15.000
It is a bit more generic streaming.

120
0:16:15.000 --> 0:16:24.000
Are there any further plans to introduce a second processor?

121
0:16:24.000 --> 0:16:30.000
The question is, are there plans to add echo cancellation or other plugins?

122
0:16:30.000 --> 0:16:35.000
Echo cancellation, we have a module that you can load.

123
0:16:35.000 --> 0:16:43.000
Echo cancellation, we have to see echo cancel and load.

124
0:16:43.000 --> 0:16:46.000
Signal processing, there is also a whole bunch of things.

125
0:16:46.000 --> 0:16:52.000
You can of course load jack tools to do this.

126
0:16:52.000 --> 0:16:58.000
We also have a native module that can load lots of Ld2 filters.

127
0:16:58.000 --> 0:17:04.000
You can use fullstruct filter chains.

128
0:17:04.000 --> 0:17:13.000
There is also easy effects, which is an app to manage the filters for you.

129
0:17:13.000 --> 0:17:17.000
There are quite a few options.

130
0:17:17.000 --> 0:17:22.000
We have an online question, is there a way to visually show pipeline use?

131
0:17:22.000 --> 0:17:27.000
Yes.

132
0:17:27.000 --> 0:17:34.000
For visualizing the pipeline blocks, you can of course use jack tools.

133
0:17:34.000 --> 0:17:39.000
There is also a native toolkit to do this.

134
0:17:39.000 --> 0:18:03.000
You can also load later in the count.

135
0:18:03.000 --> 0:18:09.000
You said you had AES output, are you referring to AES67?

136
0:18:09.000 --> 0:18:15.000
How are you dealing with the clocking elements of AES67?

137
0:18:15.000 --> 0:18:32.000
Are you just ignoring it?

138
0:18:32.000 --> 0:18:34.000
What happens if you don't?

139
0:18:34.000 --> 0:18:39.000
Do people just send garbage timestamps by default?

140
0:18:39.000 --> 0:18:43.000
This is a big problem for receivers that need to look at the timestamps and go,

141
0:18:43.000 --> 0:18:55.000
I need to do something with it.

142
0:18:55.000 --> 0:18:58.000
What should a third party receiver do?

143
0:18:58.000 --> 0:19:03.000
If they have two different clocks, what does it do with the timestamps?

144
0:19:03.000 --> 0:19:10.000
The timestamps in the receiver, what does the receiver do to synchronize itself to the screen?

145
0:19:10.000 --> 0:19:23.000
Basically follow the rate at which you receive data and try to adjust the consumption rate by resulting.

146
0:19:23.000 --> 0:19:29.000
You talked a lot about portals for video, is there also something similar for audio?

147
0:19:29.000 --> 0:19:34.000
Like for example, I want to capture an application using video and audio.

148
0:19:34.000 --> 0:19:41.000
The question is, the portal for video, we talked about lockups, is there also a portal for audio?

149
0:19:41.000 --> 0:19:52.000
The answer is, we are thinking about it, but we don't have anything to change.

150
0:19:52.000 --> 0:19:58.000
Is there anything for networking video screens?

151
0:19:58.000 --> 0:20:04.000
The question is, is there anything for networking video screens?

152
0:20:04.000 --> 0:20:14.000
Last, not sure.

153
0:20:14.000 --> 0:20:30.000
There are lots of things you can do, it's really hard to do.

154
0:20:30.000 --> 0:20:45.000
Thank you.

