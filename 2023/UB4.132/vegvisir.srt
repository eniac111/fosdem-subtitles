1
0:00:00.000 --> 0:00:08.000
All right, so good morning everybody.

2
0:00:08.000 --> 0:00:13.000
My name is Joris and I'm a PhD student over at Hasselt University here in Belgium.

3
0:00:13.000 --> 0:00:18.640
And I'm doing a PhD on multimedia streaming and natural transport layer protocols, or

4
0:00:18.640 --> 0:00:21.560
even better, the intersection of those two.

5
0:00:21.560 --> 0:00:25.800
Today I'm here to talk a little bit about a project we did called Wegwiesir, which is

6
0:00:25.800 --> 0:00:32.200
an automated testing framework for orchestrating client and server setups using the QUIC transport

7
0:00:32.200 --> 0:00:34.200
layer protocols.

8
0:00:34.200 --> 0:00:37.840
But before we jump into that, maybe let's talk a little bit about what QUIC actually

9
0:00:37.840 --> 0:00:40.920
is because I assume not everybody has heard about it.

10
0:00:40.920 --> 0:00:44.680
Well, QUIC is a general purpose transport layer protocol that was standardized by the

11
0:00:44.680 --> 0:00:47.200
ITF in May 2021.

12
0:00:47.200 --> 0:00:53.000
And if you have any updated applications on your phone or have been using the latest releases

13
0:00:53.000 --> 0:00:57.320
of browsers such as Firefox, Chrome, or whatever you're using, you've probably been already

14
0:00:57.320 --> 0:01:02.520
using QUIC as it has been deployed to a lot of many different applications and websites

15
0:01:02.520 --> 0:01:03.520
already.

16
0:01:03.520 --> 0:01:05.720
For example, Facebook, Instagram, they are using it.

17
0:01:05.720 --> 0:01:10.280
If you're streaming videos over YouTube, you have probably been already using QUIC.

18
0:01:10.280 --> 0:01:11.840
QUIC is a name.

19
0:01:11.840 --> 0:01:12.840
It's not an acronym.

20
0:01:12.840 --> 0:01:18.400
It used to stand for QUIC UDP Internet Connections, but it has actually not been called that for

21
0:01:18.400 --> 0:01:20.840
quite some time already now.

22
0:01:20.840 --> 0:01:24.720
Right, some of its features, the biggest feature is encryption.

23
0:01:24.720 --> 0:01:29.120
So the protocol actually encrypts everything by default, which is great because that's

24
0:01:29.120 --> 0:01:31.120
the main driver against ossification.

25
0:01:31.120 --> 0:01:35.400
Also it's reason that it was created because TCP is actually an ossified protocol when

26
0:01:35.400 --> 0:01:37.160
we compare it to.

27
0:01:37.160 --> 0:01:40.320
It's also great for preventing third parties from actually interfering with the data you

28
0:01:40.320 --> 0:01:42.640
are transmitting over the network.

29
0:01:42.640 --> 0:01:45.840
It's less great for research and development as you have to actually account for that in

30
0:01:45.840 --> 0:01:50.440
your test setups, which we are going to talk about a little bit further ahead.

31
0:01:50.440 --> 0:01:55.720
Currently most implementations implemented on top of UDP in user space.

32
0:01:55.720 --> 0:02:00.500
Some implementations are actually looking at implementing it more towards the kernel,

33
0:02:00.500 --> 0:02:04.480
but those steps have not been taken by many of the implementations.

34
0:02:04.480 --> 0:02:10.800
At present, at least as far as I know, 25 implementations exist, most of them also being

35
0:02:10.800 --> 0:02:14.200
open source written in multiple programming languages.

36
0:02:14.200 --> 0:02:19.440
They also provide libraries which you can directly use to actually use QUIC in your

37
0:02:19.440 --> 0:02:22.760
applications.

38
0:02:22.760 --> 0:02:27.680
Another benefit of QUIC or another new thing with QUIC is HTTP3, which you might have heard

39
0:02:27.680 --> 0:02:29.280
of.

40
0:02:29.280 --> 0:02:35.000
The reason for the introduction of H3 is that H1 and H2 actually only run over TCP.

41
0:02:35.000 --> 0:02:39.360
That's why they created a new version of HTTP called HTTP3.

42
0:02:39.360 --> 0:02:44.320
It's not that big of a difference between H2 and H3 in practice, but just for sake of

43
0:02:44.320 --> 0:02:47.240
naming it, it's HTTP3.

44
0:02:47.240 --> 0:02:52.840
So now that you know what QUIC is, that's at least the requirement for understanding

45
0:02:52.840 --> 0:03:00.060
this talk, let's talk about how we can actually use this in experiments and stuff.

46
0:03:00.060 --> 0:03:02.200
Maybe let's try doing something very simple.

47
0:03:02.200 --> 0:03:04.840
I just told you that most browsers implement QUIC.

48
0:03:04.840 --> 0:03:10.600
Maybe let's try connecting to a website that only implements an HTTP3 server.

49
0:03:10.600 --> 0:03:11.600
Should be simple, right?

50
0:03:11.600 --> 0:03:14.560
But as you can see on the screenshot, it is not in practice.

51
0:03:14.560 --> 0:03:18.240
And the reason for that is really simple, that's because browsers decided early on that

52
0:03:18.240 --> 0:03:28.080
HTTP3 server should be discoverable through the old SVC had provided by an H1 or H2 deployment,

53
0:03:28.080 --> 0:03:31.120
which really sucks if you want to do some automated testing, because that means you

54
0:03:31.120 --> 0:03:37.040
also have to put up like, or spin up an H1 or H2 server and actually account for this.

55
0:03:37.040 --> 0:03:43.000
Luckily, we have some options like, for example, within Chrome and Firefox to enable QUIC on

56
0:03:43.000 --> 0:03:49.320
certain domains, which we can automate through by means of, for example, parameters supplied

57
0:03:49.320 --> 0:03:54.400
in the command line or by configurations in the browser itself.

58
0:03:54.400 --> 0:03:55.400
Right.

59
0:03:55.400 --> 0:03:58.320
So we can connect to a web server at this point.

60
0:03:58.320 --> 0:03:59.800
How do we actually know what's happening?

61
0:03:59.800 --> 0:04:01.880
Under the root, should also be simple, right?

62
0:04:01.880 --> 0:04:03.400
Remember, everything is encrypted.

63
0:04:03.400 --> 0:04:08.400
So actually seeing what's happening is a little bit, it's not that trivial actually.

64
0:04:08.400 --> 0:04:14.400
Luckily, most implementations nowadays use standard off the shelf TLS libraries, and

65
0:04:14.400 --> 0:04:20.840
these TLS backends actually support an environment variable called SSL key lock file.

66
0:04:20.840 --> 0:04:24.360
And the idea behind the SSL key lock file is that you can point it towards a file, which

67
0:04:24.360 --> 0:04:30.080
then gets used by these TLS backends to output all the secrets used for encryption during

68
0:04:30.080 --> 0:04:32.940
a whatever the application is actually doing.

69
0:04:32.940 --> 0:04:37.000
If you load those SSL key lock files into programs like Wireshark, you can actually

70
0:04:37.000 --> 0:04:41.600
decrypt the traffic, which is nice if you want to see what happened.

71
0:04:41.600 --> 0:04:46.320
Unfortunately, tools like Wireshark, at least as far as I know, don't actually have any

72
0:04:46.320 --> 0:04:51.760
visualizations about stuff that's happening at the congestion or flow control layer.

73
0:04:51.760 --> 0:04:57.040
You have that for TCP, but QUIC, those things don't exist yet.

74
0:04:57.040 --> 0:04:59.080
But luckily we have other stuff for that.

75
0:04:59.080 --> 0:05:00.080
Qlock is one of them.

76
0:05:00.080 --> 0:05:03.920
There has been a nice talk about this by Zendvent a couple of years ago at Fosdom.

77
0:05:03.920 --> 0:05:06.200
I really invite you to look at it.

78
0:05:06.200 --> 0:05:11.040
But basically in a nutshell, what Qlock is is like a structured way of logging and a

79
0:05:11.040 --> 0:05:16.880
unified way of logging that can be implemented by any endpoint implementation using QUIC.

80
0:05:16.880 --> 0:05:24.680
In a nutshell, this is basically a file, for example, a JSON file that just logs everything

81
0:05:24.680 --> 0:05:25.960
that's happening.

82
0:05:25.960 --> 0:05:30.400
And if you have some scripts or tools that can parse this, you can actually do a lot

83
0:05:30.400 --> 0:05:31.400
of fun stuff with it.

84
0:05:31.400 --> 0:05:35.960
For example, the Qviz visualization tool, which is also by the same creator, is a tool

85
0:05:35.960 --> 0:05:40.880
that allows you to load these files and actually visualize similar to what Wireshark can do

86
0:05:40.880 --> 0:05:44.800
for TCP, but then for QUIC, what's happening on the congestion layers.

87
0:05:44.800 --> 0:05:48.560
For example, on the left you see a flow control and congestion flow graph.

88
0:05:48.560 --> 0:05:54.800
And on the right you see a port of the home trip time that was experienced by the application.

89
0:05:54.800 --> 0:05:57.920
Right, so we can look at what's happening on the route.

90
0:05:57.920 --> 0:06:04.000
Maybe let's try something more advanced, setting up your own QUIC client and QUIC server to

91
0:06:04.000 --> 0:06:07.320
do some local experiments, maybe change something to the implementations.

92
0:06:07.320 --> 0:06:09.480
It doesn't matter really what you want to do.

93
0:06:09.480 --> 0:06:13.840
Even that is not that trivial simply because there are many implementations written in

94
0:06:13.840 --> 0:06:20.440
many languages, meaning that they have their own requirements, their own installation procedures.

95
0:06:20.440 --> 0:06:25.080
Another distinction is that different implementations actually have different performance characteristics,

96
0:06:25.080 --> 0:06:28.560
meaning that some are more tuned to certain scenarios.

97
0:06:28.560 --> 0:06:31.160
Some only support a certain feature set.

98
0:06:31.160 --> 0:06:34.680
So you also have to account for that.

99
0:06:34.680 --> 0:06:40.200
An additional requirement is that you also have to set up self-signed certificates.

100
0:06:40.200 --> 0:06:44.320
And for some reason, some implementations accept all kinds of certificates.

101
0:06:44.320 --> 0:06:46.520
And then for some reason, all those fail.

102
0:06:46.520 --> 0:06:48.800
We have never really figured out why.

103
0:06:48.800 --> 0:06:52.440
We just use a common way that works for them all now.

104
0:06:52.440 --> 0:06:56.760
Anyway, another query that you can experience is within the code bases themselves.

105
0:06:56.760 --> 0:07:00.080
A fun one I always show to my students is this one.

106
0:07:00.080 --> 0:07:05.920
This is from the QUIC code base, which uses the cubic congestion control algorithm, if

107
0:07:05.920 --> 0:07:08.600
you know something about congestion control.

108
0:07:08.600 --> 0:07:11.560
And makes sense, like the file is called new cubic standard.

109
0:07:11.560 --> 0:07:13.600
The function is called new cubic standard.

110
0:07:13.600 --> 0:07:18.480
It even specifies in documentation that it makes a new cubic standard unless you actually

111
0:07:18.480 --> 0:07:24.040
put a renewable on true, then it behaves like a totally different beast, actually new Reno

112
0:07:24.040 --> 0:07:25.040
in that case.

113
0:07:25.040 --> 0:07:29.560
So some weird queries that you actually have to account for too.

114
0:07:29.560 --> 0:07:34.560
So the point I'm trying to make is that there are a lot of different implementations.

115
0:07:34.560 --> 0:07:35.560
Testing them all takes time.

116
0:07:35.560 --> 0:07:36.760
It's not that easy to set it up.

117
0:07:36.760 --> 0:07:39.200
You experience a lot of these small issues.

118
0:07:39.200 --> 0:07:45.640
It's cumbersome to test multiple implementations, which is the reason why I am presenting Wegwesir

119
0:07:45.640 --> 0:07:46.640
today.

120
0:07:46.640 --> 0:07:49.760
The idea behind Wegwesir is to actually aid with this kind of development.

121
0:07:49.760 --> 0:07:53.880
So if you're doing research or even development within QUIC, the idea is that Wegwesir can

122
0:07:53.880 --> 0:07:59.220
automatically set up these kinds of interactions between clients and servers, but also using

123
0:07:59.220 --> 0:08:04.720
simulated networks such that you have actual repeatable and shareable experiments.

124
0:08:04.720 --> 0:08:09.600
The way you do it, this is by defining experiments with configuration files.

125
0:08:09.600 --> 0:08:13.360
And a single experiment can consist out of multiple test cases.

126
0:08:13.360 --> 0:08:17.560
And the idea is that a single test case looks something like this.

127
0:08:17.560 --> 0:08:22.200
So you have the two entities, the server and the client, which just assume the prototypical

128
0:08:22.200 --> 0:08:25.320
roles as known within the server-client model.

129
0:08:25.320 --> 0:08:28.400
And in between them sets a network component that we call the shape.

130
0:08:28.400 --> 0:08:32.440
And the idea of the shape is that it actually applies some kind of scenario on the traffic

131
0:08:32.440 --> 0:08:35.160
passing between the server and client.

132
0:08:35.160 --> 0:08:39.520
For example, it can introduce some latency or it could limit the throughput.

133
0:08:39.520 --> 0:08:41.200
It doesn't really matter what you want to do.

134
0:08:41.200 --> 0:08:43.680
The idea is that you can do it in a repeatable way.

135
0:08:43.680 --> 0:08:47.280
You also see the docker container stuff on top.

136
0:08:47.280 --> 0:08:52.640
The idea of actually deploying these test cases within docker containers is that we can

137
0:08:52.640 --> 0:08:57.920
easily share them with other people, which is a really nice benefit within the academic

138
0:08:57.920 --> 0:08:59.520
community.

139
0:08:59.520 --> 0:09:01.800
But also we can free certain implementations.

140
0:09:01.800 --> 0:09:05.520
We can actually save a docker container and reuse it at a later point.

141
0:09:05.520 --> 0:09:09.040
So say, for example, something changes and we want to try an older version, that's totally

142
0:09:09.040 --> 0:09:10.560
possible with this setup.

143
0:09:10.560 --> 0:09:15.200
Additionally, within the quick community, there have been some other efforts.

144
0:09:15.200 --> 0:09:21.000
If you are part of the quick community, you might actually recognize this setup.

145
0:09:21.000 --> 0:09:25.360
It's pretty much the same as one used by an interoperability project called the Quick

146
0:09:25.360 --> 0:09:27.880
Interoperability Runnach.

147
0:09:27.880 --> 0:09:31.760
They also provide containers for their setup that are more tuned towards testing the actual

148
0:09:31.760 --> 0:09:35.480
interoperability between quick implementations.

149
0:09:35.480 --> 0:09:40.760
But the benefit of using the same architecture is that we are actually completely compatible

150
0:09:40.760 --> 0:09:42.680
with their setups.

151
0:09:42.680 --> 0:09:46.400
So that means that even though VEGWISI is relatively new, at this point in time we are

152
0:09:46.400 --> 0:09:53.280
already compatible with 15 out of the 25 quick implementations right out of the box.

153
0:09:53.280 --> 0:09:59.240
We also see on the right side that we have a client that can be defined as a CLI command.

154
0:09:59.240 --> 0:10:05.000
That's because early on we realized that if we want to test applications, not every kind

155
0:10:05.000 --> 0:10:11.080
of test is suitable to be placed in a docker container, which is why we also allow to define

156
0:10:11.080 --> 0:10:15.600
tests by just spinning up local programs as you're used to from a terminal.

157
0:10:15.600 --> 0:10:18.320
A good example of this is a browser.

158
0:10:18.320 --> 0:10:22.080
If you're doing some kind of media streaming experiments, you actually want hardware acceleration

159
0:10:22.080 --> 0:10:26.320
and search to be enabled, which I guess you can do this in docker containers because it's

160
0:10:26.320 --> 0:10:29.400
really cumbersome to actually do this in a good way.

161
0:10:29.400 --> 0:10:33.440
Right, okay, so how are these experiments actually defined?

162
0:10:33.440 --> 0:10:40.520
Well, we decided to not use one single configuration file simply because that would mean we had

163
0:10:40.520 --> 0:10:41.680
to be very verbose.

164
0:10:41.680 --> 0:10:45.280
We actually split it up in two types of configurations.

165
0:10:45.280 --> 0:10:50.120
On the left you can see the implementation configuration, which is actually what defines

166
0:10:50.120 --> 0:10:53.240
what is available within an experiment.

167
0:10:53.240 --> 0:10:57.920
The idea is that an implementation configuration is similar to your list of installed software

168
0:10:57.920 --> 0:10:58.920
on your computer.

169
0:10:58.920 --> 0:11:02.080
You simply have a list of entities that you can pick from.

170
0:11:02.080 --> 0:11:05.760
We also introduced a parametric system to make it actually really dynamic, steerable

171
0:11:05.760 --> 0:11:08.120
from within an experiment configuration.

172
0:11:08.120 --> 0:11:11.000
We will see some examples on that in a second.

173
0:11:11.000 --> 0:11:13.400
On the right you see the experiment configuration.

174
0:11:13.400 --> 0:11:17.460
That's the actual definition of what needs to happen within one experiment, so what defines

175
0:11:17.460 --> 0:11:18.760
the test cases.

176
0:11:18.760 --> 0:11:23.480
The idea is that you define how the entities from the implementation configuration should

177
0:11:23.480 --> 0:11:30.440
be here, it should behave, and what parameters should actually contain its values through

178
0:11:30.440 --> 0:11:31.440
arguments.

179
0:11:31.440 --> 0:11:32.440
It also configures answers.

180
0:11:32.440 --> 0:11:36.120
I'm going to talk about that in a second, but the biggest benefit of splitting these

181
0:11:36.120 --> 0:11:42.120
two up is actually that the configuration, the experiment configuration, automatically

182
0:11:42.120 --> 0:11:49.040
produces this permutation or rather a total of combinations from all these entities.

183
0:11:49.040 --> 0:11:52.440
Say for example you define two servers, two clients, and two shapers.

184
0:11:52.440 --> 0:11:57.480
The total amount of tests within this experiment will actually be eight because it just creates

185
0:11:57.480 --> 0:12:02.440
a, it compiles a complete combination of all these configurations.

186
0:12:02.440 --> 0:12:04.400
Another benefit is loose coupling.

187
0:12:04.400 --> 0:12:08.040
You might wonder, yeah, I still don't see the reason why you split these two up.

188
0:12:08.040 --> 0:12:12.320
Well, a big thing with an academic research is that we actually want to test different

189
0:12:12.320 --> 0:12:13.320
versions.

190
0:12:13.320 --> 0:12:18.080
If we have an implementation configuration that for example defines a client called Chrome

191
0:12:18.080 --> 0:12:23.400
which then refers to a Chrome browser, we can actually have one implementation configuration

192
0:12:23.400 --> 0:12:28.240
that refers to version, for example, 99, and we can have another implementation configuration

193
0:12:28.240 --> 0:12:30.940
that refers to, for example, version 100.

194
0:12:30.940 --> 0:12:34.920
The benefit of that is that if we simply swap these implementation configurations, we don't

195
0:12:34.920 --> 0:12:39.240
need to change the experiment configurations, meaning that we can, without having to mostly

196
0:12:39.240 --> 0:12:44.200
rewrite all these stats, really easily test multiple setups.

197
0:12:44.200 --> 0:12:45.200
Some examples.

198
0:12:45.200 --> 0:12:47.840
This is an example of an implementation configuration.

199
0:12:47.840 --> 0:12:52.440
I do invite you to go to the GitHub repository where everything is really nicely explained

200
0:12:52.440 --> 0:12:55.160
and we provide some more examples.

201
0:12:55.160 --> 0:12:59.680
I'm unfortunately limited by the screen size.

202
0:12:59.680 --> 0:13:03.240
You see that we always have to define in the implementation configuration three types of

203
0:13:03.240 --> 0:13:08.240
entities like we talked about earlier, the clients, the servers, and the shapers.

204
0:13:08.240 --> 0:13:10.960
These three are examples using Docker system.

205
0:13:10.960 --> 0:13:14.320
In the top two, you see that we actually refer to Docker Hub images.

206
0:13:14.320 --> 0:13:18.760
These are actual examples that come from the Quick Interopron project which we are compatible

207
0:13:18.760 --> 0:13:19.760
with.

208
0:13:19.760 --> 0:13:22.360
The bottom one is a locally built Docker image.

209
0:13:22.360 --> 0:13:26.440
The reason I highlight this difference is because the framework automatically pulls

210
0:13:26.440 --> 0:13:30.680
the latest Docker Hub images if these are available.

211
0:13:30.680 --> 0:13:36.000
If you are using some kind of local implementation that you built as a Docker image, you actually

212
0:13:36.000 --> 0:13:39.920
have to build it locally and then refer to it locally.

213
0:13:39.920 --> 0:13:43.000
Another thing you can see here is the parametric system.

214
0:13:43.000 --> 0:13:49.760
For example, the top client defines a requests parameter that is then used within an experiment.

215
0:13:49.760 --> 0:13:54.920
The idea is that an experiment configuration then contains a value of it and that you can

216
0:13:54.920 --> 0:14:01.240
access this value within a Docker image simply by using requests then in this case as an

217
0:14:01.240 --> 0:14:02.640
environment variable.

218
0:14:02.640 --> 0:14:09.000
All the parameters are passed as environment variables if you are using Docker images.

219
0:14:09.000 --> 0:14:13.120
Or in the case that you are using CLI commands or even in a more specific case of shapers

220
0:14:13.120 --> 0:14:18.000
because shapers are a little bit more complicated, you can also use them directly in the commands

221
0:14:18.000 --> 0:14:21.560
you specify within the implementation and experiment configurations.

222
0:14:21.560 --> 0:14:26.920
These are directly substituted and you can actually reference all the parameters within

223
0:14:26.920 --> 0:14:32.200
arguments, which is nice.

224
0:14:32.200 --> 0:14:39.400
A simple example of a CLI client, so one that's not using a Docker image in other words, you

225
0:14:39.400 --> 0:14:41.960
can see that the command is rather long.

226
0:14:41.960 --> 0:14:46.360
That's because we cannot, well, compared to a Docker container, we actually have to specify

227
0:14:46.360 --> 0:14:51.120
everything that needs to happen in a CLI command.

228
0:14:51.120 --> 0:14:56.840
This example provides three or rather four system parameters which I highlighted here.

229
0:14:56.840 --> 0:15:00.520
The reason I did this is because the framework automatically generates all these details

230
0:15:00.520 --> 0:15:04.920
for you such that the experiments can be even more dynamically steered.

231
0:15:04.920 --> 0:15:09.680
This is especially handy for future use cases where we, for example, want to expand upon

232
0:15:09.680 --> 0:15:13.280
multiple client setups and stuff like that.

233
0:15:13.280 --> 0:15:15.600
On the bottom you see a construct key.

234
0:15:15.600 --> 0:15:20.040
We actually have two special mechanisms for CLI commands.

235
0:15:20.040 --> 0:15:23.640
In Docker images, the benefit of Docker images is that they can actually have scripts on

236
0:15:23.640 --> 0:15:27.360
both that actually prime the environment.

237
0:15:27.360 --> 0:15:32.280
That's the downside of using CLI commands unless you want to put everything on one single

238
0:15:32.280 --> 0:15:35.200
line which is rather also cumbersome.

239
0:15:35.200 --> 0:15:39.440
Instead we provide two mechanisms called construct and district which are run before and after

240
0:15:39.440 --> 0:15:45.920
a command is executed, these can be used to prime an environment and clean it up afterwards.

241
0:15:45.920 --> 0:15:54.040
This example sets the changes or manipulates the Google Chrome preferences to set the standard

242
0:15:54.040 --> 0:16:01.160
download folder output towards one generated by the framework.

243
0:16:01.160 --> 0:16:03.440
Then we come to the experiment configurations examples.

244
0:16:03.440 --> 0:16:07.840
These are the actual configurations that define how a test should behave.

245
0:16:07.840 --> 0:16:12.160
You see here once again we have client shapers and servers which we picked from the implementation

246
0:16:12.160 --> 0:16:14.200
that we just showed.

247
0:16:14.200 --> 0:16:21.520
We simply fill them in with the arguments required for the test to work.

248
0:16:21.520 --> 0:16:24.960
A special thing to notice here is the shaper scenarios.

249
0:16:24.960 --> 0:16:26.640
Clients and servers are really simple.

250
0:16:26.640 --> 0:16:29.440
You just mentioned which one you want to use.

251
0:16:29.440 --> 0:16:31.560
For shapers we have a more complicated setup.

252
0:16:31.560 --> 0:16:34.520
The idea behind the shaper is that it actually entails one kind of shaping.

253
0:16:34.520 --> 0:16:39.840
For example, you can use a TC-netm shaper within one container.

254
0:16:39.840 --> 0:16:42.240
This one container does not only do one kind of shaping.

255
0:16:42.240 --> 0:16:45.680
The idea is that you can define multiple scenarios within this container.

256
0:16:45.680 --> 0:16:52.280
By passing through the scenario key you can actually pick which one is used during a test.

257
0:16:52.280 --> 0:16:56.440
In this use case we have one client, two shapers and three servers which means that

258
0:16:56.440 --> 0:17:01.640
we will have a total of six test cases that will get generated and compiled by the framework

259
0:17:01.640 --> 0:17:06.120
and run sequentially one after the other.

260
0:17:06.120 --> 0:17:07.280
I mentioned sensors earlier.

261
0:17:07.280 --> 0:17:11.640
There is also a configuration you can do with the experiment configuration files.

262
0:17:11.640 --> 0:17:15.200
The idea is normally that the framework just automates all these tests and that when a

263
0:17:15.200 --> 0:17:19.400
client accesses this should signal like the end of a test.

264
0:17:19.400 --> 0:17:23.000
However, in certain circumstances it is not possible.

265
0:17:23.000 --> 0:17:28.120
For example, if you use a browser, well, it's obvious that browsers do not have the ability

266
0:17:28.120 --> 0:17:33.320
to shut down from within a webpage which would pose some security risks which is why we built

267
0:17:33.320 --> 0:17:37.920
some sensor system which can actually govern what happens within a client.

268
0:17:37.920 --> 0:17:44.680
For example, we provide two simple sensor setups, time mode which simply checks if a

269
0:17:44.680 --> 0:17:49.480
certain amount of time has passed and then closes the client and signals that the test

270
0:17:49.480 --> 0:17:50.480
case has ended.

271
0:17:50.480 --> 0:17:56.960
Another one that we built is the browser file, Watchdog sensor which enables us to check

272
0:17:56.960 --> 0:17:59.680
if certain files were downloaded by browser context.

273
0:17:59.680 --> 0:18:05.040
This enables us to pull metrics from the browser and also signify the end of a test.

274
0:18:05.040 --> 0:18:10.160
If you provide these two configuration files to the framework, the framework will spin

275
0:18:10.160 --> 0:18:11.160
up a nice 2D.

276
0:18:11.160 --> 0:18:14.120
On the bottom you can see which tests are happening, how much time has passed.

277
0:18:14.120 --> 0:18:18.160
You can see a little bit of packets passing between them signaling that some kind of traffic

278
0:18:18.160 --> 0:18:19.160
is happening.

279
0:18:19.160 --> 0:18:23.360
You can actually increase the verbosity but this is not necessarily needed from within

280
0:18:23.360 --> 0:18:28.640
the terminal as the framework automatically saves everything that happens as output in

281
0:18:28.640 --> 0:18:33.680
a file within the test case folders that we will now discuss.

282
0:18:33.680 --> 0:18:38.040
The experiment output is always saved under the label that is provided within experiment

283
0:18:38.040 --> 0:18:42.160
configuration because we can have multiple runs of an experiment.

284
0:18:42.160 --> 0:18:46.720
The first entries that you will find within such a folder are actually time stamped to

285
0:18:46.720 --> 0:18:49.480
signify multiple runs.

286
0:18:49.480 --> 0:18:54.400
If you enter that you will actually find the different folders that contain the data of

287
0:18:54.400 --> 0:18:57.640
the multiple test cases that were compiled by the framework.

288
0:18:57.640 --> 0:19:01.640
If you take a dive into one of these folders you can see what output we are collecting

289
0:19:01.640 --> 0:19:03.320
in these cases.

290
0:19:03.320 --> 0:19:10.720
By default the framework will always create a server, client and shaper folder which get

291
0:19:10.720 --> 0:19:16.200
automatically mounted on the Docker volumes under the slash logs directory.

292
0:19:16.200 --> 0:19:19.600
Anything the implementations want to save they can just write files to this directory

293
0:19:19.600 --> 0:19:23.840
and the framework will capture this and save this in the log files.

294
0:19:23.840 --> 0:19:28.360
Additionally, clients also have a doneloads folder mounted simply because we want to differentiate

295
0:19:28.360 --> 0:19:35.040
and not come into a situation where doneloads accidentally overwrite output logs generated

296
0:19:35.040 --> 0:19:36.880
by a client.

297
0:19:36.880 --> 0:19:41.640
You can also see that we have, especially under the server and client entries, you can

298
0:19:41.640 --> 0:19:44.000
see keys.log and a qlog folder.

299
0:19:44.000 --> 0:19:50.000
The framework is automatically primed to save these encryption details and what's happening

300
0:19:50.000 --> 0:19:55.200
at the quick and HTTP tree layers by setting the SSL keylog file which we discovered in

301
0:19:55.200 --> 0:20:01.320
the beginning but also by setting a qlog environment variable which gets recognized by most quick

302
0:20:01.320 --> 0:20:05.680
implementations out there nowadays.

303
0:20:05.680 --> 0:20:07.560
Finally we come to extensibility.

304
0:20:07.560 --> 0:20:12.040
At this point in time we have a framework that is great at aggregating a lot of data.

305
0:20:12.040 --> 0:20:19.040
You can actually, we did some tests that ran for two or three days straight containing

306
0:20:19.040 --> 0:20:23.800
more than 8,000 test cases which were great if you want to gather a lot of data.

307
0:20:23.800 --> 0:20:28.640
What makes a testing framework a testing framework is the actual ability to infer something from

308
0:20:28.640 --> 0:20:34.520
the output generated by a test which is why we provide these two programmable interfaces

309
0:20:34.520 --> 0:20:36.640
called sensors and hooks.

310
0:20:36.640 --> 0:20:37.920
I explained sensors a little bit.

311
0:20:37.920 --> 0:20:43.520
We provide some basic sensors but you actually also have the ability to program custom sensors.

312
0:20:43.520 --> 0:20:48.800
This makes a lot of sense if you want to do very specific tests for very specific behavior

313
0:20:48.800 --> 0:20:50.960
within your experiment.

314
0:20:50.960 --> 0:20:56.400
For example, if you are doing a video stream in the browser you can actually send the decoding

315
0:20:56.400 --> 0:21:01.440
matrix of the video out of band to an HTTP endpoint for example that you set up in a

316
0:21:01.440 --> 0:21:02.440
custom sensor.

317
0:21:02.440 --> 0:21:07.600
If the sensor for example detects that some frames are being dropped or decoded in a wrong

318
0:21:07.600 --> 0:21:12.060
way, it could prematurely hold a test signaling that something went wrong.

319
0:21:12.060 --> 0:21:16.120
If you have lots of test cases like we do, we actually have test cases like I just said

320
0:21:16.120 --> 0:21:21.320
running 48 hours, this is really beneficial because it holds the test in an early phase

321
0:21:21.320 --> 0:21:22.320
saving us a lot of time.

322
0:21:22.320 --> 0:21:25.720
On the other hand, we have the hook system.

323
0:21:25.720 --> 0:21:28.680
The framework currently is very broadly applicable.

324
0:21:28.680 --> 0:21:32.960
The downside of that is that we don't really know what's happening inside the test but

325
0:21:32.960 --> 0:21:37.560
you can actually program some custom behavior through the pre-run hook and post-run hook

326
0:21:37.560 --> 0:21:38.840
system.

327
0:21:38.840 --> 0:21:44.440
As the name suggests, the pre-run hook runs before an actual test is run so you can prime

328
0:21:44.440 --> 0:21:51.440
environments by for example generating some dynamic files that you will need during the

329
0:21:51.440 --> 0:21:52.440
experiment.

330
0:21:52.440 --> 0:21:53.920
It doesn't really matter what you want to do there.

331
0:21:53.920 --> 0:21:58.000
The post-run hook is really nice because you can use it to analyze whatever happened during

332
0:21:58.000 --> 0:21:59.000
a test.

333
0:21:59.000 --> 0:22:04.080
For example, if Q-logs are being generated, look at the Q-logs and maybe even generate

334
0:22:04.080 --> 0:22:12.600
some nice graphs that you can immediately check after the test cases end.

335
0:22:12.600 --> 0:22:15.480
Another thing I need to mention with the pre-run hook and the post-run hook, if you don't

336
0:22:15.480 --> 0:22:17.760
like programming in Python, it's not really a problem.

337
0:22:17.760 --> 0:22:22.200
Python has this really great sub-module called sub-processes.

338
0:22:22.200 --> 0:22:26.520
If you have some existing scripts that are made to work with the output produced by your

339
0:22:26.520 --> 0:22:30.560
experiment, you can simply call them also from this hook, meaning that you get exactly

340
0:22:30.560 --> 0:22:37.360
the same results without having to actually translate your existing code within these

341
0:22:37.360 --> 0:22:40.200
provided hooks.

342
0:22:40.200 --> 0:22:42.000
That's in a nutshell what Wegwesir does.

343
0:22:42.000 --> 0:22:43.720
Thank you for your attention.

344
0:22:43.720 --> 0:22:52.040
I think we have a couple of minutes left for questions.

345
0:22:52.040 --> 0:23:05.000
A test case can be anything you want.

346
0:23:05.000 --> 0:23:08.400
If you're programming right now, you're developing something locally.

347
0:23:08.400 --> 0:23:11.680
The thing you need to do is actually wrap it within a Docker container.

348
0:23:11.680 --> 0:23:14.000
That's one way, or run it as a CLI command.

349
0:23:14.000 --> 0:23:17.320
You simply need to provide it to the framework and the framework will just spin it up.

350
0:23:17.320 --> 0:23:20.320
The framework doesn't actually check what your test case is doing.

351
0:23:20.320 --> 0:23:25.560
If you want to spin up a simple, let's say, a CLI command like actual and you want to

352
0:23:25.560 --> 0:23:31.560
print something to the terminal, you simply put it in the JSON, it will run.

353
0:23:31.560 --> 0:23:42.720
I have a question.

354
0:23:42.720 --> 0:23:52.360
I see you're from university.

355
0:23:52.360 --> 0:23:57.160
What does university have to do with testing?

356
0:23:57.160 --> 0:23:58.160
What's the relationship?

357
0:23:58.160 --> 0:23:59.160
Good question, actually.

358
0:23:59.160 --> 0:24:05.200
I'm not sure if there is a direct relationship with testing in university.

359
0:24:05.200 --> 0:24:11.360
It's just that during my PhD and also the PhD of some of my colleagues here in front

360
0:24:11.360 --> 0:24:18.080
of me, we actually encountered that we had a need of such a framework.

361
0:24:18.080 --> 0:24:24.000
We had an actual need of spinning up multiple test cases and helping us with setting up

362
0:24:24.000 --> 0:24:26.760
these experiments, which is why we designed this.

363
0:24:26.760 --> 0:24:33.280
Early on, we just had a very minimal thing that just worked for us.

364
0:24:33.280 --> 0:24:37.800
Then as time progressed, it actually became more and more mature and we decided, well,

365
0:24:37.800 --> 0:24:39.200
this is actually a very good idea.

366
0:24:39.200 --> 0:24:44.920
We created an open source project for it and we actually also submitted it to an open source

367
0:24:44.920 --> 0:24:52.000
and data set track for the MMSIS conference, which is happening in June in Vancouver.

368
0:24:52.000 --> 0:24:59.000
I think we have time for one more question.

369
0:24:59.000 --> 0:25:02.000
The last question.

370
0:25:02.000 --> 0:25:04.000
No takers.

371
0:25:04.000 --> 0:25:23.000
Thank you very much.

