1
0:00:00.000 --> 0:00:12.280
Hello, thank you very much for having us here.

2
0:00:12.280 --> 0:00:16.840
I'm Daniel Aguido, together with my colleague, Elizabeth Garrard.

3
0:00:16.840 --> 0:00:24.920
We are coming from the University of Luxembourg, from the Center of Contemporary Digital History,

4
0:00:24.920 --> 0:00:34.080
where we're running this new journal, this new idea of journal, together with a well-known publisher

5
0:00:34.080 --> 0:00:38.040
in the Open Access publication, which is the Groiter.

6
0:00:38.040 --> 0:00:46.400
The idea is the journal of digitalhistory.org, and then the idea is how to bring reproducible

7
0:00:46.400 --> 0:00:53.120
papers in the humanities and in digital history in our specific case.

8
0:00:53.120 --> 0:00:57.600
And then that's why we joined forces with them, so it's a joint venture with them directly,

9
0:00:57.600 --> 0:01:04.600
so the team is relatively small compared to other projects, and then we have two perspectives

10
0:01:04.600 --> 0:01:07.960
that we decided to put together.

11
0:01:07.960 --> 0:01:16.160
On our side, we understand that academic publishing is a bit too traditional, especially in history.

12
0:01:16.160 --> 0:01:23.800
And then our researchers, they currently work on Jupyter Notebook to run their own experiment

13
0:01:23.800 --> 0:01:31.520
and so on, so the idea was, can we pass from experiment on Jupyter Notebook to actual publication,

14
0:01:31.520 --> 0:01:33.160
also in our domain?

15
0:01:33.160 --> 0:01:37.320
And on the other side, they wanted to test out this hypothesis, because they really want

16
0:01:37.320 --> 0:01:44.040
to engage with new publication practices, and this joint venture would just be a good

17
0:01:44.040 --> 0:01:46.080
match.

18
0:01:46.080 --> 0:01:55.160
And well, reproducible papers in digital history means a lot of things, because first of all,

19
0:01:55.160 --> 0:02:03.480
we have now massive digitization process of primary sources and secondary literature and

20
0:02:03.480 --> 0:02:10.960
also new digital-born material, like the Twitter archive that we've been seeing before.

21
0:02:10.960 --> 0:02:15.520
On one side, the detail of the code, Cruz also sharing the dataset is one thing, but

22
0:02:15.520 --> 0:02:19.240
the other thing is really how this data has been created.

23
0:02:19.240 --> 0:02:22.400
So what were the conditions of the production of this data?

24
0:02:22.400 --> 0:02:30.520
So this is very important for us as historians, not for me, for my colleague, and then interpretation.

25
0:02:30.520 --> 0:02:37.800
So how the dataset has been built, which were the limits, all this questions need to be

26
0:02:37.800 --> 0:02:41.080
addressed in a different way.

27
0:02:41.080 --> 0:02:45.800
And then at the same time, we have, of course, new standards, not only digital history, but

28
0:02:45.800 --> 0:02:54.680
also the famous FAIR principle, so findable, accessible, interoperable, and reusable data.

29
0:02:54.680 --> 0:03:01.040
And we need to meet this criteria also with our journal.

30
0:03:01.040 --> 0:03:04.760
And this idea of Moolen is the one of a Braden narrative.

31
0:03:04.760 --> 0:03:09.720
So he advocates for bringing together two things.

32
0:03:09.720 --> 0:03:14.080
One is the narrative of the argumentation of our publication.

33
0:03:14.080 --> 0:03:19.560
The other one is the interpretation of data and say that they can be done in a narrative

34
0:03:19.560 --> 0:03:21.400
way.

35
0:03:21.400 --> 0:03:26.400
This is where we put these so-called multi-layers together.

36
0:03:26.400 --> 0:03:33.280
So this one is like every article published in our journal has a fingerprint sort of identity

37
0:03:33.280 --> 0:03:39.880
where this level, like the narrative, the hermeneutic level, and the data layer are

38
0:03:39.880 --> 0:03:40.880
together.

39
0:03:40.880 --> 0:03:47.720
So this is the representation of one Jupyter notebook, which is normally linear cell by

40
0:03:47.720 --> 0:03:48.720
cell.

41
0:03:48.720 --> 0:03:54.120
We just distorted, we put it in a circle, and here you can test it out.

42
0:03:54.120 --> 0:04:00.400
So this was also a tool, it is also a tool for our authors, which we own them a lot because

43
0:04:00.400 --> 0:04:05.040
they are our primary tester.

44
0:04:05.040 --> 0:04:08.560
It is still an experimental journal.

45
0:04:08.560 --> 0:04:14.440
And there you could tweak with data, you can change the content, and you see how the fingerprint

46
0:04:14.440 --> 0:04:15.440
is changing.

47
0:04:15.440 --> 0:04:25.720
This was just an experiment at the beginning, but then it really becomes integrated into

48
0:04:25.720 --> 0:04:29.640
the main interface of the journal.

49
0:04:29.640 --> 0:04:33.080
And we saw that indeed they were very different.

50
0:04:33.080 --> 0:04:35.680
Okay, yes, I run.

51
0:04:35.680 --> 0:04:42.440
They were very different, and we can see also the code style of every Jupyter notebook,

52
0:04:42.440 --> 0:04:45.920
how they also decided to narrate the arguments.

53
0:04:45.920 --> 0:04:48.800
So I will go quickly, sorry.

54
0:04:48.800 --> 0:04:53.960
And then this is like the basic layer, so the narrative layer that looks like an MV

55
0:04:53.960 --> 0:04:59.240
viewer with steroids in the sense that we have figures, we have tables, we have bibliography.

56
0:04:59.240 --> 0:05:02.960
With Zotero and Site2C.

57
0:05:02.960 --> 0:05:09.320
And then above all, it's a very thin layer on top of the Jupyter notebook because we

58
0:05:09.320 --> 0:05:12.560
use the usual output of the notebook.

59
0:05:12.560 --> 0:05:17.360
So this is very like an augmented MV viewer.

60
0:05:17.360 --> 0:05:24.080
And then we have, as it is a braided narrative, we decided to have this metaphor of this level

61
0:05:24.080 --> 0:05:25.740
one on top of the other.

62
0:05:25.740 --> 0:05:30.520
So this is a sort of animation, so on the left you see the full hermeneutic layer,

63
0:05:30.520 --> 0:05:37.780
and on the other side you can see how it slides through the, like behind the narrative layer.

64
0:05:37.780 --> 0:05:46.000
And the data layer is for the moment the part on top, right top, which we use MyBinder,

65
0:05:46.000 --> 0:05:50.680
fantastic service to publish online your notebooks.

66
0:05:50.680 --> 0:05:57.440
And we wanted this article not only to be a show off of the dataset, but also a small

67
0:05:57.440 --> 0:06:05.080
history lab so that people could just click on a button and get to the data and understand

68
0:06:05.080 --> 0:06:07.200
how the data will be composed.

69
0:06:07.200 --> 0:06:12.320
The good thing is that we decided to keep this, MyBinder, as this source of truth.

70
0:06:12.320 --> 0:06:20.040
So the article that you see published is exactly the same copy, with just a different way of

71
0:06:20.040 --> 0:06:22.440
interacting with this different layer.

72
0:06:22.440 --> 0:06:27.780
So this is how it looks like on MyBinder, so it's a classical Jupyter notebook.

73
0:06:27.780 --> 0:06:35.520
And for every notebook we have a GitHub repo, where we store all the requirements and all

74
0:06:35.520 --> 0:06:38.480
the images in the dataset.

75
0:06:38.480 --> 0:06:47.240
We have to put together the fair metadata, but still, so it's under construction.

76
0:06:47.240 --> 0:06:51.240
Then what does it mean having Jupyter notebooks for publishing?

77
0:06:51.240 --> 0:06:58.020
We see that in the literature there are a lot of critics, shouldn't use Jupyter notebooks

78
0:06:58.020 --> 0:07:04.800
because it's too complex, it's impossible to replicate and so on and so forth.

79
0:07:04.800 --> 0:07:09.680
But then for us, it was really the simplest solution.

80
0:07:09.680 --> 0:07:15.280
So at the same time, to publish with Jupyter, we had to make our pipeline a bit more complex

81
0:07:15.280 --> 0:07:21.800
as usual, so we have a first review directly on the abstract, where we start communicating

82
0:07:21.800 --> 0:07:27.960
with the authors, understanding their needs, creating a writing environment for them that

83
0:07:27.960 --> 0:07:34.480
can be replicated with Docker containers for Python and Air.

84
0:07:34.480 --> 0:07:38.360
And then the first technical review, she's in charge of the first technical review, which

85
0:07:38.360 --> 0:07:42.960
is the most complicated one, because there's a lot of checks.

86
0:07:42.960 --> 0:07:47.400
We saw some projects already, we needed to have checks.

87
0:07:47.400 --> 0:07:52.440
And then we have a lot of other open source software that enters this pipeline, like for

88
0:07:52.440 --> 0:07:58.520
the preview of the notebook, we took it up, and the viewer, we have my binder, and this

89
0:07:58.520 --> 0:08:03.440
is just for the first technical review, because then the article is being sent to the reviewer

90
0:08:03.440 --> 0:08:05.280
for the double banana review.

91
0:08:05.280 --> 0:08:11.000
So before even reviewing, we had to do this huge job because they have to review also

92
0:08:11.000 --> 0:08:14.280
the data and the pertinence of the dataset.

93
0:08:14.280 --> 0:08:21.440
And then finally, there is one important thing, so it's English editing, so how to edit something

94
0:08:21.440 --> 0:08:25.640
that which is already being run, so without running itself.

95
0:08:25.640 --> 0:08:30.920
So this could be a tool for translators, tool for correctors, that they're not into the

96
0:08:30.920 --> 0:08:33.040
Jupyter world, so how to do that?

97
0:08:33.040 --> 0:08:38.900
We have Jupyter text, we're still testing some plugin to see if this could work without

98
0:08:38.900 --> 0:08:41.640
touching the final output.

99
0:08:41.640 --> 0:08:46.280
And then the final technical review, so after all this has been shipped, we have a DOI,

100
0:08:46.280 --> 0:08:51.640
so the article is now published, needs to be indexing, and there is the problem of long-term

101
0:08:51.640 --> 0:08:56.320
archiving, which is a big problem for many reasons.

102
0:08:56.320 --> 0:09:05.600
First of all, libraries that get deprecated, also API that disappeared, so how to really

103
0:09:05.600 --> 0:09:08.140
reproduce this in the future.

104
0:09:08.140 --> 0:09:13.040
And then finally, the dataset needs to be included into, we have dataverse, but we are

105
0:09:13.040 --> 0:09:17.560
looking for Zenodo in order to match the fair metadata.

106
0:09:17.560 --> 0:09:22.480
And time is up, I have a question for you, of course.

107
0:09:22.480 --> 0:09:24.000
Thank you very much, first of all.

108
0:09:24.000 --> 0:09:31.680
And then if you want to contact us, just collaborate or work together on Jupyter publication, jdhadmin

109
0:09:31.680 --> 0:09:33.340
at uni.lu.

110
0:09:33.340 --> 0:09:37.800
And then the question are, how can we actually collaborate on something which is a notebook

111
0:09:37.800 --> 0:09:45.400
that requires quite a threshold of expertise, not only for the researcher, but for the people

112
0:09:45.400 --> 0:09:51.920
that are around, and how to maintain all this and how to make this history lab living for

113
0:09:51.920 --> 0:09:53.960
more than one year.

114
0:09:53.960 --> 0:09:54.960
Thank you.

115
0:09:54.960 --> 0:10:10.840
Thank you very much.

116
0:10:10.840 --> 0:10:29.880
Yeah, well, I repeat the question, so he asked me if the double blind review, how can we

117
0:10:29.880 --> 0:10:33.880
keep it actually an actual double blind.

118
0:10:33.880 --> 0:10:37.940
So she anonymized the data on GitHub.

119
0:10:37.940 --> 0:10:43.600
So we have specific repository that have been created after the communication with the authors,

120
0:10:43.600 --> 0:10:50.320
where we only have the code without the names, but then you still have the bibliography,

121
0:10:50.320 --> 0:10:54.160
so it's easy to, it's a very small word, one of the digital history.

122
0:10:54.160 --> 0:10:58.280
But still, this is the way to maintain double blind.

123
0:10:58.280 --> 0:11:05.960
And then we're going to send the review where both the MyBinder and the version of the article

124
0:11:05.960 --> 0:11:10.360
on our website with a hidden URL.

125
0:11:10.360 --> 0:11:12.520
So this is the only thing that we can do.

126
0:11:12.520 --> 0:11:20.000
For sure, the double blind, we have the problems that we cannot really use the peer request

127
0:11:20.000 --> 0:11:22.600
directly on the GitHub repository.

128
0:11:22.600 --> 0:11:26.800
In fact, there is some replication between the GitHub repository.

129
0:11:26.800 --> 0:11:37.080
After with the peer review, there is some recursivity that come back to technical review

130
0:11:37.080 --> 0:11:39.160
because there is a revision.

131
0:11:39.160 --> 0:11:43.800
There is this question about how we synchronize the notebook together.

132
0:11:43.800 --> 0:11:52.480
There is some authors that they have good enough with GitHub.

133
0:11:52.480 --> 0:11:59.360
But to review a notebook with the output with the metadata to track what has been changed.

134
0:11:59.360 --> 0:12:10.920
This, it was the question that you have, we are testing with ReviewNB, or also to maybe

135
0:12:10.920 --> 0:12:19.720
use some markdown or just Python script to produce several output in order to not sometimes

136
0:12:19.720 --> 0:12:26.720
touch about these metadata that they are inside the notebook.

137
0:12:26.720 --> 0:12:29.760
And there was another question, but I don't know if we have time.

138
0:12:29.760 --> 0:12:30.760
Yes?

139
0:12:30.760 --> 0:12:31.760
Yes.

140
0:12:31.760 --> 0:12:32.760
Yes.

141
0:12:32.760 --> 0:12:33.760
Please.

142
0:12:33.760 --> 0:12:36.760
I'm sorry, auto assess?

143
0:12:36.760 --> 0:12:45.200
Yeah, that's the very big, big, big question.

144
0:12:45.200 --> 0:12:52.440
So the idea behind the narrative is then you tell the story around the data on one side,

145
0:12:52.440 --> 0:12:59.880
and on the other side, you keep the data like with the Zenodo metadata coherent, or probably

146
0:12:59.880 --> 0:13:09.520
with what Paul showed us before with Ricardo, so having like an external check on the metadata

147
0:13:09.520 --> 0:13:11.320
and on the dataset itself.

148
0:13:11.320 --> 0:13:17.320
At the same time, the initial, the first technical review is the one where we assess actually

149
0:13:17.320 --> 0:13:18.320
the data.

150
0:13:18.320 --> 0:13:24.120
So if the data sets are complete, coherent, we don't judge them because then we know that

151
0:13:24.120 --> 0:13:29.600
there are conditions of production that needs to be, we try to make this as more explicit

152
0:13:29.600 --> 0:13:30.600
as possible.

153
0:13:30.600 --> 0:13:31.600
Yes, exactly.

154
0:13:31.600 --> 0:13:40.120
And this, like that's why the long term maintenance, so now we only have nine articles, but we

155
0:13:40.120 --> 0:13:45.320
have 28 in the pipeline in the coming year.

156
0:13:45.320 --> 0:13:50.080
So it's really now it's getting up speed, and we have more and more interaction with

157
0:13:50.080 --> 0:13:52.760
all those, which makes things more complicated.

158
0:13:52.760 --> 0:13:53.760
Thank you.

159
0:13:53.760 --> 0:13:54.760
Okay.

160
0:13:54.760 --> 0:14:11.480
Okay.

