WEBVTT

00:00.000 --> 00:01.000
Hi everyone.

00:01.000 --> 00:14.440
Well, I'm very impressed to have such a large audience for such a small tool.

00:14.440 --> 00:16.200
But, well, I'm Beatrice.

00:16.200 --> 00:19.680
I work at the French Media Lab.

00:19.680 --> 00:27.120
And today I'm going to present PIMI, which is a tool to study image propagation.

00:27.120 --> 00:34.800
The Media Lab is a lab where social scientists try to, among other things, study the traces

00:34.800 --> 00:39.600
that people leave online.

00:39.600 --> 00:45.240
And from now they are quite well equipped with tools to study text.

00:45.240 --> 00:54.360
But when they ask me, okay, how can I study image propagation?

00:54.360 --> 00:59.960
And I'm still struggling to give them answers.

00:59.960 --> 01:02.540
So what does it mean to study mean propagation?

01:02.540 --> 01:08.720
It means, okay, being able to recognize that some parts of an image are copied or partially

01:08.720 --> 01:12.600
copied.

01:12.600 --> 01:17.200
So what this tool does, it's very simple.

01:17.200 --> 01:26.240
It's able to create clusters of images and group together images that are total or partial

01:26.240 --> 01:28.640
copies of each other.

01:28.640 --> 01:34.360
It's able to deal with image transformation, so if the image is cropped or zoomed.

01:34.360 --> 01:39.000
And it's able to adapt to copper's characteristics.

01:39.000 --> 01:45.600
So it will try to make the best of your data sets, depending on the number of images you

01:45.600 --> 01:49.920
have or the type of images you have.

01:49.920 --> 01:57.240
What PIMI is not able to do is to cluster semantically similar images.

01:57.240 --> 02:03.120
So it's not the tool that you are going to use if you want to create clusters of cats

02:03.120 --> 02:13.560
and clusters of dogs or, I don't know, find images of violence versus images of peace.

02:13.560 --> 02:16.120
And it's not able to do some face recognition.

02:16.120 --> 02:26.440
So again, you will not be able to make some clusters of pictures of Elizabeth II versus

02:26.440 --> 02:36.280
clusters of images of Emmanuel Macron.

02:36.280 --> 02:43.280
What you could imagine doing, and we could imagine also work together if you are a researcher

02:43.280 --> 02:50.560
working on those subjects, is to study the propagation of MIMA on social networks, as

02:50.560 --> 02:52.480
I was saying.

02:52.480 --> 02:59.200
But also you could study the usage of press agency photos in a press corpus or stock photos

02:59.200 --> 03:01.880
as well.

03:01.880 --> 03:08.160
You could also study the dissemination of fake news based on image montage.

03:08.160 --> 03:15.160
Or you could study the editorial choices between different media, depending on whether they

03:15.160 --> 03:18.920
use the same images or not.

03:18.920 --> 03:26.920
So let me do a quick demo of how it looks for now.

03:26.920 --> 03:30.640
It's not on the screen.

03:30.640 --> 03:46.520
OK, let's forget about that.

03:46.520 --> 04:15.840
OK, I'm very sorry.

04:15.840 --> 04:26.000
I'll try to make it work.

04:26.000 --> 04:33.640
OK, well, still not showing totally all clusters.

04:33.640 --> 04:36.920
So we create clusters of images.

04:36.920 --> 04:41.240
So this is a data set that is created by the French INRIA.

04:41.240 --> 04:47.480
And that is presenting some degradation on images.

04:47.480 --> 04:54.400
So they take an original picture and they apply some filters or they crop the images

04:54.400 --> 04:57.080
to see if they are able to put the images together.

04:57.080 --> 05:03.240
So we can see that we have pretty correct results on that data set.

05:03.240 --> 05:10.880
And this is our results on some images that we collected ourselves on Twitter using Ellen

05:10.880 --> 05:14.240
Musk as a query.

05:14.240 --> 05:17.760
And so we try to cluster those images.

05:17.760 --> 05:22.560
So as you can see, we have images of Ellen Musk.

05:22.560 --> 05:30.200
We are able to group together some images that are crops of others.

05:30.200 --> 05:37.520
So this is probably the source image of the montage that has been done here.

05:37.520 --> 05:42.760
But we can also see that we have some problems with the tool.

05:42.760 --> 05:51.200
For example, here we have a cluster with two images that have been assembled together and

05:51.200 --> 05:55.480
we create a cluster of actually two images.

05:55.480 --> 06:02.680
But well, that's the state of the tool for now.

06:02.680 --> 06:15.880
And now I'll try to come back to my slides.

06:15.880 --> 06:25.960
OK.

06:25.960 --> 06:29.400
So how does it work?

06:29.400 --> 06:35.600
For people who work in computer vision, I'm going for a bit to say some things that are

06:35.600 --> 06:42.880
quite basic, but I try to make it clear for people who do not do computer vision.

06:42.880 --> 06:45.640
So it is not based on colors at all.

06:45.640 --> 06:49.240
It's used like the grayscale of images.

06:49.240 --> 06:54.320
And it tries to detect points of interest on a picture.

06:54.320 --> 07:02.760
And then it uses these local key points as vectors.

07:02.760 --> 07:14.280
And then those vectors are indexed in a database that is able to perform some very quick similarity

07:14.280 --> 07:24.240
approach.

07:44.280 --> 07:46.340
you

08:14.280 --> 08:16.340
you

08:44.280 --> 08:46.340
you

09:14.280 --> 09:16.340
you

09:44.280 --> 09:46.340
you

10:14.280 --> 10:16.340
you

10:44.280 --> 10:46.340
you

11:14.280 --> 11:16.340
you

11:44.280 --> 11:46.340
you

12:14.280 --> 12:16.340
you

12:44.280 --> 12:46.340
you

13:14.280 --> 13:16.340
you

13:27.440 --> 13:36.280
of the tool as I say there is that problem of parts of images that create

13:36.280 --> 13:41.960
clusters that are bigger than they should be so our plan is to be able to

13:41.960 --> 13:47.720
detect images that are actually those links between two clusters so to be able

13:47.720 --> 13:53.960
that's to detect that this image is actually containing two images and to be

13:53.960 --> 14:01.880
able to to deal with part of images and also what we would like to do is to show

14:01.880 --> 14:08.480
images in their context to be able to show the tweets that that contains those

14:08.480 --> 14:15.400
images or Instagram posts etc or at least to show additional metadata for

14:15.400 --> 14:24.000
the users and also we would like to show you the graph of image similarities so

14:24.000 --> 14:29.560
that the clusters that are resulting from that graph are not like not

14:29.560 --> 14:40.360
interpretable and to improve our tool we need your use cases because for now like

14:40.360 --> 14:52.800
we have those two three databases but but we would be very glad to like do some

14:52.800 --> 14:58.320
partnerships with other researchers to improve the tool thank you very much for

14:58.320 --> 15:00.320
your attention

15:00.880 --> 15:06.520
he she wanted to look at the slides we have the references to all the images

15:06.520 --> 15:16.600
used and to the papers of the algorithms used by teeny I'm open for questions

15:16.600 --> 15:28.040
we had a bit of trouble with the sound stream but it's back online so yeah you

15:28.040 --> 15:33.000
should repeat the question okay I'll do

15:33.000 --> 15:45.960
yes

16:03.320 --> 16:12.720
well trying to find similarities in oh sorry I have to repeat the question so

16:12.720 --> 16:21.640
the question was if I understand well well how to reproduce that that use case

16:21.640 --> 16:27.840
not on images but on other types of documents that would be I guess some

16:27.840 --> 16:40.640
features 3d counterparts and I'd say well as long as you can you like represent

16:40.640 --> 16:47.920
your data in the shape of vectors then you ready to use face to do like do some

16:47.920 --> 16:54.560
some search from for nearest neighbor in your database and then you can go for

16:54.560 --> 17:00.760
the whole pipeline create some graphs find communities in graph and go for it

17:00.760 --> 17:08.960
but I'm not sure PME is your tool but but well the the architecture of PME

17:08.960 --> 17:13.840
could be of course a model

17:14.840 --> 17:20.760
is there any project current or you're going that media labs has used them for

17:20.760 --> 17:29.040
or is it still largely in development it is largely in the development sorry I

17:29.040 --> 17:36.520
repeat the question so are there some projects at the media lab that are

17:36.520 --> 17:45.440
currently using PME and the response is no yes

17:45.440 --> 17:50.280
sorry can you

17:50.280 --> 18:07.520
well yes have you considered other ways of presenting picture similarity or

18:07.520 --> 18:13.440
using picture similarity all the types of image similarity if you understand

18:13.440 --> 18:26.840
well well I'd say that that that was what I was saying in my second slide

18:26.840 --> 18:31.600
there are other types of image similarity for example semantic or

18:31.600 --> 18:40.320
similarity and well maybe in a few months if we have like a robust

18:40.320 --> 18:51.240
architecture we could maybe include some other types of vectorization of images

18:51.240 --> 19:00.760
but for now well they are already tools that do that like there is something

19:00.760 --> 19:10.280
called clip server that that helps you like find similar images from clip

19:10.280 --> 19:16.280
vectors that are like semantical vectors so you you you could use that tool it's

19:16.280 --> 19:33.040
great yes yes

19:46.280 --> 19:53.640
so the question is is the tool really able to distinguish the thing that is of

19:53.640 --> 20:01.320
interest to us the fact that we are talking about a dog so the tool is only

20:01.320 --> 20:08.160
able to find partial copies in an image so the tool would probably be able to

20:08.160 --> 20:17.600
say that all those images contain the same parts of face of a dog so it would

20:17.600 --> 20:22.520
probably be able to group all those images together the problem is that if

20:22.520 --> 20:29.080
there are other images in the database that contain the rest of the images then

20:29.080 --> 20:36.080
they would probably also be grouped in the same cluster so that's why what we

20:36.080 --> 20:43.120
are currently doing about parts of images who let us improve the cluster

20:43.120 --> 20:53.080
so that it's purified from the rest of the images and we could have a cluster

20:53.080 --> 21:02.120
of the face of that specific dog and then a cluster of that taco in the second

21:02.120 --> 21:19.080
cluster yes well for now we have the best result with excuse me what kind of

21:19.080 --> 21:24.480
cluster ization do you use on the graph for now we have our best results using

21:24.480 --> 21:32.880
pure connected components so actually the specification we do on the graph to

21:32.880 --> 21:38.520
reduce the number of links between images is enough to have separated

21:38.520 --> 21:43.200
connected components in the graph and so we take each connected component and

21:43.200 --> 21:53.200
it's our cluster what we would like to do is to try to like mix with some

21:53.200 --> 21:59.600
wrong from detection but actually for now it's not the thing that works best

22:00.960 --> 22:03.960
yes

22:03.960 --> 22:30.600
I'm not sure I understand the question can you try to rephrase it okay what

22:30.600 --> 22:45.200
what things are you looking at to improve the model well there are many

22:45.200 --> 22:54.760
things where we we are looking at for now mainly we we look at techniques to

22:54.760 --> 23:07.800
to do a better graph specification in order to find more coherent clusters we

23:07.800 --> 23:14.560
are not so much working on the on the like local descriptors parts of the

23:14.560 --> 23:41.800
tool for now yes have you considered and used the direct

23:41.800 --> 23:50.240
clique to to the Twitter images or social media images online did I repeat

23:50.240 --> 23:59.520
everything well yes we would like people to be able to to see images in their

23:59.520 --> 24:04.320
context because actually they they won't understand what's happening if they just

24:04.320 --> 24:11.400
have images they need to see okay why was this image published who answered

24:11.400 --> 24:20.880
etc so this would probably mean that we need to to add at least the links to to

24:20.880 --> 24:43.880
the pulse and or maybe some some kind of visualization of it

24:50.880 --> 24:52.920
you
