1
0:00:00.000 --> 0:00:08.120
Thank you for coming to my talk.

2
0:00:08.120 --> 0:00:12.360
It's not a TED talk, but it's just my talk.

3
0:00:12.360 --> 0:00:14.560
Continuous delivery to many coronavirus clusters.

4
0:00:14.560 --> 0:00:20.520
My name is Carlos Sanchez, and I'm here to talk to you about our life experience, real

5
0:00:20.520 --> 0:00:22.020
world.

6
0:00:22.020 --> 0:00:24.800
I'm not here to solve you anything.

7
0:00:24.800 --> 0:00:31.280
I'll try to tell you if I have time for some of the mistakes we made, she's not all beautiful

8
0:00:31.280 --> 0:00:33.520
and wonderful.

9
0:00:33.520 --> 0:00:40.120
I'm a principal scientist at Adobe Experience Manager Cloud Service.

10
0:00:40.120 --> 0:00:43.320
I'll talk a little bit about the product.

11
0:00:43.320 --> 0:00:48.400
On the open source side, I started the Jenkins Kubernetes plugin.

12
0:00:48.400 --> 0:00:49.800
Anybody heard about Jenkins?

13
0:00:49.800 --> 0:00:52.760
Yes, some people probably.

14
0:00:52.760 --> 0:00:55.880
I'm a Kubernetes.

15
0:00:55.880 --> 0:00:59.080
Anybody heard about Kubernetes?

16
0:00:59.080 --> 0:01:04.160
Anybody using Kubernetes in production?

17
0:01:04.160 --> 0:01:10.280
I'm a long time contributor to open source, multiple projects on Jenkins, Apache Foundation,

18
0:01:10.280 --> 0:01:11.280
and all that.

19
0:01:11.280 --> 0:01:18.480
A quick intro to what Adobe Experience Manager is, because every time I say Adobe, people

20
0:01:18.480 --> 0:01:28.280
say Photoshop and PDF and Flash.

21
0:01:28.280 --> 0:01:31.160
That's not any of those.

22
0:01:31.160 --> 0:01:37.280
This is a content management system that you probably never heard of, but it's powering

23
0:01:37.280 --> 0:01:43.480
80% of the 4100, and it's very enterprise-y, so I'm not expecting people in front of them

24
0:01:43.480 --> 0:01:46.840
to know.

25
0:01:46.840 --> 0:01:51.560
This is widely used because it's based in a lot of open source.

26
0:01:51.560 --> 0:01:56.920
It's a distributed OSDI application that was started many years ago, and uses a lot of

27
0:01:56.920 --> 0:02:01.440
components of open source from the Apache Foundation, and we contribute back to those

28
0:02:01.440 --> 0:02:09.160
components like Felix, Apache Felix, Sling, and a few things about content management

29
0:02:09.160 --> 0:02:10.160
there.

30
0:02:10.160 --> 0:02:16.000
It has a huge market of extension developers, people that are writing their own Java code

31
0:02:16.000 --> 0:02:23.200
and then runs on Adobe Experience Manager in AM.

32
0:02:23.200 --> 0:02:28.520
When I'm doing Adobe, the goal was let's move this into a cloud service, and this is running

33
0:02:28.520 --> 0:02:31.720
AM on Kubernetes.

34
0:02:31.720 --> 0:02:38.920
We're running currently on Azure, and we have 35 clusters and growing very quickly.

35
0:02:38.920 --> 0:02:42.840
Because this is a content management, we run it in multiple regions.

36
0:02:42.840 --> 0:02:48.640
Right now, 11, so multiple ones in the US, Europe, Australia, Singapore, Japan, whatever,

37
0:02:48.640 --> 0:02:55.640
because people want to have low latency between their users and the content.

38
0:02:55.640 --> 0:03:03.080
Then, another interesting fight is that we have on the Kubernetes clusters, we don't

39
0:03:03.080 --> 0:03:07.400
run them directly, we build stuff on top of them, and we have a different team at Adobe

40
0:03:07.400 --> 0:03:12.240
that manages Kubernetes for us.

41
0:03:12.240 --> 0:03:17.400
Some curiosity is that customers can run their own code, so we are running this for them,

42
0:03:17.400 --> 0:03:22.800
and we take their code and run it inside our processes.

43
0:03:22.800 --> 0:03:28.880
We have to limit clusters' permissions for security, and we have several security concerns,

44
0:03:28.880 --> 0:03:34.960
because this is a very multi-tenant setup.

45
0:03:34.960 --> 0:03:42.760
Each customer can have multiple environments, multiple copies, and they can self-service,

46
0:03:42.760 --> 0:03:47.800
so they can deploy new environments whenever they want, they can update them and do a few

47
0:03:47.800 --> 0:03:52.480
things, so it's not just us controlling what is running, it's also the customers.

48
0:03:52.480 --> 0:03:58.640
Each customer can have three or more Kubernetes namespaces where these environments run, and

49
0:03:58.640 --> 0:04:05.800
I like to call this a micromanolith, so we don't run a big service that expands like

50
0:04:05.800 --> 0:04:13.480
thousands of instances, we run slightly different versions of the same service over a thousand,

51
0:04:13.480 --> 0:04:16.880
ten thousand times.

52
0:04:16.880 --> 0:04:23.560
Micromanolith defines it very well, and then we use namespace, Kubernetes namespaces, to

53
0:04:23.560 --> 0:04:28.840
provide the scope of network isolation, quotas, permissions, and so on.

54
0:04:28.840 --> 0:04:36.920
Now internally, we have multiple teams building services, so different services have different

55
0:04:36.920 --> 0:04:43.000
requirements, people can use different languages, and we are more in a philosophy of you build

56
0:04:43.000 --> 0:04:51.760
it, you run it, and we are basically doing each service as an API, or we follow the Kubernetes

57
0:04:51.760 --> 0:04:54.440
operator patterns.

58
0:04:54.440 --> 0:05:01.280
We also use, to split the monolith, we use a lot of init containers and sidecars, if

59
0:05:01.280 --> 0:05:07.280
you know in Kubernetes, you can run multiple containers at the same time, so the main application

60
0:05:07.280 --> 0:05:12.880
runs in one container, and then we have to apply division of concern, many sidecars that

61
0:05:12.880 --> 0:05:20.680
do different things, and it's an easy way to split separate concerns without having

62
0:05:20.680 --> 0:05:28.480
to rewrite your whole architecture to go to a fully network-based maker service oriented

63
0:05:28.480 --> 0:05:32.240
architecture.

64
0:05:32.240 --> 0:05:37.520
On the continuous delivery side, which is probably what you are interested in here,

65
0:05:37.520 --> 0:05:45.000
we are running, we are moving from a generally released to, I mean we are pushing changes

66
0:05:45.000 --> 0:05:52.840
daily multiple times, not only, not just the application, that the application is maybe

67
0:05:52.840 --> 0:05:59.840
slower to move, but on the operational side, and all the services, and operators, all these

68
0:05:59.840 --> 0:06:06.560
things, all of them together, any of them at any point in time, any day can receive

69
0:06:06.560 --> 0:06:09.640
changes.

70
0:06:09.640 --> 0:06:17.640
So we use Jenkins for CI CD in some places, we have Tekton, you heard about that in one

71
0:06:17.640 --> 0:06:24.440
of the talks before, it's another open source project to do workflows on Kubernetes to

72
0:06:24.440 --> 0:06:32.840
orchestrate some pipelines, and we also started using Argo CD for some new micro services.

73
0:06:32.840 --> 0:06:39.600
We follow a GitOps process, so where most of the configuration is a storing Git, and

74
0:06:39.600 --> 0:06:41.640
it's reconciling each commit, right?

75
0:06:41.640 --> 0:06:50.740
And we use a pull versus push model to scale, and I'll go through this in a bit.

76
0:06:50.740 --> 0:06:57.680
We have a combination of multiple things being deployed to the clusters, we have the AM

77
0:06:57.680 --> 0:07:04.120
version that is deployed with a Helm chart, we have operation services that are operators

78
0:07:04.120 --> 0:07:10.040
and services and all the other things that are not the application, these are deployed

79
0:07:10.040 --> 0:07:17.080
using Kubernetes files but templatized, and we are also using customized Argo CD for some

80
0:07:17.080 --> 0:07:20.800
new micro services.

81
0:07:20.800 --> 0:07:28.680
On the Helm side, we use the Helm operator, so in each namespace we use the Helm operator

82
0:07:28.680 --> 0:07:37.480
CRDs to do a more state-based installation of Helm.

83
0:07:37.480 --> 0:07:42.220
So we create the CRD and the Helm operator is going to install the application based

84
0:07:42.220 --> 0:07:45.040
on the parameters on the CRD.

85
0:07:45.040 --> 0:07:53.600
A word of advice is don't mix application and infrastructural configuration on the same

86
0:07:53.600 --> 0:08:00.800
package because if you cannot enforce the same Helm chart for all tenants, for example,

87
0:08:00.800 --> 0:08:06.080
as I said mentioned before, customers can decide when to update things, right?

88
0:08:06.080 --> 0:08:11.440
So we have some customers in older releases and some ones in newer releases, this is something

89
0:08:11.440 --> 0:08:17.760
that we want to change, but in the meantime, if we want to update a specific version of

90
0:08:17.760 --> 0:08:24.440
something in an old release, it's hard when this is already packaged on Helm.

91
0:08:24.440 --> 0:08:29.600
So we built a solution for this.

92
0:08:29.600 --> 0:08:35.020
So from the platform level, we can go and manipulate this Helm chart.

93
0:08:35.020 --> 0:08:42.200
So we can have overrides and this is easy to do when you have the Helm operator.

94
0:08:42.200 --> 0:08:50.160
So you can inject, whenever there's a request to install a new Helm chart, we change parameters.

95
0:08:50.160 --> 0:08:56.160
So we change both Helm values, this is easy, instead of passing some values, we pass different

96
0:08:56.160 --> 0:08:57.600
ones.

97
0:08:57.600 --> 0:09:02.880
Or you can use customized patches and this is also support from the Helm operator, this

98
0:09:02.880 --> 0:09:05.200
is also support for customized patches.

99
0:09:05.200 --> 0:09:09.760
And customized patches are very interesting because they allow you to patch any Kubernetes

100
0:09:09.760 --> 0:09:16.440
resource so even if there was no previous Helm value defined for it.

101
0:09:16.440 --> 0:09:23.360
So if we want to change a sidecar container image version across the Helm fleet, we just

102
0:09:23.360 --> 0:09:25.440
have to change the patch.

103
0:09:25.440 --> 0:09:32.800
And this patch is going to be applied to all the clusters, all the namespaces, and all

104
0:09:32.800 --> 0:09:37.280
the Helm charts that were installed are going to get reinstalled with the right version

105
0:09:37.280 --> 0:09:38.640
that we want.

106
0:09:38.640 --> 0:09:48.520
So we do this combination of both Helm chart and then operational values on the other hand.

107
0:09:48.520 --> 0:09:52.880
Very important for us was the shift left mentality, right?

108
0:09:52.880 --> 0:09:58.960
Detecting problems as soon as possible, not waiting for developers to push things to production

109
0:09:58.960 --> 0:10:02.380
because the cost increases.

110
0:10:02.380 --> 0:10:09.280
So we run checks as soon as we can on pull requests so it is still fresh in your memory

111
0:10:09.280 --> 0:10:14.880
when you make a change and something is broken, you want to catch it as soon as possible.

112
0:10:14.880 --> 0:10:22.400
And we do this by generating all these templates, we have some tests that generate these templates

113
0:10:22.400 --> 0:10:29.780
and then apply tests, multiple tests on them.

114
0:10:29.780 --> 0:10:36.360
The most basic check that you can run is the apply kubectl apply drive run.

115
0:10:36.360 --> 0:10:43.320
This will tell you if the manifest is wrong in some very obvious way.

116
0:10:43.320 --> 0:10:47.760
So if it's valid or it's not valid.

117
0:10:47.760 --> 0:10:52.540
KubeConform is a tool that will allow you to validate the Kubernetes schemas.

118
0:10:52.540 --> 0:10:55.840
So this is the successor of kubefall.

119
0:10:55.840 --> 0:10:58.440
Anybody heard about kubefall or kubefirm?

120
0:10:58.440 --> 0:10:59.440
Yeah?

121
0:10:59.440 --> 0:11:08.520
So this is very useful for if you have custom CRDs or yeah, just to make sure typical problems,

122
0:11:08.520 --> 0:11:14.600
you miss the JAML indentation and now it's not valid anymore and then you catch this

123
0:11:14.600 --> 0:11:19.800
on a PR to just run this and it will tell you this property is missing or this property

124
0:11:19.800 --> 0:11:26.080
is in the wrong place because everybody loves JAML, right?

125
0:11:26.080 --> 0:11:30.840
Most tests is another tool for open policy agents.

126
0:11:30.840 --> 0:11:34.960
Any people familiar with open policy agents?

127
0:11:34.960 --> 0:11:35.960
Open policy?

128
0:11:35.960 --> 0:11:38.520
OPA, yeah.

129
0:11:38.520 --> 0:11:50.440
So OPA allows you to write policies where you can go and pretty much check anything in any

130
0:11:50.440 --> 0:11:52.400
structure file.

131
0:11:52.400 --> 0:12:01.320
In the case of Kubernetes, you could say, I don't know, don't run the pod as root, make

132
0:12:01.320 --> 0:12:07.040
sure you don't mount secrets as environment variables or with files, make sure and force

133
0:12:07.040 --> 0:12:14.880
that all the pods have some labels, any random thing that you can think of, you can do it.

134
0:12:14.880 --> 0:12:21.800
And like don't pull from Docker Hub, pull from the internal registry, you can do that

135
0:12:21.800 --> 0:12:24.720
with contest and OPA policies.

136
0:12:24.720 --> 0:12:29.600
The only problem is that uses the regular language that if you haven't heard of is very

137
0:12:29.600 --> 0:12:39.680
painful to work with, but it works great once you try to figure out.

138
0:12:39.680 --> 0:12:42.680
We added another tool which is called Pluto.

139
0:12:42.680 --> 0:12:48.520
Pluto is just a CLI that will tell you what API versions have been deprecated or removed.

140
0:12:48.520 --> 0:12:55.120
So if you are thinking about upgrading Kubernetes, you run Pluto and it will tell you, you know,

141
0:12:55.120 --> 0:12:59.280
this is deprecated, it's going to be removed in this version and so on.

142
0:12:59.280 --> 0:13:04.080
So you can enforce that.

143
0:13:04.080 --> 0:13:10.540
We built a tool that we call Git init, which is our own version of a GitHub spool.

144
0:13:10.540 --> 0:13:15.000
So we have the Kubernetes definitions store in Git and we deploy these to blob stores

145
0:13:15.000 --> 0:13:17.360
across regions.

146
0:13:17.360 --> 0:13:21.000
So they are pulled in each cluster.

147
0:13:21.000 --> 0:13:24.440
And Git init is a deployment that runs continuously on each namespace.

148
0:13:24.440 --> 0:13:29.720
We have around 10,000 namespaces in our fleet.

149
0:13:29.720 --> 0:13:36.640
So it basically pulls the blob, applies the changes and does this thing every so often.

150
0:13:36.640 --> 0:13:42.720
And an example of why we do pull versus pull, because pushing to all the clusters, we have

151
0:13:42.720 --> 0:13:49.320
a job that does this and it runs in parallel, like in 20 threads or something, and still

152
0:13:49.320 --> 0:13:52.240
takes like five hours to run.

153
0:13:52.240 --> 0:13:56.120
So we cannot push things when we want.

154
0:13:56.120 --> 0:14:08.320
On Argo CD, we have a new CAS platform that allows you to do Argo CD based microservices.

155
0:14:08.320 --> 0:14:14.320
Argo CD basically this would create a new Git repo, it would come with some templates

156
0:14:14.320 --> 0:14:17.720
and that would get deployed with Argo CD to the cluster.

157
0:14:17.720 --> 0:14:24.560
And this is for us, we're thinking about moving this way and each team will have their own

158
0:14:24.560 --> 0:14:29.080
Git repo, because right now we have mostly centralized operators and everything.

159
0:14:29.080 --> 0:14:33.480
And this is good for the, okay, you go on your own direction, you do whatever you want,

160
0:14:33.480 --> 0:14:35.000
you build it, you run it.

161
0:14:35.000 --> 0:14:39.560
On the other hand, this will be tricky because when we decide or figure out something is

162
0:14:39.560 --> 0:14:45.440
problematic, we cannot just centrally say, you know, and this Git repo tell me who is

163
0:14:45.440 --> 0:14:48.360
doing this and let's change it.

164
0:14:48.360 --> 0:14:53.920
But we're moving towards that direction.

165
0:14:53.920 --> 0:15:00.000
Let me skip this and talk a bit about progressive delivery.

166
0:15:00.000 --> 0:15:06.000
So progressive delivery is a way, well, it's something that is a name for something that

167
0:15:06.000 --> 0:15:14.200
you probably heard of, which is Canary rollouts and doing percentage based rollouts, feature

168
0:15:14.200 --> 0:15:15.840
flags, blue ring.

169
0:15:15.840 --> 0:15:22.920
So basically don't update everybody at the same time, because you can break everybody.

170
0:15:22.920 --> 0:15:28.000
So we can do rollouts to different customer groups in separate waves and we can also do

171
0:15:28.000 --> 0:15:32.160
rollouts to percentage of customers.

172
0:15:32.160 --> 0:15:38.160
By default we have a time based rollout that goes from dev to stage to prod candidate after

173
0:15:38.160 --> 0:15:39.440
a period of time.

174
0:15:39.440 --> 0:15:44.280
And this is running on Jenkins and ensures that things have been running on dev and stage

175
0:15:44.280 --> 0:15:46.080
before we merge them to prod.

176
0:15:46.080 --> 0:15:49.160
I mean, this is very basic.

177
0:15:49.160 --> 0:15:53.680
What we built was feature flags at the namespace level.

178
0:15:53.680 --> 0:15:59.760
We have 10,000 namespaces and the in the Kubernetes definition templates.

179
0:15:59.760 --> 0:16:07.920
So what we allow developers to do is for each namespace, they can decide I want to roll

180
0:16:07.920 --> 0:16:14.560
out this change to this environment, dev, stage or prod, or I want to deploy this change

181
0:16:14.560 --> 0:16:23.640
to a specific cluster or by template namespace type of namespace or a percentage.

182
0:16:23.640 --> 0:16:26.360
And this is just using templates on Kubernetes objects.

183
0:16:26.360 --> 0:16:35.800
So an example is in this case, a Kubernetes definition where you can have a template that

184
0:16:35.800 --> 0:16:44.120
is says full version or bar version, or you can enable a site card container or disable

185
0:16:44.120 --> 0:16:45.120
it.

186
0:16:45.120 --> 0:16:47.200
And then at the bottom you can see the rules.

187
0:16:47.200 --> 0:16:51.120
So by default we want full version to be 1.0.

188
0:16:51.120 --> 0:16:55.800
But for the namespace, all the namespaces on the dev environment, we want that to be

189
0:16:55.800 --> 0:16:57.080
1.1.

190
0:16:57.080 --> 0:17:02.560
So this allows us to quickly roll out changes, but progressively.

191
0:17:02.560 --> 0:17:04.720
We can also do it for percentile.

192
0:17:04.720 --> 0:17:09.800
So in this case we could say, I want all the namespaces in dev and all the namespaces in

193
0:17:09.800 --> 0:17:16.320
a stage to have this full version 1.1 and enable my rule true, but for prod I only want

194
0:17:16.320 --> 0:17:17.400
5%.

195
0:17:17.400 --> 0:17:25.720
I roll out the change to 5% of prod and then I can continue after that.

196
0:17:25.720 --> 0:17:32.040
So this has proven really useful for developers to test things safely, increase development

197
0:17:32.040 --> 0:17:39.520
speed, PRs are much faster, so it's all great.

198
0:17:39.520 --> 0:17:45.400
And we are thinking about, well, we are thinking, we are working on getting our good rollouts,

199
0:17:45.400 --> 0:17:51.880
but at the deployment level, article rollouts allows you to do blue, green and canary rollouts

200
0:17:51.880 --> 0:17:59.920
where you can say progress the number of pods over a period of time.

201
0:17:59.920 --> 0:18:04.720
So instead of changing, I don't know, 10 pods at the same time, it goes one by one.

202
0:18:04.720 --> 0:18:09.960
And if you have a service mesh, you can go even more fine grained and say, I want 5%

203
0:18:09.960 --> 0:18:14.000
of the traffic to go to the old version, to the new version, everything else to the old

204
0:18:14.000 --> 0:18:20.000
version and keep progressing that and do automatic rollbacks.

205
0:18:20.000 --> 0:18:29.680
So yeah, with the service mesh you can fine tune the traffic percentages, but with Kubernetes

206
0:18:29.680 --> 0:18:35.040
services you can still do it, it's just that we are limited with the number of pods.

207
0:18:35.040 --> 0:18:42.160
So to sum up, shift left on guard rails, so keeping people safe on what they are doing,

208
0:18:42.160 --> 0:18:48.120
this increases development speed, it reduces the issues that you are going to have in production,

209
0:18:48.120 --> 0:18:56.320
and you're never going to prevent having issues in production, what you can prevent is how

210
0:18:56.320 --> 0:19:01.280
many customers are affected and how fast you can fix them, right?

211
0:19:01.280 --> 0:19:07.800
So for us, what was very useful is the process delivery techniques like canaries, percent

212
0:19:07.800 --> 0:19:15.720
of rollouts or automated rollbacks, and the automation to do these control and progressive

213
0:19:15.720 --> 0:19:19.320
rollout pays off over time.

214
0:19:19.320 --> 0:19:22.480
So I think we have one minute for questions.

215
0:19:22.480 --> 0:19:30.560
Or you can find me afterwards.

216
0:19:30.560 --> 0:19:38.520
Thank you.

