1
0:00:00.000 --> 0:00:11.500
Hekate is a Haskell from the trenches with an interest in resilient systems and documentation.

2
0:00:11.500 --> 0:00:16.300
When not at work or in the Haskell community, they are a trombonist in various orchestras

3
0:00:16.300 --> 0:00:17.780
and brass bands.

4
0:00:17.780 --> 0:00:25.340
Hekate uses they and them pronouns and farcical amounts of caffeine to retain human form.

5
0:00:25.340 --> 0:00:30.740
They are going to present to us a presentation entitled Web Application Architecture in

6
0:00:30.740 --> 0:00:33.320
Haskell with Flora.pm.

7
0:00:33.320 --> 0:00:34.780
Thank you Hekate.

8
0:00:34.780 --> 0:00:35.780
Thank you very much.

9
0:00:35.780 --> 0:00:37.780
Can everyone hear me?

10
0:00:37.780 --> 0:00:38.780
Perfect.

11
0:00:38.780 --> 0:00:45.440
So, welcome to this talk entitled Web Application Architecture in Haskell, When the Domain Drives

12
0:00:45.440 --> 0:00:48.580
the Types and Types Drive the Program.

13
0:00:48.580 --> 0:00:53.940
So this talk is intended for a missed audience of software engineers who are acquainted with

14
0:00:53.940 --> 0:01:00.420
the practice of domain-driven design and Haskell programmers who are interested in crafting

15
0:01:00.420 --> 0:01:01.980
better systems.

16
0:01:01.980 --> 0:01:07.020
The goal is to create a bridge between the practitioners of domain-driven design and

17
0:01:07.020 --> 0:01:10.620
the users of Haskell.

18
0:01:10.620 --> 0:01:16.540
So my name is ThÃ©ophile Chautry, aka Hekate, to the community.

19
0:01:16.540 --> 0:01:19.020
I am a backend engineer at Scryve.

20
0:01:19.020 --> 0:01:26.060
We are a three-ish company and we have an e-signature platform for contracts and various

21
0:01:26.060 --> 0:01:32.420
documents as well as a digital identity hub where we aggregate various national identity

22
0:01:32.420 --> 0:01:38.260
providers like Itzme in Belgium, for example, or BankID, France Connect for the French people

23
0:01:38.260 --> 0:01:39.660
here.

24
0:01:39.660 --> 0:01:46.820
I am also privileged to be a board member of the Haskell Foundation.

25
0:01:46.820 --> 0:01:53.100
This is one of my numerous involvement in the community.

26
0:01:53.100 --> 0:01:58.940
So Haskell, the pure functional programming language, so these are words and words don't

27
0:01:58.940 --> 0:02:02.340
mean nothing until we can practically apply them.

28
0:02:02.340 --> 0:02:07.460
These words bring us concrete features like native supers for recursion, for example,

29
0:02:07.460 --> 0:02:12.700
without blowing your stack type system that doesn't hate you, high order functions that

30
0:02:12.700 --> 0:02:17.140
almost every language has today and many other features.

31
0:02:17.140 --> 0:02:22.500
There are two features especially that I want to talk about and it is going to be its ability

32
0:02:22.500 --> 0:02:28.860
of the language to adequately represent business domains and the ability to track side effects

33
0:02:28.860 --> 0:02:31.940
in a semantic way.

34
0:02:31.940 --> 0:02:37.580
For example, the adequate representation of business domain, we can use algebraic data

35
0:02:37.580 --> 0:02:45.060
types to allow us to model with more precision the real world and its nuances.

36
0:02:45.060 --> 0:02:50.500
Encoding rules by construction at the type level is something that we can easily do.

37
0:02:50.500 --> 0:02:56.020
In this example, for example, the members of the excess data type visitor and admin

38
0:02:56.020 --> 0:03:02.980
are promoted to the type level for this user type, which means that, for example, there

39
0:03:02.980 --> 0:03:10.500
can only be two values in the privileges parameter of this user type.

40
0:03:10.500 --> 0:03:18.380
And also it means that I am going to get rejected if I pass a visitor user to this function

41
0:03:18.380 --> 0:03:20.180
called view back office.

42
0:03:20.180 --> 0:03:23.780
But I'm going to get rejected at the compilation.

43
0:03:23.780 --> 0:03:27.060
This is something that is trivial to implement at the value level.

44
0:03:27.060 --> 0:03:32.260
I could have a check on a member of the object, of a property of the object that would be

45
0:03:32.260 --> 0:03:34.980
ease admin with a Boolean.

46
0:03:34.980 --> 0:03:40.180
But I have to write the check manually and possibly for every function that needs to

47
0:03:40.180 --> 0:03:41.380
have such a check.

48
0:03:41.380 --> 0:03:47.180
If I encode this property, this immutable property at the type system, at the level

49
0:03:47.180 --> 0:03:56.020
of the types, the compiler then is tasked with checking if I'm doing my job correctly.

50
0:03:56.020 --> 0:03:58.460
Checking side effects semantically.

51
0:03:58.460 --> 0:04:02.980
If we take the previous example, we can see that view back office has a result type of

52
0:04:02.980 --> 0:04:09.740
IOHTML, which more or less means I am doing observable side effects and I return you a

53
0:04:09.740 --> 0:04:11.820
value in HTML.

54
0:04:11.820 --> 0:04:18.020
But that's, you know, it doesn't adequately represent the reality of the function.

55
0:04:18.020 --> 0:04:25.700
And for example, here we have a way of tracking side effects that are being executed in a

56
0:04:25.700 --> 0:04:30.340
more human readable form and we can declare them at the type level.

57
0:04:30.340 --> 0:04:38.620
So here we have a function that's, so the signature is we get an int, which is an identifier,

58
0:04:38.620 --> 0:04:42.740
and we return a function that returns text.

59
0:04:42.740 --> 0:04:49.580
And this F, monad, this F return type has also a list of effects.

60
0:04:49.580 --> 0:04:52.580
So what are these effects?

61
0:04:52.580 --> 0:04:58.700
So, I declare that I'm going to perform database access and possibly mutation.

62
0:04:58.700 --> 0:05:03.460
I am going to access a ready server for the caching and I'm also going to ship my logs

63
0:05:03.460 --> 0:05:11.940
to an external platform or at least to perform the loading effects, whatever that means.

64
0:05:11.940 --> 0:05:18.860
And then we can have more useful breakdown of which functions have which effects.

65
0:05:18.860 --> 0:05:23.940
So get entity name is composed of first we get the entity from the cache if we have it

66
0:05:23.940 --> 0:05:29.500
and then if we don't we can switch to the database to perform a perhaps more costly

67
0:05:29.500 --> 0:05:33.780
access and then finally we log the effects.

68
0:05:33.780 --> 0:05:41.260
So logging, DB, Redis, all of them are then unified in this list of effects at the type

69
0:05:41.260 --> 0:05:44.220
level.

70
0:05:44.220 --> 0:05:52.460
So when a type system is both strong and expressive, we get a lot closer to TLS refactoring.

71
0:05:52.460 --> 0:05:53.620
And what does that mean?

72
0:05:53.620 --> 0:05:59.580
Because many languages today claim to provide such a thing.

73
0:05:59.580 --> 0:06:05.460
So TLS refactoring, you more or less get vibe checked by the compiler, which is pretty cool

74
0:06:05.460 --> 0:06:09.820
because then the compiler keeps you in check regarding the changes in your program and

75
0:06:09.820 --> 0:06:12.420
how they affect the program's behavior.

76
0:06:12.420 --> 0:06:16.580
We also took up the terms with the fact that your worst enemy is now yourself.

77
0:06:16.580 --> 0:06:23.940
You can't blame errors in production because undefined is not a function.

78
0:06:23.940 --> 0:06:31.020
So there are limits of course to correct by construction and I think it's especially important

79
0:06:31.020 --> 0:06:33.940
to be intellectually honest with that.

80
0:06:33.940 --> 0:06:35.460
Haskell is not a prover.

81
0:06:35.460 --> 0:06:40.860
You can prove lemmas and theorems with it.

82
0:06:40.860 --> 0:06:45.420
So you have to write tests and tests come in many shapes and forms.

83
0:06:45.420 --> 0:06:49.420
You write tests for your integrations, your properties and end-to-end tests.

84
0:06:49.420 --> 0:06:54.020
Tests are not optional, unlike maybe.

85
0:06:54.020 --> 0:06:57.260
So functional application architecture.

86
0:06:57.260 --> 0:07:02.340
So this that I showed you gives us a tool to focus now on the topic of functional application

87
0:07:02.340 --> 0:07:07.860
architecture and this time we arrive in the lens of domain-driven design.

88
0:07:07.860 --> 0:07:12.340
There will be a brief overview of the terminology and the techniques that were created in the

89
0:07:12.340 --> 0:07:15.900
discipline and how they apply to us.

90
0:07:15.900 --> 0:07:20.300
So we have, without surprise, the concept of a bounded context.

91
0:07:20.300 --> 0:07:21.300
It's a context.

92
0:07:21.300 --> 0:07:23.500
There are workflow in there.

93
0:07:23.500 --> 0:07:25.020
So what is it really?

94
0:07:25.020 --> 0:07:28.080
It's an autonomous subsystem.

95
0:07:28.080 --> 0:07:33.220
So it's responsible for one or multiple workflows and it has well-defined boundaries, which

96
0:07:33.220 --> 0:07:34.640
is extremely important.

97
0:07:34.640 --> 0:07:41.340
So we have to formalize, or at least be very explicit, how we talk to it, its inputs and

98
0:07:41.340 --> 0:07:42.940
its outputs.

99
0:07:42.940 --> 0:07:48.300
If we take the example of florida.pm, which is a community website, an alternative package

100
0:07:48.300 --> 0:07:52.820
index for the Haskell community, the schema is fairly simple.

101
0:07:52.820 --> 0:07:57.180
We have the web component that talks to the core component, which is tasked then to interface

102
0:07:57.180 --> 0:07:58.420
with the database.

103
0:07:58.420 --> 0:08:04.180
And we have a jobs worker for the jobs queue that also talks to the core components and

104
0:08:04.180 --> 0:08:05.300
to the database.

105
0:08:05.300 --> 0:08:11.400
But we know that it's not going to talk with the web components.

106
0:08:11.400 --> 0:08:18.260
So this is the kind of setting boundaries because they are in a healthy relationship.

107
0:08:18.260 --> 0:08:22.560
And we know that we will not talk to each other.

108
0:08:22.560 --> 0:08:26.980
One more step forward, fearless refactoring.

109
0:08:26.980 --> 0:08:34.540
Now something that the Java and C-sharp world gave us are the concepts of data transfer

110
0:08:34.540 --> 0:08:39.260
objects, data access objects, and business objects.

111
0:08:39.260 --> 0:08:40.940
Sometimes they are the same thing.

112
0:08:40.940 --> 0:08:47.020
Sometimes you are lucky that the JSON payload you receive is the same object upon which

113
0:08:47.020 --> 0:08:52.420
you will perform your business computations and which you will store in your database.

114
0:08:52.420 --> 0:08:53.940
But sometimes they are not.

115
0:08:53.940 --> 0:08:57.700
And really it is pure luck that sometimes these types align.

116
0:08:57.700 --> 0:09:03.820
An example of how this bit me when I was young and hopeful, obviously, without much practice.

117
0:09:03.820 --> 0:09:08.700
During meeting with other people, we were trying to define a JSON-based format for data

118
0:09:08.700 --> 0:09:10.940
exchange between several systems.

119
0:09:10.940 --> 0:09:14.980
And we had Elixir systems, PHP, Ruby, Python.

120
0:09:14.980 --> 0:09:23.060
And these all give you several slight differences in how you can have data types encoded in

121
0:09:23.060 --> 0:09:24.620
these languages.

122
0:09:24.620 --> 0:09:29.780
And for example, if you are dealing with a Rubyist or PHP users, they will try and push

123
0:09:29.780 --> 0:09:33.020
a heterogeneous list in the data format.

124
0:09:33.020 --> 0:09:36.900
So you can have a string and natively in Haskell we don't do that.

125
0:09:36.900 --> 0:09:41.180
So we would have to create some abstraction on top of it.

126
0:09:41.180 --> 0:09:48.060
And I was realizing that I was constraining myself with the capacity of each language

127
0:09:48.060 --> 0:09:52.420
to create this data format based on JSON.

128
0:09:52.420 --> 0:09:53.820
But you don't have to do it.

129
0:09:53.820 --> 0:10:01.620
You can have your fully external way to talk to your mates, your other systems, and have

130
0:10:01.620 --> 0:10:05.940
different representation inside your core components.

131
0:10:05.940 --> 0:10:12.740
For example, if we apply this to Flora, we can see that actually I have my business objects

132
0:10:12.740 --> 0:10:15.620
living inside my bounded context.

133
0:10:15.620 --> 0:10:22.140
When I need to store them, I serialize them to a data access object that will be compliant

134
0:10:22.140 --> 0:10:24.540
with what my database expects.

135
0:10:24.540 --> 0:10:29.220
So it means no fancy mutually recursive types, for example, or something like that.

136
0:10:29.220 --> 0:10:33.980
And when I need to send that on the wire, I will serialize that to a format that is

137
0:10:33.980 --> 0:10:39.820
easily representable by XML, JSON, and other various cursed binary representations that

138
0:10:39.820 --> 0:10:44.580
we may find, especially in the banking system.

139
0:10:44.580 --> 0:10:51.460
So in the end, if I was to summarize bounded context, I showed you a very simple diagram

140
0:10:51.460 --> 0:10:53.100
earlier of Flora.

141
0:10:53.100 --> 0:10:55.860
But how does it interface with each other?

142
0:10:55.860 --> 0:11:02.220
So we have DTOs between each component, and especially between the clients and us, DAOs

143
0:11:02.220 --> 0:11:09.700
for storage access, and inside each component we operate on our business objects.

144
0:11:09.700 --> 0:11:14.460
It so happens that the business object can be extremely similar between the web and the

145
0:11:14.460 --> 0:11:17.060
core components, but sometimes they are not.

146
0:11:17.060 --> 0:11:24.020
And I think it's very liberating to know that you don't have to keep to a single representation

147
0:11:24.020 --> 0:11:26.100
from A to Z all the way.

148
0:11:26.100 --> 0:11:31.980
You really can have conversion layers between your components, between your interfaces,

149
0:11:31.980 --> 0:11:33.620
and it's perfectly all right.

150
0:11:33.620 --> 0:11:37.580
For example, very trivial, but reading configuration.

151
0:11:37.580 --> 0:11:42.100
The 12-factor application model tells us to read configuration from the environment, from

152
0:11:42.100 --> 0:11:43.100
the shell.

153
0:11:43.100 --> 0:11:50.620
So what we have on the left is the config type, which models what I get from the environment

154
0:11:50.620 --> 0:11:53.780
with a twist, because I can force some types.

155
0:11:53.780 --> 0:11:55.420
It's not all text-based.

156
0:11:55.420 --> 0:12:02.580
I can force my parsing of HTTP ports to be a word 16, for example, because I'm not so

157
0:12:02.580 --> 0:12:10.260
interested in having port number of 1 million, unless not without overflow.

158
0:12:10.260 --> 0:12:14.980
So I've got my external configuration that describes, for example, the first member is

159
0:12:14.980 --> 0:12:17.340
DB config with a pool configuration.

160
0:12:17.340 --> 0:12:20.720
So it's all the information I need for the pool, the database pool.

161
0:12:20.720 --> 0:12:25.180
And then internal configuration, it's the pool itself.

162
0:12:25.180 --> 0:12:32.660
And it's very useful because then I have this very explicit conversion, and it's perfectly

163
0:12:32.660 --> 0:12:38.540
all right then to change something inside or outside my core components.

164
0:12:38.540 --> 0:12:43.900
Because then I only have this bottleneck that I can easily change and one more step towards

165
0:12:43.900 --> 0:12:47.260
TLS refactoring.

166
0:12:47.260 --> 0:12:49.980
Separating commands and queries.

167
0:12:49.980 --> 0:12:57.620
So this has practical effects in terms of operation infrastructure and also in terms

168
0:12:57.620 --> 0:13:02.940
of ergonomics for the people who read our code.

169
0:13:02.940 --> 0:13:07.860
In a practical way, if we know that we have a recurrent, fairly heavy processing query

170
0:13:07.860 --> 0:13:13.900
that runs and can take significant lock or CPUs on our server, we have the option to

171
0:13:13.900 --> 0:13:19.140
have these queries run on a read-only replica for our database.

172
0:13:19.140 --> 0:13:22.020
And put this replica on another machine.

173
0:13:22.020 --> 0:13:26.780
So PostgreSQL, for example, very specific example, but I can talk about that.

174
0:13:26.780 --> 0:13:31.980
You can have read-only replicas which take read-only queries and will be very angry at

175
0:13:31.980 --> 0:13:35.700
you if you ever try to mutate the state of this replica.

176
0:13:35.700 --> 0:13:42.020
So you have your primary server which upon which you perform mutating commands and then

177
0:13:42.020 --> 0:13:47.380
it will stream these changes to read-only replica and then the replica will provide

178
0:13:47.380 --> 0:13:49.560
you with a read-only interface.

179
0:13:49.560 --> 0:13:55.820
That is like not only enforced at the level of the types, for example, in your applications,

180
0:13:55.820 --> 0:13:58.860
but fundamentally on the protocol itself.

181
0:13:58.860 --> 0:14:02.900
You will get a runtime error if you try to mutate this state.

182
0:14:02.900 --> 0:14:10.980
So you can't unsafe perform on an unsafe course your way behind that.

183
0:14:10.980 --> 0:14:18.260
So something I learned at my current place of employment scribe is to have a physical

184
0:14:18.260 --> 0:14:22.660
separation in the code between types, the commands and the queries.

185
0:14:22.660 --> 0:14:32.100
So the dialect, the idiom that we have here is that we have these.query and.update modules

186
0:14:32.100 --> 0:14:37.500
in which we put the read-only and mutating queries.

187
0:14:37.500 --> 0:14:43.500
And then when we import them, we qualify them, for example, import qualified as query and

188
0:14:43.500 --> 0:14:45.820
then there is a visual indicator.

189
0:14:45.820 --> 0:14:49.500
So it's very bare-bones but it does work.

190
0:14:49.500 --> 0:14:51.980
This is a query that is going to be read-only.

191
0:14:51.980 --> 0:14:58.060
It's not going to increment a counter in a side table because you have performed something

192
0:14:58.060 --> 0:15:00.380
that is seemingly read-only.

193
0:15:00.380 --> 0:15:05.740
A good example, for example, it's LinkedIn.

194
0:15:05.740 --> 0:15:10.260
When you view someone's page on LinkedIn, they have a notification.

195
0:15:10.260 --> 0:15:16.300
So you would think that viewing something, it's fundamentally read-only, even the terms

196
0:15:16.300 --> 0:15:19.260
reading, viewing, you know, you would think it's read-only.

197
0:15:19.260 --> 0:15:24.860
But perhaps there is a counter that is increased with user tracking so that you can later report

198
0:15:24.860 --> 0:15:27.020
who has viewed your page.

199
0:15:27.020 --> 0:15:35.740
But if you can bring one step more into separating the queries and the commands, then it's much

200
0:15:35.740 --> 0:15:43.260
easier to know which kind of operation you're performing at which place in the code.

201
0:15:43.260 --> 0:15:51.180
So we could go further even and declare queries and commands as effects with their own connection

202
0:15:51.180 --> 0:15:52.180
pulls.

203
0:15:52.180 --> 0:15:57.060
For example, I don't only have the DB effects in my stack.

204
0:15:57.060 --> 0:16:06.060
I'm declaring that I'm performing a read-only operation on the read-only replica of my PostgreSQL

205
0:16:06.060 --> 0:16:07.220
database.

206
0:16:07.220 --> 0:16:11.220
So one more step towards, you know, more...

207
0:16:11.220 --> 0:16:16.180
So of course it can be a technical detail but also I think it's very important to be

208
0:16:16.180 --> 0:16:22.380
able to say to the readers of your code what are you performing, which side effect does

209
0:16:22.380 --> 0:16:28.500
it have, especially in the system that you have ownership of.

210
0:16:28.500 --> 0:16:29.500
Now that's my...

211
0:16:29.500 --> 0:16:33.660
An orchist tendency is coming up.

212
0:16:33.660 --> 0:16:35.740
Let's keep our distance from the state.

213
0:16:35.740 --> 0:16:40.060
The state is best contained.

214
0:16:40.060 --> 0:16:45.420
So the cache of our application is actually a bounded context in its own.

215
0:16:45.420 --> 0:16:48.900
It has its own lifecycle, data storage and API.

216
0:16:48.900 --> 0:16:54.540
And by decoupling our application monolith from its state, we have worked a significant

217
0:16:54.540 --> 0:17:00.580
portion of the path to having a setup where we can have multiple instances of our application

218
0:17:00.580 --> 0:17:03.620
and serving data from the same database in cache.

219
0:17:03.620 --> 0:17:10.860
So at this point, by ensuring that the database server keeps operations in sync, we've got

220
0:17:10.860 --> 0:17:15.020
higher consistency of the application.

221
0:17:15.020 --> 0:17:18.260
So that's the CAP theorem for the disability systems.

222
0:17:18.260 --> 0:17:20.300
You've got CAP.

223
0:17:20.300 --> 0:17:22.100
Is your application consistent?

224
0:17:22.100 --> 0:17:26.100
Is it available or is it tolerant to partition?

225
0:17:26.100 --> 0:17:32.980
And in some industries where you work in very sensitive... with very sensitive data, if you

226
0:17:32.980 --> 0:17:40.860
have a production incident, you can't risk having inconsistent data or having an inconsistent

227
0:17:40.860 --> 0:17:45.500
state where people can read someone else's private folder.

228
0:17:45.500 --> 0:17:48.780
So it's better to shut things down for a bit.

229
0:17:48.780 --> 0:17:52.980
We keep our count, we take a long, deep, long breath and then we restart the system.

230
0:17:52.980 --> 0:18:02.100
But it's because availability has to take one for the team in order to keep consistent.

231
0:18:02.100 --> 0:18:06.660
And partition, tolerance, sorry, to partition, can go out the window.

232
0:18:06.660 --> 0:18:13.060
So for Flora, for example, very simple, we can have our clients that talk to our NGINX

233
0:18:13.060 --> 0:18:18.180
gateway and then the multiple instances of Flora that still speak to the same database

234
0:18:18.180 --> 0:18:24.300
server for mutating operations and the same replica for read-only commands.

235
0:18:24.300 --> 0:18:30.780
I'm not selling you microservice architectures and scale to the moon type of stuff.

236
0:18:30.780 --> 0:18:36.500
But I think it's a very decent way to start a monolith.

237
0:18:36.500 --> 0:18:42.420
We all know that a good distributed system has to start as a monolith and then split

238
0:18:42.420 --> 0:18:44.020
it further and further.

239
0:18:44.020 --> 0:18:51.700
If you start with a microservice-based architecture, you might end up with a distributed monolith.

240
0:18:51.700 --> 0:18:57.060
But the whole thing of a microservice-based application is to have independent contexts

241
0:18:57.060 --> 0:18:58.620
that can still run.

242
0:18:58.620 --> 0:19:04.300
So here we don't take the bet that every component is fully independent.

243
0:19:04.300 --> 0:19:09.260
We acknowledge the boundaries that we have some boundaries between the web, the core,

244
0:19:09.260 --> 0:19:10.980
and the job worker's components.

245
0:19:10.980 --> 0:19:15.540
And then themselves, they have their own context.

246
0:19:15.540 --> 0:19:18.740
So it's also about realism.

247
0:19:18.740 --> 0:19:22.220
Do you want to scale to the moon and raise like hundreds of thousands of dollars from

248
0:19:22.220 --> 0:19:23.220
venture capitalists?

249
0:19:23.220 --> 0:19:28.220
Or do you want to create a nice community website that indexes packages for the Haskell

250
0:19:28.220 --> 0:19:30.860
environment?

251
0:19:30.860 --> 0:19:36.820
I'm going to make a short detour here, and it's directing our workflows with types.

252
0:19:36.820 --> 0:19:42.460
So it's a technique that brings together type safety and ergonomics, which is one of my

253
0:19:42.460 --> 0:19:45.900
favorite subjects, to create type-directed state machines.

254
0:19:45.900 --> 0:19:47.900
Very fancy word.

255
0:19:47.900 --> 0:19:56.420
Basically, it's really the way that your operations are composed together, and you will be driven

256
0:19:56.420 --> 0:19:58.820
to compose these operations via their types.

257
0:19:58.820 --> 0:20:03.500
It can be a bit scary sometimes to think of your business operations as a state machine,

258
0:20:03.500 --> 0:20:10.300
but it gives us a terminology and a literature to take from and to think of how we organize

259
0:20:10.300 --> 0:20:12.180
and compose our operations.

260
0:20:12.180 --> 0:20:19.700
So for example, here we have a workflow state, which can have three values, arrival, processed,

261
0:20:19.700 --> 0:20:25.380
and departure, and a workflow that has this state type parameter.

262
0:20:25.380 --> 0:20:32.660
So we have a new workflow value that creates a workflow w1, and then the process workflow

263
0:20:32.660 --> 0:20:35.860
function takes a workflow, but not any kind of workflow.

264
0:20:35.860 --> 0:20:38.820
It has to be set to arrival.

265
0:20:38.820 --> 0:20:45.220
It can only take newly arrived workflows and then sets them as processed.

266
0:20:45.220 --> 0:20:52.820
Again, this could be in-codes trivially implemented at the value level with properties of the

267
0:20:52.820 --> 0:21:01.380
workflow object, and we could very easily verify, check these properties in the value

268
0:21:01.380 --> 0:21:02.860
level in the code.

269
0:21:02.860 --> 0:21:08.740
But here I factorize all these checks, and I put them really at a place where the compiler

270
0:21:08.740 --> 0:21:13.580
can guide my hand and tell me where I went wrong with that.

271
0:21:13.580 --> 0:21:19.980
And finally, the send back workflow can only take processed workflows by the laws of the

272
0:21:19.980 --> 0:21:25.300
use, and then sets the workflow as deported.

273
0:21:25.300 --> 0:21:30.140
So if I compose the functions in the good order, so new workflow and then a pipeline

274
0:21:30.140 --> 0:21:35.580
of functions, and then I pipe it into process workflow and send back workflow, everything

275
0:21:35.580 --> 0:21:36.580
is good.

276
0:21:36.580 --> 0:21:45.180
If I try to skip a step, I will get a compiler error that says you wanted me to take a processed

277
0:21:45.180 --> 0:21:46.460
workflow.

278
0:21:46.460 --> 0:21:52.420
But actually, I need, sorry, you wanted me to take an arrival workflow, but actually

279
0:21:52.420 --> 0:21:56.340
I need the processed workflow.

280
0:21:56.340 --> 0:22:00.300
And this code, you're not sending that code to production because you cannot compile this

281
0:22:00.300 --> 0:22:02.980
code.

282
0:22:02.980 --> 0:22:10.260
In terms of web application development, there are also some, for us, haskalers, we like

283
0:22:10.260 --> 0:22:14.940
to put everything at the level of types and think of our code as being formally proven

284
0:22:14.940 --> 0:22:16.820
or code by construction.

285
0:22:16.820 --> 0:22:22.180
But sometimes we must not drink all the cool aid or all the clemate.

286
0:22:22.180 --> 0:22:26.540
For example, database layers that promise type safe SQL.

287
0:22:26.540 --> 0:22:31.980
If you ever find a database layer that promise type safety, either it's the kind of type

288
0:22:31.980 --> 0:22:37.980
safety that is trivial to implement, and it's totally expected of the tool to have it, or

289
0:22:37.980 --> 0:22:43.020
it has encoded the semantics of SQL at the type level, and we've either found the golden

290
0:22:43.020 --> 0:22:51.340
goose or someone who has clearly underestimated the difficulties of SQL semantics.

291
0:22:51.340 --> 0:22:55.700
Also SQLite for development and PostgreSQL for production, that's something that the Python

292
0:22:55.700 --> 0:23:01.900
community has popularized in the 2010s.

293
0:23:01.900 --> 0:23:06.060
So we can accomplish great things by lying to the universe, but we scarcely accomplish

294
0:23:06.060 --> 0:23:07.980
anything by lying to ourselves.

295
0:23:07.980 --> 0:23:15.460
And SQLite is its own system, and unless you somehow perfectly code in this common subset

296
0:23:15.460 --> 0:23:21.180
of SQL supported by both implementations, you will be maintaining two sets of database

297
0:23:21.180 --> 0:23:24.340
migrations and sometimes of code.

298
0:23:24.340 --> 0:23:30.940
So PostgreSQL has very good features, SQLite has different but also good features, not

299
0:23:30.940 --> 0:23:32.420
its type system, of course.

300
0:23:32.420 --> 0:23:37.860
But if you get used to one locally and then discover the second one once you're deployed,

301
0:23:37.860 --> 0:23:42.660
you're going to have a bad time and also the muscle memory, because the brain is a muscle,

302
0:23:42.660 --> 0:23:49.340
that you will have accumulated with SQLite would be fairly useless with PostgreSQL.

303
0:23:49.340 --> 0:23:50.700
So where to go from here?

304
0:23:50.700 --> 0:23:51.700
Documentation.

305
0:23:51.700 --> 0:23:53.500
You produce documentation.

306
0:23:53.500 --> 0:24:00.060
We have many ways of producing documentation, and we hold also tremendous power in the types.

307
0:24:00.060 --> 0:24:04.580
And coupled with introspection, it means that the algebraic data types, like the sum types

308
0:24:04.580 --> 0:24:10.780
and the product types, so the enums and the records, they can serve as the backbone for

309
0:24:10.780 --> 0:24:12.700
further even documentation.

310
0:24:12.700 --> 0:24:18.460
The types themselves are not documentation, but they can be used to guide the reader.

311
0:24:18.460 --> 0:24:21.060
And you remember how I told you to write the tests.

312
0:24:21.060 --> 0:24:26.740
So the best tests are those that can describe real world behaviors.

313
0:24:26.740 --> 0:24:33.700
And if you can even produce a summary web page that shows the behaviors and the high

314
0:24:33.700 --> 0:24:40.380
level paths taken by your program according to some input, this is very particularly helpful

315
0:24:40.380 --> 0:24:45.740
for less technical people, like product managers, who want to know the behavior of your program.

316
0:24:45.740 --> 0:24:50.740
If you can present a nice interface of how the code is executed according to some high

317
0:24:50.740 --> 0:24:56.780
level business operation, it's even better.

318
0:24:56.780 --> 0:25:00.380
So I have a couple of sources for what I'm saying.

319
0:25:00.380 --> 0:25:02.940
I'm not pulling that out of my ass.

320
0:25:02.940 --> 0:25:07.060
The first one is Dominant Modeling Made Functional by Scott Vlachin.

321
0:25:07.060 --> 0:25:13.300
It's an excellent book written in F-sharp for the functional and DDD practitioners.

322
0:25:13.300 --> 0:25:14.300
It's excellent.

323
0:25:14.300 --> 0:25:15.620
I encourage you to read it.

324
0:25:15.620 --> 0:25:19.660
As well as Living Documentation by Cyril Marcher.

325
0:25:19.660 --> 0:25:21.900
And that one is also excellent.

326
0:25:21.900 --> 0:25:28.220
Really it puts documentation as its own living system for which you will have real clients,

327
0:25:28.220 --> 0:25:34.420
because PMs and other engineers in your organization or consumers of documentation, and of course

328
0:25:34.420 --> 0:25:38.140
hideous amounts of caffeine, as Fraser told earlier.

329
0:25:38.140 --> 0:25:48.660
So that would be the end of my talk.

330
0:25:48.660 --> 0:25:50.900
Do we have a couple of minutes for questions perhaps?

331
0:25:50.900 --> 0:25:52.660
Yes, thank you, Akate.

332
0:25:52.660 --> 0:25:55.900
And we do have about 10 minutes for questions.

333
0:25:55.900 --> 0:26:00.300
Yes, young man there.

334
0:26:00.300 --> 0:26:03.380
This is on.

335
0:26:03.380 --> 0:26:08.180
This is more of a comment than a question.

336
0:26:08.180 --> 0:26:13.700
So one little detail that I think that sort of you could have sold also, right, is the

337
0:26:13.700 --> 0:26:21.060
fact that when you do this, when you do the data kind annotation on your workflow, instead

338
0:26:21.060 --> 0:26:26.900
of checking that during runtime, we do the type annotation and that's actually more efficient,

339
0:26:26.900 --> 0:26:32.820
right, because of type erasure that there's no runtime data or check that has to happen.

340
0:26:32.820 --> 0:26:38.900
Yes, so what Bjorn says is that indeed there is a matter of efficiency, because the data

341
0:26:38.900 --> 0:26:46.980
kinds when we encode the nature of parameters in our workflow, this all goes away at code

342
0:26:46.980 --> 0:26:48.140
generation.

343
0:26:48.140 --> 0:26:55.820
So if you are in a setup where you need some very minimal code that is being generated,

344
0:26:55.820 --> 0:27:01.260
if you are in tight loop for example, this code is completely raised at the time of code

345
0:27:01.260 --> 0:27:06.860
generation and indeed you spare some CPU cycles.

346
0:27:06.860 --> 0:27:07.860
Any other question?

347
0:27:07.860 --> 0:27:09.260
You can also call me up on my bullshit.

348
0:27:09.260 --> 0:27:11.260
I won't be offended.

349
0:27:11.260 --> 0:27:12.260
Yes?

350
0:27:12.260 --> 0:27:14.540
Do I need my code?

351
0:27:14.540 --> 0:27:15.540
I can repeat your question.

352
0:27:15.540 --> 0:27:16.540
Oh yes, that's not quite quickly.

353
0:27:16.540 --> 0:27:26.300
The libraries that offer type safe database access that are, I'm sure, hideously incomplete

354
0:27:26.300 --> 0:27:33.460
also offer abstraction of a different database back ends, which is one of the problems you

355
0:27:33.460 --> 0:27:37.340
were talking about, like why you're using Postgres to develop locally.

356
0:27:37.340 --> 0:27:44.100
So my question is, are there really situations for a 4PM where those libraries didn't provide

357
0:27:44.100 --> 0:27:45.580
a feature that you needed?

358
0:27:45.580 --> 0:27:53.020
Yes, so the question is, those libraries that encode all of the semantics of SQL at the

359
0:27:53.020 --> 0:27:57.860
type level, are there situations where they don't provide features that I would need for

360
0:27:57.860 --> 0:27:58.860
a 4PM?

361
0:27:58.860 --> 0:27:59.860
Yes.

362
0:27:59.860 --> 0:28:00.860
Yes.

363
0:28:00.860 --> 0:28:05.100
So as I told earlier, I'm very preoccupied by ergonomics.

364
0:28:05.100 --> 0:28:14.140
20 minutes of compilation time and 20 gigabytes of half the interface files on disk, I would

365
0:28:14.140 --> 0:28:19.700
consider that a problem in terms of feedback loop for contributors.

366
0:28:19.700 --> 0:28:26.100
My previous place of employment, we used the toolkit Squeal for type level-encoded SQL

367
0:28:26.100 --> 0:28:29.500
queries because they were business critical.

368
0:28:29.500 --> 0:28:35.300
So we wanted to invest in something very much type safe because of the critical aspect of

369
0:28:35.300 --> 0:28:37.200
these queries.

370
0:28:37.200 --> 0:28:38.200
It was hell.

371
0:28:38.200 --> 0:28:39.200
It was horrendous.

372
0:28:39.200 --> 0:28:45.900
It was not only to view and to review, but also because it took so much time to compile,

373
0:28:45.900 --> 0:28:52.820
like unironically 20 minutes, and we had some problems with stack because the interface

374
0:28:52.820 --> 0:28:56.860
files on disk were taking way too much space.

375
0:28:56.860 --> 0:29:04.460
Type families in Haskell are best consumed responsibly.

376
0:29:04.460 --> 0:29:10.420
I'm a servant user, so I can't shit too much on type families, but in some cases, very

377
0:29:10.420 --> 0:29:14.820
specific cases, it's best to rely on the expertise of outside systems.

378
0:29:14.820 --> 0:29:21.220
For example, my best friend, who's here actually in FOSDEM, is my database administrator at

379
0:29:21.220 --> 0:29:22.220
work.

380
0:29:22.220 --> 0:29:24.220
I keep him close.

381
0:29:24.220 --> 0:29:32.940
Do you ever have experience to need to onboard like a newer developer to maintain or even

382
0:29:32.940 --> 0:29:35.060
do new feature to the project?

383
0:29:35.060 --> 0:29:38.340
If so, what's the experience, especially if they don't have any Haskell experience or

384
0:29:38.340 --> 0:29:39.340
especially this kind of experience?

385
0:29:39.340 --> 0:29:40.340
Yes, very good question.

386
0:29:40.340 --> 0:29:43.500
Do we have any experience onboarding new developers on the project?

387
0:29:43.500 --> 0:29:48.300
Actually this talk was supposed to be the continuation of the different onboarding sessions

388
0:29:48.300 --> 0:29:50.060
rather than on Flora PM.

389
0:29:50.060 --> 0:29:56.060
So sometimes if you find me on Discord or Matrix, I will share my screen and introduce

390
0:29:56.060 --> 0:29:57.580
people to the code base.

391
0:29:57.580 --> 0:30:02.100
I think that's one of the most important aspects of Flora as a project.

392
0:30:02.100 --> 0:30:09.340
Not only it is a community tool that aims to satisfy the users, but also it's a vessel

393
0:30:09.340 --> 0:30:10.340
for teaching.

394
0:30:10.340 --> 0:30:15.940
So I have got many techniques that I explained in this talk implemented in Flora, and Flora

395
0:30:15.940 --> 0:30:20.060
is the factor code base to teach these techniques.

396
0:30:20.060 --> 0:30:27.300
I had very bad experience with community tools that have badly aged, and the code is only

397
0:30:27.300 --> 0:30:36.220
known by the 10% of maintainers that stick around, even if the vast majority of contributors

398
0:30:36.220 --> 0:30:43.220
of a project are the 90% of people who just make one pull request and then go away forever.

399
0:30:43.220 --> 0:30:48.540
So it's very hard to retain institutional knowledge, and also it's very hard not to

400
0:30:48.540 --> 0:30:56.300
aim to please the 10% of people who stick around and submit patches on the regular.

401
0:30:56.300 --> 0:31:01.960
So yes, I would think that, and that's the goal of Flora, onboarding new contributors

402
0:31:01.960 --> 0:31:09.860
easily is actually a feature, and if it can't be done anymore, it's a bug.

403
0:31:09.860 --> 0:31:10.860
Any other question?

404
0:31:10.860 --> 0:31:11.860
Nope.

405
0:31:11.860 --> 0:31:22.300
With such a representation, is it possible to write a function that, say, generates a

406
0:31:22.300 --> 0:31:23.300
diagram?

407
0:31:23.300 --> 0:31:24.620
It technically is.

408
0:31:24.620 --> 0:31:26.660
I have references for you.

409
0:31:26.660 --> 0:31:31.980
So the question is, can we generate diagrams from such representations?

410
0:31:31.980 --> 0:31:36.540
Because indeed we have the possible values that we have at a type level, and we can do

411
0:31:36.540 --> 0:31:39.860
many things with our types, including inspecting them.

412
0:31:39.860 --> 0:31:46.220
So yes, I believe there are several libraries on Hackage that aim to, for example, provenance.

413
0:31:46.220 --> 0:31:52.180
It's a library that gives you the path that the data takes and the provenance of your

414
0:31:52.180 --> 0:31:55.460
data throughout the code.

415
0:31:55.460 --> 0:32:02.300
I would say it's one of the greatest things to be able to do, is to represent your code

416
0:32:02.300 --> 0:32:11.020
and to extract facts and movements from your code in a higher level representation.

417
0:32:11.020 --> 0:32:12.860
So yeah, I believe we can do it today.

418
0:32:12.860 --> 0:32:14.100
I don't do it personally.

419
0:32:14.100 --> 0:32:19.700
I think it's possible.

420
0:32:19.700 --> 0:32:22.380
There's time for more questions.

421
0:32:22.380 --> 0:32:26.860
Or you can like, duel me if you want to challenge my beliefs.

422
0:32:26.860 --> 0:32:30.460
Okay.

423
0:32:30.460 --> 0:32:31.460
That seems like it.

424
0:32:31.460 --> 0:32:32.460
So thank you again, Ekate.

425
0:32:32.460 --> 0:32:50.420
Thank you very much.

