WEBVTT

00:00.000 --> 00:11.440
So hello and welcome to my talk about green software engineering and more specifically

00:11.440 --> 00:17.180
about building energy measurement tools and ecosystems around software.

00:17.180 --> 00:23.640
My name is Arna and I work for Green Coding Berlin, which is a company that specializes

00:23.640 --> 00:31.040
in making open source tools for energy aware software measurement.

00:31.040 --> 00:37.960
I would like to take you on a tour today of a concept for a possible future ecosystem

00:37.960 --> 00:43.880
we imagine where energy consumption of software is a first world metric and available for

00:43.880 --> 00:48.020
every developer and user.

00:48.020 --> 00:50.640
So let's have a look at a hypothetical scenario.

00:50.640 --> 00:56.260
So Windows 10 operating system typically comes with a minimum system requirements.

00:56.260 --> 01:00.080
So if you look on the vendors web page, you can see it has a processor that is needed

01:00.080 --> 01:05.800
1 gigahertz, 1 gigabyte of RAM, a particular amount of hard disk space, graphics cards,

01:05.800 --> 01:06.800
etc.

01:06.800 --> 01:12.520
However, what is never given is the power on for instance idle that this operating system

01:12.520 --> 01:18.200
uses on this reference hardware that it apparently already specifies.

01:18.200 --> 01:20.600
So this should be pretty doable, right?

01:20.600 --> 01:23.640
Also something like the desktop activity.

01:23.640 --> 01:28.640
So how much power does it use just to go around in the operating system, opening the file

01:28.640 --> 01:34.440
explorer using the taskbar and stuff like this on the reference system, for instance,

01:34.440 --> 01:41.240
that Microsoft specifies or on a reference system that we or the community specifies.

01:41.240 --> 01:43.880
And imagine then you can make could make informed choices.

01:43.880 --> 01:51.440
So by just saying, hey, I'm looking at Windows 10 and I see that it has 45 watts an idle,

01:51.440 --> 01:54.120
but apparently my computer is mostly an idle.

01:54.120 --> 01:58.600
So it might be more interesting to use Ubuntu, for instance, which has just 20 watts an idle

01:58.600 --> 02:00.820
or desktop activity is even lower.

02:00.820 --> 02:05.360
So why not choose this operating system with energy is my main concern.

02:05.360 --> 02:10.160
And this is what I what I cherish the most in the operating system or which is an important

02:10.160 --> 02:11.940
metric for me.

02:11.940 --> 02:18.280
If you think this process even further, you can think about comparing energy of applications

02:18.280 --> 02:24.480
very specific, not only in the idle scenario or in one scenario, but in very specific usage

02:24.480 --> 02:30.760
scenarios that are ingrained to how people typically use such an application.

02:30.760 --> 02:35.120
What you see here is two radar charts on the left side is WhatsApp and on the right side

02:35.120 --> 02:36.120
is Telegram.

02:36.120 --> 02:38.200
Please keep in mind that these are concept pictures.

02:38.200 --> 02:44.800
So this is not actually the energy that these applications use for this use case.

02:44.800 --> 02:49.800
But let's say your use case is that you message a lot with an app, but you don't do that many

02:49.800 --> 02:51.360
video calls.

02:51.360 --> 02:55.400
So if you look at WhatsApp, you see here that it has quite a high energy budget when it

02:55.400 --> 02:59.240
comes to messaging, whereas Telegram has quite a lower budget.

02:59.240 --> 03:03.880
Telegram is however very bad when it comes to video where WhatsApp could be for instance

03:03.880 --> 03:04.880
better.

03:04.880 --> 03:09.840
If you say that you are mostly doing messaging with your application and you would like to

03:09.840 --> 03:14.560
keep your battery life or maybe use Telegram on the desktop, your desktop energy consumption

03:14.560 --> 03:20.600
low, then with such metrics, you could actually make an informed decision if WhatsApp or Telegram

03:20.600 --> 03:26.200
is the better app for you if energy is an important concern.

03:26.200 --> 03:31.540
And imagine as a developer, if you think even one step further, that you go to GitHub or

03:31.540 --> 03:36.160
to GitLab or wherever your software is hosted and you look in the repository and you see

03:36.160 --> 03:42.720
right away with something like an open energy batch, how we call it internally, to see how

03:42.720 --> 03:48.360
much the software, you see it down here, how much the software is actually using for its

03:48.360 --> 03:52.720
intended use case that the developer of the software had in mind.

03:52.720 --> 03:57.880
So you can compare one software that maybe has very limited use case to another software

03:57.880 --> 04:04.560
or library just by the energy budget because you have the metrics already available.

04:04.560 --> 04:10.760
We actually try to build these tools and I would like to take you in this very short

04:10.760 --> 04:15.320
timeframe that we have been given by Fostem, so just about 20 minutes, I would like you

04:15.320 --> 04:21.160
to take a tour through our projects that we are doing more as an appetizer so you see

04:21.160 --> 04:26.560
what we are working on and what we think could be possible or a possible ecosystem in the

04:26.560 --> 04:29.640
future.

04:29.640 --> 04:36.360
You will be presented with a view that looks like such, so the Green Metrics tool, EcoCI,

04:36.360 --> 04:38.840
Open Energy Badge and Cloud Energy.

04:38.840 --> 04:43.480
So the Green Metrics tool is what I would like to talk about today mostly because I

04:43.480 --> 04:49.840
think it is the tool that outlines our concept of transparency in the software community

04:49.840 --> 04:54.780
the best and then we'll talk about later about our approaches for CI pipelines or restricted

04:54.780 --> 04:58.040
environments like the cloud.

04:58.040 --> 05:03.960
So first of all I think it makes sense, although I know people tend to hate diagrams or flowcharts

05:03.960 --> 05:10.200
to some degree, but I think it makes sense to quickly go over how the concept of the

05:10.200 --> 05:13.440
tool works from a high level perspective.

05:13.440 --> 05:18.420
So in order to measure software we follow the container based approach.

05:18.420 --> 05:23.980
So we assume that your software is already in a containerized format or can be put in

05:23.980 --> 05:25.360
such a format.

05:25.360 --> 05:29.840
So for instance even a Firefox browser if you want to measure desktop applications can

05:29.840 --> 05:33.120
be put in a container and be measured with our tool.

05:33.120 --> 05:39.360
Also machine learning applications, simple command line applications but also web applications.

05:39.360 --> 05:44.360
Typically when you develop software you already have infrastructure files like Docker files,

05:44.360 --> 05:50.960
Docker compose file or even a Kubernetes file available which our tool can consume in all

05:50.960 --> 05:58.200
fairness, Kubernetes is still a work in progress but Docker files it can consume.

05:58.200 --> 06:03.880
And then the tool basically orchestrates the containers and attaches every reporter that

06:03.880 --> 06:06.440
you want in terms of measuring metrics.

06:06.440 --> 06:12.020
So here we are still very similar to typical data logging approaches like Datadog does

06:12.020 --> 06:14.520
it for instance or other big players.

06:14.520 --> 06:21.120
So the memory, the AC power, DC power, the network traffic, CPU percentage, CPU and RAM

06:21.120 --> 06:27.720
is all locked during the execution of what we call a standard usage scenario.

06:27.720 --> 06:32.160
So in the first couple of slides I have shown you the concept of looking at software from

06:32.160 --> 06:34.880
how is it typically used.

06:34.880 --> 06:39.280
And people already have thought about this concept quite a lot when they make end to

06:39.280 --> 06:43.760
end tests with their software because this is a typical flow that a user goes through

06:43.760 --> 06:49.920
in your application or unit tests which might be very reduced amounts of functionality that

06:49.920 --> 06:56.080
is tested in a block or benchmarks that are already inside of the software repository,

06:56.080 --> 07:01.280
session replays, shell scripts, build files that basically measure where we could measure

07:01.280 --> 07:02.280
your build process.

07:02.280 --> 07:07.480
All of this is already available typically and our tool can consume these files, will

07:07.480 --> 07:12.680
run these workflows and then tell you the energy budget over the time of this run in

07:12.680 --> 07:14.800
particular.

07:14.800 --> 07:19.520
This slide is more just if you're not too familiar with Docker the idea is just to have

07:19.520 --> 07:25.080
every service or every component of the application in a separate container so that we can later

07:25.080 --> 07:31.420
on better granularize the metrics and better look at which component might be interesting

07:31.420 --> 07:36.960
to look at if you want to do energy optimizations in particular.

07:36.960 --> 07:41.000
When you use the tool and I will just go quickly over that and then probably go with you through

07:41.000 --> 07:45.880
a live version of what we are hosting at the moment you will get a lot of metrics so you

07:45.880 --> 07:50.680
will obviously get something like the CPU utilization or the average memory that was

07:50.680 --> 07:56.720
used or maybe the network bandwidth that was used but what is interesting for its dashboard

07:56.720 --> 08:02.240
and basically its USB is that you get also the energy metrics from the CPU, from the

08:02.240 --> 08:09.360
memory, you get a calculation what the network has used in energy and you get convoluted

08:09.360 --> 08:16.440
or basically aggregated values where it makes often sense to look at CPU and memory in conjunction

08:16.440 --> 08:20.320
or it makes sense to look at all the metrics that you have available to get something like

08:20.320 --> 08:23.800
a total energy budget.

08:23.800 --> 08:28.160
Then you obviously can look also at the AC so at the wall plaques so not only what is

08:28.160 --> 08:33.160
your CPU and your RAM using but what is the total machine using or something that we have

08:33.160 --> 08:38.560
in our lab as a setup you just look at the mainboard so not on the outside of the PSU

08:38.560 --> 08:42.760
so what is basically plucked in the desktop computer but only the power that flows directly

08:42.760 --> 08:48.520
into the mainboard and here you can see that our tool automatically calculates the CO2

08:48.520 --> 08:54.520
budget based on the energy that it has used for this run.

08:54.520 --> 08:59.640
The tool also shows you which reporters have been used in an overview and then it tells

08:59.640 --> 09:04.960
you a lot of charts so this is a sample chart and what the tool can basically give you is

09:04.960 --> 09:10.440
not only an overview capability but also an introspection where you for instance are interested

09:10.440 --> 09:16.440
in the idle time of the application so what is my application doing when no user is interacting

09:16.440 --> 09:22.960
with it is it actually using energy and is this too much energy for my belief or for

09:22.960 --> 09:28.720
the belief of the community so for instance here we have an example of a setup of a WordPress

09:28.720 --> 09:35.760
setup that we have done with an Apache, a Puppeteer container that runs Chrome and also

09:35.760 --> 09:41.400
a MariaDB instance and you can see here that here are a couple of requests that have been

09:41.400 --> 09:46.600
done to a WordPress instance and then we are basically just idling but still the web service

09:46.600 --> 09:51.480
doing quite some work and there have been no web sockets active so why is there server

09:51.480 --> 09:53.320
and database activity here?

09:53.320 --> 09:54.320
Is this valid?

09:54.320 --> 09:59.120
Is this maybe some caching, some housekeeping or is this unintended behavior?

09:59.120 --> 10:04.880
We picture that our tool could highlight such energy, hotspot or energy malfunctions as

10:04.880 --> 10:10.520
we call them to better understand how software uses energy.

10:10.520 --> 10:16.360
You can also look at energy anomalies so we work sometimes with features like TurboBoost

10:16.360 --> 10:20.620
which is typically not turned on in cloud environments but very often for desktops which

10:20.620 --> 10:25.080
brings a processor in kind of like an overdrive state so that it can react very quickly in

10:25.080 --> 10:28.360
a frequency above its normal frequency.

10:28.360 --> 10:34.640
However, what we have done here in this example we have run a constant CPU utilization but

10:34.640 --> 10:40.080
as you can see here the CPU clocks at different frequency over the time and sometimes it uses

10:40.080 --> 10:48.000
exponentially more energy for the same task so it finishes quicker but it uses more than

10:48.000 --> 10:53.360
only a linear amount more of energy to do the task so this is a very interesting insight

10:53.360 --> 11:00.040
that our tool can for instance deliver when you try for energy optimizations of your software.

11:00.040 --> 11:03.960
So what is the whole idea that we have behind all this project?

11:03.960 --> 11:09.120
And let me move myself down here a little bit so you can see the full slide.

11:09.120 --> 11:17.040
We want to create an open source community or a green software community that focuses

11:17.040 --> 11:22.440
on the transparency of software so that you have basically an interface which we call

11:22.440 --> 11:29.520
the usage scenario where you can measure software against and then ask later on questions against

11:29.520 --> 11:33.780
a database or against an API which has measured all these softwares.

11:33.780 --> 11:36.640
Questions like how much does this software consume?

11:36.640 --> 11:42.800
Is there a more carbon friendly alternative or is there a software that makes less network

11:42.800 --> 11:44.480
requests?

11:44.480 --> 11:50.120
The idea if these softwares are available in your country so YUKA to my knowledge is

11:50.120 --> 11:55.720
for instance from the US and code check is more like a German application is we want

11:55.720 --> 12:03.520
to be the YUKA or the code check of software so we want to deliver answers to developers

12:03.520 --> 12:08.280
where they can ask questions about the energy budgeting of a library of a software or of

12:08.280 --> 12:15.600
a functionality by providing a framework to make these measurements.

12:15.600 --> 12:19.460
So let me move up here again and then back to the slides.

12:19.460 --> 12:23.560
So let me show you our other tools that we believe are needed to build an ecosystem around

12:23.560 --> 12:29.440
green software because software is not only running in desktop environments or is not

12:29.440 --> 12:34.080
only on a single machine it also runs a lot in the clouds where these measurements that

12:34.080 --> 12:38.640
we have and I would like to encourage you to read a bit on what sensors are available

12:38.640 --> 12:45.440
in our tool but where these sensors are not available which is for instance in the cloud.

12:45.440 --> 12:51.120
So let me bring up my browser again.

12:51.120 --> 12:54.680
So if you are on the homepage and here you've seen the green metrics tool that I've just

12:54.680 --> 13:01.000
talked about you also see that we have the cloud energy project and the EECO CI project.

13:01.000 --> 13:08.400
So EECO CI focuses on measuring the energy of software in a continuous integration pipeline

13:08.400 --> 13:10.840
that for instance runs in a virtual machine.

13:10.840 --> 13:13.320
Our focus is currently on GitHub actions.

13:13.320 --> 13:18.400
In order to estimate the energy in a virtual machine because you cannot measure you have

13:18.400 --> 13:22.720
no access to the wall plug in the data center you have no access to sensors and the CPU

13:22.720 --> 13:27.440
or whatever you have to estimate the machine based on measurements that you already have

13:27.440 --> 13:29.720
for the same hardware.

13:29.720 --> 13:35.400
If you click on cloud energy you can see here that we have based our machine learning model

13:35.400 --> 13:40.440
on a research paper from Interact DC and the University of London and they have basically

13:40.440 --> 13:47.920
taken the data from the spec power database which is an open database for servers that

13:47.920 --> 13:54.320
have been measured just with a fixed workload to compare it against each other and based

13:54.320 --> 13:59.200
on this data we can create a machine learning model which is also free and open source to

13:59.200 --> 14:06.160
use that is just a Python tool which you call with the information that you have.

14:06.160 --> 14:10.040
So let's say you have the information that your CPU is from Intel that the frequency

14:10.040 --> 14:15.480
that you're running is 2.6 gigahertz you have 7 gigabytes of RAM and you know the CPU has

14:15.480 --> 14:20.720
24 threads but you don't know any more info you don't know if it's a Skylake processor

14:20.720 --> 14:27.480
or a modern a more modern Intel processor you do you have no more information because

14:27.480 --> 14:32.200
the hypervisor limits this to you so you if you give the model more information it can

14:32.200 --> 14:35.960
give you more accurate estimates but it can also work with the limited information in

14:35.960 --> 14:42.480
the cloud and then it spits out to the standard out the current watch that you have been using

14:42.480 --> 14:47.000
and then you can reuse that in a tool that we build upon that.

14:47.000 --> 14:50.240
So now that you've understood that there is a machine learning model behind the idea I

14:50.240 --> 14:52.920
would like to bring you to EECO CI.

14:52.920 --> 14:58.320
So EECO CI is a GitHub action that is based on the work from the cloud energy project

14:58.320 --> 15:05.440
that can give you in a GitHub action the information of how much a CI pipeline has used in terms

15:05.440 --> 15:07.140
of energy.

15:07.140 --> 15:15.360
So if you go for instance to the GitHub repository you can also go to the marketplace so we go

15:15.360 --> 15:20.560
one step further and here you can see you can directly use it.

15:20.560 --> 15:26.760
It is very easy to use it just needs two calls to initialize a tool and then one more call

15:26.760 --> 15:32.080
whenever you want to get a measurement and what it does for you so let's quickly go to

15:32.080 --> 15:40.600
our repository where we actually use GitHub actions to measure every of our workflows

15:40.600 --> 15:46.520
in the tool so we click on actions let's say we go to manual test run virtual machine we

15:46.520 --> 15:52.680
click on main and you see here I've run this run yesterday it succeeded so our log tells

15:52.680 --> 15:58.260
us hey all tests have to work fine so to run a work point fine and also the API and for

15:58.260 --> 16:04.960
this run in the Azure cloud where GitHub actions runs its virtual machines I have used 650

16:04.960 --> 16:09.560
joules of energy and you get a nice ASCII graph over time we are a bit limited here

16:09.560 --> 16:13.960
in the graphs we can display in the GitHub actions overview but you can see here at what

16:13.960 --> 16:18.800
point in time the energy for instance is the highest and then maybe look at the later tests

16:18.800 --> 16:25.200
if they if you deem them to be more energy consuming then for instance at the start where

16:25.200 --> 16:32.120
it was using only a fixed amount of energy so this gives a developer and also user the

16:32.120 --> 16:38.040
information how much energy is not only the software using but also the development of

16:38.040 --> 16:45.280
the software is it maybe using more than we want as developers or maybe even as a community

16:45.280 --> 16:50.820
and these are our concept tools to just get a first start of what we what we think could

16:50.820 --> 16:58.120
be possible what we think could be possible in a new future where software is basically

16:58.120 --> 17:05.920
measured and the data of the of its usage is constantly published by developers also

17:05.920 --> 17:09.920
the idea is then to have something like an open energy badge that is basically in every

17:09.920 --> 17:15.600
repository that tells you for this software and for this usage scenario that comes with

17:15.600 --> 17:21.560
it so be it for instance running the tests or be it for instance building the containers

17:21.560 --> 17:26.400
or the intended use case of the software so let's say the NumPy library of Python has

17:26.400 --> 17:32.760
an energy badge where it says hey for a 1000 times 1000 matrix multiplication this software

17:32.760 --> 17:39.240
uses this amount of energy on the reference system that we have specified and when you

17:39.240 --> 17:43.280
use the same reference systems to compare software against each other you come to a

17:43.280 --> 17:47.920
scenario that we have basically shown from the starters in the first slides where you

17:47.920 --> 17:53.560
can basically tell is the one software more energy hungry than the other one comparing

17:53.560 --> 18:02.600
the same use case so let me quickly get back to my slide deck so let's wrap up measuring

18:02.600 --> 18:07.120
software energy consumption we believe is still too hard the goal should be easy as

18:07.120 --> 18:11.480
starting a docker container and it should happen transparently therefore we have created

18:11.480 --> 18:16.480
the green matrix tool which can reuse docker files and infrastructure files to make it

18:16.480 --> 18:22.160
very easy to orchestrate your architecture and then in a flow that you already have be

18:22.160 --> 18:27.480
it a puppeteer file or be it just a shell script you can run that with our tool just

18:27.480 --> 18:33.800
as a parameter appended and it will tell you how much energy has been used over this particular

18:33.800 --> 18:39.000
scenario that you feed in measuring software is also very complex so this is what we have

18:39.000 --> 18:44.580
integrated best practices or tool like pausing between measurements letting systems idle

18:44.580 --> 18:50.960
before you actually use them turning functionalities like SGX off looking at if turbo boost is

18:50.960 --> 18:56.880
on and very more features just inline measuring like data dog or other providers are doing

18:56.880 --> 19:02.120
it at the moment we believe is not enough and is too arbitrary to talk about energy

19:02.120 --> 19:08.420
software must be measured against a standard usage case so we provide standard usage cases

19:08.420 --> 19:14.360
for software as an interface but we ask you the community also or we need to see over

19:14.360 --> 19:21.120
time what are the standard usage cases we can all agree on a software must be comparable

19:21.120 --> 19:26.800
to another similar software in terms of energy this is why we need these standard usage cases

19:26.800 --> 19:32.840
to make it comparable this also means it must be measured on reference machines that everybody

19:32.840 --> 19:39.040
has access to that we want to provide for the community as a free service energy metrics

19:39.040 --> 19:43.720
must also be available in restricted environments like the cloud so I've talked about estimation

19:43.720 --> 19:49.040
models that need to be open source and available and for everybody to implement and energy

19:49.040 --> 19:54.640
must be transparent and a first auto metric and order in developing and using software

19:54.640 --> 20:00.160
so people should know before they use software how much energy it is consuming and this is

20:00.160 --> 20:04.820
what we are trying to achieve with the tools we are developing I hope it could pick your

20:04.820 --> 20:10.520
interest in our work and in the tools we are developing some as concepts some already production

20:10.520 --> 20:25.360
ready and I thank you for listening and now I hope it's time for questions
