1
0:00:00.000 --> 0:00:10.420
Okay, thank you. Thank you, Rasaan. Actually, after hearing your talk, I'm kind of

2
0:00:10.420 --> 0:00:13.920
concerned I should join the UniCraft community. Sounds to be fun there.

3
0:00:13.920 --> 0:00:17.020
It's a treasure there, Kim.

4
0:00:17.020 --> 0:00:18.020
Yeah, I see.

5
0:00:18.020 --> 0:00:20.020
You don't have to test.

6
0:00:20.020 --> 0:00:26.100
Okay, so my name is Sihan Kunza, as you now heard. I'm the lead maintainer, also the

7
0:00:26.100 --> 0:00:31.720
original person that started that UniCraft project while being still a researcher at

8
0:00:31.720 --> 0:00:38.760
NEC Labs Europe. In the meantime, we spinned off. We have now a startup also called UniCraft,

9
0:00:38.760 --> 0:00:45.080
so it's the UniCraft GmbH, and I'm their CTO and co-founder. And yeah, we're building

10
0:00:45.080 --> 0:00:49.200
a community and a startup at the same time.

11
0:00:49.200 --> 0:00:58.080
So first question into the room, who has used UniCraft before, I would like to know. Okay.

12
0:00:58.080 --> 0:01:07.400
Who has maybe a more theoretical background, what our key concepts in UniCraft are? Okay.

13
0:01:07.400 --> 0:01:15.080
So then, yeah, I'll have some background slides to bring everybody on the same stage. And

14
0:01:15.080 --> 0:01:22.440
then we jump directly into the binary compatibility topic, but I won't spend too much time here.

15
0:01:22.440 --> 0:01:32.720
Okay. So with this picture, I usually start that. You see on the left side the traditional

16
0:01:32.720 --> 0:01:38.880
setup when you have virtual machines and your applications running on them, so I mean, stuff

17
0:01:38.880 --> 0:01:46.640
that you know since 20 years now. Then you have a setup which is more recent, the more

18
0:01:46.640 --> 0:01:53.760
popular is using containers, where you basically run a hostOS on your hardware and then you

19
0:01:53.760 --> 0:02:01.740
use isolation primitives on your host kernel to separate your containers from each other.

20
0:02:01.740 --> 0:02:07.200
And then there's UniCernels. I don't know, is this interrupted somewhere? Okay.

21
0:02:07.200 --> 0:02:14.440
It seems to be okay. Okay. So we think this could be a different execution environment,

22
0:02:14.440 --> 0:02:20.200
especially for the container setup, bringing kind of maraging what you had before with

23
0:02:20.200 --> 0:02:25.680
virtual machines with strong isolation and really more minimal hypervisors underneath

24
0:02:25.680 --> 0:02:32.920
that are much more secure as well. And you don't need to do a shared host base which

25
0:02:32.920 --> 0:02:39.240
can become an attack surface. And then you want the flexibility of containers, and this

26
0:02:39.240 --> 0:02:47.560
is where we think a UniCernel can come in, so where you build a kernel per application.

27
0:02:47.560 --> 0:02:54.800
So the thing is, since you know the application that you run on, you can also give up a lot

28
0:02:54.800 --> 0:03:01.380
of principles you had in standard operating systems and do simplifications, which is totally

29
0:03:01.380 --> 0:03:08.600
okay because it's not hitting your attack vector actually. So if you say one application,

30
0:03:08.600 --> 0:03:12.060
you can go for a flat and single address space because that kernel that you have underneath

31
0:03:12.060 --> 0:03:20.060
is just for your application for nothing else. We in UniCraft build a single monolithic

32
0:03:20.060 --> 0:03:26.360
binary usually, so it's your application plus the kernel layers, and everything ends up

33
0:03:26.360 --> 0:03:37.360
in function calls into drivers. And you get then further benefits, first by this simple

34
0:03:37.360 --> 0:03:42.840
setup but also since you know your environment, you know where you run on, you know what you

35
0:03:42.840 --> 0:03:49.640
run, so you can specialize the kernel layers that you need underneath. So you put only

36
0:03:49.640 --> 0:03:54.240
drivers that you need to run on your target hypervisor. You build a separate image if you

37
0:03:54.240 --> 0:03:59.160
run that application with a different hypervisor. So floppy drivers, forget it, you don't need

38
0:03:59.160 --> 0:04:06.840
it. Virta.io only for KVM guests. Zen.netfront, for instance, only for Zen guests. And you

39
0:04:06.840 --> 0:04:12.120
know the application, you have knowledge which features of the OS is needed, and that way

40
0:04:12.120 --> 0:04:18.600
you can also from the top down specialize the operating system to just provide that

41
0:04:18.600 --> 0:04:27.880
what you need. So this makes us also slightly different from the other UniCrun projects

42
0:04:27.880 --> 0:04:34.880
maybe that you had heard of, so we are for sure not the first ones. But we claim we are

43
0:04:34.880 --> 0:04:41.880
the ones that follow at least this principle as most strongest because we build it from

44
0:04:41.880 --> 0:04:47.640
the beginning with that in mind, which is specialization. So everything that we implement

45
0:04:47.640 --> 0:04:56.720
should never dictate any design principles. The concept is you know what you need for

46
0:04:56.720 --> 0:05:04.120
your application, you know what you need to run your UniCrunals, so I want to give you

47
0:05:04.120 --> 0:05:12.160
a highly customizable base where you pick and choose and configure of components and

48
0:05:12.160 --> 0:05:23.320
specialize the kernel for you. So that led us to this principle, everything is a microlibrary,

49
0:05:23.320 --> 0:05:28.600
which means for us even OS primitives are microlibraries, meaning a scheduler is a microlibrary,

50
0:05:28.600 --> 0:05:33.560
a specific scheduler implementation is a microlibrary, so like a cooperative scheduler

51
0:05:33.560 --> 0:05:40.080
or some schedulers that do a preemptive scheduling are different libraries, memory allocators,

52
0:05:40.080 --> 0:05:45.640
also things like VFS, network stacks, the architectures, the platform supports and the

53
0:05:45.640 --> 0:05:52.040
drivers are all libraries and because we are also going up the stack, the application interfaces.

54
0:05:52.040 --> 0:05:58.520
So everything that has to do with POSIX, even that is split into multiple POSIX subsystem

55
0:05:58.520 --> 0:06:05.480
libraries, the Linux system called ABI, which you will see in this talk now, and even language

56
0:06:05.480 --> 0:06:17.240
run times, if you let's say run a JavaScript UniCrunal, you can build it with a JS engine.

57
0:06:17.240 --> 0:06:25.160
And the project consists basically of a K config based configuration system and a build

58
0:06:25.160 --> 0:06:31.720
system also make based to not come up with yet another build system, to make actually

59
0:06:31.720 --> 0:06:36.440
entrance easy when people are familiar with Linux before.

60
0:06:36.440 --> 0:06:40.800
And our library pool actually.

61
0:06:40.800 --> 0:06:47.920
And to give you a rough idea of how this library pool is organized, I find this diagram nice,

62
0:06:47.920 --> 0:06:52.040
so let's see if this works at this point.

63
0:06:52.040 --> 0:06:59.800
So we divide roughly, so you don't find it that way in the repos, but we write roughly

64
0:06:59.800 --> 0:07:06.320
the libraries into these different categories, so you have like here on the bottom, the platform

65
0:07:06.320 --> 0:07:12.040
layer which basically includes drivers and platform support where you run on.

66
0:07:12.040 --> 0:07:16.600
Then we have this OS primitives layer, these are then libraries that implement like a TCP

67
0:07:16.600 --> 0:07:23.680
IP stack or file systems or something regarding scheduling, memory allocation, etc., etc.

68
0:07:23.680 --> 0:07:30.480
And then always in mind there's like first the opportunity for you to replace components

69
0:07:30.480 --> 0:07:34.200
in here and also that we provide also alternatives.

70
0:07:34.200 --> 0:07:38.120
So you don't need to stick with light may IP if you don't like it, so you can provide

71
0:07:38.120 --> 0:07:44.760
your own network stack here as well and reuse the rest of the stack too.

72
0:07:44.760 --> 0:07:49.560
Then we have this POSIX compatibility layer, this is basically things here, FDTA, this

73
0:07:49.560 --> 0:07:55.040
is for instance file descriptor handling as you know it, POSIX process has then aspects

74
0:07:55.040 --> 0:08:01.400
about process IDs, process handling, etc., pthread API of course.

75
0:08:01.400 --> 0:08:09.400
And then we have a libc layer where we also have at the moment actually three libcs, muscle

76
0:08:09.400 --> 0:08:15.160
which is becoming our main thing now, a new lib that we had in the past to actually provide

77
0:08:15.160 --> 0:08:19.880
all the libc functionally to the application but also actually for the other layers too.

78
0:08:19.880 --> 0:08:28.880
It provides also things like mem copy which is like all over the place used.

79
0:08:28.880 --> 0:08:36.480
Then Linux application compatibility, that was now a big topic for this release.

80
0:08:36.480 --> 0:08:39.320
Why do we do application compatibility?

81
0:08:39.320 --> 0:08:47.400
It's actually for us for adoption, to drive the adoption because most cloud software is

82
0:08:47.400 --> 0:08:50.160
developed for Linux.

83
0:08:50.160 --> 0:08:54.920
People are used to their software so we don't feel confident to ask them to use something

84
0:08:54.920 --> 0:08:59.240
new or rewrite stuff from scratch.

85
0:08:59.240 --> 0:09:04.440
And if you provide something like Linux compatibility you remove all the obstacles that people start

86
0:09:04.440 --> 0:09:10.360
using UniCraft because they can run their application with UniCraft.

87
0:09:10.360 --> 0:09:16.800
And our vision behind the project is to give seamless application support.

88
0:09:16.800 --> 0:09:25.960
So the users that say they tell you I use that in that web server and it should be like

89
0:09:25.960 --> 0:09:32.040
with the push of a button, so including with some tooling that we provide that we can run

90
0:09:32.040 --> 0:09:37.680
that on UniCraft as they run it before on Linux and they benefit from all these nice

91
0:09:37.680 --> 0:09:42.600
UniColonal properties which are lower boot times, less memory consumption and also improved

92
0:09:42.600 --> 0:09:50.480
performance.

93
0:09:50.480 --> 0:09:59.440
So now speaking about which possibilities you have for supporting Linux compatibility,

94
0:09:59.440 --> 0:10:06.560
we divide actually compatibility into two main tracks.

95
0:10:06.560 --> 0:10:13.120
One track is so-called native which means that we have the application sources and we

96
0:10:13.120 --> 0:10:18.000
compile that together and link that together with the UniCraft build system.

97
0:10:18.000 --> 0:10:23.800
And then we have on the other side the binary compatibility mode where the story is that

98
0:10:23.800 --> 0:10:31.000
the application is built externally and we just get binary artifacts or the final image

99
0:10:31.000 --> 0:10:33.720
event.

100
0:10:33.720 --> 0:10:38.760
And then actually you can subdivide these two tracks.

101
0:10:38.760 --> 0:10:45.440
On the native side we have which we did actually quite a lot until recently this UniCraft driven

102
0:10:45.440 --> 0:10:51.920
compilation which basically meant that when you have your application you had to port

103
0:10:51.920 --> 0:10:58.800
or mimic the application's original build system with the UniCraft build system and

104
0:10:58.800 --> 0:11:01.680
then you compile all the sources with UniCraft.

105
0:11:01.680 --> 0:11:07.520
Has the benefit that you're then staying in one universe and don't have potential conflicts

106
0:11:07.520 --> 0:11:17.440
with compiler flags or things that influence your calling conventions between objects.

107
0:11:17.440 --> 0:11:22.480
And then there is this way that you probably have also seen for instance with RAM kernels.

108
0:11:22.480 --> 0:11:30.000
They did it a lot using an instrumented way where you actually utilize the build system

109
0:11:30.000 --> 0:11:36.720
of an application with the cross compile feature and then you hook in and that's your entry

110
0:11:36.720 --> 0:11:45.400
point into replacing the compile calls and make it fit for your UniCraft.

111
0:11:45.400 --> 0:11:50.560
And then on the binary compatibility side we have so let's start here because that's

112
0:11:50.560 --> 0:11:51.720
easier.

113
0:11:51.720 --> 0:12:00.320
So of course so externally built and this means basically you have elf files so like

114
0:12:00.320 --> 0:12:04.480
a shared library or an elf application.

115
0:12:04.480 --> 0:12:08.240
What you need here is basically just to support loading that and get that into your address

116
0:12:08.240 --> 0:12:11.380
space and then run it.

117
0:12:11.380 --> 0:12:18.240
And then there's also this flavor of let's say build time linking which means that you

118
0:12:18.240 --> 0:12:25.880
take some build artifacts from the original application build system like the intermediate

119
0:12:25.880 --> 0:12:32.120
object files before it does the final link to the application image and you link those

120
0:12:32.120 --> 0:12:36.160
together with the UniCraft system.

121
0:12:36.160 --> 0:12:44.320
And I call it here binary compatible because you interface it on an API and not on the

122
0:12:44.320 --> 0:12:50.240
API level like in the native cases.

123
0:12:50.240 --> 0:12:58.680
So and here this is just a little mark that in the UniCraft project you will mostly find

124
0:12:58.680 --> 0:13:04.080
these three modes in the project that people are working on.

125
0:13:04.080 --> 0:13:09.800
So here that we never tried with UniCraft in fact but I mean some tooling and this should

126
0:13:09.800 --> 0:13:13.960
work too actually.

127
0:13:13.960 --> 0:13:22.060
So as you may have noticed native is about API compatibility so really on the programming

128
0:13:22.060 --> 0:13:27.600
interface and binary compatibility is about the application binary interface so really

129
0:13:27.600 --> 0:13:34.760
the compiled artifacts and how you have calling conventions here etc.

130
0:13:34.760 --> 0:13:40.160
Where are your arguments in which register or how is your stack layout etc.

131
0:13:40.160 --> 0:13:47.180
And this is here on a programming language level.

132
0:13:47.180 --> 0:13:57.160
So the requirements for providing you let's say a native experience is POSIX and POSIX.

133
0:13:57.160 --> 0:14:04.920
Most applications are written for POSIX so we have to do POSIX no excuse right.

134
0:14:04.920 --> 0:14:13.800
So libc's will mostly cover that but yeah it's all about POSIX.

135
0:14:13.800 --> 0:14:21.560
And the second point is that you also need to port the libraries that your application

136
0:14:21.560 --> 0:14:28.160
additionally uses let's say yeah let's take engine access and web so right you have then

137
0:14:28.160 --> 0:14:34.480
tons of library dependencies for instance for cryptographic things like setting up HTTPS

138
0:14:34.480 --> 0:14:37.080
tunnels or doing some other things.

139
0:14:37.080 --> 0:14:46.680
So those libraries you need also port here and add them so that you have the application

140
0:14:46.680 --> 0:14:50.800
sources available during the build right.

141
0:14:50.800 --> 0:14:57.360
On the binary compatibility side the requirements are you need to understand the else format,

142
0:14:57.360 --> 0:15:04.400
shared libraries or binaries depending on which level you are driving it and then since

143
0:15:04.400 --> 0:15:12.840
this stuff got built for Linux you must be aware that it can happen that that binary

144
0:15:12.840 --> 0:15:17.960
will do directly a system call so it's instrumented because it got built together with a libc or

145
0:15:17.960 --> 0:15:24.960
something like that to do an syscall assembly instruction which means on our side we need

146
0:15:24.960 --> 0:15:28.840
to be able to handle those system calls as well.

147
0:15:28.840 --> 0:15:35.760
And if we speak about shared library support we need to support all this library function

148
0:15:35.760 --> 0:15:39.280
or library symbol linking actually right.

149
0:15:39.280 --> 0:15:46.000
And additionally of course each data that is exchanged needs to be in the same representation.

150
0:15:46.000 --> 0:15:52.920
This means because this is ABI right now imagine you have a C struct and here it's fine to

151
0:15:52.920 --> 0:15:57.200
move some fields around because if you use the same definition for your compilation is

152
0:15:57.200 --> 0:16:01.480
all fine you can sort the fields in the struct will all work.

153
0:16:01.480 --> 0:16:08.680
Here you can't because your application they got built externally that layout of that struct

154
0:16:08.680 --> 0:16:15.120
that binary layout that must fit otherwise you will read different fields right obviously.

155
0:16:15.120 --> 0:16:21.120
And then for both modes which is important for us as an operating system we have of course

156
0:16:21.120 --> 0:16:25.160
also some things that we need to provide to the application which are things that the

157
0:16:25.160 --> 0:16:31.800
application just requires because it is that way on Linux meaning providing a procfs or

158
0:16:31.800 --> 0:16:39.280
syscfs entries or files in slash etc or something like that right for because you know they

159
0:16:39.280 --> 0:16:43.600
do they do sometimes silly things just to figure out in which time soon there are so

160
0:16:43.600 --> 0:16:52.800
they go to slash etc and figure out what is configured and also the locales and etc.

161
0:16:52.800 --> 0:16:58.040
So in closing that let's say this high level view up so that we have the full understanding

162
0:16:58.040 --> 0:17:03.920
let's speak a bit about the pros and cons between these two modes.

163
0:17:03.920 --> 0:17:10.400
The native side what is really nice here which is a really interesting pro so if you've

164
0:17:10.400 --> 0:17:19.360
got everything put together you have quite of a natural way to change code in the application

165
0:17:19.360 --> 0:17:28.000
to change code in the kernel to make maybe shortcuts between the application kernel interaction

166
0:17:28.000 --> 0:17:34.920
and can use that for driving your specialization even further right and performance tune your

167
0:17:34.920 --> 0:17:40.880
unique kernel for that application. The disadvantages you always need the source

168
0:17:40.880 --> 0:17:47.480
codes because we are compiling everything here together and which is also let's say

169
0:17:47.480 --> 0:17:57.000
for newcomers a bit difficult is if you require them that the application they have and they

170
0:17:57.000 --> 0:18:01.320
say okay I have the source codes and I just run make and then it compiles but I have the

171
0:18:01.320 --> 0:18:05.880
source code you need to instrument either the build system of the application as we

172
0:18:05.880 --> 0:18:13.560
just saw with the instrument to build that also prompted or you actually we must say

173
0:18:13.560 --> 0:18:19.600
okay sorry you can't use that build system now you need to mimic and write and uni-craft

174
0:18:19.600 --> 0:18:30.800
make file equivalent to build your application. So this is why binary compatibility is actually

175
0:18:30.800 --> 0:18:35.720
interesting really interesting for let's say newcomers because you don't need the source

176
0:18:35.720 --> 0:18:41.040
code they can compile the application that they're interested in so if they need to compile

177
0:18:41.040 --> 0:18:46.960
it let's say right the way as they usually do they don't need to care about uni-craft at all and

178
0:18:46.960 --> 0:18:53.640
normally also no modifications to the application is needed obviously you can still do things here

179
0:18:53.640 --> 0:19:03.160
but it's not a requirement. The risk that we saw by doing the work is at least for the for let's

180
0:19:03.160 --> 0:19:10.520
say on the uni-kernel side is that you get into a risk that you need to implement things the way

181
0:19:10.520 --> 0:19:17.880
how Linux does it and one really stupid example I get a bit nuts on that is providing an

182
0:19:17.880 --> 0:19:25.360
implementation for Netlink sockets because if you have like a web application or you know any

183
0:19:25.360 --> 0:19:30.960
application that does some networking and that application wants to figure out which networking

184
0:19:30.960 --> 0:19:35.440
interfaces are configured and what are the IP addresses there so it will likely lose the libc

185
0:19:35.440 --> 0:19:43.440
function get if address and that is implemented with a Netlink socket so this goes back here

186
0:19:43.440 --> 0:19:47.920
right here I can just provide a get if address which is highly optimized in that sense right

187
0:19:47.920 --> 0:19:53.640
which just returns in that struct all the interfaces but if I go binary compatible and if

188
0:19:53.640 --> 0:20:02.840
I do it really don't an extreme means because that libc which is part of your binary here maybe opens

189
0:20:02.840 --> 0:20:07.660
a socket which is address family Netlink and starts communicating about a socket with the

190
0:20:07.660 --> 0:20:14.400
kernel to figure out the interface addresses which can be really silly right for a uni-kernel

191
0:20:14.400 --> 0:20:20.880
right to do and then also it's maybe it's less opportunities but also a bit harder to specialize

192
0:20:20.880 --> 0:20:27.040
in tune the kernel application interaction right because assuming you don't have access to the

193
0:20:27.040 --> 0:20:34.240
source code of the application there's nothing you can do on the application side right so to give

194
0:20:34.240 --> 0:20:41.400
you a rough idea what that means in performance because it uni-craft let's say the the second

195
0:20:41.400 --> 0:20:50.960
important thing for us is always performance performance performance here we we just show

196
0:20:50.960 --> 0:20:58.600
you nginx here compiled as a as a native version so meaning it uses the uni-craft build system to

197
0:20:58.600 --> 0:21:06.040
build the nginx sources versus we run nginx on we call it elf loader so this is actually our

198
0:21:06.040 --> 0:21:15.080
uni-craft application to load elf binaries and then a comparison here with a standard Linux and here

199
0:21:15.080 --> 0:21:22.680
this is the same binary what that means in performance so it's this quick test we have

200
0:21:22.680 --> 0:21:30.720
just the index page the standard default of any nginx installation served and this is like that the

201
0:21:30.720 --> 0:21:39.520
performance numbers the takeaway here is if you just you know don't go into any special performance

202
0:21:39.520 --> 0:21:45.280
tuning yes and start just you know getting the thing compiled and run you will end up in a similar

203
0:21:45.280 --> 0:21:55.120
performance as if you just take the you know the elf loader to to run that application in binary

204
0:21:55.120 --> 0:22:02.240
compatibility mode that is interesting because you don't need to see necessarily huge performance

205
0:22:02.240 --> 0:22:09.120
drops the only thing that you lose is the potential to further optimize in this mode if you go for

206
0:22:09.120 --> 0:22:16.400
this one but this the nice thing is you can still see benefits right running your application on

207
0:22:16.400 --> 0:22:26.760
uni-craft right and to just give you an impression so this is here a go HTTP application where we go

208
0:22:26.760 --> 0:22:32.520
a bit crazy about we are optimizing and specializing the interaction between the go application and

209
0:22:32.520 --> 0:22:39.840
uni-craft yeah we can get more out of this we can really performance to increase stuff out of it

210
0:22:39.840 --> 0:22:52.960
okay so now in the next slides I go over how we implement these modes with uni-craft because as

211
0:22:52.960 --> 0:22:59.960
I said we we don't want to target just one mode we want to target multiple modes and it has also

212
0:22:59.960 --> 0:23:08.600
some implementation challenges because as an engineer you also want to reuse code as much as

213
0:23:08.600 --> 0:23:20.080
possible so we'll talk about the structure here okay so to give you an overview so this doesn't

214
0:23:20.080 --> 0:23:26.120
mean now this that these applications run at the same time could be also be possible but it's just

215
0:23:26.120 --> 0:23:33.480
to show you how the components get involved in our ecosystem so if you take just the left part the

216
0:23:33.480 --> 0:23:43.840
native port of application we settle now on muscle to provide all the libc functionality that the

217
0:23:43.840 --> 0:23:51.040
application needs and we have we have a library called syscall shim which is actually the heart

218
0:23:51.040 --> 0:24:00.160
of our application compatibility and this is actually you can imagine this is a bit of a

219
0:24:00.160 --> 0:24:06.720
registry where you know it knows where in which sub library a system called handler is implemented

220
0:24:06.720 --> 0:24:13.840
and it can forward then the muscle calls to those places on the binary compatibility side you have

221
0:24:13.840 --> 0:24:19.480
a library called this elf loader which is the the library that loads an elf binary into memory and

222
0:24:19.480 --> 0:24:28.640
then here's the syscall shim taking care of handling binary system calls and now I will go

223
0:24:28.640 --> 0:24:35.080
into the individual items to show a bit bit more zoomed in view what's happening there and we of

224
0:24:35.080 --> 0:24:46.320
course you start with the heart with the core the syscall shim so here we have I mean some macros

225
0:24:46.320 --> 0:24:53.920
when so when you develop like VFS core is our VFS library actually ported from OSB or POSIX

226
0:24:53.920 --> 0:25:00.200
process where you do some some process functionality like get PID or something like that we have some

227
0:25:00.200 --> 0:25:06.520
some macros that help you to define and a system call handler and it's really a system

228
0:25:06.520 --> 0:25:12.840
kind of it's just a function that is defined at that point and you will register this to the

229
0:25:12.840 --> 0:25:22.400
syscall shim then the the shim provides you two options how that system called handler can be

230
0:25:22.400 --> 0:25:31.320
reached one is that compile time this is like macros macros and preprocessor which allows you

231
0:25:31.320 --> 0:25:37.520
when you have a native application that does or they actually it's on the on the muscle side to

232
0:25:37.520 --> 0:25:44.560
call a system call it will replace those calls or will return at compile time the function of

233
0:25:44.560 --> 0:25:54.000
that library that implements that system call then it was also a runtime handler which is provided

234
0:25:54.000 --> 0:26:02.400
here which does you know the typical syscall trap and running that function and behind the scenes

235
0:26:02.400 --> 0:26:12.400
yeah and our aim as I mentioned we want to use we use code as much as possible so the idea is

236
0:26:12.400 --> 0:26:18.760
that we implement that function for that system called just once and the syscall shim is helping

237
0:26:18.760 --> 0:26:26.800
us depending on the modes doing a link or provided as binary compatible so let's go back to the

238
0:26:26.800 --> 0:26:33.080
overview and then you will see it a bit more concrete with muscle but probably I said everything

239
0:26:33.080 --> 0:26:42.400
already so we have muscle natively compiled with a unicraft build system now imagine you have the

240
0:26:42.400 --> 0:26:47.520
application you have a write goes to muscle and muscle does then a UK syscall r write which is

241
0:26:47.520 --> 0:26:54.720
then actually the symbol that is provided by the actual library that's implementing it and the

242
0:26:54.720 --> 0:27:02.560
the rewriting happens as I said with the macros at compile time in libmuscle so what we did for

243
0:27:02.560 --> 0:27:11.320
that is to replace that syscall muscle internal function with our syscall macro which then kicks

244
0:27:11.320 --> 0:27:19.960
in the whole machinery to map a system call request to the direct function call the thing is that in

245
0:27:19.960 --> 0:27:27.600
muscle not all but most of the system call requests have a static argument with the system

246
0:27:27.600 --> 0:27:33.840
call number first so so so this this let's say write is an MC wrapper and internally there they're

247
0:27:33.840 --> 0:27:39.720
setting preparing the arguments just maybe some checks before they go to the kernel and then they

248
0:27:39.720 --> 0:27:45.440
have this syscall function with the number of the system call and then the arguments hand it over

249
0:27:45.440 --> 0:27:53.560
and as soon that number is a const static you know just just written down in your code literally we

250
0:27:53.560 --> 0:27:59.080
can do a direct mapping so that that right will directly do a function call with you kiss is cool

251
0:27:59.080 --> 0:28:06.280
alright if if it's not static which is really happening only on two three places if I remember

252
0:28:06.280 --> 0:28:11.440
correctly then of course we can provide an intermediate function that then does a switch

253
0:28:11.440 --> 0:28:18.560
case and switch and jumps them to the actual system call handler and the thing is since everything

254
0:28:18.560 --> 0:28:24.840
is configurable means I can have a build where be this core is not part of the build or POSIX

255
0:28:24.840 --> 0:28:30.360
process is not part of the build then the syscall symbol automatically also with all this macro

256
0:28:30.360 --> 0:28:38.680
magic that we do replace calls to non-existing system call handles with an inosys stop so that

257
0:28:38.680 --> 0:28:47.760
for the applications look like a functional to implement it yeah and exactly so it's runtime

258
0:28:47.760 --> 0:28:52.560
this is called shim is for that point out out of the game so everything happens at the compartment

259
0:28:52.560 --> 0:29:02.160
so for the binary compatibility side that's unfortunately runtime thing and we have actually

260
0:29:02.160 --> 0:29:09.960
two components here as I was mentioning the elf load itself which loads the the elf application

261
0:29:09.960 --> 0:29:17.160
what we support today is static pies so if you have a static position independent executable

262
0:29:17.160 --> 0:29:26.320
compiled you can run that and what also works is using your let's say with your libc together

263
0:29:26.320 --> 0:29:32.200
provided dynamic linker meaning if you use glibc with the application you can use that dynamic

264
0:29:32.200 --> 0:29:40.640
linkers so LD or SO and also run dynamically linked applications with that what it needs

265
0:29:40.640 --> 0:29:47.280
is POSIX mapp as a library which implements all these mapp and unapp and protect functions

266
0:29:47.280 --> 0:29:56.840
on the on the system call there then system calls are trapped here this is called shim and yeah I

267
0:29:56.840 --> 0:30:04.120
think I said that then the library is not selected it's replaced with inosys so this is called shim

268
0:30:04.120 --> 0:30:10.320
knows which system calls are available which which are not then there's a bit of a specialty

269
0:30:10.320 --> 0:30:20.600
for handling a system call so the the system called trap handler so we provide it with a

270
0:30:20.600 --> 0:30:27.860
system call shim and we don't need to do an domain switch so we have still a single address

271
0:30:27.860 --> 0:30:38.720
space a single what's called not forget the word so it's all kernel privilege yeah so we have done

272
0:30:38.720 --> 0:30:43.640
it's the same privilege domain exactly so we don't have a privilege domain switch as well right now

273
0:30:43.640 --> 0:30:54.520
we have it good good good you learn something but we are sliding a different environment that

274
0:30:54.520 --> 0:31:00.520
will show you later in the slide exactly what this means we have some different assumptions

275
0:31:00.520 --> 0:31:08.240
that you have on the Linux system called API which requires us to do some extra steps unfortunately

276
0:31:08.240 --> 0:31:15.520
so the first thing is Linux does not use extended register or if they use it they they guard it

277
0:31:15.520 --> 0:31:24.040
meaning extended registers are floating point units vector units MMX SSE you know we do

278
0:31:24.040 --> 0:31:28.560
unfortunately so we need to save that state because that's unexpected for an application

279
0:31:28.560 --> 0:31:34.680
that was compiled for Linux before that these units could screw up when coming back from a

280
0:31:34.680 --> 0:31:44.400
system call and the second thing is we don't have a TLS you know in the Linux kernel but

281
0:31:44.400 --> 0:31:51.280
unfortunately on uni craft we have so we use the same even unfortunately the same TLS register so

282
0:31:51.280 --> 0:31:57.560
we also need to save and restore that so that the application keeps its TLS and all the uni craft

283
0:31:57.560 --> 0:32:07.400
functions operate on the uni craft TLS good before I continue and give you some let's say lessons

284
0:32:07.400 --> 0:32:14.080
learned while implementing all these things I would like to give you a short demo and then

285
0:32:14.080 --> 0:32:22.640
I give you speak a bit about what was tricky during the implementation and what our special

286
0:32:22.640 --> 0:32:33.140
considerations that we had to do so then let's hope that this works so this is a super fresh

287
0:32:33.140 --> 0:32:41.040
demo is don't touch it you will burn your fingers my colleagues so thank you mark for getting that

288
0:32:41.040 --> 0:32:51.040
work just you know half an hour before the talk yeah he's amazing yeah okay so in this demo I have

289
0:32:51.040 --> 0:32:57.120
actually engine X as a web server with a standard file system I'll show you with the files around

290
0:32:57.120 --> 0:33:03.160
I have it once compiled natively and once compiled as a Linux application will run it with the

291
0:33:03.160 --> 0:33:10.680
off-loader and you will see that the result is the same right so let's start with the native one

292
0:33:10.680 --> 0:33:17.440
so I'm actually already so probably I need to increase a bit the size right that you can read

293
0:33:17.440 --> 0:33:27.920
it the background is that good yeah that's to any hit you so I hope you can also in the last row

294
0:33:27.920 --> 0:33:41.480
you can read perfect so yeah you have here the the engine X app checked out so we have my new

295
0:33:41.480 --> 0:33:52.840
config so you can oh this the windows somehow wider no wait just one second no it's better

296
0:33:52.840 --> 0:34:03.880
okay so you see the the application is here as an library here the engine X and then you have here

297
0:34:03.880 --> 0:34:12.360
the configuration you know of of you know all this HTTP modules that engine X provides and you can

298
0:34:12.360 --> 0:34:19.880
select and choose like this is really the uni craft way to do things because it builds a while and

299
0:34:19.880 --> 0:34:32.320
for that that my laptop is not the fastest I built it already so you see here the result of the the

300
0:34:32.320 --> 0:34:38.680
build directory you see each individual library that because of dependencies we're coming in and

301
0:34:38.680 --> 0:34:50.320
we're compiled so like for instance POSIX, Feutex, POSIX socket, RAMFS, in memory file system and the

302
0:34:50.320 --> 0:35:05.120
where is it now the application here that's the application image uncompressed so wait I can do

303
0:35:05.120 --> 0:35:19.480
let you see how big it is so it's here 1.1 megabyte so this is like it a full image of engine X

304
0:35:19.480 --> 0:35:29.080
including muscle including all the kernel code and driver to run on a chemo KVM x-rated machine

305
0:35:29.080 --> 0:35:41.880
yeah and then let's let's run it to see what what happens so exactly it's already up and running to

306
0:35:41.880 --> 0:35:50.640
show you these were roughly the arguments so we have in the meantime because I found chemo system

307
0:35:50.640 --> 0:35:57.320
sometimes a bit brutal with command line arguments a wrapper script that shortens a few things but

308
0:35:57.320 --> 0:36:05.120
in the end I mean this is this is running a chemo system and then you know it's attaching to this

309
0:36:05.120 --> 0:36:15.120
virtual bridge take that kernel image load that in ID file system because we we serve a file from

310
0:36:15.120 --> 0:36:21.240
from that RAMFS and here's also some parameters to set the IP address and that mask for that guest

311
0:36:21.240 --> 0:36:32.520
and here down there so we can check actually see here set IPV4 that's the address where the unicorn

312
0:36:32.520 --> 0:36:43.960
is up and yeah you see here with this w get line that yeah I get the page served and to prove that

313
0:36:43.960 --> 0:36:53.720
this is real let kill let us kill this now the guest is gone and this is dead so no response

314
0:36:53.720 --> 0:37:03.440
anymore good so now let's go to the elf loader which is also treated as an application that can

315
0:37:03.440 --> 0:37:16.000
run other applications also here in the build directly let's do the same thing so has also

316
0:37:16.000 --> 0:37:22.520
like similar dependencies of course it's prepared to run nginx so POSIX socket is there etc etc

317
0:37:22.520 --> 0:37:33.080
where's G here so here's the image it's a bit smaller is now 526 kilobytes which provides

318
0:37:33.080 --> 0:37:37.720
your environment to run and Linux elf of course the nginx image is not included here anymore right

319
0:37:37.720 --> 0:37:47.720
so that is part of the rule file system and if I run this now so I so on purpose I enabled now

320
0:37:47.720 --> 0:37:53.960
some debug output so that you see the proof that it does system calls well if you scroll up so the

321
0:37:53.960 --> 0:38:00.120
initialization phase looks a bit different also sets the IP address here it extracting the the

322
0:38:00.120 --> 0:38:10.840
the in it RD and here is starting to load the nginx binary the Linux binary from the in it ID and then

323
0:38:10.840 --> 0:38:17.240
from that point on the elf loader was jumping into the application and you see every system call

324
0:38:17.240 --> 0:38:25.520
that the application was doing and you can even see that you know some stuff probably this is

325
0:38:25.520 --> 0:38:32.960
first GLC initialization here for instance etc local time it's trying to open and find some

326
0:38:32.960 --> 0:38:38.560
configuration of course we don't have it we could provide one but it's still fine it's continuous

327
0:38:38.560 --> 0:38:54.320
booting affinity we don't have so but whatever it continues yeah exactly and there's tons of mmaps

328
0:38:54.320 --> 0:39:01.520
and you know EDC password etc so those files we had provide so you get a file descriptor returned

329
0:39:01.520 --> 0:39:09.400
back otherwise would have stopped etc and then you know configuration and so forth and now you

330
0:39:09.400 --> 0:39:16.560
should see that some system will happen when I access the access the page and you saw it happened

331
0:39:16.560 --> 0:39:24.720
index was opened file descriptor 7 and here is there should be a right to the socket you know

332
0:39:24.720 --> 0:39:31.800
over here this is probably the socket number four yeah I mean you get you get the impression what's

333
0:39:31.800 --> 0:39:40.440
going on so it's working the same way okay how much time I do I have left five minutes five minutes

334
0:39:40.440 --> 0:39:46.280
okay then actually three minutes just to leave some room for questions yeah exactly okay so let's

335
0:39:46.280 --> 0:40:01.960
get quickly back so we had some learned lessons learned lessons for the native mode I mean the

336
0:40:01.960 --> 0:40:07.320
thing is we have we have also this model like you heard the noise V we want to use just one libc in

337
0:40:07.320 --> 0:40:12.400
our build right so meaning all the kernel implementation and all everything that the

338
0:40:12.400 --> 0:40:19.560
application needs is one libc we provide multiple implementations of libc because muscle might be

339
0:40:19.560 --> 0:40:24.720
for some users cases too thick still or too big so we have some and the alternative like no libc

340
0:40:24.720 --> 0:40:31.760
and originally we had new lib and we need also what we want as well in our project is to keep

341
0:40:31.760 --> 0:40:37.040
the libc as vanilla as possible like upstream as possible because we want to keep the maintenance

342
0:40:37.040 --> 0:40:45.000
effort for updating the libc versions low but these causes then I mean let's just list them

343
0:40:45.000 --> 0:40:52.120
I've speak just about one of these items some things that that you stumble on and one was quite

344
0:40:52.120 --> 0:40:59.040
interesting was this get dense 64 issue that cost us some headache was many rust when fixing it

345
0:40:59.040 --> 0:41:04.720
which caused or required actually a patch I've always fixing it yeah I've required a patch to

346
0:41:04.720 --> 0:41:11.480
muscle the thing what happened here is that in this dear end dot H muscle is providing a mark

347
0:41:11.480 --> 0:41:19.120
and alias right to use the non 64 version for get dense and if it finds code with using get that get

348
0:41:19.120 --> 0:41:25.480
dense 64 because of this large file system support thing that was happening it maps it to get dense

349
0:41:25.480 --> 0:41:32.200
right on the other side on the vfs of the first course side so this is the VFS implementation

350
0:41:32.200 --> 0:41:37.840
where we provide the system call we need to provide both obviously we need to provide the

351
0:41:37.840 --> 0:41:44.640
non 64 version and the 64 version and guess what we include dear end because we need a struct

352
0:41:44.640 --> 0:41:51.720
definition here and then you can imagine so if you're familiar with C and preprocessor there's

353
0:41:51.720 --> 0:41:58.280
a little hint with this thunder of course I mean this gets replaced and then you have two times

354
0:41:58.280 --> 0:42:07.080
the same symbol and you're like what the hell is going on here all right yeah so let's keep this

355
0:42:07.080 --> 0:42:17.200
because of time upcoming features Russell was telling a bit already especially for this topic

356
0:42:17.200 --> 0:42:21.960
for application compatibility we will further improve it so this will be now our first release

357
0:42:21.960 --> 0:42:30.400
to officially release out loader and an updated muscle version we want to make that more seamless

358
0:42:30.400 --> 0:42:38.480
which requires a bit more under the hood libraries for that support you should also watch out for

359
0:42:38.480 --> 0:42:42.960
features that are coming up for a seamless integration of unicraft into your Kubernetes

360
0:42:42.960 --> 0:42:50.600
deployment no pressure Alex running unicraft on your infrastructure provider for instance AWS

361
0:42:50.600 --> 0:42:59.600
Google Cloud etc and automatically packaging of your applications right and it would love or

362
0:42:59.600 --> 0:43:04.840
actually all of us everyone with a new culture will off to hear also your feedback and what you

363
0:43:04.840 --> 0:43:12.680
think about you know turning the cloud with unicorns to the next level yeah any feedback to me please

364
0:43:12.680 --> 0:43:37.840
send to Simone right and these are again the project resources if you're interested you can just scan the QR code I think that's it okay Simone right we can take a couple of questions you can also address me to listen to me I mean yeah yeah so any quick yeah please first here and then on the back

365
0:43:42.800 --> 0:43:49.640
yeah thanks a lot both of you for your talks I have a question regarding dynamically linked applications yeah

366
0:43:49.640 --> 0:44:09.920
Linux as far as I can see you only use muscle and how does this work out if my application is linked against GWC and I want to run it with yeah I've loaded what do I have to do because in Linux world when I think against GWC and I only have muscle nothing works right right no so I'm so I'm assuming we

367
0:44:09.920 --> 0:44:20.840
speak you know about the binary compatibility mode in the end what you just need to do is providing the muscle loader if you have compiled with your application with muscle or the G.

368
0:44:20.840 --> 0:44:36.680
Lipsy loaded and then both works the thing is in that setup in memory there is actually two lip sees there's the lip see on the uni craft side and there's the lip see with your application so that's why it works seamless actually okay thank you

369
0:44:36.680 --> 0:45:06.280
so just add to that when you build your unique kernel for binary compatibility you don't use muscle I mean you can if you want I mean because the entire lip see is provided by the application either by the application of course that the binary or the application plus it's lip see inside the root file system and it's loaded from there there's no need to have anything like that yeah please yeah yeah so the question is about the

370
0:45:06.280 --> 0:45:35.280
API you spoke about the POSIX API yeah you also add a diagram showing a direct link to unique kernel so the question is is there some variable next diagram perhaps one of the next day at the other arm okay is it a variable use case yes this one there is a link

371
0:45:35.280 --> 0:46:05.240
directly from the native application to the unique kernel yeah yeah this is what it shows you is like how the calls are going it can happen because some system calls don't have a provided lip see wrapper yeah it's like for that completeness this error is here for instance the few takes call if you do if you use few takes directly from your application there is no wrapper function in lip see you need to do a system call directly and you can do that by also using

372
0:46:05.240 --> 0:46:23.640
the syscall macro then or actually I mean the syscall shim will replace that with the direct function call then to actually POSIX few takes no is it valuable to have kind of application that you develop specially for a unique unique

373
0:46:23.640 --> 0:46:52.760
kernel and native API are you yes yes that's for sure that's for sure so this talk is just about how we get application compatibility in case you have your application already but if you write it anyway from scratch I recommend forget everything about POSIX and speak the native API's you get much more performance and more directly connected to your driver layers and API's that you know POSIX has some implications right there's a lot of things like read write

374
0:46:52.760 --> 0:47:21.320
imply there's a mem copy happening and with these lower level API's you can do way quicker transfers because just because you can do a zero copy one sense yeah sure of course of course yeah have you looked into patching the binary to remove the syscall overhead patching the binary to remove for a couple

375
0:47:21.320 --> 0:47:35.960
of the now with the syscalls do you have to emulate the syscalls have you looked into patching the binary itself yeah instead of running the EL doing it at runtime handling the syscalls at runtime yeah let's say this is at least we thought about that but we didn't do it I mean the

376
0:47:35.960 --> 0:47:58.840
hardware talks that is the other exactly he's sitting in front of it they were doing some experiments with that that works too so you can patch it but yeah I mean this is just we didn't do it okay in regards to memory usage obviously

377
0:47:58.840 --> 0:48:25.200
the unicorn all lowers it but what if I ran multiple unicorn alls multiple VMs how how do you support member loaning or something like that or is it like just over provision and yeah I mean the idea is to have member loaning it's but it's not upstream yet of course there's also some really interesting research project and we should mention that works on memory

378
0:48:25.200 --> 0:48:43.200
deed application so if you run the same unicorn the same like a hundred times you can share VM memory pages right on the hypervisor side but you need hypervisor support for them okay thank you so much Simone let's end it here we're going to ask yeah yeah and get some stickers

379
0:48:43.200 --> 0:48:58.680
Anastasia is for the next talk on VXL so please so please get some stickers yeah stickers they're they're free don't have to pay for now next year 100 euro each

