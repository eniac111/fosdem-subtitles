1
0:00:00.000 --> 0:00:07.000
Is Lightning talk on DPC++?

2
0:00:07.000 --> 0:00:11.000
Is it DPC++ first, I'm aware?

3
0:00:11.000 --> 0:00:12.000
Yeah, yeah, exactly.

4
0:00:12.000 --> 0:00:14.000
Okay, good afternoon.

5
0:00:14.000 --> 0:00:16.000
Yeah, so I'm going to be talking about compiler

6
0:00:16.000 --> 0:00:21.000
intrinsics in SQL, in DPC++ specifically.

7
0:00:21.000 --> 0:00:24.000
This is Intel's open source SQL implementation.

8
0:00:24.000 --> 0:00:26.000
This is what I work on.

9
0:00:26.000 --> 0:00:28.000
Yeah, so hopefully I'll be able to say something

10
0:00:28.000 --> 0:00:32.000
without saying too much in 10 minutes.

11
0:00:32.000 --> 0:00:35.000
Yeah, so Codeplay, I work for Codeplay.

12
0:00:35.000 --> 0:00:38.000
We had the first SQL implementation, compute CBP.

13
0:00:38.000 --> 0:00:42.000
We now work, we were acquired by Intel.

14
0:00:42.000 --> 0:00:44.000
So now we work on the Intel SQL implementation,

15
0:00:44.000 --> 0:00:47.000
DPC++, that's what I work on.

16
0:00:47.000 --> 0:00:49.000
We have lots of partners, you know,

17
0:00:49.000 --> 0:00:51.000
hardware companies, that kind of thing.

18
0:00:51.000 --> 0:00:53.000
Whoever needs an open CL implementation,

19
0:00:53.000 --> 0:00:57.000
SQL implementation, and so on, come to us.

20
0:00:57.000 --> 0:01:00.000
Yeah, so SQL is a single source heterogeneous programming API,

21
0:01:00.000 --> 0:01:02.000
so you can write single source code

22
0:01:02.000 --> 0:01:07.000
that can run on NVIDIA Intel AMD GPUs.

23
0:01:07.000 --> 0:01:09.000
Close to the mic, okay.

24
0:01:09.000 --> 0:01:11.000
Voice up, sorry.

25
0:01:11.000 --> 0:01:13.000
Yeah, so it's great for someone who's developing

26
0:01:13.000 --> 0:01:17.000
scientific applications to be able to write single source code

27
0:01:17.000 --> 0:01:22.000
that runs on whatever GPU the implementation enables,

28
0:01:22.000 --> 0:01:27.000
such as CUDA, Level Zero for Intel AMD GPUs, and so on.

29
0:01:27.000 --> 0:01:29.000
Yeah, this is a really good thing.

30
0:01:29.000 --> 0:01:32.000
So I work specifically on the NVIDIA and the HIP

31
0:01:32.000 --> 0:01:37.000
the AMD backends for DPC++.

32
0:01:37.000 --> 0:01:39.000
Okay, so yeah, I just want to talk a little bit about

33
0:01:39.000 --> 0:01:41.000
compiler intrinsics and how kind of, you know,

34
0:01:41.000 --> 0:01:45.000
math function calls work in SQL and DPC++ at the moment,

35
0:01:45.000 --> 0:01:47.000
and how we can hopefully improve them

36
0:01:47.000 --> 0:01:50.000
so that we're contributing upstream.

37
0:01:50.000 --> 0:01:52.000
So what happens to SQL cause?

38
0:01:52.000 --> 0:01:55.000
So essentially you get your SQL cause in your source code.

39
0:01:55.000 --> 0:01:59.000
This is redirected to Sphere V OpenCL cause F.

40
0:01:59.000 --> 0:02:01.000
You compile to Sphere V, you make a Sphere V module.

41
0:02:01.000 --> 0:02:03.000
This is a symbol within the Sphere V module,

42
0:02:03.000 --> 0:02:06.000
and then that is the implementation is provided by

43
0:02:06.000 --> 0:02:09.000
a CL Level Zero Vulkan driver.

44
0:02:09.000 --> 0:02:13.000
Okay, as I said, I don't work on the Sphere V backend at all.

45
0:02:13.000 --> 0:02:18.000
I work the PTX, the CUDA, or the AMD GPU backends.

46
0:02:18.000 --> 0:02:21.000
What do we do with these symbols so that we get to the native implementations?

47
0:02:21.000 --> 0:02:23.000
We're not trying to reinvent the wheel.

48
0:02:23.000 --> 0:02:27.000
We're not trying to do anything that the people who are making the GPUs

49
0:02:27.000 --> 0:02:28.000
aren't doing already.

50
0:02:28.000 --> 0:02:30.000
We're just trying to redirect to that.

51
0:02:30.000 --> 0:02:34.000
So how do we go from this to that and then compile to our PTX module,

52
0:02:34.000 --> 0:02:41.000
our AMD GPU module, HSA module, and so on?

53
0:02:41.000 --> 0:02:47.000
So yeah, how do we go from Sphere V OCL to NV cause F?

54
0:02:47.000 --> 0:02:50.000
So use the SHIM library. Easy peasy, that's fine.

55
0:02:50.000 --> 0:02:53.000
You just redirect it, you compile it to Bitcode,

56
0:02:53.000 --> 0:02:57.000
you link it at compilation time, and you get to this native Bitcode implementation.

57
0:02:57.000 --> 0:02:58.000
This is great.

58
0:02:58.000 --> 0:03:00.000
So we use libclc for this.

59
0:03:00.000 --> 0:03:03.000
So libclc is written in OpenCL.

60
0:03:03.000 --> 0:03:07.000
OpenCL does lots of stuff that SQL doesn't expose as easily,

61
0:03:07.000 --> 0:03:09.000
like address spaces, that kind of thing.

62
0:03:09.000 --> 0:03:11.000
So we write it in OpenCL.

63
0:03:11.000 --> 0:03:12.000
This is great.

64
0:03:12.000 --> 0:03:14.000
This makes our lives really, really easy.

65
0:03:14.000 --> 0:03:16.000
We can do it.

66
0:03:16.000 --> 0:03:21.000
So before we get into this, just why do we want to use a BC library in the first place?

67
0:03:21.000 --> 0:03:24.000
Why don't we use a.so, why don't we just resolve to some symbol

68
0:03:24.000 --> 0:03:28.000
that then a runtime is called and we don't care about it?

69
0:03:28.000 --> 0:03:32.000
So on a GPU, the overhead of a function call is really high.

70
0:03:32.000 --> 0:03:35.000
It's because we lose information about, say, address spaces, that kind of thing.

71
0:03:35.000 --> 0:03:40.000
The GPU memory hierarchy is a bit more complex than, say, for CPUs.

72
0:03:40.000 --> 0:03:42.000
So we really, really need to worry about this.

73
0:03:42.000 --> 0:03:45.000
We want to inline everything so we don't lose any information

74
0:03:45.000 --> 0:03:48.000
about our memory hierarchies.

75
0:03:48.000 --> 0:03:50.000
We also allow compile time branching of code

76
0:03:50.000 --> 0:03:53.000
based on the architecture, based on the backend, that kind of thing.

77
0:03:53.000 --> 0:03:55.000
We don't want to have these checks at runtime.

78
0:03:55.000 --> 0:03:56.000
We want high performance.

79
0:03:56.000 --> 0:03:59.000
That's the name of the game for what we're doing.

80
0:03:59.000 --> 0:04:02.000
This gives us greater optimization opportunities as well.

81
0:04:02.000 --> 0:04:04.000
You can do lots of dead code elimination,

82
0:04:04.000 --> 0:04:07.000
lots of fun stuff in the middle end

83
0:04:07.000 --> 0:04:12.000
because you're doing all these checks at the IR level.

84
0:04:12.000 --> 0:04:14.000
Okay, so this is just kind of what it looks like.

85
0:04:14.000 --> 0:04:16.000
So we just have Spirbio CL, COSF.

86
0:04:16.000 --> 0:04:18.000
We return nb-cosf. Great. Amazing.

87
0:04:18.000 --> 0:04:20.000
That's so easy.

88
0:04:20.000 --> 0:04:24.000
And then this is the implementation which is provided by NVIDIA.

89
0:04:24.000 --> 0:04:26.000
This is in bit code.

90
0:04:26.000 --> 0:04:29.000
We link this, and then this is just inlined into our IR.

91
0:04:29.000 --> 0:04:33.000
This is great.

92
0:04:33.000 --> 0:04:35.000
Okay.

93
0:04:35.000 --> 0:04:37.000
Yes, so we're linking the SQL code with libclc.

94
0:04:37.000 --> 0:04:40.000
Then we link that with the vendor provided BC library.

95
0:04:40.000 --> 0:04:42.000
So we're linking, linking.

96
0:04:42.000 --> 0:04:44.000
We get to the implementation. It's all inlined.

97
0:04:44.000 --> 0:04:48.000
It's all great. We love it.

98
0:04:48.000 --> 0:04:50.000
Okay. So this works well.

99
0:04:50.000 --> 0:04:54.000
So this is a bit of code from libclc.

100
0:04:54.000 --> 0:04:57.000
Because we're dealing in openclc, we could choose something else.

101
0:04:57.000 --> 0:04:58.000
We could write a native IR.

102
0:04:58.000 --> 0:05:01.000
We find that opencl is actually easier to use

103
0:05:01.000 --> 0:05:04.000
than easier to maintain than writing a native IR.

104
0:05:04.000 --> 0:05:07.000
So we end up with some funny kind of problems with mangling

105
0:05:07.000 --> 0:05:08.000
and all this kind of thing.

106
0:05:08.000 --> 0:05:09.000
This isn't nice.

107
0:05:09.000 --> 0:05:11.000
Sometimes we need manual mangling.

108
0:05:11.000 --> 0:05:15.000
This has got to do with namespaces when they're interpreted

109
0:05:15.000 --> 0:05:21.000
by the opencl mangling, unfortunately.

110
0:05:21.000 --> 0:05:23.000
Yeah, we need to sometimes as well.

111
0:05:23.000 --> 0:05:25.000
Sometimes opencl isn't as good as we want it to be.

112
0:05:25.000 --> 0:05:27.000
So we need to actually write in native IR as well.

113
0:05:27.000 --> 0:05:30.000
So it's a mix of like lvm IR, libclc.

114
0:05:30.000 --> 0:05:35.000
It's a bit messy. It's not great.

115
0:05:35.000 --> 0:05:39.000
Yeah, so also we're exposing some compiler internals here.

116
0:05:39.000 --> 0:05:42.000
This is the nvvm reflect pass,

117
0:05:42.000 --> 0:05:45.000
which essentially takes your function call for nvvm reflect,

118
0:05:45.000 --> 0:05:46.000
replaces it with the numeric value.

119
0:05:46.000 --> 0:05:48.000
This is totally done at the IR level.

120
0:05:48.000 --> 0:05:54.000
So you can branch at the IR level based on this is a high architecture,

121
0:05:54.000 --> 0:05:57.000
a newer architecture, do this new implementation,

122
0:05:57.000 --> 0:05:58.000
do this new built-in.

123
0:05:58.000 --> 0:06:02.000
This is an old architecture, da-da-da, as well for things like rounding modes.

124
0:06:02.000 --> 0:06:03.000
This pass is used.

125
0:06:03.000 --> 0:06:06.000
We're exposing this in source code through hacks.

126
0:06:06.000 --> 0:06:12.000
This isn't really, you know, it's not kosher.

127
0:06:12.000 --> 0:06:15.000
But it works. Who cares?

128
0:06:15.000 --> 0:06:20.000
Okay, but consider the new proposal to add FP accuracy attributes to math built-ins.

129
0:06:20.000 --> 0:06:23.000
This is where we have, say, FP built-in cause,

130
0:06:23.000 --> 0:06:28.000
and we specify the accuracy in ULP that we want it to be computed to.

131
0:06:28.000 --> 0:06:31.000
Okay, this is totally lost on us.

132
0:06:31.000 --> 0:06:33.000
Okay, so this is what it would look like.

133
0:06:33.000 --> 0:06:35.000
Yeah, you have this attribute here.

134
0:06:35.000 --> 0:06:37.000
You've FP max error.

135
0:06:37.000 --> 0:06:41.000
This is really, really needed in sickle because sickle is targeting lots

136
0:06:41.000 --> 0:06:43.000
and lots of different platforms.

137
0:06:43.000 --> 0:06:47.000
All these platforms have different numerical accuracy guarantees.

138
0:06:47.000 --> 0:06:48.000
We really, really need this.

139
0:06:48.000 --> 0:06:49.000
We don't use built-ins at all.

140
0:06:49.000 --> 0:06:53.000
We're sorry, we don't use LLVM intrinsics at all.

141
0:06:53.000 --> 0:06:58.000
So this is, we need to get to a point where we can start using this compiler infrastructure.

142
0:06:58.000 --> 0:07:02.000
We're not using it as much as you want to.

143
0:07:02.000 --> 0:07:07.000
So we could do this using a libclc compiler kind of hack workaround.

144
0:07:07.000 --> 0:07:09.000
We do another pass.

145
0:07:09.000 --> 0:07:10.000
You just say compiler precision valve.

146
0:07:10.000 --> 0:07:12.000
If it's that, do some precise square root.

147
0:07:12.000 --> 0:07:14.000
If it's not, do some approx thing.

148
0:07:14.000 --> 0:07:16.000
Yeah, we could do that.

149
0:07:16.000 --> 0:07:20.000
The problem with libclc and this stuff, it's not upstreamable.

150
0:07:20.000 --> 0:07:22.000
It's a collection of hacks.

151
0:07:22.000 --> 0:07:25.000
It's not totally hacks, but it's a little bit messy.

152
0:07:25.000 --> 0:07:27.000
It's not written in the same API.

153
0:07:27.000 --> 0:07:31.000
It's opencl and it's lvmyr.

154
0:07:31.000 --> 0:07:32.000
It's messy.

155
0:07:32.000 --> 0:07:33.000
We can upstream this.

156
0:07:33.000 --> 0:07:36.000
We can all benefit from this.

157
0:07:36.000 --> 0:07:38.000
Okay.

158
0:07:38.000 --> 0:07:43.000
So the pro about doing some, adding another hack to the kind of pass,

159
0:07:43.000 --> 0:07:45.000
there's another hack to the bunch, is that it's easy to do.

160
0:07:45.000 --> 0:07:46.000
Okay.

161
0:07:46.000 --> 0:07:49.000
We can do this and we can keep going with our libclc implementation.

162
0:07:49.000 --> 0:07:50.000
It's pretty straightforward.

163
0:07:50.000 --> 0:07:51.000
We've been doing this the whole time.

164
0:07:51.000 --> 0:07:52.000
Yeah, fine.

165
0:07:52.000 --> 0:07:56.000
We don't need to worry about the broader LLVM concerns.

166
0:07:56.000 --> 0:08:00.000
However, we miss out on LLVM community collaboration, which is why we're here.

167
0:08:00.000 --> 0:08:04.000
And then how many of these workarounds do we actually need in order to keep up

168
0:08:04.000 --> 0:08:06.000
with the latest trends?

169
0:08:06.000 --> 0:08:10.000
And then libclc, as bad as it could be now, like it just degenerates into an

170
0:08:10.000 --> 0:08:14.000
absolute mess and we don't want that.

171
0:08:14.000 --> 0:08:15.000
Okay.

172
0:08:15.000 --> 0:08:20.000
So we think the answer for this is to try and redirect, try and actually have it

173
0:08:20.000 --> 0:08:22.000
call in the compiler intrinsic.

174
0:08:22.000 --> 0:08:23.000
Okay.

175
0:08:23.000 --> 0:08:26.000
We want to use compiler intrinsic and then have some generic behavior of these

176
0:08:26.000 --> 0:08:30.000
are the intrinsic for offload targets.

177
0:08:30.000 --> 0:08:31.000
Okay.

178
0:08:31.000 --> 0:08:35.000
And this would be used by say open MP, by, by, you know, coup de clang and so on,

179
0:08:35.000 --> 0:08:36.000
all these different targets.

180
0:08:36.000 --> 0:08:37.000
But we don't have this transformation.

181
0:08:37.000 --> 0:08:40.000
We're not comfortable with this connection.

182
0:08:40.000 --> 0:08:41.000
Okay.

183
0:08:41.000 --> 0:08:44.000
From an intrinsic to a vendor provided BC built in.

184
0:08:44.000 --> 0:08:45.000
Okay.

185
0:08:45.000 --> 0:08:46.000
Why is that?

186
0:08:46.000 --> 0:08:51.000
Essentially this needs to happen as early as possible in the, at the IR level.

187
0:08:51.000 --> 0:08:56.000
We're adding an external dependency in our LLVM kind of, you know, pipeline.

188
0:08:56.000 --> 0:09:02.000
We need to link this BC library early on in our, in our pipeline.

189
0:09:02.000 --> 0:09:03.000
We don't do this.

190
0:09:03.000 --> 0:09:04.000
We're not comfortable with doing this.

191
0:09:04.000 --> 0:09:07.000
We need to figure out a way that people will be happy with us doing this.

192
0:09:07.000 --> 0:09:08.000
Okay.

193
0:09:08.000 --> 0:09:13.000
Obviously we're used to things resolving to external symbols, but then that's a

194
0:09:13.000 --> 0:09:14.000
runtime thing.

195
0:09:14.000 --> 0:09:16.000
It's not, it's not a compile time thing.

196
0:09:16.000 --> 0:09:17.000
Okay.

197
0:09:17.000 --> 0:09:18.000
This needs to be in line.

198
0:09:18.000 --> 0:09:22.000
We need to be able to do some stuff with this at the IR level.

199
0:09:22.000 --> 0:09:23.000
Okay.

200
0:09:23.000 --> 0:09:27.000
So there will still be cases where we need libCLC potentially.

201
0:09:27.000 --> 0:09:31.000
It's not going to, you know, just disappear from our SQL implementation.

202
0:09:31.000 --> 0:09:32.000
Hopefully.

203
0:09:32.000 --> 0:09:38.000
But we need to start pushing towards better kind of resolution, better use of

204
0:09:38.000 --> 0:09:41.000
these intrinsics in LLVM for offload in general.

205
0:09:41.000 --> 0:09:42.000
Okay.

206
0:09:42.000 --> 0:09:43.000
So why?

207
0:09:43.000 --> 0:09:48.000
Shared infrastructure, keep an eye, keep on the cutting edge of new

208
0:09:48.000 --> 0:09:52.000
developments, left compiler hacks, and we make sickle compilation eventually

209
0:09:52.000 --> 0:09:53.000
work upstream.

210
0:09:53.000 --> 0:09:56.000
It doesn't at the moment, but eventually we want it to, of course.

211
0:09:56.000 --> 0:09:59.000
We're trying to upstream as much as possible, but libCLC is not upstreamable.

212
0:09:59.000 --> 0:10:00.000
And that's a problem.

213
0:10:00.000 --> 0:10:03.000
Okay.

214
0:10:03.000 --> 0:10:07.000
So the first step, try and have this discussion about making the

215
0:10:07.000 --> 0:10:08.000
intrinsics work for offload.

216
0:10:08.000 --> 0:10:09.000
Okay.

217
0:10:09.000 --> 0:10:10.000
So time.

218
0:10:10.000 --> 0:10:11.000
Okay.

219
0:10:11.000 --> 0:10:12.000
Time's up.

220
0:10:12.000 --> 0:10:16.000
So we need to have this link step at the IR level early on in the IR kind of

221
0:10:16.000 --> 0:10:17.000
pipeline.

222
0:10:17.000 --> 0:10:20.000
There's problematic for some people, but we need to talk about this.

223
0:10:20.000 --> 0:10:22.000
So please join in the discussion here.

224
0:10:22.000 --> 0:10:29.000
This is MVPTX code gen for LLVM sign in front if you have any opinions on this.

225
0:10:29.000 --> 0:10:35.000
Sorry, I kind of ran over a little bit, but yeah, any questions?

226
0:10:35.000 --> 0:10:42.000
I was wondering, would it make sense to try to get rid of the mess by going to

227
0:10:42.000 --> 0:10:47.000
an MLIR type of approach or like what are the benefits or downsides to MLIR?

228
0:10:47.000 --> 0:10:49.000
So I'm not an expert.

229
0:10:49.000 --> 0:10:52.000
So the question was, are there benefits?

230
0:10:52.000 --> 0:10:57.000
Can we avoid this by going to MLIR?

231
0:10:57.000 --> 0:10:59.000
I think it's more fundamental than MLIR.

232
0:10:59.000 --> 0:11:04.000
I'm not an expert on MLIR, but I think we need basic resolution of intrinsic

233
0:11:04.000 --> 0:11:06.000
presumably with MLIR.

234
0:11:06.000 --> 0:11:10.000
You'll have, you know, other MLIR, our intrinsics that will need the same kind

235
0:11:10.000 --> 0:11:11.000
of treatment.

236
0:11:11.000 --> 0:11:12.000
We'll have the same questions there.

237
0:11:12.000 --> 0:11:15.000
So this is the first case study.

238
0:11:15.000 --> 0:11:16.000
This is the most simple case.

239
0:11:16.000 --> 0:11:20.000
We're not trying to implement the new a few built-ins with the accuracy thing.

240
0:11:20.000 --> 0:11:23.000
We're just trying to decide how do we make this dependency on this external

241
0:11:23.000 --> 0:11:27.000
BC live work and do it in a very, very confined sort of way.

242
0:11:27.000 --> 0:11:28.000
Yeah.

243
0:11:28.000 --> 0:11:30.000
Thank you.

244
0:11:30.000 --> 0:11:31.000
Yeah.

245
0:11:31.000 --> 0:11:34.000
I have two questions.

246
0:11:34.000 --> 0:11:37.000
First one is a tutorial to generate NV for a PTX from MLIR.

247
0:11:37.000 --> 0:11:41.000
There is a whole section about linking with the Bitcoin library from NVIDIA.

248
0:11:41.000 --> 0:11:43.000
So what's the difference with this?

249
0:11:43.000 --> 0:11:49.000
And the second question is you mentioned NVVM, which is the closed source

250
0:11:49.000 --> 0:11:51.000
PTX generator from NVIDIA.

251
0:11:51.000 --> 0:11:56.000
And there is also the LLVM NVPTX back end.

252
0:11:56.000 --> 0:12:01.000
Are we reaching SPE RT with the closed source one?

253
0:12:01.000 --> 0:12:03.000
It depends on the application.

254
0:12:03.000 --> 0:12:08.000
We find that with the second question first, is there still a big performance

255
0:12:08.000 --> 0:12:13.000
gap between the native, say, NVCC compiler and LLVM clang?

256
0:12:13.000 --> 0:12:21.000
So in terms of DPC++, which is a fork of LLVM, we're attaining, say, roughly

257
0:12:21.000 --> 0:12:27.000
comparable performance, whether you're using SYCL or you're using CUDA with

258
0:12:27.000 --> 0:12:32.000
NVCC, and then any improvements that we make to the kind of compiler or whatever.

259
0:12:32.000 --> 0:12:35.000
They're shared by Clang CUDA as well.

260
0:12:35.000 --> 0:12:39.000
So the first question again was how is this different from?

261
0:12:39.000 --> 0:12:44.000
It's a tutorial to link Bitcoin with LLVM.

262
0:12:44.000 --> 0:12:50.000
So essentially when you're linking Bitcoin or whatever, you're not using any

263
0:12:50.000 --> 0:12:52.000
LLVM intrinsics.

264
0:12:52.000 --> 0:12:56.000
You're just redirecting things yourself.

265
0:12:56.000 --> 0:12:57.000
You're not using intrinsics.

266
0:12:57.000 --> 0:13:00.000
So you need to do everything explicitly.

267
0:13:00.000 --> 0:13:05.000
You need to either have a specific kind of driver path that will do this for you

268
0:13:05.000 --> 0:13:10.000
or you need to specifically say, I want to link this in at this time or whatever.

269
0:13:10.000 --> 0:13:12.000
And so it's more manual.

270
0:13:12.000 --> 0:13:14.000
It's not happening automatically.

271
0:13:14.000 --> 0:13:16.000
It's not happening really within the compiler.

272
0:13:16.000 --> 0:13:20.000
It's happening at link time, LLVM link time.

273
0:13:20.000 --> 0:13:21.000
All right.

274
0:13:21.000 --> 0:13:22.000
Thank you, Hugh.

275
0:13:22.000 --> 0:13:51.000
Thank you.

