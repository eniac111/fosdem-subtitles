WEBVTT

00:00.000 --> 00:10.360
Welcome, everyone. Thank you. We start with a small introduction to have a bit of context

00:02.000 --> 00:28.820
eaMse. What is Kuwix? Kuwix is a project to provide

00:10.360 --> 00:19.480
about Jupyco. I'm Maciej Goeche. I'm a flamethrower. And I'm working. My main client is a Kuwix

00:19.480 --> 00:28.820
project. And for there, I'm the lead developer of L

00:28.820 --> 00:34.720
content where the Internet is not there. And the question we try to answer and we have

00:34.720 --> 00:41.560
answer is how to distribute static websites. And, for example, if you don't know all Wikipedia

00:41.560 --> 00:50.960
in English, it's 95 gigabytes and six billion article and media. And to do that, we use

00:50.960 --> 00:59.440
the ZIM format. It's an archive format for web content. And content is partially compressed.

00:59.440 --> 01:05.800
So you can compress textual content or not compress images or videos. And you can do

01:05.800 --> 01:11.400
random access without initial decompression so you can access the content inside the archive

01:11.400 --> 01:18.060
directly. It works well and pretty efficient. But there is a few flaws in the design and

01:18.060 --> 01:26.600
the archive is really tied to web content and to Kuwix. And you cannot add another metadata.

01:26.600 --> 01:31.400
So the question I try to answer is could we reuse the ZIM format, the good idea of the

01:31.400 --> 01:39.440
ZIM format, and do better and more generic? So here is Jupyco. Jupyco is a Japanese name

01:39.440 --> 01:45.760
for the bento boxes. And it's more boxes you can compress the way you want depending on

01:45.760 --> 01:53.600
your needs. And Jupyco is a new format independent of Kuwix project. And this is a good idea

01:53.600 --> 02:00.880
of the ZIM format but generic. And Jupyco is a meta-container. It tells you how to store

02:00.880 --> 02:07.640
things but it's up to you to decide what do you want to store and how do you want to organize

02:07.640 --> 02:16.680
them. And there is a reference library written in Rust. The feature of Jupyco, it's mainly

02:16.680 --> 02:21.760
read-only archive or mainly read-only. This is selective compression so you can compress

02:21.760 --> 02:27.960
the content or not. No initial decompression needed and you can do random access on the

02:27.960 --> 02:35.280
archive. It's configurable so you can decide which property you want on the entries. There

02:35.280 --> 02:43.640
is an extension system so your user can download an archive and they can download extra content

02:43.640 --> 02:51.400
to add content to the archive you provide. It's embeddable in other files and it's composable

02:51.400 --> 02:56.320
so you can compose different kinds of entries together in the same container. So it checks

02:56.320 --> 03:04.320
them. And a few features to do, signature and encryption, direct access to uncompressed

03:04.320 --> 03:13.840
content, content deduplication, modification, different patch between archive and overlay.

03:13.840 --> 03:23.720
Let's have a quick tour on the internal structure. The Jupyco container are organized about a

03:23.720 --> 03:29.880
round packs. There is three kinds of packs, the manifest pack, the content and the directory.

03:29.880 --> 03:35.000
Each pack can be stored individually in the file system or they can be put together in

03:35.000 --> 03:42.880
one file and then you distribute this file to your user. The manifest pack is the main

03:42.880 --> 03:48.800
pack. This is a pack you will try to open when you want to open the Jupyco container

03:48.800 --> 03:56.080
and it's mainly a list of all the other packs of the container. The content pack is a pack

03:56.080 --> 04:02.640
which contains the raw content, compressed or not, and without any metadata. And the

04:02.640 --> 04:09.040
directory pack is where you store the entries and the entries can point to content in the

04:09.040 --> 04:18.680
content pack. This is a configural part of Jupyco. And inside directory pack there is

04:18.680 --> 04:25.720
entries with a specific schema. So you have to define the schema and the schema is the

04:25.720 --> 04:30.960
series of properties and their types. The content is just a property. It's a link to

04:30.960 --> 04:36.480
the content in the content pack so you can have entries that point to several contents

04:36.480 --> 04:49.280
or no content at all. And each schema can contain violence. It's kind of in your own

04:49.280 --> 04:57.840
in pre-commission. You can have different kind of entry inside one directory pack. Which

04:57.840 --> 05:05.840
use case? Why you would like to use Jupyco? The first use case is one archive. There is

05:05.840 --> 05:12.880
a tool, ARX, which is an equivalent of tar. And here we have one kind of entry with three

05:12.880 --> 05:21.320
variants, file, simlink and directory. All three variants share two common properties.

05:21.320 --> 05:28.240
And for example, the file variants add the pointer to a content. Simlink, tar.get.link

05:28.240 --> 05:37.920
and the directory just stores the first entry and the number of entries in the directory.

05:37.920 --> 05:47.520
So it's a kind of a nogization and a three structure as a file system. There is no index

05:47.520 --> 05:52.880
property for now but just mainly because ARX is pretty young and I don't want to bother

05:52.880 --> 06:00.440
with them while testing ARX and Jupyco. But is it hard? It's a fun archive so we can compile

06:00.440 --> 06:11.200
bits of ARX with tar to see how Jupyco and ARX perform. If we take the Linux source code,

06:11.200 --> 06:19.480
the full Linux source code is more than one gigabytes and both tar and ARX are compressing

06:19.480 --> 06:30.840
the source code is about 130 or 140 megabytes. Creation time is a bit faster than tar and

06:30.840 --> 06:38.440
extraction time we are pretty close. ARX is a bit slower but we have someone pretty close,

06:38.440 --> 06:46.560
both tools are pretty close. What is interesting is when we try to list the content of the

06:46.560 --> 06:55.720
archive, tar took almost the same time that expression because to list the content in

06:55.720 --> 07:03.200
the tar archive you need to uncompress all the content. ARX is very faster because the

07:03.200 --> 07:12.040
list of the entry are separated from the content itself. If you want to extract only one content

07:12.040 --> 07:23.200
from the archive and we try to dump a third of all the entries you can see that ARX is

07:23.200 --> 07:31.520
really, really, really faster. The same way extracting one entry from the tar is pretty

07:31.520 --> 07:39.360
close from the time of listing the content the same way as you need to uncompress all

07:39.360 --> 07:45.880
the content of the archive and ARX you can locate the content and do a direct access

07:45.880 --> 07:56.520
to the content without compressing the content. Once a few things that we can do is mount

07:56.520 --> 08:03.240
the archive, directly mount the archive on the file system and if you mount the archive

08:03.240 --> 08:11.720
and you do a diff of the content between the original source and what is mounted, if you

08:11.720 --> 08:19.720
do a diff between two plain directories it's a bit less than a second, with ARX it's four

08:19.720 --> 08:26.840
seconds and half and tar is an estimation it will take something like ten hours to do

08:26.840 --> 08:36.360
the comparison. You can do something even more interesting with a mounted file system

08:36.360 --> 08:43.960
with a mounting Linux source is compiling the kernel. So if you compile the kernel on

08:43.960 --> 08:50.480
the plain file system it's a bit more than half an hour and if you compile the kernel

08:50.480 --> 08:58.160
using the mounted archive is a bit less than an hour. What is interesting here is that

08:58.160 --> 09:06.680
the compilation is made with G8, so there is eight processes and ARX is monosplated

09:06.680 --> 09:14.720
so there is a huge bottleneck for now but if we move to a multithreaded system it should

09:14.720 --> 09:24.000
be even better. Another use case is the GIMM, it's an equivalent of, kind of equivalent

09:24.000 --> 09:32.000
of the GIMM format, there is two variants only and here we are storing the entries as

09:32.000 --> 09:38.240
a playlist, there is no tree structure and the GIMM by now we just integrate a small

09:38.240 --> 09:46.400
HTTP server looking for the entries. What we can do also is we could replace for example

09:46.400 --> 09:56.400
a PM and deb with ARX or a thing based on Jupyco so you could download your package

09:56.400 --> 10:03.200
and not extract it on the file system just open it directly and even a Jevil or Debug

10:03.200 --> 10:10.360
Info that could be put in specific content pack of the same archive so it could simplify

10:10.360 --> 10:16.560
the management and you will not need to have different package to different subtype of

10:16.560 --> 10:26.120
content of your packages. OCI-Conner are based on Tor, you need to extract them on the file

10:26.120 --> 10:33.200
system before running a container so you could just use ARX among them or you can even use

10:33.200 --> 10:42.000
directe to put different layer in different content pack and so the whole image will be

10:42.000 --> 10:54.040
one Jupyco container. File format, almost all file formats are in fact container for

10:54.040 --> 11:01.800
the content so you could use Jupyco to just organize the content you want to store what

11:01.800 --> 11:09.960
you want for your own project and your own file format. Website, Jupyco is written in

11:09.960 --> 11:18.560
REST, you could run it in Wasm and so Jupyco could load your Jupyco archive in the browser

11:18.560 --> 11:29.160
once and just open it directly in the browser. Backups, Jupyco is almost incremental by design

11:29.160 --> 11:35.360
if you reuse the content pack of the backups, previous backup this is incremental and you

11:35.360 --> 11:40.640
can decide which property you want to add so for example you can add a checksum on each

11:40.640 --> 11:47.440
entry to do a comparison between the content store in the backup and what you have on the

11:47.440 --> 11:57.800
file system. Embedding resources, Jupyco can be embedded in the executor program or even

11:57.800 --> 12:03.800
more this presentation you can download this presentation at this address and you will

12:03.800 --> 12:10.680
have a file and this file is an ARX archive so you can just use the ARX tool to list the

12:10.680 --> 12:16.600
content extract on the archive and you will have access to all the files in this presentation

12:16.600 --> 12:24.760
it is rebuilt yes and it's HTML content but the same file is also a GIM archive so you

12:24.760 --> 12:31.920
can just use the GIM tool to just serve the content and open a browser to the local host

12:31.920 --> 12:40.040
it's not and the same files is also a program so if you make it executable you can run the

12:40.040 --> 12:49.120
program itself to extract or serve the content what is interesting is that between the content

12:49.120 --> 12:55.840
is not shared it is an ARX and GIM archive but it's just a view to the same content there

12:55.840 --> 13:01.480
is no duplication it's not two archives put together it's really one archive with two

13:01.480 --> 13:08.880
kind of view of the same content and the last line is the exact command used to serve this

13:08.880 --> 13:11.960
actual presentation.

13:11.960 --> 13:21.120
Conclusion, this is a new way of thinking we could extract you could use the archive

13:21.120 --> 13:33.160
directly instead of extracting it so we can reinvent the wall without thinking about using

13:33.160 --> 13:40.800
directly the archive it's a new way of thinking it's generic it's a common base tool that

13:40.800 --> 13:50.920
can add that can adapt to different usage but it's pretty new maybe some crash and you

13:50.920 --> 13:56.800
can expect maybe some change in the specification.

13:56.800 --> 14:10.880
Thank you.

14:10.880 --> 14:13.160
Are there any questions?

14:13.160 --> 14:18.000
How do you compare to GramFS?

14:18.000 --> 14:19.000
Can you repeat the question?

14:19.000 --> 14:20.000
Okay.

14:20.000 --> 14:23.520
How does your format compare to GramFS?

14:23.520 --> 14:26.520
I don't know.

14:26.520 --> 14:32.080
I know about SquashFS.

14:32.080 --> 14:35.200
The thing is that Jupyco is not a file system.

14:35.200 --> 14:42.120
ARX is an archive to store files but Jupyco is not so Jupyco is more generic than GramFS

14:42.120 --> 14:54.840
or SquashFS probably and ARX compared to SquashFS is half slower than SquashFS.

14:54.840 --> 15:08.200
On the size ARX is better but on the performance is slower.

15:08.200 --> 15:16.360
Any ideas on implementing this in other languages?

15:16.360 --> 15:18.440
We could implement that in other languages.

15:18.440 --> 15:21.480
Repeat the question because for the...

15:21.480 --> 15:26.120
Could we re-implement this in other languages?

15:26.120 --> 15:27.120
You could.

15:27.120 --> 15:32.240
The specification is language-anoustic but I've just implemented the reference library

15:32.240 --> 15:35.360
in Rust but the specification is public.

15:35.360 --> 15:36.360
Sorry?

15:36.360 --> 15:56.560
Jupyco is much slower than ARX in almost any kind of operation and is bigger than ARX also.

15:56.560 --> 16:00.680
Thank you.

16:00.680 --> 16:07.320
Thank you.
