WEBVTT

00:00.000 --> 00:11.920
Okay. Hello, everyone, and welcome to the last lightning talk of the conference. I hope

00:11.920 --> 00:16.520
you've enjoyed yourselves. This will be the FOSDIM infrastructure review, same as every

00:16.520 --> 00:27.760
year presented by Richard and Basti.

00:27.760 --> 00:32.840
So normally I do this thing, but Basti has been helping a ton, and the ball of spaghetti

00:32.840 --> 00:40.400
and spit and duct tape which I left him turned into something usable. So I'm just going to

00:40.400 --> 00:45.120
sit here on the side, and I'm here around for the Q&A. But for the rest, it's Basti,

00:45.120 --> 00:56.080
and it's his first public talk for realty, so give him a big round of applause.

00:56.080 --> 01:02.480
Thank you. I hope I will not screw this one up. Okay. So we'll have about 15 minutes,

01:02.480 --> 01:10.120
10 minutes of talk, and five minutes for Q&A, and I hope it's somewhat interesting to you.

01:10.120 --> 01:16.600
First the facts. The core infrastructure hasn't changed that much since the last FOSDIM 2020.

01:16.600 --> 01:24.400
We're still running on its Cisco ASR 10K for routing ACLs, NAT64, and DHCP. We have already

01:24.400 --> 01:31.280
reused several switches that we are already here from the last FOSDIM. They're on by FOSDIM.

01:31.280 --> 01:41.120
These are Cisco C3750 switches. We had our old servers which are now turning 10 this

01:41.120 --> 01:47.640
year. They were still here, and they will be replaced next year. We have done, like

01:47.640 --> 01:54.360
all the years before, everything with Prometheus, Loki, and Grafana for monitoring our infrastructure,

01:54.360 --> 02:00.240
because that's what helps us running all the conference here. And we've built some public

02:00.240 --> 02:05.920
dashboards, and we just put it out to a VM outside of ULB because we were running out

02:05.920 --> 02:13.600
of bandwidth like the years before, and I'll come to that back later.

02:13.600 --> 02:20.120
We have a quite beefy video infrastructure. You might have seen this one here. It's a

02:20.120 --> 02:26.440
video capturing device. It's called a video box here at FOSDIM. It's all public. It's

02:26.440 --> 02:31.920
all open source except one piece that's in there. You can find it on GitHub if you try

02:31.920 --> 02:39.600
to build it yourself. Go ahead. Just grab the GitHub repo and clone it. These devices,

02:39.600 --> 02:45.000
there's two of them, one at the camera, one here for the presenter's laptop. They sent

02:45.000 --> 02:50.960
their streams to a big render farm that we have over in the K building where every year

02:50.960 --> 03:00.080
our render farm is running on some laptops. So laptops sent the streams off to the cloud

03:00.080 --> 03:05.480
from Hetzner, and from there we just distribute it to the world so everyone at home can see

03:05.480 --> 03:14.680
the talks. We have some sort of semi-automatic rev up on cutting process. Those of you have

03:14.680 --> 03:20.480
been talking here, maybe have known S-Review for years. This is the first time it's running

03:20.480 --> 03:27.680
on Kubernetes. So we are trying to go cloud native as well with our infrastructure just

03:27.680 --> 03:34.680
to show how all has been held together. This is our video boxes. I don't know if you can

03:34.680 --> 03:43.240
see it. We got those black magic encoders here that are turning the signals that we

03:43.240 --> 03:50.400
get, like SDI, HDMI, into a useful signal that we can process with our banana pie that

03:50.400 --> 03:56.920
we have in there. Everything is wired up to a dump switch here and then we go out like

03:56.920 --> 04:03.360
here and have our own switching infrastructure inside those boxes. There's some SSD below

04:03.360 --> 04:10.000
here where we just, in case of network failure, dump everything to the SSD as well. So hopefully

04:10.000 --> 04:15.280
everything that has been talked about at the conference is still captured and available

04:15.280 --> 04:23.280
in case of a network breakdown. Those boxes also have a nice display for the speaker so

04:23.280 --> 04:28.620
we can see if everything is running or it's not running, which makes it easy for people

04:28.620 --> 04:33.280
to operate these boxes here. You don't have to be a video pro. You just have to wire yourself

04:33.280 --> 04:37.020
up to the box. You see a nice Fostom logo and see, okay, everything is working and you're

04:37.020 --> 04:46.800
done and everything gets set out. This is like how the video system is actually working.

04:46.800 --> 04:53.480
All this can be found on the GitHub. You don't have to take screenshots for that. If you

04:53.480 --> 04:59.720
like to see it, we will tear down this room afterwards so everyone can have a look at

04:59.720 --> 05:04.560
the infrastructure we're using because it's not being used after this talk. You see it's

05:04.560 --> 05:11.280
quite some interesting things to do. This is the instructions that all our volunteers

05:11.280 --> 05:20.960
get when they wire up the whole buildings here on one day on Friday. They're not here,

05:20.960 --> 05:25.280
but they should be given some round of applause because they're volunteers that are doing

05:25.280 --> 05:30.920
really the hard work and building up on one day the complete Fostom. Maybe it's time for

05:30.920 --> 05:45.560
a round of applause for them. Here we have another thing. This is also on the GitHub

05:45.560 --> 05:51.240
rapid where you can see where's something coming from. We have the room sound system.

05:51.240 --> 05:55.520
This is what you're hearing me through. We have a camera with audio gear, speaker laptops,

05:55.520 --> 06:01.480
that's all getting pushed down until someone reaches your device down here. There's a ton

06:01.480 --> 06:12.040
of services processing it in between. This is almost all done with open source software.

06:12.040 --> 06:18.800
Expect for the encoder that's running in there, which is from Blackmagic Design. How is it

06:18.800 --> 06:26.040
used? We have a rendering farm. This is the laptops. It's 27 this year. For those of you

06:26.040 --> 06:32.200
who don't know, those laptops are being sold after Fostom. If you want one, you can grab

06:32.200 --> 06:37.760
one. This year they're already gone. For next year, maybe you want to have a cheap device.

06:37.760 --> 06:43.400
You can have them with everything that's on them because we literally don't care for that.

06:43.400 --> 06:50.120
You can have it because everything's been processed after the Fostom. You can see it.

06:50.120 --> 06:59.400
We have some racks where we just put them four-wise. We have 27 of them. We have some

06:59.400 --> 07:07.440
switch infrastructure that is used for processing all that stuff. This one's not running out

07:07.440 --> 07:12.400
of bandwidth, but we're coming back to what's running out of bandwidth. You might see this

07:12.400 --> 07:23.160
mess over here. This is our Internet. Looks like every common Internet on the planet.

07:23.160 --> 07:28.120
This is our safety net. We have a big box here where all the streams go. This will be

07:28.120 --> 07:33.480
sent out to Bulgaria, to the video team right after Fostom. We have a really off-site copy

07:33.480 --> 07:42.920
of everything. The challenges for this year. DNS64. All the

07:42.920 --> 07:52.320
years we've been running on Bind 9 since ages. We switched to Cordian S, just testing it

07:52.320 --> 07:59.720
on Sunday of Fostom 2020. We really saw a significant reduction in CPU usage. That's

07:59.720 --> 08:07.800
why we stuck to Cordian S since then. This year we also replaced the remaining Bind installations

08:07.800 --> 08:12.160
that we handled for all the internal DNS and all other recursive stuff that's been used

08:12.160 --> 08:19.400
here to provide you Internet access. Richie always used to give you some timelines,

08:19.400 --> 08:27.400
and that's what I'm trying to do as well. There were times when it was mentally challenging

08:27.400 --> 08:34.480
for people building up Fostom. We got better by year by year by year by doing some sort

08:34.480 --> 08:41.840
of automation and getting people used to know what to do and have everything set up before

08:41.840 --> 08:49.160
that. We installed routers. You see that? There's a slide. It's getting better year

08:49.160 --> 08:56.280
of the year. This year we had a very... We thought it would be okay from what we know.

08:56.280 --> 09:01.800
We just set it up in January, and everything worked. We came here on the 5th of January,

09:01.800 --> 09:08.320
I think, put everything up, and it just worked, which is great, which gives you some sort

09:08.320 --> 09:16.320
of things not to care about, because there were other things to care about. The network

09:16.320 --> 09:21.880
to have it up and running here took us a bit longer this year than the last years, because

09:21.880 --> 09:29.400
we were playing around with the second uplink that we got. We used to have one gigabit uplink.

09:29.400 --> 09:34.640
Last week we got a 10 gigabit uplink, and we thought, okay, just enable that and play

09:34.640 --> 09:40.680
with it, and it turned out to be not that easy to getting up both of the BGP sessions

09:40.680 --> 09:48.480
running and doing it properly. That's why it took us a bit longer this year. The monitoring

09:48.480 --> 09:54.360
was also one thing, which really helps us to understand if FOSDIM is ready to go or

09:54.360 --> 10:02.400
if something has to stay very, very late here. The last years we've been very, very good

10:02.400 --> 10:09.360
at that. Basically, in January everything was done, like the last of January, but it's

10:09.360 --> 10:14.800
January. This time in the first half of January everything was set up and was running, and

10:14.800 --> 10:22.680
it worked. It was really great, because some people actually got some sleep at FOSDIM.

10:22.680 --> 10:31.400
They didn't need to stay here very long, because everything was all pre-made, and they just

10:31.400 --> 10:37.320
go and look at the dashboard, okay, this is missing, this is missing, and just say, okay,

10:37.320 --> 10:44.080
just have them all checked. The video build-up took a bit longer this year, because of getting

10:44.080 --> 10:50.920
old and rusty at that. Also, very many new faces that have never built up such a great

10:50.920 --> 10:58.880
conference. This is why we took it a bit longer, and the video team also, yeah, I think they

10:58.880 --> 11:06.080
got the least amount of sleep of all of the stuff that was running the conference. This

11:06.080 --> 11:15.240
was the story so far. We closed FOSDIM 2020, I was also there at 2020. 2020 was really

11:15.240 --> 11:22.040
one of the best ones we ever had from a technical perspective. We had everything running via

11:22.040 --> 11:27.080
Ansible, just like one command, and then wait an hour until everything is deployed and you're

11:27.080 --> 11:32.880
gone. Cool, have some beer, some latte in between, and everything was cool. Then we had this

11:32.880 --> 11:43.240
pandemic, just for me, like a week after FOSDIM, everything went down. You had FOSDIM 2021

11:43.240 --> 11:49.040
and 2022, there were no conference here at the UB, so we had no infrastructure to manage,

11:49.040 --> 11:54.960
which was quite okay. We had to do some other things, like most of you have learned that

11:54.960 --> 12:02.480
we have a big metrics installation to run the FOSDIM conference and help you with communicating

12:02.480 --> 12:10.080
during the conference. Then there was this bad thing that the maintainer of the infrastructure

12:10.080 --> 12:18.120
left FOSDIM between these years. So Richie searched for someone who was dumb enough to

12:18.120 --> 12:29.280
do that. That's me. So this year we're back again in persona. Sorry? Yeah, thanks.

12:29.280 --> 12:41.320
Yeah. So after two years, we came looking for the two machines after almost two years,

12:41.320 --> 12:47.840
like no one touched them. They rebooted one or two times due to power outages in the server

12:47.840 --> 12:55.480
cabinet. But we had a working SSH key. We had tons of updates to install after literally

12:55.480 --> 13:01.280
three years. I wonder, nobody broke into the machines because they were public exposed

13:01.280 --> 13:09.080
on the Internet. But only SSH and I think a three-year-old or three-and-a-half-year-old

13:09.080 --> 13:16.040
Prometheus installation which was full of bugs. Yeah. We noticed that the battery controllers,

13:16.040 --> 13:19.840
the battery packs of the rate controllers have been depleted, so this was the only thing

13:19.840 --> 13:27.520
that actually happened in the three years. The batteries went to zero and didn't set

13:27.520 --> 13:33.360
themselves on fire, so everything was okay. The machines worked. Just a bit of performance

13:33.360 --> 13:38.960
degradation, but everything seemed to be okay. And then we tried to run this Ansible thing

13:38.960 --> 13:45.880
from the last years. And three years later, Ansible has done a lot of things in the time

13:45.880 --> 13:52.680
and you want to use a current version of Ansible with that old stuff. You end up like this.

13:52.680 --> 13:59.160
This is me. Start from scratch or fix all the Ansible roles. You can have a look at

13:59.160 --> 14:07.560
them. They're also on GitHub. So when we saw, okay, how do we do this and said, okay, then

14:07.560 --> 14:14.800
just be gone. Ansible be gone. We just fix it after the first time because we will have

14:14.800 --> 14:22.440
to renew the service anyway and everything will change. So the service timeline, we had

14:22.440 --> 14:29.960
them service alive at the 8th of January. Services, DNS, we had centralized all our

14:29.960 --> 14:35.040
locks. This was something Richie was looking for since ages that we had easy accessible

14:35.040 --> 14:41.920
lock files for everything that's running here at FOSDEM, which was good that we had them

14:41.920 --> 14:48.680
because we could see things like, oh, the Internet line that was proposed to be there

14:48.680 --> 14:57.000
actually came. Nobody told us, but it came up. You see that? We, thanks to the centralized

14:57.000 --> 15:07.840
logging, we were aware of things like that. And then we could go and fire up our BGP sessions.

15:07.840 --> 15:11.440
Then two days later, we noticed, okay, firing up the BGP sessions wasn't that a good idea

15:11.440 --> 15:20.680
because we lost almost all connectivity. Stop it, Seth, but I don't care. I just keep talking.

15:20.680 --> 15:26.360
We lost all our connectivity and said, okay, damn it. We're in some sort of panic mode

15:26.360 --> 15:32.080
because the reason for looking at the service was like this bind security issue that was

15:32.080 --> 15:40.080
been, I read the mail at the morning of January 28th and said, okay, we have to fix the bind

15:40.080 --> 15:43.880
installations and then you suddenly can't reach the service anymore. So, okay, are they

15:43.880 --> 15:49.740
already hacked or what's going on? And doing some back and forth with our centralized logging,

15:49.740 --> 15:57.480
you see that? This is Grafana Loki that we leveraged for that. We were kind of like,

15:57.480 --> 16:04.160
yeah, it's been really nice to debug things like that. We also noticed that there was

16:04.160 --> 16:13.240
an interface constantly flapping to our backbone, which we also could fix within that session.

16:13.240 --> 16:21.360
And after that, we said, okay, there are some MTU problems. We have to restart BGP and so

16:21.360 --> 16:29.560
on and back and forth. And then we finally agreed to just throw away the BGP sessions,

16:29.560 --> 16:35.240
go with the one gigabit line. And yesterday evening, we switched to the 10 gigabit line

16:35.240 --> 16:43.640
because we had the congested uplink like since 11 in the morning. So many people using too

16:43.640 --> 16:49.960
much bandwidth. And since yesterday evening, everything is okay. It's better. And we are

16:49.960 --> 16:55.240
on the 10 gigabit link due to the fact that there are not so many people here today. Yesterday

16:55.240 --> 17:01.720
there were quite a bit more. The link was not fully saturated. But you can tell we this

17:01.720 --> 17:07.000
is the place where we could use some more bandwidth was like, I don't know, this is

17:07.000 --> 17:12.160
usually time for something to eat. But at 330, we could actually use something of the

17:12.160 --> 17:18.920
new bandwidth that we had available. So if you want to look at all of the things, we

17:18.920 --> 17:23.120
have a dashboard put out there publicly. If you want to have a look at the infrastructure

17:23.120 --> 17:27.680
and the Ansible repo that will be fixed to work with current Ansible versions within

17:27.680 --> 17:34.040
the next few days, just clone our infrastructure, clone everything. And if you have any questions,

17:34.040 --> 18:01.440
I'll be glad to take them. Yeah, fire away. As I don't see any questions, then we are

18:01.440 --> 18:07.800
about to tear down this room after this. So please don't leave anything in here because

18:07.800 --> 18:16.080
it will be cleaned and everything will be torn out. If anyone else has a question, just

18:16.080 --> 18:25.240
there's one. We use the question is why do you use laptops for rendering because they

18:25.240 --> 18:30.640
have a built in USB called battery. So in place of the power outage, we can easily run

18:30.640 --> 18:37.400
with them. Also, they're very cheap for us. We can just use the computing power and sell

18:37.400 --> 18:41.360
it at the same price that we bought it to the people here. You get a cheap laptop. We

18:41.360 --> 18:48.080
get some computing time on them before and that's the main reason for running it on laptops.

18:48.080 --> 19:02.960
Well, actually, the question was why you were using banana pie. That's a good question.

19:02.960 --> 19:08.400
The thing is that the capabilities of the banana pie were a bit better than the Raspberry

19:08.400 --> 19:16.320
Pi. The times the decision was made. If you see there's a big LCD screen in front of the

19:16.320 --> 19:21.960
boxes where you can see that thing, I think it was driving those LCD panels and also the

19:21.960 --> 19:28.760
computing power available on the banana pie. But actually, we have to look that up in the

19:28.760 --> 19:45.800
repo. There's everything documented. Okay? Yeah, there's another one in the front. So

19:45.800 --> 19:52.040
the question was if there are any public dashboards out there. Yeah, we've put some public dashboards

19:52.040 --> 20:02.680
on dashboard.grafana.org. Oh, dashboard.fosdom.org. Sorry. Which you can have a look at the infrastructure.

20:02.680 --> 20:07.520
We used to have some more dashboards like the t-shirts that have been sold. But due

20:07.520 --> 20:14.160
to the fact that we changed the shop, we converted to something that we bought to an open source

20:14.160 --> 20:22.360
solution. And the thing is we totally forgot to monitor that. But there are some dashboards

20:22.360 --> 20:26.820
out there to monitor it. And if you want to see something more, just come to me after

20:26.820 --> 20:33.080
the talk and I'll show you something more here at the laptop. Okay? Yeah, another one.

20:33.080 --> 20:44.840
What was the biggest issue that you faced with this year? The biggest one standing here.

20:44.840 --> 20:56.040
No. Actually, the biggest issues we had was like running all that stuff after three years

20:56.040 --> 21:02.480
and not having set up everything properly was quite challenging. Like on Saturday morning,

21:02.480 --> 21:10.400
we had to run and redo the whole video installation on the K building because of you see those

21:10.400 --> 21:15.080
transmitters here. They were not plugged properly. And so we had no audio on the stream. This

21:15.080 --> 21:20.120
was one thing. And then another very challenging thing was like when we played around and I

21:20.120 --> 21:26.280
said play, we did not engineer anything properly. When we played around with the BGP sessions,

21:26.280 --> 21:33.880
it was not clear how long it would take till things distributed to the whole net. And we

21:33.880 --> 21:39.720
were literally just trying to get information. Is it working? Is it working not? And till

21:39.720 --> 21:44.800
this BGP information propagates from here to the rest of the planet like Brazil, it

21:44.800 --> 21:49.880
takes quite some time. And so you can't be sure that you're setting up the BGP session,

21:49.880 --> 21:57.200
everything works because we'll hit the fan after 10, 20, 30 minutes and not instantly.

21:57.200 --> 22:19.320
And so it's quite a problem to have instant recognition if things are going well or not.

22:19.320 --> 22:24.880
So the question was if the problems with the Wi-Fi that we had here on site were due to

22:24.880 --> 22:32.760
the BGP playing or was it due to something else, solar flares or so. The thing is that

22:32.760 --> 22:39.160
we had some issues. We've been given access to the WLC, the wireless controllers. You

22:39.160 --> 22:44.480
see these boxes over there, they're centrally controlled and we have to dig in that. We

22:44.480 --> 22:49.160
have some visibility of the infrastructure that's owned by the ULB. They've given us

22:49.160 --> 22:55.840
access to that so we can engineer that. But we're not quite sure why it was that. Most

22:55.840 --> 23:02.600
of the time, FOSDIM, which is an IPv6 only, was working quite good except for some Apple

23:02.600 --> 23:11.160
devices that do tend to just set up an IPv4 address even if there's no proper IPv4. And

23:11.160 --> 23:18.240
things get complicated then. FOSDIM dual stack, which is dual stack, usually worked for most

23:18.240 --> 23:31.280
of the Apple devices. But we're not very certain. Yeah. Yeah. You will see that. There's another

23:31.280 --> 23:46.760
one. So the question is if the live streams will be made, yeah, this is rewindable or

23:46.760 --> 23:52.240
not. Honestly, I can't tell you that. I don't know. I can ask the video guys if they're

23:52.240 --> 23:57.560
planning that for next year. But there's no plan of that as far as I know. The biggest

23:57.560 --> 24:06.480
challenge was to redo things with HDMI over VGA, which we had the last year. But there's

24:06.480 --> 24:21.720
another one. Yeah. So the question is that we're planning to use service. Do we know

24:21.720 --> 24:27.600
what and what's planned for next year? We'll have a talk about that next week, I think.

24:27.600 --> 24:31.400
And then we go through the post-mortem, which is usually a week after FOSDIM. And then we

24:31.400 --> 24:40.520
decide on things to be bought for next year because switches are old and routers are also

24:40.520 --> 24:46.000
old, I think. And we have one more year on the route to go that should be fine for next

24:46.000 --> 24:50.680
year. But what after that? We have to make some decisions and some investments for next

24:50.680 --> 24:56.480
year to run this stuff. And this will be done next week when we're all a bit cooled down

24:56.480 --> 25:15.920
and refreshed after this FOSDIM. Anyone else? Yeah. Come.

25:15.920 --> 25:24.480
So the question was what part of the infrastructure are being reused and what do we bring for

25:24.480 --> 25:34.120
the event? Well, in numbers, I think it was three truckloads of stuff. No, three because

25:34.120 --> 25:44.720
the video arrived in the second year. We bring mainly cameras and those boxes here. Switches

25:44.720 --> 25:53.240
stay at the ULB. Most of them stay here. But the one that didn't stay here, they won't

25:53.240 --> 25:59.560
be here next year because ULB is planning to do some tidying up and giving us here some

25:59.560 --> 26:07.000
video ports for our VLANs. They're very, very good at working with us. We get access to

26:07.000 --> 26:12.400
most of the infrastructure. We just say, tell them what we like to use and they just throw

26:12.400 --> 26:19.080
it on their controllers and bridge it to our servers and we can use it and make fun with

26:19.080 --> 26:26.520
it. And they will be replacing part of the network infrastructure next year. And we then

26:26.520 --> 26:33.640
will have to bring even less gear here. Yeah. Which one first?

26:33.640 --> 26:49.400
Yeah. So the question was what's about all the other stuff that FOSDIM is doing through

26:49.400 --> 26:54.600
the year that we hosted on our own hardware? Is it in the cloud or somewhere? We used,

26:54.600 --> 26:59.560
yeah, we have another company called T-Gron here. It's a Belgian provider and there's

26:59.560 --> 27:05.480
most of the stuff is running at T-Gron during the year. During FOSDIM, we also spin up some

27:05.480 --> 27:12.960
VMs at Hetzner in Germany and they are only for during the event and short time after

27:12.960 --> 27:18.880
the event. So like cutting videos and so on in the cloud. And they will be turned off

27:18.880 --> 27:23.760
for like two or three weeks and then everything is running on T-Gron on our own hardware there

27:23.760 --> 27:26.160
as well. So there was another question.

27:26.160 --> 27:32.960
What are you using to communicate with volunteers?

27:32.960 --> 27:38.000
So the question was what is being used for the communication between volunteers? We have

27:38.000 --> 27:43.680
that matrix set up. I don't know who's aware of matrix. It's a real time communication

27:43.680 --> 27:51.360
tool like, yeah, like Slack or something like that. We use matrix since 2020 internal for

27:51.360 --> 28:00.040
our video team for communicating and then we expanded that for 2020 and then with the

28:00.040 --> 28:05.640
pandemic we opened it up for all of the people and now the volunteers are being coordinated

28:05.640 --> 28:12.640
to that. And we also have our own trunk chair still that we have here, especially for this

28:12.640 --> 28:20.640
event set up. And volunteers are also can be reached via those radios.

28:20.640 --> 28:32.080
And my correct volunteers. Yes, yes. Okay. We have two volunteers here. So yeah. Yeah.

28:32.080 --> 28:39.640
Is there anything else you want to know or any where's the money? The question is where's

28:39.640 --> 28:45.080
the money Lebowski? That's the real phrase from the film. I don't actually know. I'm

28:45.080 --> 28:50.880
not yet a member of Fostum stuff. So you have to ask someone in a yellow shirt. There happens

28:50.880 --> 29:09.040
to be one next to me. Just throw him the microphone. We have a money box and a bank account. Anyone

29:09.040 --> 29:22.320
else? Three to one. Thank you very much.
