WEBVTT

00:00.000 --> 00:17.720
I'm going to be presented by two amazing researchers, Iraklis and Christos.

00:17.720 --> 00:20.920
Good morning, thank you for the introduction, thank you for being here and attending our

00:20.920 --> 00:22.400
presentation.

00:22.400 --> 00:27.640
So I'm Iraklis Varlamis and here is Christos Cronis.

00:27.640 --> 00:33.880
We come from Harakopi University but here we are also representing the Open Technology

00:33.880 --> 00:38.920
Alliance, the Greek Open Technology Alliance for Open Source Software.

00:38.920 --> 00:45.880
So we will present today Fosbot which is a project that started a couple of years ago

00:45.880 --> 00:53.040
in terms of the Google Summer of Code as an open design, an open source software robot

00:53.040 --> 01:00.120
and gradually it evolved to what you see here which is a more concrete, let's say, robot,

01:00.120 --> 01:07.400
a more concrete design that is specifically targeted to educators in our educational levels.

01:07.400 --> 01:12.680
So together with me I have Christos and I will give a follow-up to Christos Cronis who

01:12.680 --> 01:21.560
is the lead developer of the team, Fosbot, and also the designer of this robot.

01:21.560 --> 01:24.600
So Christos, the floor is yours.

01:24.600 --> 01:25.600
Thank you.

01:25.600 --> 01:27.600
Hello, I'm Christos.

01:27.600 --> 01:32.840
I would like first to introduce the team behind the Fosbot.

01:32.840 --> 01:38.360
Let's start with my PhD supervisor, Professor Iraklis Varlamis, who is the coordinator of

01:38.360 --> 01:43.760
the project, me as the designer of the robot including the hardware and the software, Elisari

01:43.760 --> 01:49.920
and Vanay who are front-end and backend developers and past Google Summer of Code contributors

01:49.920 --> 01:56.120
of the project, Dimitris and Jorvos are backend developers and assemblers of the physical

01:56.120 --> 02:02.680
robot, and finally Manusos who is a backend developer and also the developer of the Fosbot

02:02.680 --> 02:04.040
simulator.

02:04.040 --> 02:13.000
Now, so this is the Fosbot, also we have a physical version of the robot in the table.

02:13.000 --> 02:20.000
Let's start with an overview of the hardware and design aspects of the Fosbot.

02:20.000 --> 02:26.560
On the front side of the robot we have a multi-core RGB lead on the top left, a photo resistor

02:26.560 --> 02:30.840
on the top right and ultrasonic sensor in the middle.

02:30.840 --> 02:41.160
The entire body of the robot is 3D printable in any FDM printer with bed size 220 by 220

02:41.160 --> 02:42.760
millimeters.

02:42.760 --> 02:48.160
The design is customizable and easy to assemble.

02:48.160 --> 02:54.240
At the bottom of the robot there are three IR optical sensors suitable for line following

02:54.240 --> 03:00.680
or edge detection application.

03:00.680 --> 03:06.560
The robot moves based on two DC motors and the free rotor on the back side.

03:06.560 --> 03:14.160
This motor have odometers to measure the movement of the robot and there is also a

03:14.160 --> 03:20.480
three axis accelerometer and gyroscope sensor inside.

03:20.480 --> 03:27.480
At the back of the robot there is a speaker and an off switch charging port and the robot

03:27.480 --> 03:33.640
powered by three lithium ion rechargeable batteries.

03:33.640 --> 03:39.480
On the top of the robot there are some unique features, a pulling component in the back

03:39.480 --> 03:41.520
side of the robot.

03:41.520 --> 03:48.040
That component gives the opportunity to user to attach small object, let's say using a

03:48.040 --> 03:56.440
rope, in order to measure how the extra weight affects the movement of the robot.

03:56.440 --> 03:59.320
Also we have a large detachable cover.

03:59.320 --> 04:05.240
It's the white circular piece on the top.

04:05.240 --> 04:13.280
That component is Lego brick compatible and also have a hole in the front side.

04:13.280 --> 04:19.200
This hole drives to the bottom of the robot and allowing the market to be attached for

04:19.200 --> 04:23.200
programmatic drawing.

04:23.200 --> 04:31.800
Now let's summarize the key features from the hardware design aspects.

04:31.800 --> 04:36.960
The robot is 3D readable and offers repairability and customization.

04:36.960 --> 04:43.560
Can be designed to be used with common electronics.

04:43.560 --> 04:49.000
In the current version the brain of the robot is based on the Raspberry Pi but we already

04:49.000 --> 04:53.760
see some variation of the robot with Arduino or micro bit inside.

04:53.760 --> 05:01.720
It's open source and open design of course and it comes in a low cost around 90 to 120

05:01.720 --> 05:03.720
euros.

05:03.720 --> 05:05.800
In the slide you can see our lab on Her

05:05.800 --> 05:05.800
Her

05:05.800 --> 05:10.880
University and some pictures from let's say the assembly line of the robot, from the physical

05:10.880 --> 05:21.080
robot or also have some pictures from different assembly phases of the robot.

05:21.080 --> 05:23.120
Now we'll speak about the software.

05:23.120 --> 05:27.640
We have created the custom platform built in the robot with three modes.

05:27.640 --> 05:32.280
The Gitter Carder mode, the Elementor School mode and the High School or Advanced mode.

05:32.280 --> 05:38.120
The Gitter Carder mode features a friendly UI with card blocks based on Google's Blockly.

05:38.120 --> 05:44.320
Additionally it's expandable with the options to add new cards to execute Python or Blockly

05:44.320 --> 05:45.520
scripts.

05:45.520 --> 05:51.920
For the Elementor School we have a custom user interface once again based on more complicated

05:51.920 --> 06:00.760
Google's Blockly version that uses custom code blocks for all the sensors of the robot.

06:00.760 --> 06:09.640
The experience is similar to Scratch and that makes the robot to be easy, that offers easy

06:09.640 --> 06:11.880
direction with the robot.

06:11.880 --> 06:15.600
Finally we have the High School or Advanced mode.

06:15.600 --> 06:20.720
This mode based on Jupyter Notebooks and the native Python language.

06:20.720 --> 06:27.360
This mode is under construction but will be available soon.

06:27.360 --> 06:30.600
Now let's take a look to the platform UI.

06:30.600 --> 06:34.000
The platform, this is the platform's home screen.

06:34.000 --> 06:37.880
That home screen allows the creation of multiple projects.

06:37.880 --> 06:45.440
Also we have the ability to import or import export of shared project between users.

06:45.440 --> 06:50.760
Also using the little cog in the top right we can modify the behaviors on some blocks

06:50.760 --> 06:55.160
such as the default distance, let's say for one step movement.

06:55.160 --> 07:08.280
The icon with the three ABC cubes in the lower right offers access to the Kitter Kardon mode.

07:08.280 --> 07:12.200
Now we see the Kitter Kardon mode.

07:12.200 --> 07:17.280
The Kitter Kardon mode utilizes a simplified version of Blockly using card based blocks

07:17.280 --> 07:19.720
for basic actions.

07:19.720 --> 07:25.000
In the bottom right corner we can see an example of how this mode can be used in a classroom

07:25.000 --> 07:26.000
setting.

07:26.000 --> 07:31.720
In this example we are trying to teach students the numbers through a greeted carpet with

07:31.720 --> 07:35.440
numbers on it.

07:35.440 --> 07:40.960
In the elementary school mode we have as already said a fully custom version of Blockly.

07:40.960 --> 07:46.840
On the left side we have different categories of blocks including mathematics, programming,

07:46.840 --> 07:49.400
movement and sensing.

07:49.400 --> 07:55.120
On the right there are some control buttons and a terminal window for printing real time

07:55.120 --> 07:59.560
measurements and messages.

07:59.560 --> 08:01.720
Now for the advanced mode.

08:01.720 --> 08:05.400
The advanced mode of the robot is based in Jupiter.

08:05.400 --> 08:12.600
The user can directly program the robot using native Python language combined with our custom

08:12.600 --> 08:17.920
robot library and the code can be combined with text and images.

08:17.920 --> 08:24.240
Then the whole page can be exported including the result of the program execution as an

08:24.240 --> 08:30.120
experimental report in a class.

08:30.120 --> 08:33.760
Now for the action.

08:33.760 --> 08:38.200
This is a line following program written using Blockly.

08:38.200 --> 08:43.960
It's a very common task for students when we teach them robotics.

08:43.960 --> 08:46.360
We have some videos to present you.

08:46.360 --> 08:51.720
On the left you see a video of the robot line following a line and stopping when it detects

08:51.720 --> 08:54.200
an obstacle in front of it.

08:54.200 --> 08:59.400
On the right we have a video of the robot running the same code but this time following

08:59.400 --> 09:01.360
the line in the loop.

09:01.360 --> 09:07.280
When a colleague puts her hand in front of the robot it stops and waits until no obstacle

09:07.280 --> 09:10.280
is detected.

09:10.280 --> 09:24.080
Additionally, the physical robot will also have a simulated environment.

09:24.080 --> 09:32.120
We have developed a library and a custom simulation environment for our robot using CopleiaSim.

09:32.120 --> 09:37.800
This was a crucial step for us because it eliminates the need for a physical robot and

09:37.800 --> 09:42.800
that means that the experimentation with the robot comes in no cost.

09:42.800 --> 09:50.000
Our software platform works seamlessly in both the physical and the simulated environment

09:50.000 --> 09:54.440
allowing the project to run identically in either setting.

09:54.440 --> 09:59.000
On the left you can see a video of a simple example of our platform combined with the

09:59.000 --> 10:00.000
simulator.

10:00.000 --> 10:09.360
Here are more examples of our virtual environment.

10:09.360 --> 10:13.320
Those examples created for different teaching scenarios.

10:13.320 --> 10:18.760
Also we have a video in the top right that demonstrates a line following project inside

10:18.760 --> 10:22.120
the simulator.

10:22.120 --> 10:31.240
We are trying to constantly improve the robot and we have received strong interest from

10:31.240 --> 10:33.120
our university students.

10:33.120 --> 10:38.720
We have already students creating educational material and developing new features such

10:38.720 --> 10:46.960
as the real-time graphs and soon we will hope to integrate the new features to the main

10:46.960 --> 10:49.000
platform.

10:49.000 --> 10:55.600
Now let's dig deeper into the workings of our platform.

10:55.600 --> 11:00.360
Firstly we have created a custom library to simplify the process of controlling the electronic

11:00.360 --> 11:02.760
parts of the robot.

11:02.760 --> 11:07.680
That library is based of my 2019 Google Summer of Code contribution.

11:07.680 --> 11:14.880
The platform was built using Flask, Socket.io, Python, Blockly and can be deployed to the

11:14.880 --> 11:20.840
robot via token containers for easy distribution and maintenance.

11:20.840 --> 11:27.760
The robot after powering up tried to connect to a non-WiFi and if that is not possible

11:27.760 --> 11:31.640
then the robot creates its own wireless access point.

11:31.640 --> 11:38.720
The access to the platform can be gained through a user preferred browser such as Chromium

11:38.720 --> 11:46.880
and finally all the necessary tools are already pre-installed inside the robot.

11:46.880 --> 11:51.520
This allows a hassle-free experience as the user never needs to install anything to their

11:51.520 --> 11:54.560
computer.

11:54.560 --> 11:59.520
In this slide we present a brief overview of how users can be accessed at multiple levels

11:59.520 --> 12:00.520
of the robot.

12:00.520 --> 12:06.640
The top level is designed for less experienced users and is where the platform resides inside

12:06.640 --> 12:09.840
multiple docker containers.

12:09.840 --> 12:15.000
The access to this layer can be achieved through a web browser.

12:15.000 --> 12:22.080
The second and third levels are designed for advanced users with knowledge of Python language

12:22.080 --> 12:29.600
and bus and can be accessed through SSH.

12:29.600 --> 12:33.560
Before concluding I would like to present the future prospects for the robot and its

12:33.560 --> 12:39.000
potential use in higher education.

12:39.000 --> 12:44.700
In Herakopio University we have already started to examine the potential of using the force

12:44.700 --> 12:50.680
boot as a machine learning robotics platform by combining the custom high-level library,

12:50.680 --> 12:56.560
the simulated environment and the physical robot with advanced algorithms.

12:56.560 --> 13:01.680
With this combination the force boot has the potential to be used in various ways, for

13:01.680 --> 13:03.840
example, reinforcement learning.

13:03.840 --> 13:11.440
Additionally, if attached to the robot some advanced sensors such as cameras or lighters,

13:11.440 --> 13:19.720
it can be used as a self-driving platform or a computer vision platform.

13:19.720 --> 13:22.240
So that brings us to the end of our presentation.

13:22.240 --> 13:24.040
I hope you enjoyed it.

13:24.040 --> 13:31.040
Before closing I want to add a couple of things to this excellent presentation of Christos.

13:31.040 --> 13:37.600
First of all I have to say that technology wouldn't be successful without content, first

13:37.600 --> 13:39.760
of all, and without people.

13:39.760 --> 13:48.520
With the help of Open Technologies Alliance we also managed to have a great group of educators,

13:48.520 --> 13:54.840
primary and secondary education, that currently are creating or developing educational activities

13:54.840 --> 14:00.880
and educational content for teachers in Greece.

14:00.880 --> 14:07.320
They are currently running some seminars for force boot and they are currently educating

14:07.320 --> 14:16.320
them on programming and using force boot in their teaching activities.

14:16.320 --> 14:22.560
Over 1,000 or almost 1,000 teachers around Greece.

14:22.560 --> 14:29.240
So the benefit is that we have the virtual simulation environment of force boot so they

14:29.240 --> 14:33.600
can start working in the simulation environment and then everything that they have created

14:33.600 --> 14:38.680
there, they can directly apply it to force boot, they can print the force boot, assemble

14:38.680 --> 14:42.480
it and use it in the actual process.

14:42.480 --> 14:48.680
Another thing that I would like to add to the higher education part of this presentation

14:48.680 --> 14:54.120
of this work is that we are currently working with some colleagues in the university in

14:54.120 --> 15:00.400
order to develop a short term curriculum, let's say one year curriculum with basic IT

15:00.400 --> 15:07.840
courses such as data management courses, IoT programming, basic Python programming, machine

15:07.840 --> 15:13.760
learning and AI as Christo said, in order to develop content that in most of the activities

15:13.760 --> 15:17.840
we'll use force boot as its main demonstration platform.

15:17.840 --> 15:21.560
So this is another effort that we are trying to do, we are working on at the moment and

15:21.560 --> 15:25.640
we hope that it will soon bring us some results.

15:25.640 --> 15:53.640
And I would like to thank you once again for your attendance.
