WEBVTT

00:00.000 --> 00:14.560
The

00:14.560 --> 00:17.680
next presentation will be by Fabien Choteau.

00:17.680 --> 00:25.640
He will give an introduction on formal verification and will learn us how to mathematically prove

00:25.640 --> 00:27.600
the XaraBox in your software.

00:27.600 --> 00:29.480
So thank you.

00:29.480 --> 00:38.560
I need a timer because I have quite a lot of things to say.

00:38.560 --> 00:44.240
So hi everyone, I'm Fabien and today I want to talk about formal verification, open source

00:44.240 --> 00:46.920
formal verification.

00:46.920 --> 00:51.680
So first a disclaimer, I'm not an expert in formal verification but I'm a user of this

00:51.680 --> 00:53.160
technology.

00:53.160 --> 00:58.380
What I'm an expert at is embedded software but I use formal verification and I will explain

00:58.380 --> 01:04.820
later our work in a company that's developing formal verification solutions.

01:04.820 --> 01:10.400
So if we look at what Wikipedia says, formal verification is the act of proving or disproving

01:10.400 --> 01:17.040
the correctness of intended algorithms using formal methods of mathematics.

01:17.040 --> 01:20.440
So in practice, what does that mean?

01:20.440 --> 01:24.880
Let's take a very trivial example.

01:24.880 --> 01:30.800
If we look at this line of code and we want to prove that it's correct, that it never

01:30.800 --> 01:35.080
fails, first we will have to look at what can go wrong.

01:35.080 --> 01:40.240
So for instance here we can say, well there's potentially a division by zero, right?

01:40.240 --> 01:41.240
That's bad.

01:41.240 --> 01:49.920
So if we want to prove that the line is correct, we have to prove that X minus 10 is different

01:49.920 --> 01:57.240
from zero, which in terms means we have to prove that X is different than 10.

01:57.240 --> 02:05.640
This is known as a verification condition, something that has to be true for our program

02:05.640 --> 02:09.600
to be correct.

02:09.600 --> 02:16.720
Now if we look at this line of code in a context, just a trivial example, here we see that there

02:16.720 --> 02:22.720
is a if statement that's guarding the expression, so we know that X is always different from

02:22.720 --> 02:31.000
10 and therefore we know that there's no possible division by zero in this piece of code.

02:31.000 --> 02:32.880
So that was easy, right?

02:32.880 --> 02:37.840
But now let's look at another very trivial piece of code.

02:37.840 --> 02:41.200
Are you able to spot all the verification conditions?

02:41.200 --> 02:47.440
Are you able to check that they are respected or not?

02:47.440 --> 02:50.440
This is actually very, very difficult.

02:50.440 --> 02:54.760
Most programmers will know some of the things that can go wrong.

02:54.760 --> 02:58.040
Most of the time we will forget what they are.

02:58.040 --> 03:01.280
I'm looking at you, Integral Flow.

03:01.280 --> 03:07.680
And so that's why programming correctly is very difficult for human beings because we

03:07.680 --> 03:12.800
are not able to keep in mind all the verification conditions and play with them and check them

03:12.800 --> 03:13.960
all the time.

03:13.960 --> 03:17.080
Again, this is very simple piece of code.

03:17.080 --> 03:24.720
And so what formal verification is, in particular automatic formal verification, well the goal

03:24.720 --> 03:32.320
is to have tools that will extract the verification conditions from the code and then run a mathematical

03:32.320 --> 03:37.480
proof to check that they are respected.

03:37.480 --> 03:44.280
And so today I want to talk about one framework for automatic formal verification which is

03:44.280 --> 03:47.400
called Spark.

03:47.400 --> 03:57.000
So Spark is both a set of tools and a language to perform automatic formal verification.

03:57.000 --> 04:02.440
So on the tool side we have different tools that are working together to achieve this

04:02.440 --> 04:03.840
goal.

04:03.840 --> 04:09.560
The first one is GnaProve, it's developed by the company I work for, Adacore.

04:09.560 --> 04:14.280
It's going to take Spark code as the input and translate it to another language called

04:14.280 --> 04:16.280
YML.

04:16.280 --> 04:23.840
Then we have this, the tool itself, Y3, developed by the INRIIA in France.

04:23.840 --> 04:32.240
It's a research institute which is going to again translate the code and extract the verification

04:32.240 --> 04:39.800
conditions and call the different solvers which are on the right here to ask them to

04:39.800 --> 04:42.520
prove the verification conditions.

04:42.520 --> 04:47.240
So we have different solvers that will have properties on different kinds of algorithms,

04:47.240 --> 04:50.760
AltairGo, CVC5, Z3.

04:50.760 --> 04:58.360
And so this full tool chain is open source and developed by different entities as I mentioned.

04:58.360 --> 05:02.280
And so the solvers for instance, they are not only used for Spark, they are used for

05:02.280 --> 05:11.600
other formal verification frameworks, but all of them work together in this framework.

05:11.600 --> 05:16.080
And so on the other side Spark is also a language.

05:16.080 --> 05:22.140
And actually Spark is a subset of the ADAP programming language.

05:22.140 --> 05:28.560
And so the question you may ask is why would you use ADAP, why would you use a subset of

05:28.560 --> 05:32.440
ADAP for formal verification?

05:32.440 --> 05:38.920
So I'm going to take just two simple examples.

05:38.920 --> 05:43.920
Why ADAP is great for when you want to do formal verification?

05:43.920 --> 05:48.200
Well this language provides a lot of specification power.

05:48.200 --> 05:54.760
The developers can express very precisely what they want from the program, from the

05:54.760 --> 06:02.360
code, which then the formal verification framework will be able to check.

06:02.360 --> 06:07.440
Just simple example, if you program in any other language, if you want to have in your

06:07.440 --> 06:13.960
application a percentage value, for instance for the completion of a process or whatever,

06:13.960 --> 06:20.760
usually we'll say okay, my percentage is a float and I'm going to say I'm going to use

06:20.760 --> 06:23.120
the value from 0 to 1.

06:23.120 --> 06:27.400
And if you are an extremely good programmer, you're going to write that in a comment.

06:27.400 --> 06:32.000
Like you know, my lowest value is 0, my highest value is 1.

06:32.000 --> 06:34.160
And that's just a comment.

06:34.160 --> 06:37.960
And then if five years down the line you want to say oh actually it's better if it's from

06:37.960 --> 06:41.560
0 to 100, what happens to the comment?

06:41.560 --> 06:43.000
Maybe you're dead hit, maybe you don't.

06:43.000 --> 06:48.560
How do you make sure that everything, all the code is updated to follow this new rule?

06:48.560 --> 06:50.880
That's very difficult to maintain.

06:50.880 --> 06:57.280
So one example with Ada, you just define your own type and you say it's a new float, it's

06:57.280 --> 07:05.360
a different kind of float that has only valid value between 0 and 1.

07:05.360 --> 07:11.440
And so what's great here is that the solvers that will try to prove the code, they get

07:11.440 --> 07:15.440
a lot of information from here.

07:15.440 --> 07:20.280
First they will add verification conditions when you try to cast from a regular float

07:20.280 --> 07:22.440
to this percentage value.

07:22.440 --> 07:25.700
Because if the value is not within the range, that's a bug in your program and you want

07:25.700 --> 07:27.160
to know it.

07:27.160 --> 07:32.360
Also you can extract information like if you take two percentage value and you multiply

07:32.360 --> 07:36.080
them you also know that the result is between 0 and 1.

07:36.080 --> 07:40.800
And so in terms that means a lot of information for the provers to do their work and so there

07:40.800 --> 07:52.160
will be able to more automatically reason and prove that the program is correct.

07:52.160 --> 07:57.960
Another example is the contract-based programming of Ada.

07:57.960 --> 08:04.440
So you can have preconditions and pass conditions on your subprograms.

08:04.440 --> 08:10.400
So precondition is something that has to be true when you call the function or the procedure.

08:10.400 --> 08:16.880
So precondition is something that has to be true when you return from the subprogram.

08:16.880 --> 08:20.360
So very simple example here with the stack.

08:20.360 --> 08:21.840
We implement the stack.

08:21.840 --> 08:26.840
We have functions to know if the stack is full or if it's empty.

08:26.840 --> 08:33.080
And we implement the push and obviously, well not obviously, but in this API we say it doesn't

08:33.080 --> 08:36.920
make sense to push something on the stack if the stack is already full.

08:36.920 --> 08:38.600
So never do that.

08:38.600 --> 08:44.400
That's the contract that the procedure is asking from the caller.

08:44.400 --> 08:49.680
And then the implementation says if you push something on the stack, well it's not empty

08:49.680 --> 08:53.120
anymore at the return.

08:53.120 --> 08:59.440
And so with Spark, what's great here is that you have formal verification both on the caller

08:59.440 --> 09:00.600
side.

09:00.600 --> 09:09.600
So Spark will prove that you never call the push function when the stack is full.

09:09.600 --> 09:13.920
And on the implementation side, it's going to prove that when you return from the push

09:13.920 --> 09:16.880
function, the stack is never empty.

09:16.880 --> 09:25.600
And so that's going into functional correctness verification, which means your software is

09:25.600 --> 09:30.080
doing what it's supposed to do and only what it's supposed to do.

09:30.080 --> 09:36.680
And so with the integrated pre- and post-conditions in Ada and other features that I don't have

09:36.680 --> 09:46.300
time to mention, well this makes Ada a very great language for formal verification.

09:46.300 --> 09:53.680
So why should I care about Spark and I would say formal verification in general?

09:53.680 --> 10:00.120
So with Spark you can have mathematical proof that there is no possible vulnerabilities

10:00.120 --> 10:04.380
in your application for any possible inputs.

10:04.380 --> 10:12.600
That means no buffer overflow, no division by zero, no integral overflow and so on.

10:12.600 --> 10:18.760
If you go beyond and you use contracts, you can also prove, as I mentioned, the functional

10:18.760 --> 10:19.760
correctness.

10:19.760 --> 10:25.040
The program does what it's supposed to do and only what it's supposed to do.

10:25.040 --> 10:31.360
And in terms that means you can avoid some of the testing efforts because, for instance,

10:31.360 --> 10:34.680
unit testing is more or less trying to achieve the same goal.

10:34.680 --> 10:41.000
So if you already have a mathematical proof that the functional correctness of your code,

10:41.000 --> 10:43.160
you don't need to do unit testing anymore.

10:43.160 --> 10:47.400
And so you're going to save time on that.

10:47.400 --> 10:53.120
Finally we published a case study from NVDA.

10:53.120 --> 11:02.680
So a few years ago the NVDA security team was questioning the methodology for security

11:02.680 --> 11:06.800
and how to achieve their goals in terms of security.

11:06.800 --> 11:10.160
And so they said testing security is pretty much impossible.

11:10.160 --> 11:14.820
You cannot test all possible combinations of all possible values for your application.

11:14.820 --> 11:19.240
And so they decided to try probability.

11:19.240 --> 11:22.460
And they selected Spark as an experiment.

11:22.460 --> 11:26.580
And now they are deploying more and more Spark in the GPU.

11:26.580 --> 11:34.420
So if you get the latest, greatest NVDA GPU, there should be some Spark proven code embedded

11:34.420 --> 11:43.200
in the firmware, which lets them actually focus on other parts of the security on more

11:43.200 --> 11:49.480
interesting verifications and more interesting security properties of the application.

11:49.480 --> 11:53.600
They don't have to deal with buffer overflows and integrals overflow.

11:53.600 --> 11:56.220
All the low level stuff it's already taken care of.

11:56.220 --> 12:00.400
And they focus on more interesting points.

12:00.400 --> 12:05.200
So now let's do some proof.

12:05.200 --> 12:11.160
So for the ADAN Spark programming language, we have this package manager called Alair.

12:11.160 --> 12:16.600
So here are a few instructions to make your first and prove your first piece of Spark

12:16.600 --> 12:17.700
code.

12:17.700 --> 12:22.160
So you don't know that install the package manager.

12:22.160 --> 12:27.400
So from the command line, we start by creating a project or a crates with Alair in it.

12:27.400 --> 12:29.580
We enter the directory.

12:29.580 --> 12:33.800
We add the Gnet Prove tool suite as dependency.

12:33.800 --> 12:37.240
So it's going to download everything and set it up for you.

12:37.240 --> 12:45.920
Then we write some piece of code so you can recognize our very nice equation here.

12:45.920 --> 12:51.920
Just for the declaration of the X constants, doesn't matter what it is.

12:51.920 --> 12:55.800
I'm just taking an integral value that Spark doesn't know.

12:55.800 --> 13:00.880
So just to make sure I'm not cheating or anything.

13:00.880 --> 13:02.720
We go to the console again.

13:02.720 --> 13:04.760
We run a Gnet Prove.

13:04.760 --> 13:07.200
And so Gnet Prove will tell us, well, there might be a problem.

13:07.200 --> 13:11.680
There might be a division by zero error at this point.

13:11.680 --> 13:15.880
So as you can see, the message is pretty clear.

13:15.880 --> 13:20.880
Actually it can be even better than that because the tool can provide counter examples.

13:20.880 --> 13:27.200
So if we had the switch, counter examples on, Gnet Prove will say division by zero might

13:27.200 --> 13:28.200
fail.

13:28.200 --> 13:31.720
For instance, when X equals 10.

13:31.720 --> 13:34.820
And so that's pretty easy to fix.

13:34.820 --> 13:38.440
We just add this if statement.

13:38.440 --> 13:40.160
And we run the tool again.

13:40.160 --> 13:41.160
And that's it.

13:41.160 --> 13:45.840
We proved our first piece of code.

13:45.840 --> 13:49.720
So as you can see, it was easy.

13:49.720 --> 13:56.400
If you want to try and learn a little bit of Spark, we have an online website.

13:56.400 --> 14:02.200
So learn.alacor.com, online interactive website.

14:02.200 --> 14:04.920
So you don't even have to install what I showed before.

14:04.920 --> 14:08.680
Just to learn and try the tool sheets.

14:08.680 --> 14:12.600
So there are different chapters and one specific to Spark.

14:12.600 --> 14:17.200
So that's one way to get started.

14:17.200 --> 14:22.760
And for those who wondered, just the piece of code before, there are seven potential

14:22.760 --> 14:26.480
bugs or errors in this one.

14:26.480 --> 14:31.080
So I let you, as an exercise, to fix this one.

14:31.080 --> 14:32.080
Thank you very much.

14:32.080 --> 14:33.080
Thank you.

14:33.080 --> 14:37.080
Thank you for the presentation.

14:37.080 --> 14:49.640
Let me unwrap you with a shot.

14:49.640 --> 15:04.080
Let me turn it off.

15:04.080 --> 15:33.720
Here we go.
