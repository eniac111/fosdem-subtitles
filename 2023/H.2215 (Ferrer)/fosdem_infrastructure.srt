1
0:00:00.000 --> 0:00:11.920
Okay. Hello, everyone, and welcome to the last lightning talk of the conference. I hope

2
0:00:11.920 --> 0:00:16.520
you've enjoyed yourselves. This will be the FOSDIM infrastructure review, same as every

3
0:00:16.520 --> 0:00:27.760
year presented by Richard and Basti.

4
0:00:27.760 --> 0:00:32.840
So normally I do this thing, but Basti has been helping a ton, and the ball of spaghetti

5
0:00:32.840 --> 0:00:40.400
and spit and duct tape which I left him turned into something usable. So I'm just going to

6
0:00:40.400 --> 0:00:45.120
sit here on the side, and I'm here around for the Q&A. But for the rest, it's Basti,

7
0:00:45.120 --> 0:00:56.080
and it's his first public talk for realty, so give him a big round of applause.

8
0:00:56.080 --> 0:01:02.480
Thank you. I hope I will not screw this one up. Okay. So we'll have about 15 minutes,

9
0:01:02.480 --> 0:01:10.120
10 minutes of talk, and five minutes for Q&A, and I hope it's somewhat interesting to you.

10
0:01:10.120 --> 0:01:16.600
First the facts. The core infrastructure hasn't changed that much since the last FOSDIM 2020.

11
0:01:16.600 --> 0:01:24.400
We're still running on its Cisco ASR 10K for routing ACLs, NAT64, and DHCP. We have already

12
0:01:24.400 --> 0:01:31.280
reused several switches that we are already here from the last FOSDIM. They're on by FOSDIM.

13
0:01:31.280 --> 0:01:41.120
These are Cisco C3750 switches. We had our old servers which are now turning 10 this

14
0:01:41.120 --> 0:01:47.640
year. They were still here, and they will be replaced next year. We have done, like

15
0:01:47.640 --> 0:01:54.360
all the years before, everything with Prometheus, Loki, and Grafana for monitoring our infrastructure,

16
0:01:54.360 --> 0:02:00.240
because that's what helps us running all the conference here. And we've built some public

17
0:02:00.240 --> 0:02:05.920
dashboards, and we just put it out to a VM outside of ULB because we were running out

18
0:02:05.920 --> 0:02:13.600
of bandwidth like the years before, and I'll come to that back later.

19
0:02:13.600 --> 0:02:20.120
We have a quite beefy video infrastructure. You might have seen this one here. It's a

20
0:02:20.120 --> 0:02:26.440
video capturing device. It's called a video box here at FOSDIM. It's all public. It's

21
0:02:26.440 --> 0:02:31.920
all open source except one piece that's in there. You can find it on GitHub if you try

22
0:02:31.920 --> 0:02:39.600
to build it yourself. Go ahead. Just grab the GitHub repo and clone it. These devices,

23
0:02:39.600 --> 0:02:45.000
there's two of them, one at the camera, one here for the presenter's laptop. They sent

24
0:02:45.000 --> 0:02:50.960
their streams to a big render farm that we have over in the K building where every year

25
0:02:50.960 --> 0:03:00.080
our render farm is running on some laptops. So laptops sent the streams off to the cloud

26
0:03:00.080 --> 0:03:05.480
from Hetzner, and from there we just distribute it to the world so everyone at home can see

27
0:03:05.480 --> 0:03:14.680
the talks. We have some sort of semi-automatic rev up on cutting process. Those of you have

28
0:03:14.680 --> 0:03:20.480
been talking here, maybe have known S-Review for years. This is the first time it's running

29
0:03:20.480 --> 0:03:27.680
on Kubernetes. So we are trying to go cloud native as well with our infrastructure just

30
0:03:27.680 --> 0:03:34.680
to show how all has been held together. This is our video boxes. I don't know if you can

31
0:03:34.680 --> 0:03:43.240
see it. We got those black magic encoders here that are turning the signals that we

32
0:03:43.240 --> 0:03:50.400
get, like SDI, HDMI, into a useful signal that we can process with our banana pie that

33
0:03:50.400 --> 0:03:56.920
we have in there. Everything is wired up to a dump switch here and then we go out like

34
0:03:56.920 --> 0:04:03.360
here and have our own switching infrastructure inside those boxes. There's some SSD below

35
0:04:03.360 --> 0:04:10.000
here where we just, in case of network failure, dump everything to the SSD as well. So hopefully

36
0:04:10.000 --> 0:04:15.280
everything that has been talked about at the conference is still captured and available

37
0:04:15.280 --> 0:04:23.280
in case of a network breakdown. Those boxes also have a nice display for the speaker so

38
0:04:23.280 --> 0:04:28.620
we can see if everything is running or it's not running, which makes it easy for people

39
0:04:28.620 --> 0:04:33.280
to operate these boxes here. You don't have to be a video pro. You just have to wire yourself

40
0:04:33.280 --> 0:04:37.020
up to the box. You see a nice Fostom logo and see, okay, everything is working and you're

41
0:04:37.020 --> 0:04:46.800
done and everything gets set out. This is like how the video system is actually working.

42
0:04:46.800 --> 0:04:53.480
All this can be found on the GitHub. You don't have to take screenshots for that. If you

43
0:04:53.480 --> 0:04:59.720
like to see it, we will tear down this room afterwards so everyone can have a look at

44
0:04:59.720 --> 0:05:04.560
the infrastructure we're using because it's not being used after this talk. You see it's

45
0:05:04.560 --> 0:05:11.280
quite some interesting things to do. This is the instructions that all our volunteers

46
0:05:11.280 --> 0:05:20.960
get when they wire up the whole buildings here on one day on Friday. They're not here,

47
0:05:20.960 --> 0:05:25.280
but they should be given some round of applause because they're volunteers that are doing

48
0:05:25.280 --> 0:05:30.920
really the hard work and building up on one day the complete Fostom. Maybe it's time for

49
0:05:30.920 --> 0:05:45.560
a round of applause for them. Here we have another thing. This is also on the GitHub

50
0:05:45.560 --> 0:05:51.240
rapid where you can see where's something coming from. We have the room sound system.

51
0:05:51.240 --> 0:05:55.520
This is what you're hearing me through. We have a camera with audio gear, speaker laptops,

52
0:05:55.520 --> 0:06:01.480
that's all getting pushed down until someone reaches your device down here. There's a ton

53
0:06:01.480 --> 0:06:12.040
of services processing it in between. This is almost all done with open source software.

54
0:06:12.040 --> 0:06:18.800
Expect for the encoder that's running in there, which is from Blackmagic Design. How is it

55
0:06:18.800 --> 0:06:26.040
used? We have a rendering farm. This is the laptops. It's 27 this year. For those of you

56
0:06:26.040 --> 0:06:32.200
who don't know, those laptops are being sold after Fostom. If you want one, you can grab

57
0:06:32.200 --> 0:06:37.760
one. This year they're already gone. For next year, maybe you want to have a cheap device.

58
0:06:37.760 --> 0:06:43.400
You can have them with everything that's on them because we literally don't care for that.

59
0:06:43.400 --> 0:06:50.120
You can have it because everything's been processed after the Fostom. You can see it.

60
0:06:50.120 --> 0:06:59.400
We have some racks where we just put them four-wise. We have 27 of them. We have some

61
0:06:59.400 --> 0:07:07.440
switch infrastructure that is used for processing all that stuff. This one's not running out

62
0:07:07.440 --> 0:07:12.400
of bandwidth, but we're coming back to what's running out of bandwidth. You might see this

63
0:07:12.400 --> 0:07:23.160
mess over here. This is our Internet. Looks like every common Internet on the planet.

64
0:07:23.160 --> 0:07:28.120
This is our safety net. We have a big box here where all the streams go. This will be

65
0:07:28.120 --> 0:07:33.480
sent out to Bulgaria, to the video team right after Fostom. We have a really off-site copy

66
0:07:33.480 --> 0:07:42.920
of everything. The challenges for this year. DNS64. All the

67
0:07:42.920 --> 0:07:52.320
years we've been running on Bind 9 since ages. We switched to Cordian S, just testing it

68
0:07:52.320 --> 0:07:59.720
on Sunday of Fostom 2020. We really saw a significant reduction in CPU usage. That's

69
0:07:59.720 --> 0:08:07.800
why we stuck to Cordian S since then. This year we also replaced the remaining Bind installations

70
0:08:07.800 --> 0:08:12.160
that we handled for all the internal DNS and all other recursive stuff that's been used

71
0:08:12.160 --> 0:08:19.400
here to provide you Internet access. Richie always used to give you some timelines,

72
0:08:19.400 --> 0:08:27.400
and that's what I'm trying to do as well. There were times when it was mentally challenging

73
0:08:27.400 --> 0:08:34.480
for people building up Fostom. We got better by year by year by year by doing some sort

74
0:08:34.480 --> 0:08:41.840
of automation and getting people used to know what to do and have everything set up before

75
0:08:41.840 --> 0:08:49.160
that. We installed routers. You see that? There's a slide. It's getting better year

76
0:08:49.160 --> 0:08:56.280
of the year. This year we had a very... We thought it would be okay from what we know.

77
0:08:56.280 --> 0:09:01.800
We just set it up in January, and everything worked. We came here on the 5th of January,

78
0:09:01.800 --> 0:09:08.320
I think, put everything up, and it just worked, which is great, which gives you some sort

79
0:09:08.320 --> 0:09:16.320
of things not to care about, because there were other things to care about. The network

80
0:09:16.320 --> 0:09:21.880
to have it up and running here took us a bit longer this year than the last years, because

81
0:09:21.880 --> 0:09:29.400
we were playing around with the second uplink that we got. We used to have one gigabit uplink.

82
0:09:29.400 --> 0:09:34.640
Last week we got a 10 gigabit uplink, and we thought, okay, just enable that and play

83
0:09:34.640 --> 0:09:40.680
with it, and it turned out to be not that easy to getting up both of the BGP sessions

84
0:09:40.680 --> 0:09:48.480
running and doing it properly. That's why it took us a bit longer this year. The monitoring

85
0:09:48.480 --> 0:09:54.360
was also one thing, which really helps us to understand if FOSDIM is ready to go or

86
0:09:54.360 --> 0:10:02.400
if something has to stay very, very late here. The last years we've been very, very good

87
0:10:02.400 --> 0:10:09.360
at that. Basically, in January everything was done, like the last of January, but it's

88
0:10:09.360 --> 0:10:14.800
January. This time in the first half of January everything was set up and was running, and

89
0:10:14.800 --> 0:10:22.680
it worked. It was really great, because some people actually got some sleep at FOSDIM.

90
0:10:22.680 --> 0:10:31.400
They didn't need to stay here very long, because everything was all pre-made, and they just

91
0:10:31.400 --> 0:10:37.320
go and look at the dashboard, okay, this is missing, this is missing, and just say, okay,

92
0:10:37.320 --> 0:10:44.080
just have them all checked. The video build-up took a bit longer this year, because of getting

93
0:10:44.080 --> 0:10:50.920
old and rusty at that. Also, very many new faces that have never built up such a great

94
0:10:50.920 --> 0:10:58.880
conference. This is why we took it a bit longer, and the video team also, yeah, I think they

95
0:10:58.880 --> 0:11:06.080
got the least amount of sleep of all of the stuff that was running the conference. This

96
0:11:06.080 --> 0:11:15.240
was the story so far. We closed FOSDIM 2020, I was also there at 2020. 2020 was really

97
0:11:15.240 --> 0:11:22.040
one of the best ones we ever had from a technical perspective. We had everything running via

98
0:11:22.040 --> 0:11:27.080
Ansible, just like one command, and then wait an hour until everything is deployed and you're

99
0:11:27.080 --> 0:11:32.880
gone. Cool, have some beer, some latte in between, and everything was cool. Then we had this

100
0:11:32.880 --> 0:11:43.240
pandemic, just for me, like a week after FOSDIM, everything went down. You had FOSDIM 2021

101
0:11:43.240 --> 0:11:49.040
and 2022, there were no conference here at the UB, so we had no infrastructure to manage,

102
0:11:49.040 --> 0:11:54.960
which was quite okay. We had to do some other things, like most of you have learned that

103
0:11:54.960 --> 0:12:02.480
we have a big metrics installation to run the FOSDIM conference and help you with communicating

104
0:12:02.480 --> 0:12:10.080
during the conference. Then there was this bad thing that the maintainer of the infrastructure

105
0:12:10.080 --> 0:12:18.120
left FOSDIM between these years. So Richie searched for someone who was dumb enough to

106
0:12:18.120 --> 0:12:29.280
do that. That's me. So this year we're back again in persona. Sorry? Yeah, thanks.

107
0:12:29.280 --> 0:12:41.320
Yeah. So after two years, we came looking for the two machines after almost two years,

108
0:12:41.320 --> 0:12:47.840
like no one touched them. They rebooted one or two times due to power outages in the server

109
0:12:47.840 --> 0:12:55.480
cabinet. But we had a working SSH key. We had tons of updates to install after literally

110
0:12:55.480 --> 0:13:01.280
three years. I wonder, nobody broke into the machines because they were public exposed

111
0:13:01.280 --> 0:13:09.080
on the Internet. But only SSH and I think a three-year-old or three-and-a-half-year-old

112
0:13:09.080 --> 0:13:16.040
Prometheus installation which was full of bugs. Yeah. We noticed that the battery controllers,

113
0:13:16.040 --> 0:13:19.840
the battery packs of the rate controllers have been depleted, so this was the only thing

114
0:13:19.840 --> 0:13:27.520
that actually happened in the three years. The batteries went to zero and didn't set

115
0:13:27.520 --> 0:13:33.360
themselves on fire, so everything was okay. The machines worked. Just a bit of performance

116
0:13:33.360 --> 0:13:38.960
degradation, but everything seemed to be okay. And then we tried to run this Ansible thing

117
0:13:38.960 --> 0:13:45.880
from the last years. And three years later, Ansible has done a lot of things in the time

118
0:13:45.880 --> 0:13:52.680
and you want to use a current version of Ansible with that old stuff. You end up like this.

119
0:13:52.680 --> 0:13:59.160
This is me. Start from scratch or fix all the Ansible roles. You can have a look at

120
0:13:59.160 --> 0:14:07.560
them. They're also on GitHub. So when we saw, okay, how do we do this and said, okay, then

121
0:14:07.560 --> 0:14:14.800
just be gone. Ansible be gone. We just fix it after the first time because we will have

122
0:14:14.800 --> 0:14:22.440
to renew the service anyway and everything will change. So the service timeline, we had

123
0:14:22.440 --> 0:14:29.960
them service alive at the 8th of January. Services, DNS, we had centralized all our

124
0:14:29.960 --> 0:14:35.040
locks. This was something Richie was looking for since ages that we had easy accessible

125
0:14:35.040 --> 0:14:41.920
lock files for everything that's running here at FOSDEM, which was good that we had them

126
0:14:41.920 --> 0:14:48.680
because we could see things like, oh, the Internet line that was proposed to be there

127
0:14:48.680 --> 0:14:57.000
actually came. Nobody told us, but it came up. You see that? We, thanks to the centralized

128
0:14:57.000 --> 0:15:07.840
logging, we were aware of things like that. And then we could go and fire up our BGP sessions.

129
0:15:07.840 --> 0:15:11.440
Then two days later, we noticed, okay, firing up the BGP sessions wasn't that a good idea

130
0:15:11.440 --> 0:15:20.680
because we lost almost all connectivity. Stop it, Seth, but I don't care. I just keep talking.

131
0:15:20.680 --> 0:15:26.360
We lost all our connectivity and said, okay, damn it. We're in some sort of panic mode

132
0:15:26.360 --> 0:15:32.080
because the reason for looking at the service was like this bind security issue that was

133
0:15:32.080 --> 0:15:40.080
been, I read the mail at the morning of January 28th and said, okay, we have to fix the bind

134
0:15:40.080 --> 0:15:43.880
installations and then you suddenly can't reach the service anymore. So, okay, are they

135
0:15:43.880 --> 0:15:49.740
already hacked or what's going on? And doing some back and forth with our centralized logging,

136
0:15:49.740 --> 0:15:57.480
you see that? This is Grafana Loki that we leveraged for that. We were kind of like,

137
0:15:57.480 --> 0:16:04.160
yeah, it's been really nice to debug things like that. We also noticed that there was

138
0:16:04.160 --> 0:16:13.240
an interface constantly flapping to our backbone, which we also could fix within that session.

139
0:16:13.240 --> 0:16:21.360
And after that, we said, okay, there are some MTU problems. We have to restart BGP and so

140
0:16:21.360 --> 0:16:29.560
on and back and forth. And then we finally agreed to just throw away the BGP sessions,

141
0:16:29.560 --> 0:16:35.240
go with the one gigabit line. And yesterday evening, we switched to the 10 gigabit line

142
0:16:35.240 --> 0:16:43.640
because we had the congested uplink like since 11 in the morning. So many people using too

143
0:16:43.640 --> 0:16:49.960
much bandwidth. And since yesterday evening, everything is okay. It's better. And we are

144
0:16:49.960 --> 0:16:55.240
on the 10 gigabit link due to the fact that there are not so many people here today. Yesterday

145
0:16:55.240 --> 0:17:01.720
there were quite a bit more. The link was not fully saturated. But you can tell we this

146
0:17:01.720 --> 0:17:07.000
is the place where we could use some more bandwidth was like, I don't know, this is

147
0:17:07.000 --> 0:17:12.160
usually time for something to eat. But at 330, we could actually use something of the

148
0:17:12.160 --> 0:17:18.920
new bandwidth that we had available. So if you want to look at all of the things, we

149
0:17:18.920 --> 0:17:23.120
have a dashboard put out there publicly. If you want to have a look at the infrastructure

150
0:17:23.120 --> 0:17:27.680
and the Ansible repo that will be fixed to work with current Ansible versions within

151
0:17:27.680 --> 0:17:34.040
the next few days, just clone our infrastructure, clone everything. And if you have any questions,

152
0:17:34.040 --> 0:18:01.440
I'll be glad to take them. Yeah, fire away. As I don't see any questions, then we are

153
0:18:01.440 --> 0:18:07.800
about to tear down this room after this. So please don't leave anything in here because

154
0:18:07.800 --> 0:18:16.080
it will be cleaned and everything will be torn out. If anyone else has a question, just

155
0:18:16.080 --> 0:18:25.240
there's one. We use the question is why do you use laptops for rendering because they

156
0:18:25.240 --> 0:18:30.640
have a built in USB called battery. So in place of the power outage, we can easily run

157
0:18:30.640 --> 0:18:37.400
with them. Also, they're very cheap for us. We can just use the computing power and sell

158
0:18:37.400 --> 0:18:41.360
it at the same price that we bought it to the people here. You get a cheap laptop. We

159
0:18:41.360 --> 0:18:48.080
get some computing time on them before and that's the main reason for running it on laptops.

160
0:18:48.080 --> 0:19:02.960
Well, actually, the question was why you were using banana pie. That's a good question.

161
0:19:02.960 --> 0:19:08.400
The thing is that the capabilities of the banana pie were a bit better than the Raspberry

162
0:19:08.400 --> 0:19:16.320
Pi. The times the decision was made. If you see there's a big LCD screen in front of the

163
0:19:16.320 --> 0:19:21.960
boxes where you can see that thing, I think it was driving those LCD panels and also the

164
0:19:21.960 --> 0:19:28.760
computing power available on the banana pie. But actually, we have to look that up in the

165
0:19:28.760 --> 0:19:45.800
repo. There's everything documented. Okay? Yeah, there's another one in the front. So

166
0:19:45.800 --> 0:19:52.040
the question was if there are any public dashboards out there. Yeah, we've put some public dashboards

167
0:19:52.040 --> 0:20:02.680
on dashboard.grafana.org. Oh, dashboard.fosdom.org. Sorry. Which you can have a look at the infrastructure.

168
0:20:02.680 --> 0:20:07.520
We used to have some more dashboards like the t-shirts that have been sold. But due

169
0:20:07.520 --> 0:20:14.160
to the fact that we changed the shop, we converted to something that we bought to an open source

170
0:20:14.160 --> 0:20:22.360
solution. And the thing is we totally forgot to monitor that. But there are some dashboards

171
0:20:22.360 --> 0:20:26.820
out there to monitor it. And if you want to see something more, just come to me after

172
0:20:26.820 --> 0:20:33.080
the talk and I'll show you something more here at the laptop. Okay? Yeah, another one.

173
0:20:33.080 --> 0:20:44.840
What was the biggest issue that you faced with this year? The biggest one standing here.

174
0:20:44.840 --> 0:20:56.040
No. Actually, the biggest issues we had was like running all that stuff after three years

175
0:20:56.040 --> 0:21:02.480
and not having set up everything properly was quite challenging. Like on Saturday morning,

176
0:21:02.480 --> 0:21:10.400
we had to run and redo the whole video installation on the K building because of you see those

177
0:21:10.400 --> 0:21:15.080
transmitters here. They were not plugged properly. And so we had no audio on the stream. This

178
0:21:15.080 --> 0:21:20.120
was one thing. And then another very challenging thing was like when we played around and I

179
0:21:20.120 --> 0:21:26.280
said play, we did not engineer anything properly. When we played around with the BGP sessions,

180
0:21:26.280 --> 0:21:33.880
it was not clear how long it would take till things distributed to the whole net. And we

181
0:21:33.880 --> 0:21:39.720
were literally just trying to get information. Is it working? Is it working not? And till

182
0:21:39.720 --> 0:21:44.800
this BGP information propagates from here to the rest of the planet like Brazil, it

183
0:21:44.800 --> 0:21:49.880
takes quite some time. And so you can't be sure that you're setting up the BGP session,

184
0:21:49.880 --> 0:21:57.200
everything works because we'll hit the fan after 10, 20, 30 minutes and not instantly.

185
0:21:57.200 --> 0:22:19.320
And so it's quite a problem to have instant recognition if things are going well or not.

186
0:22:19.320 --> 0:22:24.880
So the question was if the problems with the Wi-Fi that we had here on site were due to

187
0:22:24.880 --> 0:22:32.760
the BGP playing or was it due to something else, solar flares or so. The thing is that

188
0:22:32.760 --> 0:22:39.160
we had some issues. We've been given access to the WLC, the wireless controllers. You

189
0:22:39.160 --> 0:22:44.480
see these boxes over there, they're centrally controlled and we have to dig in that. We

190
0:22:44.480 --> 0:22:49.160
have some visibility of the infrastructure that's owned by the ULB. They've given us

191
0:22:49.160 --> 0:22:55.840
access to that so we can engineer that. But we're not quite sure why it was that. Most

192
0:22:55.840 --> 0:23:02.600
of the time, FOSDIM, which is an IPv6 only, was working quite good except for some Apple

193
0:23:02.600 --> 0:23:11.160
devices that do tend to just set up an IPv4 address even if there's no proper IPv4. And

194
0:23:11.160 --> 0:23:18.240
things get complicated then. FOSDIM dual stack, which is dual stack, usually worked for most

195
0:23:18.240 --> 0:23:31.280
of the Apple devices. But we're not very certain. Yeah. Yeah. You will see that. There's another

196
0:23:31.280 --> 0:23:46.760
one. So the question is if the live streams will be made, yeah, this is rewindable or

197
0:23:46.760 --> 0:23:52.240
not. Honestly, I can't tell you that. I don't know. I can ask the video guys if they're

198
0:23:52.240 --> 0:23:57.560
planning that for next year. But there's no plan of that as far as I know. The biggest

199
0:23:57.560 --> 0:24:06.480
challenge was to redo things with HDMI over VGA, which we had the last year. But there's

200
0:24:06.480 --> 0:24:21.720
another one. Yeah. So the question is that we're planning to use service. Do we know

201
0:24:21.720 --> 0:24:27.600
what and what's planned for next year? We'll have a talk about that next week, I think.

202
0:24:27.600 --> 0:24:31.400
And then we go through the post-mortem, which is usually a week after FOSDIM. And then we

203
0:24:31.400 --> 0:24:40.520
decide on things to be bought for next year because switches are old and routers are also

204
0:24:40.520 --> 0:24:46.000
old, I think. And we have one more year on the route to go that should be fine for next

205
0:24:46.000 --> 0:24:50.680
year. But what after that? We have to make some decisions and some investments for next

206
0:24:50.680 --> 0:24:56.480
year to run this stuff. And this will be done next week when we're all a bit cooled down

207
0:24:56.480 --> 0:25:15.920
and refreshed after this FOSDIM. Anyone else? Yeah. Come.

208
0:25:15.920 --> 0:25:24.480
So the question was what part of the infrastructure are being reused and what do we bring for

209
0:25:24.480 --> 0:25:34.120
the event? Well, in numbers, I think it was three truckloads of stuff. No, three because

210
0:25:34.120 --> 0:25:44.720
the video arrived in the second year. We bring mainly cameras and those boxes here. Switches

211
0:25:44.720 --> 0:25:53.240
stay at the ULB. Most of them stay here. But the one that didn't stay here, they won't

212
0:25:53.240 --> 0:25:59.560
be here next year because ULB is planning to do some tidying up and giving us here some

213
0:25:59.560 --> 0:26:07.000
video ports for our VLANs. They're very, very good at working with us. We get access to

214
0:26:07.000 --> 0:26:12.400
most of the infrastructure. We just say, tell them what we like to use and they just throw

215
0:26:12.400 --> 0:26:19.080
it on their controllers and bridge it to our servers and we can use it and make fun with

216
0:26:19.080 --> 0:26:26.520
it. And they will be replacing part of the network infrastructure next year. And we then

217
0:26:26.520 --> 0:26:33.640
will have to bring even less gear here. Yeah. Which one first?

218
0:26:33.640 --> 0:26:49.400
Yeah. So the question was what's about all the other stuff that FOSDIM is doing through

219
0:26:49.400 --> 0:26:54.600
the year that we hosted on our own hardware? Is it in the cloud or somewhere? We used,

220
0:26:54.600 --> 0:26:59.560
yeah, we have another company called T-Gron here. It's a Belgian provider and there's

221
0:26:59.560 --> 0:27:05.480
most of the stuff is running at T-Gron during the year. During FOSDIM, we also spin up some

222
0:27:05.480 --> 0:27:12.960
VMs at Hetzner in Germany and they are only for during the event and short time after

223
0:27:12.960 --> 0:27:18.880
the event. So like cutting videos and so on in the cloud. And they will be turned off

224
0:27:18.880 --> 0:27:23.760
for like two or three weeks and then everything is running on T-Gron on our own hardware there

225
0:27:23.760 --> 0:27:26.160
as well. So there was another question.

226
0:27:26.160 --> 0:27:32.960
What are you using to communicate with volunteers?

227
0:27:32.960 --> 0:27:38.000
So the question was what is being used for the communication between volunteers? We have

228
0:27:38.000 --> 0:27:43.680
that matrix set up. I don't know who's aware of matrix. It's a real time communication

229
0:27:43.680 --> 0:27:51.360
tool like, yeah, like Slack or something like that. We use matrix since 2020 internal for

230
0:27:51.360 --> 0:28:00.040
our video team for communicating and then we expanded that for 2020 and then with the

231
0:28:00.040 --> 0:28:05.640
pandemic we opened it up for all of the people and now the volunteers are being coordinated

232
0:28:05.640 --> 0:28:12.640
to that. And we also have our own trunk chair still that we have here, especially for this

233
0:28:12.640 --> 0:28:20.640
event set up. And volunteers are also can be reached via those radios.

234
0:28:20.640 --> 0:28:32.080
And my correct volunteers. Yes, yes. Okay. We have two volunteers here. So yeah. Yeah.

235
0:28:32.080 --> 0:28:39.640
Is there anything else you want to know or any where's the money? The question is where's

236
0:28:39.640 --> 0:28:45.080
the money Lebowski? That's the real phrase from the film. I don't actually know. I'm

237
0:28:45.080 --> 0:28:50.880
not yet a member of Fostum stuff. So you have to ask someone in a yellow shirt. There happens

238
0:28:50.880 --> 0:29:09.040
to be one next to me. Just throw him the microphone. We have a money box and a bank account. Anyone

239
0:29:09.040 --> 0:29:22.320
else? Three to one. Thank you very much.

