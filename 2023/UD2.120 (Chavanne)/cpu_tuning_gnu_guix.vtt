WEBVTT

00:00.000 --> 00:11.160
Okay, final lightning talk for today is Ludovic talking about Geeks.

00:11.160 --> 00:13.880
All right, thank you.

00:13.880 --> 00:14.880
Hello HPC people.

00:14.880 --> 00:17.120
So my name is Ludovic Cortez.

00:17.120 --> 00:23.000
I work at INRIER, which is a French research institute in France in computer science.

00:23.000 --> 00:26.960
And I work as a research engineer, so I'm very much concerned about engineering issues

00:26.960 --> 00:29.080
in general.

00:29.080 --> 00:31.560
And in particular, I'm concerned about deployments.

00:31.560 --> 00:37.560
So if you're an HPC dev room aficionado, we've probably met before.

00:37.560 --> 00:41.720
I gave a couple of talks, I guess, in this room.

00:41.720 --> 00:43.200
More specifically about Geeks.

00:43.200 --> 00:45.000
So maybe you've heard about Geeks.

00:45.000 --> 00:46.520
It's a software deployment tool.

00:46.520 --> 00:52.080
So we have Easy Build, Spark, also RPM, well, you know, app, etc.

00:52.080 --> 00:55.400
And this is yet another deployment tool, if you will.

00:55.400 --> 01:00.040
But we have this very particular vision, the grand vision, where we're trying to build

01:00.040 --> 01:04.480
a tool for reproducible research and HPC.

01:04.480 --> 01:07.640
So the thing here that you see is the vision, so to speak.

01:07.640 --> 01:13.520
So at one end of the spectrum, we have research articles, and we want the research to be solid.

01:13.520 --> 01:17.040
So we want the computational workflows to be reproducible.

01:17.040 --> 01:21.320
And at the other end of the spectrum on the left, we have archives, source code archives,

01:21.320 --> 01:27.120
software heritage, which we really need to have if we want that scientific source code

01:27.120 --> 01:29.320
to remain available over time.

01:29.320 --> 01:34.040
And in the middle, while we need a bunch of tools, in particular, deployment tools like

01:34.040 --> 01:38.120
Geeks to reproduce, well, to deploy software reproducibly.

01:38.120 --> 01:39.720
Yes.

01:39.720 --> 01:44.680
So in a nutshell, yes, Geeks provides actual tools for reproducible research people.

01:44.680 --> 01:48.760
I'm not going to go into the details, but basically you can say, all right, I've made

01:48.760 --> 01:53.160
an experimental computational experiment, so now I'm going to pin the exact revision

01:53.160 --> 01:54.160
of Geeks that I used.

01:54.160 --> 01:56.360
This is the first command here.

01:56.360 --> 02:02.120
And the second command is sometime later, or some colleague wants to reproduce a result.

02:02.120 --> 02:06.280
And so they use a time machine to jump to that specific revision of Geeks, and from

02:06.280 --> 02:11.680
there they deploy the exact same packages that I have in that manifest file, bit for

02:11.680 --> 02:13.000
bit.

02:13.000 --> 02:14.000
That's the idea.

02:14.000 --> 02:15.760
All right.

02:15.760 --> 02:22.520
So in HPC, I guess most people in this room would agree we have two obsessions.

02:22.520 --> 02:26.880
That's MPI and AVX, well, vector instructions.

02:26.880 --> 02:28.640
We want things to run fast, right?

02:28.640 --> 02:32.380
We have those fancy clusters, so we want to make sure that the communications are going

02:32.380 --> 02:33.380
to be fast.

02:33.380 --> 02:37.720
We want to make sure we're going to use the latest vector instructions of our CPUs, and

02:37.720 --> 02:39.680
that makes a lot of sense.

02:39.680 --> 02:45.780
But sometimes we're going maybe we have preconceptions about the implications of all this.

02:45.780 --> 02:49.440
So here I'm quoting Todd Gamblin, who's maybe in this room actually.

02:49.440 --> 02:52.400
Hi, Todd, if you see me.

02:52.400 --> 02:57.120
This is an example where we, well, Todd here was saying, you know, binaries, distributions

02:57.120 --> 03:02.800
like Debian or Geeks or Fedora, for example, are just targeting the baseline of the CPU,

03:02.800 --> 03:06.920
like A6664 without AVX, for example.

03:06.920 --> 03:11.520
And that's a problem for performance, because of course if you have that latest fancy Intel

03:11.520 --> 03:15.720
processor, then you probably want to use those vector instructions.

03:15.720 --> 03:22.320
But the conclusion that because of this, we cannot use, you know, binary distributions,

03:22.320 --> 03:26.920
distributions like Geeks or Debian that provide binaries is not entirely accurate.

03:26.920 --> 03:30.800
That's the point I'm trying to make in this talk.

03:30.800 --> 03:35.720
So yeah, as most of you know, there's a whole bunch of vector extensions.

03:35.720 --> 03:37.720
It keeps growing.

03:37.720 --> 03:42.600
You know, like every few years we have new vector extensions in Intel or AMD CPUs or

03:42.600 --> 03:46.400
even ARH64 CPUs, Power9, et cetera.

03:46.400 --> 03:51.640
And it's even worse if you look at the actual CPU models.

03:51.640 --> 03:53.080
For example, this is just for Intel.

03:53.080 --> 03:55.360
There's a whole bunch of things.

03:55.360 --> 03:59.840
It's not always a superset of the previous CPU.

03:59.840 --> 04:02.800
You know, we were discussing it the other day for dinner.

04:02.800 --> 04:04.360
And yeah, sometimes it's complicated.

04:04.360 --> 04:09.240
You cannot tell that Skylake ABX is exactly a superset of Skylake.

04:09.240 --> 04:10.240
This is complicated.

04:10.240 --> 04:15.000
And yet you want to be able to target this CPU specifically, this microarchitecture.

04:15.000 --> 04:17.640
And it makes a big deal of a difference.

04:17.640 --> 04:20.320
So this is an example from an Eigen benchmark.

04:20.320 --> 04:27.480
So Eigen is a C++ library for linear algebra, specifically targeting small matrices.

04:27.480 --> 04:32.800
And well, you know, if on my laptop if I'm targeting, if I'm compiling with MR equals

04:32.800 --> 04:39.400
to Skylake, then I get throughput that's three times the baseline performance.

04:39.400 --> 04:40.880
So it's a pretty big deal.

04:40.880 --> 04:42.400
So we definitely want to use that.

04:42.400 --> 04:49.120
We want to be able to compile specifically for the CPU microarchitecture that we have.

04:49.120 --> 04:55.280
But so the good news is that to a large extent, that's a solved problem for a long time.

04:55.280 --> 05:02.160
So there is this thing called function multiversioning that is already used in a number of performance

05:02.160 --> 05:03.280
critical libraries.

05:03.280 --> 05:07.720
So if you look at libc for string comparison, or if you look at openblast, if you look at

05:07.720 --> 05:15.200
FFTW, GMP for multiprecision arithmetic, you know, many libraries, programming languages,

05:15.200 --> 05:18.600
run times already use function multiversioning.

05:18.600 --> 05:20.040
So what's the deal here?

05:20.040 --> 05:24.920
Well roughly you, when you have function multiversioning, you can say, well, I have one function that

05:24.920 --> 05:28.360
does some linear algebra stuff, for example.

05:28.360 --> 05:33.880
And I'm actually providing several variants of that function, and when I start my program

05:33.880 --> 05:38.840
at runtime, the loader or, you know, the runtime system is going to pick the most optimized

05:38.840 --> 05:40.880
one for the CPU I have at hand.

05:40.880 --> 05:41.880
Right?

05:41.880 --> 05:46.440
So if I use GMP, for example, for multiprecision, multiprecision arithmetic, it's going to

05:46.440 --> 05:49.880
pick the fastest implementation it has, you know.

05:49.880 --> 05:55.040
So you can compile GMP once, and then it's going to use the right thing at runtime.

05:55.040 --> 06:00.880
And even if you're using GCC or Clang, you can specify in your C code, well, I want this

06:00.880 --> 06:07.080
particular function to be cloned, so to have several variants for each CPU micro-architectures,

06:07.080 --> 06:11.720
and GCC or Clang is going to create several variants of that function so that it can pick

06:11.720 --> 06:15.320
the right one at runtime.

06:15.320 --> 06:21.400
So kind of a solved problem in a way, while except in some cases.

06:21.400 --> 06:28.720
Well, one particular case where we have a problem is C++ template libraries, like Eigen,

06:28.720 --> 06:31.840
which I was mentioning before.

06:31.840 --> 06:36.080
They are not able to benefit from function multiversioning in any way, so when you compile

06:36.080 --> 06:41.520
your Eigen benchmark, well, you really have to use march equals to Skylake, for example,

06:41.520 --> 06:44.680
if you were targeting a skylight CPU.

06:44.680 --> 06:49.400
And this is because if you look at Eigen headers, for example, where there are many places where

06:49.400 --> 06:54.780
you have EAV depth, do I have AVX 512 at compilation time?

06:54.780 --> 06:58.480
If yes, then I'm going to use the optimized implementation, otherwise I'm going to use

06:58.480 --> 07:00.680
the baseline implementation.

07:00.680 --> 07:05.400
And this is all happening at compilation time, so you really have to have a solution at compilation

07:05.400 --> 07:08.400
time to address this.

07:08.400 --> 07:11.680
And so this is where Geeks comes in.

07:11.680 --> 07:16.400
So Geeks is, you know, it's a distribution, like Debian, like I was saying, that's targeting

07:16.400 --> 07:21.440
the baseline instruction set, but we came up with a new thing that's called package

07:21.440 --> 07:22.440
multiversioning.

07:22.440 --> 07:27.880
It's actually one year old or something, which is roughly the idea is taking the same idea

07:27.880 --> 07:34.400
as function multiversioning, but applying it at the level of entire packages.

07:34.400 --> 07:37.320
So let's say I have those Eigen benchmarks.

07:37.320 --> 07:44.240
I can run them using just the baseline x8664 architecture using this Geeks shell command.

07:44.240 --> 07:51.080
It's taking the Eigen benchmarks package and in that package running the bench plus gem

07:51.080 --> 07:55.160
command on a small matrix.

07:55.160 --> 08:01.160
And then I can say, all right, now I want to tune that code specifically for my CPU,

08:01.160 --> 08:09.320
and then I just put that extra dash dash tune option, and it's telling Geeks, all right,

08:09.320 --> 08:16.000
please optimize that Eigen benchmarks package directly for the CPU I'm on, which is Skylake

08:16.000 --> 08:17.960
in this case.

08:17.960 --> 08:19.200
And this is it.

08:19.200 --> 08:23.560
And what happens behind the scenes is that on the fly Geeks is creating a new package

08:23.560 --> 08:24.560
variant.

08:24.560 --> 08:29.800
So it's taking that Eigen benchmarks package, creating a new package variant that is built

08:29.800 --> 08:35.800
specifically with a compiler wrapper that passes the march equals to Skylake flag.

08:35.800 --> 08:39.720
And I get the performance and I'm happy.

08:39.720 --> 08:43.400
Right, so this is in Geeks since 2022.

08:43.400 --> 08:47.920
And it's still reproducible, you know, because we can still say, all right, what precise

08:47.920 --> 08:49.040
option did I use?

08:49.040 --> 08:50.920
What dash dash tune option did I use?

08:50.920 --> 08:52.400
And it's Skylake, all right?

08:52.400 --> 08:55.680
So the build process of the package remains reproducible, right?

08:55.680 --> 09:01.000
I'm still getting the same binary if I use dash dash tune equals to Skylake on my laptop

09:01.000 --> 09:05.760
or on some HPC cluster or whatever.

09:05.760 --> 09:09.960
And there are no world rebuilds, which means that the build farm, for example, the official

09:09.960 --> 09:16.280
build farm of the project is providing several variants of those packages, those, you know,

09:16.280 --> 09:21.440
performance sensitive packages built for Skylake, Skylake AVX, 512, you know, different things.

09:21.440 --> 09:26.560
So if you install them, most likely you're going to get a pre-built binary that specifically

09:26.560 --> 09:28.600
optimize for that CPU.

09:28.600 --> 09:30.360
And if not, well, that's fine.

09:30.360 --> 09:32.440
It's going to be to build it for you.

09:32.440 --> 09:34.580
That's okay.

09:34.580 --> 09:42.160
So my conclusion here is, you know, we keep talking about performance of MPI, vector instruction

09:42.160 --> 09:43.160
and so forth.

09:43.160 --> 09:45.520
Well, I think we can have performance.

09:45.520 --> 09:49.320
We can have portable performance that we should aim for.

09:49.320 --> 09:51.160
And we can still have reproducibility.

09:51.160 --> 09:54.920
We don't have to sacrifice reproducibility for performance.

09:54.920 --> 09:57.120
That's my take-home message.

09:57.120 --> 09:58.120
Thank you.

09:58.120 --> 10:06.160
Thank you very much.

10:06.160 --> 10:08.400
Again time for one question.

10:08.400 --> 10:14.640
Okay, yeah, this whole dash tune thing looks awesome.

10:14.640 --> 10:18.800
But what if the majority of the computation time is spent in libraries that that library

10:18.800 --> 10:19.960
is actually using?

10:19.960 --> 10:22.760
How do I tell it to optimize those instead as well?

10:22.760 --> 10:23.760
Right.

10:23.760 --> 10:29.520
So the way it works in gigs, you can annotate packages that really need to be tunable, right?

10:29.520 --> 10:34.000
So you can add a property to a package like so it would be Eigen benchmarks in this case,

10:34.000 --> 10:37.280
or it could be the GNU scientific library, GSL.

10:37.280 --> 10:39.760
And you said this package needs to be tunable.

10:39.760 --> 10:43.920
So if I use dash dash tune, please tune specifically this package.

10:43.920 --> 10:48.040
And it's going to work even if you're installing, you know, an application that actually depends

10:48.040 --> 10:50.440
on GSL, for example.

10:50.440 --> 10:51.440
Right.

10:51.440 --> 10:54.320
All right, thanks a lot, Ludovic.
