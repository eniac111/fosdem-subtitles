1
0:00:00.000 --> 0:00:08.040
All right, we'll get started with the next talk.

2
0:00:08.040 --> 0:00:12.720
Julien Annon from ParaTools is going to talk about testing and validation.

3
0:00:12.720 --> 0:00:13.720
Hello, everyone.

4
0:00:13.720 --> 0:00:16.720
Thanks, Janet, for the introduction.

5
0:00:16.720 --> 0:00:18.440
So, yes, I'm Julien Annon.

6
0:00:18.440 --> 0:00:20.440
I'm going to talk to you about testing.

7
0:00:20.440 --> 0:00:24.680
As you may notice, I'm a bit happy to have a mic today.

8
0:00:24.680 --> 0:00:32.960
So please let me know if I'm becoming unreadable.

9
0:00:32.960 --> 0:00:36.320
So first of all, a bit of background.

10
0:00:36.320 --> 0:00:45.480
Back some years ago, we were actually, we still had a team developing an MPI runtime.

11
0:00:45.480 --> 0:00:52.760
And while developing this runtime, we had the measure stake to develop a validation

12
0:00:52.760 --> 0:00:58.160
system to assess our software quality, but also to be able to compare our implementation

13
0:00:58.160 --> 0:01:00.120
to others.

14
0:01:00.120 --> 0:01:07.480
So like everybody in each PC field at this time, we started to build our own ultra-specific

15
0:01:07.480 --> 0:01:12.800
shell scripts to validate our implementation, because we were considering that our implementation

16
0:01:12.800 --> 0:01:16.040
were too specific to be able to use some main screen tools.

17
0:01:16.040 --> 0:01:19.680
So we started with search scripts, criteria.

18
0:01:19.680 --> 0:01:26.120
The fact is that with the team growing, people working in separate place, working on multiple

19
0:01:26.120 --> 0:01:33.440
heterogeneous machines, we had a huge issue to make people continue to validate, to use

20
0:01:33.440 --> 0:01:41.240
this validation system, because it was slow, not really efficient, and hard to make it

21
0:01:41.240 --> 0:01:45.000
go, especially about maintenance.

22
0:01:45.000 --> 0:01:49.840
When we wanted to add anything from 2D validation process, it was just a nightmare.

23
0:01:49.840 --> 0:01:52.840
It was really costly in term of time.

24
0:01:52.840 --> 0:02:02.320
But also when our software was evolving, was growing, just adding just even a little test

25
0:02:02.320 --> 0:02:05.520
into this non-recursion base was a nightmare.

26
0:02:05.520 --> 0:02:12.920
So we started to consider why not creating a validation system able to take care of HPC

27
0:02:12.920 --> 0:02:18.560
environments and what it implies, like, validation in multiple architectures, multiple machines

28
0:02:18.560 --> 0:02:23.400
by multiple users with multiple benchmarks.

29
0:02:23.400 --> 0:02:31.460
And we just thought about having a generic tool able to handle all of that at one point.

30
0:02:31.460 --> 0:02:38.520
So what we want in that scenario, we are here in the case of validating an MPI implementation,

31
0:02:38.520 --> 0:02:42.800
which means having a standard API.

32
0:02:42.800 --> 0:02:46.920
So there is a lot of well-known MPI benchmarks already existing.

33
0:02:46.920 --> 0:02:49.040
We don't have to rewrite a whole non-recursion.

34
0:02:49.040 --> 0:02:50.040
We have benchmarks.

35
0:02:50.040 --> 0:02:52.480
You have proxy applications and so on.

36
0:02:52.480 --> 0:03:00.360
So how to scale these benchmarks to any runtime or any project using them to build a proper

37
0:03:00.360 --> 0:03:02.120
validation process?

38
0:03:02.120 --> 0:03:08.520
So what people want, I mean, what users of this validation system want, it's a simple

39
0:03:08.520 --> 0:03:09.520
tool.

40
0:03:09.520 --> 0:03:15.240
And we don't want to have really complex, cute, GTK, any kind of complex architecture

41
0:03:15.240 --> 0:03:17.080
to deploy to this.

42
0:03:17.080 --> 0:03:20.880
So what we want is just a command line interface, basically.

43
0:03:20.880 --> 0:03:27.160
And really, really, really, really if you set up really, really, really few configuration

44
0:03:27.160 --> 0:03:33.980
to deploy to have such test working, because a lot of people, maybe it's not a generality

45
0:03:33.980 --> 0:03:36.880
here, but a lot of people, it tests, basically.

46
0:03:36.880 --> 0:03:40.640
So we have to convince them that testing is good for software quality.

47
0:03:40.640 --> 0:03:46.880
Something really simple, but also able to handle any really complex scenario we may

48
0:03:46.880 --> 0:03:49.960
find in HPC running an MPI application.

49
0:03:49.960 --> 0:03:54.800
It is not that hard, but it may become really, really complex.

50
0:03:54.800 --> 0:04:00.640
And we don't want to have to rewrite this tool every two years because a new technology,

51
0:04:00.640 --> 0:04:05.680
a new approach, a new paradigm is implemented, and the validation process should have to

52
0:04:05.680 --> 0:04:08.280
be rewriting.

53
0:04:08.280 --> 0:04:17.240
So from that state, we decided to write a tool to fit our needs, but to be able to be

54
0:04:17.240 --> 0:04:20.320
used by people meeting the same requirements.

55
0:04:20.320 --> 0:04:27.080
Before going further, I would like to tell you that testing is not a brand new field,

56
0:04:27.080 --> 0:04:32.440
and some other projects are taking such kind of issue until now.

57
0:04:32.440 --> 0:04:37.240
And so please take a look at them if you think that PCVS does not completely fit your needs.

58
0:04:37.240 --> 0:04:42.280
They are really, really powerful tools in the field.

59
0:04:42.280 --> 0:04:47.560
So today I'm here to talk to you about PCVS.

60
0:04:47.560 --> 0:04:50.000
It's a tool maintained by the CEA.

61
0:04:50.000 --> 0:04:51.000
It's written in Python.

62
0:04:51.000 --> 0:04:53.600
Yes, everything is in Python now.

63
0:04:53.600 --> 0:04:57.920
So we are based on Python.

64
0:04:57.920 --> 0:05:00.800
It's a simple command line interface.

65
0:05:00.800 --> 0:05:07.800
And with few configuration files, obviously in YAML, it's a trend.

66
0:05:07.800 --> 0:05:17.160
The design of this framework is to bring simplicity when writing test logic to users.

67
0:05:17.160 --> 0:05:23.400
So we want tests to be simple to write, easy to port, okay?

68
0:05:23.400 --> 0:05:32.080
And these benchmarks, written by the user, we want to be able to be run in multiple environments,

69
0:05:32.080 --> 0:05:36.120
so we don't want to bind a test suite to a given application.

70
0:05:36.120 --> 0:05:38.120
Let's consider MPI runtime.

71
0:05:38.120 --> 0:05:45.520
We don't want to have our LULash or our IMB benchmark bound to a specific MPI implementation

72
0:05:45.520 --> 0:05:49.360
to be run on any kind of architecture.

73
0:05:49.360 --> 0:05:52.520
So this is what we call in PCVS the retargeting approach.

74
0:05:52.520 --> 0:06:00.720
The other approach we want to focus on is the fact that we have heterogeneous test environments.

75
0:06:00.720 --> 0:06:01.720
We have benchmarks.

76
0:06:01.720 --> 0:06:08.120
How to scale, automatically scale this benchmark to the actual test environment, consider,

77
0:06:08.120 --> 0:06:13.680
for example, having users wanting to validate the IMB, but they are working on their workstation.

78
0:06:13.680 --> 0:06:18.520
You don't want to launch up to, I don't know, 100 MPI processes on their workstation.

79
0:06:18.520 --> 0:06:23.640
They are going to be not happy with the use question of their machine.

80
0:06:23.640 --> 0:06:30.040
But once this validation system is run on a real HPC cluster, you want the test suite

81
0:06:30.040 --> 0:06:36.560
to automatically scale to this supercomputer resources without having to rewrite 100 of

82
0:06:36.560 --> 0:06:37.560
configuration files.

83
0:06:37.560 --> 0:06:42.800
Or even one file is already too much, okay?

84
0:06:42.800 --> 0:06:49.240
So this work is maintained by the CEA, which is a French research administration.

85
0:06:49.240 --> 0:06:59.840
We are collaborating with them to make this tool more generic and more generic and attempt

86
0:06:59.840 --> 0:07:06.480
to make as many users happy as possible.

87
0:07:06.480 --> 0:07:16.160
So at a glance, some features provide the idea is to split the test effort into specific

88
0:07:16.160 --> 0:07:17.160
fields.

89
0:07:17.160 --> 0:07:22.960
The first one is the specification of test.

90
0:07:22.960 --> 0:07:25.640
What a benchmark need to expose to build tests.

91
0:07:25.640 --> 0:07:30.960
So this kind of information is carried by the benchmark, obviously, or to build, what

92
0:07:30.960 --> 0:07:34.280
is the program, what are the parameters, and so on.

93
0:07:34.280 --> 0:07:39.880
Even the environment, the testing environment here is carried by the people deploying or

94
0:07:39.880 --> 0:07:42.760
providing the testing resources.

95
0:07:42.760 --> 0:07:55.880
So most of the time it's just a team policy to schedule jobs or system needs, right?

96
0:07:55.880 --> 0:08:01.960
All of this to pursue two goals, still the retargeting of tests automatically when the

97
0:08:01.960 --> 0:08:08.680
user is calling the benchmark, depending on the compiler and runtime you want to target,

98
0:08:08.680 --> 0:08:12.680
and autoscaling tests to test environment.

99
0:08:12.680 --> 0:08:21.160
Obviously, as PCVS is a kind of test framework, we had to add some functionality around testing,

100
0:08:21.160 --> 0:08:27.400
like in-place reporting, because most users are running their tests on HPC cluster where

101
0:08:27.400 --> 0:08:33.880
the set of functionality can be restrained so they don't have access to all their GitLab,

102
0:08:33.880 --> 0:08:36.760
GitHub, Jira, and so on and stuff.

103
0:08:36.760 --> 0:08:42.440
So we had some basic tools to answer this need.

104
0:08:42.440 --> 0:08:52.040
And beyond a single execution validation run, we added a way to make, to build the history

105
0:08:52.040 --> 0:08:58.760
of the validation for a given application by storing results over time and allowing

106
0:08:58.760 --> 0:09:07.200
the user to run simple analysis, still in Pton, to produce statistics over time.

107
0:09:07.200 --> 0:09:15.320
So quickly, the architecture of PCVS is based on files, so by the CLI, so by the file system.

108
0:09:15.320 --> 0:09:24.320
It's parsing some user inputs, and it's run through a dedicated connector to mainly SLURM

109
0:09:24.320 --> 0:09:31.440
currently, mainly SLURM, but we are focusing on supporting the batch manager.

110
0:09:31.440 --> 0:09:36.480
So the idea is that the benchmark express job descriptions and resource requirements

111
0:09:36.480 --> 0:09:39.000
and the environment will provide resources.

112
0:09:39.000 --> 0:09:44.840
Let's consider, for example, a basic component called number of MPI tasks the job is taking

113
0:09:44.840 --> 0:09:52.200
the job will say, okay, my job is only running up to two processes, or it's only taking,

114
0:09:52.200 --> 0:09:55.960
I don't know, cubic value of MPI processes.

115
0:09:55.960 --> 0:10:05.160
People aware of users of the Lulash proxy application will know what I meant by cubic.

116
0:10:05.160 --> 0:10:11.080
So it will describe constraint, and then we will have environment configuration files

117
0:10:11.080 --> 0:10:17.840
called profile in PCVS where the system will say, okay, in that context, I will have up

118
0:10:17.840 --> 0:10:25.560
to 100 nodes, so you will be able to spawn up to 100 MPI processes to run your application.

119
0:10:25.560 --> 0:10:32.760
Based on that, PCVS will cost this information and we'll say, okay, I have MPI jobs, I can

120
0:10:32.760 --> 0:10:38.120
run up to 1,000 MPI processes based on this specification.

121
0:10:38.120 --> 0:10:45.720
By not running the user benchmark 100 times once for each combination.

122
0:10:45.720 --> 0:10:54.360
PCVS has an opt-out approach, so it will consider that every combination provided by the environment

123
0:10:54.360 --> 0:10:57.640
will be used to scale your tests.

124
0:10:57.640 --> 0:11:03.840
So if your test is not able to run up to 1,000 jobs, it's up to you to specify that you can't

125
0:11:03.840 --> 0:11:07.840
reach this limit.

126
0:11:07.840 --> 0:11:13.080
So here is a quick example, I don't know if you can see up there, but we have a really,

127
0:11:13.080 --> 0:11:16.880
really basic environment configuration where you can see that there is what we call an

128
0:11:16.880 --> 0:11:24.320
iterator, this is a variadic component, and it can take up to four values for the NMPI

129
0:11:24.320 --> 0:11:30.920
attributes, and when describing a simple job, we just say, okay, my job just consists in

130
0:11:30.920 --> 0:11:33.920
running a program.

131
0:11:33.920 --> 0:11:43.520
So PCVS will enroll up to four common lines to run four independent tests to execute.

132
0:11:43.520 --> 0:11:54.080
So PCVS will automatically build your test scenarios based on your specification.

133
0:11:54.080 --> 0:11:59.600
So how to basically write a test, but more specifically a compilation test, there is

134
0:11:59.600 --> 0:12:05.200
a lot of fields to customize how you can build your tests, so it looks complicated, but as

135
0:12:05.200 --> 0:12:14.880
you may see on the previous slide, all the keys in that TML are not more data-free.

136
0:12:14.880 --> 0:12:20.080
At least the files, obviously, you have to specify which kind of application you want

137
0:12:20.080 --> 0:12:22.320
to compile.

138
0:12:22.320 --> 0:12:32.080
So the framework will try to auto-detect your language to select the proper compiler, obviously

139
0:12:32.080 --> 0:12:36.200
you have a manually designed approach also.

140
0:12:36.200 --> 0:12:41.960
If you are not based on compiling for files but already using a well-known build system,

141
0:12:41.960 --> 0:12:47.240
we have also an interface to invoke directly build system to build your framework.

142
0:12:47.240 --> 0:12:54.480
I'm thinking about, for example, Lulash, which is using a Mac file, DIMB using a Mac file,

143
0:12:54.480 --> 0:12:59.360
or even the mPitch test suite using a configure-magnet style approach.

144
0:12:59.360 --> 0:13:02.840
So you have many options, all of them are optional.

145
0:13:02.840 --> 0:13:10.200
What I would like to highlight is a variant, it's a capability from PCVS to expose to benchmarks

146
0:13:10.200 --> 0:13:17.680
a specificity, a requirement this job has to be run.

147
0:13:17.680 --> 0:13:23.840
So in that case, the openMP keyword probably means something to everyone here, but it just

148
0:13:23.840 --> 0:13:31.560
a token saying that to run this job, the component openMP is required to be scheduled, and in

149
0:13:31.560 --> 0:13:36.240
the environment, the user will say, okay, what is my variant openMP?

150
0:13:36.240 --> 0:13:43.160
In case of GCC, GCC-like compiler, it would be dash F openMP, if it's intact, it's not

151
0:13:43.160 --> 0:13:44.160
the same option.

152
0:13:44.160 --> 0:13:45.160
You see the ID.

153
0:13:45.160 --> 0:13:54.520
I will add, PCVS will add flavor depending on what you have specified in your environment.

154
0:13:54.520 --> 0:13:57.040
How to write a run test.

155
0:13:57.040 --> 0:14:01.720
So this is where the components, the iterative components take place, we didn't put it yet

156
0:14:01.720 --> 0:14:10.520
on compilation model because we have issues with the rate condition, reaching the same

157
0:14:10.520 --> 0:14:17.320
file on the file system, but we are planning to capitalize, to encapsulate, to isolate

158
0:14:17.320 --> 0:14:23.360
such model to be able to support also combination computation test, I'm sorry.

159
0:14:23.360 --> 0:14:29.040
So what does a user have to do to integrate such tests in your workflow?

160
0:14:29.040 --> 0:14:39.280
You can write a PCVS file, you put it anywhere you want in your benchmark pass, and it looks

161
0:14:39.280 --> 0:14:45.520
like just a red node, and everything below is totally optional.

162
0:14:45.520 --> 0:14:52.560
Here we can see that we restrict our add.out program to specific MPI value because as a

163
0:14:52.560 --> 0:14:58.240
tester, I know that my test has this constraint.

164
0:14:58.240 --> 0:15:06.960
You can even create this variable component for your own application if you want to programmatically

165
0:15:06.960 --> 0:15:15.440
generate a list of scenario that PCVS should integrate to its own process to build multiple

166
0:15:15.440 --> 0:15:16.440
scenarios.

167
0:15:16.440 --> 0:15:20.680
So in that case, we this, sorry, why am I moving?

168
0:15:20.680 --> 0:15:25.920
In the program node, you'll see that with this simple line, it will be able to build

169
0:15:25.920 --> 0:15:36.760
three times the number of scenarios that you are expected to have initially.

170
0:15:36.760 --> 0:15:42.560
And what a test without having a way to express or validate a test, obviously.

171
0:15:42.560 --> 0:15:49.440
So for any test, not only for one, you have a YAML description to say, okay, so I want

172
0:15:49.440 --> 0:15:57.400
my job to exit with this particular return code, having an execution time within this

173
0:15:57.400 --> 0:16:02.160
range, matching or not matching this kind of pattern.

174
0:16:02.160 --> 0:16:08.840
Even here is my script, give him the regular output of my test, and I will tell you if

175
0:16:08.840 --> 0:16:12.440
it's okay or not.

176
0:16:12.440 --> 0:16:13.480
Okay.

177
0:16:13.480 --> 0:16:16.280
So I just write my test.

178
0:16:16.280 --> 0:16:21.840
So to run them now, it's just cell-based, so you just have to call PCVS run.

179
0:16:21.840 --> 0:16:27.720
But before running my benchmark, I just have to create a profile to express the resources

180
0:16:27.720 --> 0:16:29.760
my environment has.

181
0:16:29.760 --> 0:16:36.480
Obviously, in case of MPI, we provided some templates, some basic templates to initiate

182
0:16:36.480 --> 0:16:37.760
the testing process.

183
0:16:37.760 --> 0:16:42.640
So here we are just creating a profile named myMPI-based, just on MPI.

184
0:16:42.640 --> 0:16:50.920
So by quickly running that, I will have a full profile-based MPI running tests for one,

185
0:16:50.920 --> 0:16:54.080
two, three, and four MPI processes combination.

186
0:16:54.080 --> 0:16:59.600
But from that, you can then expand the profile to feature needs.

187
0:16:59.600 --> 0:17:06.040
The whole build of PCVS relies on a single directory, and in that directory, you will

188
0:17:06.040 --> 0:17:15.680
find anything required to analyze the results and even rerun in the same condition the tests

189
0:17:15.680 --> 0:17:17.960
for reproducibility.

190
0:17:17.960 --> 0:17:24.440
You can see on the right, repository we provided alongside with PCVS, which is called PCVS

191
0:17:24.440 --> 0:17:31.440
benchmarks, and we attempt to put in that repository many well-known MPI benchmarks,

192
0:17:31.440 --> 0:17:34.520
PCVS enabled.

193
0:17:34.520 --> 0:17:38.440
So here is a fancy view of PCVS.

194
0:17:38.440 --> 0:17:43.720
Obviously, there is many options when running a validation.

195
0:17:43.720 --> 0:17:49.680
You can have an interactive approach, non-interactive approach, slur-enable, I mean batch manager

196
0:17:49.680 --> 0:17:55.360
enabled, running inside an allocation, outside an allocation.

197
0:17:55.360 --> 0:18:02.120
And once the whole configuration has been generated, we have commands, especially a

198
0:18:02.120 --> 0:18:06.640
database exec, to interact independently, uniquely with your benchmarks.

199
0:18:06.640 --> 0:18:12.240
So for instance, what people are used to do is to run their validation, and after maybe

200
0:18:12.240 --> 0:18:17.600
ten seconds, some failures appear, and they would like without interrupting the non-recursion

201
0:18:17.600 --> 0:18:19.000
system.

202
0:18:19.000 --> 0:18:25.960
Just rerun in an isolated environment their tests to see why it failed.

203
0:18:25.960 --> 0:18:34.000
So we have some extra commands to rerun this special pattern.

204
0:18:34.000 --> 0:18:43.880
Obviously, I'm going to just peel it up, obviously not everything is always perfect, and the

205
0:18:43.880 --> 0:18:46.040
static approach of your MPI is not what you need.

206
0:18:46.040 --> 0:18:50.280
You would like something more dynamic because you have some stuff to integrate to read to

207
0:18:50.280 --> 0:18:54.840
process before knowing what you want to test, even within a benchmark.

208
0:18:54.840 --> 0:18:56.560
So we have a dynamic approach.

209
0:18:56.560 --> 0:19:03.200
Instead of providing a static ML5, you will provide an executable script, an executable

210
0:19:03.200 --> 0:19:09.400
file, whatever it is, and it will produce by itself the actual ML5.

211
0:19:09.400 --> 0:19:17.360
This way you can programmatically generate your benchmark suite without having to know

212
0:19:17.360 --> 0:19:22.600
it in advance, without knowing in which environment your non-recursion base will be run.

213
0:19:22.600 --> 0:19:30.560
Let's consider the NAS framework where within the name of the binary bit, you have the number

214
0:19:30.560 --> 0:19:32.960
of MPI processes.

215
0:19:32.960 --> 0:19:34.600
Cool.

216
0:19:34.600 --> 0:19:41.880
Now we have run our tests, but we would like to see what it looks like.

217
0:19:41.880 --> 0:19:44.640
We have a test framework, just a job runner.

218
0:19:44.640 --> 0:19:56.320
So obviously we had some tools to report results to the user, spoiler, cannot be compared with

219
0:19:56.320 --> 0:19:58.320
a real tool for that.

220
0:19:58.320 --> 0:20:05.400
It is just to offer a way to the user to grab their results directly on their machine in

221
0:20:05.400 --> 0:20:06.400
place.

222
0:20:06.400 --> 0:20:15.600
And essentially it is just a way to look at tests at a glance to be able to rerun if necessary

223
0:20:15.600 --> 0:20:17.680
in the process.

224
0:20:17.680 --> 0:20:26.320
So as I said, we can isolate and rerun independently jobs, which is pretty convenient when some

225
0:20:26.320 --> 0:20:29.720
failure wants to be explored right away.

226
0:20:29.720 --> 0:20:46.760
And in Infinee, we are using a web server to report in a web browser directly offering

227
0:20:46.760 --> 0:20:49.360
more interactivity for your results.

228
0:20:49.360 --> 0:20:53.880
So what it looks like, for example, here gathered by Labelle, you can see that there is some

229
0:20:53.880 --> 0:20:58.600
head, so some failures.

230
0:20:58.600 --> 0:20:59.600
Let's dive into it.

231
0:20:59.600 --> 0:21:03.360
You can see that, oh, some trouble with MPIIO, what a surprise.

232
0:21:03.360 --> 0:21:08.320
And when clicking a job, you will see the complete log of this trial, so the command

233
0:21:08.320 --> 0:21:13.640
line and the actual, so I truncated the actual error.

234
0:21:13.640 --> 0:21:21.080
And you can directly dive into the error without leaving your actual SSH terminal.

235
0:21:21.080 --> 0:21:26.920
So a quick overview of how to configure your site, so the test environment configuration

236
0:21:26.920 --> 0:21:27.920
part.

237
0:21:27.920 --> 0:21:29.480
This is also AML.

238
0:21:29.480 --> 0:21:41.360
You define directly compilers, compiler and run times, and the special variadic components

239
0:21:41.360 --> 0:21:42.360
here.

240
0:21:42.360 --> 0:21:45.520
It's split in five different modules.

241
0:21:45.520 --> 0:21:46.520
Why?

242
0:21:46.520 --> 0:21:51.160
Because this whole profile can be split up to five blocks, independent blocks.

243
0:21:51.160 --> 0:21:57.360
We can be distributed over a cluster because it's not always the same teams who are responsible

244
0:21:57.360 --> 0:21:58.920
of this particular block.

245
0:21:58.920 --> 0:22:02.800
Let's consider, for example, the variadic component.

246
0:22:02.800 --> 0:22:09.840
It's in charge of the team to build this list, while for the compiler and runtime, it may

247
0:22:09.840 --> 0:22:16.800
be in charge of the sys admins of the test environment machines.

248
0:22:16.800 --> 0:22:23.560
And after running a single job, what I would like to see is to have a trend over multiple

249
0:22:23.560 --> 0:22:35.000
runs, how my tests should behave, and in PCVES, we integrated a way of history to stack multiple

250
0:22:35.000 --> 0:22:43.680
runs over time, and then run analysis on them to build stats, to build trends, to have more

251
0:22:43.680 --> 0:22:49.400
things than just a test result, but a test result over time.

252
0:22:49.400 --> 0:23:01.240
So here is an example of what you can do afterwards, running analysis directly on this historic

253
0:23:01.240 --> 0:23:12.000
path, and this is enabled, I would like to call that a DSL, but actually just a Python

254
0:23:12.000 --> 0:23:19.360
API to interact with that, and you can build such beautiful graphics to see over time,

255
0:23:19.360 --> 0:23:29.040
the rates of success inside your test benchmark.

256
0:23:29.040 --> 0:23:34.000
So finally, just a quick glance at Spark and PCVES.

257
0:23:34.000 --> 0:23:39.280
We are not in Spark, but we are supporting Spark, especially to do such things, by specifying

258
0:23:39.280 --> 0:23:47.480
a simple package, a simple spec package, we will be able to check any combination of building

259
0:23:47.480 --> 0:23:53.800
this package to see if there is some curiosity into your package recipe.

260
0:23:53.800 --> 0:24:02.200
For future work, we have many things scheduled, and the most interesting in the capturing

261
0:24:02.200 --> 0:24:11.080
metrics, the capacity to PCVES to capture directly some metadata to be able to then run

262
0:24:11.080 --> 0:24:17.160
analysis on them, and many other things, but I think I'm running out of time.

263
0:24:17.160 --> 0:24:21.560
Thanks for your attention, and two questions.

264
0:24:21.560 --> 0:24:31.560
I'm just going to run a quick demo.

265
0:24:31.560 --> 0:24:37.000
So from your configuration file, I assume you already have control of the cluster, at

266
0:24:37.000 --> 0:24:39.880
least you've allocated some nodes or something.

267
0:24:39.880 --> 0:24:44.960
Do you have some step that then allocates and de-allocates these resources on the fly

268
0:24:44.960 --> 0:24:46.640
for each one of the tests?

269
0:24:46.640 --> 0:24:52.720
So actually, currently, most of our test scenarios have run through an MPI run with Slurman

270
0:24:52.720 --> 0:24:59.120
Evel or Srun command hierarchy, so they are taking care of the resource allocations.

271
0:24:59.120 --> 0:25:06.600
Some other users are just running the whole PCVES inside a given allocation, like resource

272
0:25:06.600 --> 0:25:11.160
allocation, just a dialogue, for example, and then any test doing this Srun does not

273
0:25:11.160 --> 0:25:13.360
pay the cost of waiting the...

274
0:25:13.360 --> 0:25:18.120
Right, but if some tests need some type of CPU, the other tests need other type of CPU,

275
0:25:18.120 --> 0:25:19.440
then you need to...

276
0:25:19.440 --> 0:25:24.080
And if one of them is unavailable because an other user is using, you have to wait instead

277
0:25:24.080 --> 0:25:25.080
of fail.

278
0:25:25.080 --> 0:25:28.080
Yes, this is something we still haven't...

279
0:25:28.080 --> 0:25:35.560
Have a solution for, would be to be able to put a job aside while we add the allocation.

280
0:25:35.560 --> 0:25:38.600
Yes, something we are currently investigating, absolutely.

281
0:25:38.600 --> 0:25:40.600
Thanks for the question.

282
0:25:40.600 --> 0:25:45.040
Any other questions?

283
0:25:45.040 --> 0:25:56.320
Yeah, so one thing that I wanted to ask was kind of, for your future work, you had mentioned

284
0:25:56.320 --> 0:25:59.800
building out a graphical frontend using Textualize.

285
0:25:59.800 --> 0:26:04.320
I was kind of wondering how much assessment have you done into that, because I've done

286
0:26:04.320 --> 0:26:10.560
some work like trying to build GUIs with Textualize, and while I do think that it's very interesting

287
0:26:10.560 --> 0:26:14.960
framework and it's great for making textual GUIs, I think that it still has a bit of a

288
0:26:14.960 --> 0:26:23.240
way to come before it can really make a standalone or comprehensive or textual interface.

289
0:26:23.240 --> 0:26:25.240
So I was just wondering what your thoughts were on that.

290
0:26:25.240 --> 0:26:31.240
I'm not sure, and I understand the whole question, but you mean, why did we choose Textualize?

291
0:26:31.240 --> 0:26:34.800
Yeah, why did you say Textualize?

292
0:26:34.800 --> 0:26:39.840
Absolutely, just we discovered just recently, because we were using Rich to highlight the

293
0:26:39.840 --> 0:26:46.720
output of PCVS within the console, and we are looking for a solution to present the

294
0:26:46.720 --> 0:26:56.240
things graphically in a terminal, and we still are looking for the ideal framework, and as

295
0:26:56.240 --> 0:27:01.160
Rich is already, as Textualize, I'm sorry, is based on that, we are considering Textualize,

296
0:27:01.160 --> 0:27:05.600
but if you have any other offer to propose, I would be happy to discuss with you about

297
0:27:05.600 --> 0:27:06.600
that.

298
0:27:06.600 --> 0:27:07.600
Thank you.

299
0:27:07.600 --> 0:27:10.000
Thank you.

