1
0:00:00.000 --> 0:00:29.700
Okay, next talk is Pablo.

2
0:00:29.700 --> 0:00:32.460
who was going to explain us how to set up

3
0:00:32.460 --> 0:00:34.500
Slurm client environments more easily.

4
0:00:36.300 --> 0:00:39.140
Good morning everybody, thanks for attending.

5
0:00:39.140 --> 0:00:42.240
My name is Pablo, I'm representing

6
0:00:42.240 --> 0:00:46.740
the Simplified Creation of Slurm Client Environment,

7
0:00:46.740 --> 0:00:48.400
especially for containers.

8
0:00:50.340 --> 0:00:52.300
Just a quick introduction about myself.

9
0:00:53.540 --> 0:00:58.540
I first started working with Slurm professionally at CERN

10
0:00:58.540 --> 0:01:00.420
for about five years.

11
0:01:00.420 --> 0:01:03.540
I was running the HPC clusters at CERN.

12
0:01:03.540 --> 0:01:07.100
That involved mostly Slurm, running Slurm.

13
0:01:07.100 --> 0:01:11.260
That's when I came up with the idea for this tool.

14
0:01:11.260 --> 0:01:15.500
Since about AOR nine months ago,

15
0:01:15.500 --> 0:01:17.420
I started working at EPFL,

16
0:01:17.420 --> 0:01:19.700
it's a university in Switzerland.

17
0:01:19.700 --> 0:01:22.980
And there I also, I'm in a team that manages

18
0:01:22.980 --> 0:01:25.780
the HPC clusters, and I'm also participating

19
0:01:25.780 --> 0:01:28.860
in the SKA project, hence the free account,

20
0:01:29.820 --> 0:01:32.780
where we do also things related to the HPC

21
0:01:32.780 --> 0:01:33.940
and HPC infrastructure.

22
0:01:37.440 --> 0:01:40.820
So just a brief introduction to Slurm

23
0:01:40.820 --> 0:01:43.860
in case anybody is not familiar with it.

24
0:01:44.820 --> 0:01:48.580
Slurm is basically both a resource manager

25
0:01:48.580 --> 0:01:52.740
and a job scheduler, meaning Slurm will manage

26
0:01:52.740 --> 0:01:57.260
your allocations, it will track which machines are used

27
0:01:57.260 --> 0:02:00.980
and allocate to which jobs and which users own,

28
0:02:00.980 --> 0:02:05.060
which CPUs and which nodes, et cetera.

29
0:02:05.060 --> 0:02:07.500
And it's also the job scheduler,

30
0:02:07.500 --> 0:02:10.340
meaning it will, when users submit jobs,

31
0:02:10.340 --> 0:02:12.020
you have your happy users over there,

32
0:02:12.020 --> 0:02:14.820
or hopefully people will be happy users.

33
0:02:14.820 --> 0:02:17.020
And they will be one-on-one on your cluster,

34
0:02:17.020 --> 0:02:18.380
so they make a job submission,

35
0:02:18.380 --> 0:02:23.380
usually writing a script that launches some workloads.

36
0:02:25.820 --> 0:02:28.380
And they will basically interact with Slurm,

37
0:02:28.380 --> 0:02:30.860
and Slurm will manage all of these job submissions.

38
0:02:30.860 --> 0:02:32.620
You won't just have one by one,

39
0:02:32.620 --> 0:02:35.220
you will have hundreds or even thousands of jobs

40
0:02:35.220 --> 0:02:38.220
that are scheduled to run on the infrastructure,

41
0:02:38.220 --> 0:02:41.740
and Slurm will manage the fees and the priorities

42
0:02:41.740 --> 0:02:44.460
and the accounting, et cetera.

43
0:02:44.460 --> 0:02:47.380
So basically it's a batch manager,

44
0:02:47.380 --> 0:02:49.740
but there's both resource managing

45
0:02:49.740 --> 0:02:51.900
and the scheduling of the jobs.

46
0:02:54.420 --> 0:02:56.380
Building a bit deeper into how Slurm works,

47
0:02:56.380 --> 0:02:59.340
because this is relevant for this talk,

48
0:02:59.340 --> 0:03:01.420
there's basically two main components,

49
0:03:01.420 --> 0:03:04.180
two demons that are most relevant,

50
0:03:04.180 --> 0:03:05.980
and those are the controller,

51
0:03:06.900 --> 0:03:08.860
which is called the Slurm CTLD,

52
0:03:08.860 --> 0:03:11.740
and then the demons that run on the worker nodes

53
0:03:11.740 --> 0:03:15.380
at the bottom, which is the Slurm VDL.

54
0:03:15.380 --> 0:03:17.860
And then you have other demons,

55
0:03:17.860 --> 0:03:21.260
like the Slurm VPL, Slurm SD, Slurm VPL.

56
0:03:21.260 --> 0:03:22.580
Those are not relevant for this talk,

57
0:03:22.580 --> 0:03:25.340
but we mostly focus on the part on the left here.

58
0:03:27.980 --> 0:03:30.300
So users and client tools,

59
0:03:30.300 --> 0:03:33.260
they basically interact with the controller

60
0:03:33.260 --> 0:03:34.740
over a Slurm protocol.

61
0:03:35.940 --> 0:03:37.420
There's nowadays Slurm SD,

62
0:03:37.420 --> 0:03:40.740
so you can also interact over the rest with some scripts,

63
0:03:40.740 --> 0:03:43.700
but mostly the older user lab tools,

64
0:03:43.700 --> 0:03:47.460
and mostly almost everything in the Slurm ecosystem

65
0:03:47.460 --> 0:03:49.420
just talks to the Slurm CTLD,

66
0:03:49.420 --> 0:03:53.140
and this controller handles the source of truth for Slurm,

67
0:03:53.140 --> 0:03:55.940
so it knows which resources are allocated where,

68
0:03:55.940 --> 0:03:57.500
it knows which jobs exist,

69
0:03:57.500 --> 0:03:59.620
it knows who the users are, et cetera.

70
0:04:00.980 --> 0:04:04.140
The controller talks to the Slurm demons,

71
0:04:04.140 --> 0:04:06.140
and talking to the nodes in the Slurm units

72
0:04:06.140 --> 0:04:07.860
are a charge of launching the jobs,

73
0:04:07.860 --> 0:04:11.180
so you clean up, setting up the C-groups of the jobs,

74
0:04:11.180 --> 0:04:12.020
whatever you have.

75
0:04:12.020 --> 0:04:15.940
Now, what's important here is to know that

76
0:04:15.940 --> 0:04:19.420
for all of this to work, you need at least two things.

77
0:04:19.420 --> 0:04:21.500
You need the Slurm config files,

78
0:04:21.500 --> 0:04:24.020
and they need to be in sync between the whole cluster,

79
0:04:24.020 --> 0:04:26.340
so you may have some differences,

80
0:04:26.340 --> 0:04:28.420
but mostly it should be the same.

81
0:04:35.060 --> 0:04:36.020
There was no audio online?

82
0:04:36.020 --> 0:04:36.860
Okay, oh.

83
0:04:36.860 --> 0:04:41.180
So, as I was saying,

84
0:04:41.180 --> 0:04:45.420
the Slurm CTLD handles the source of truth,

85
0:04:45.420 --> 0:04:49.540
the Slurm demons are in charge of launching the jobs,

86
0:04:49.540 --> 0:04:51.540
and the two important things are that

87
0:04:51.540 --> 0:04:55.060
you need the Slurm configuration files,

88
0:04:55.060 --> 0:04:56.220
it's mostly the Slurm comp file,

89
0:04:56.220 --> 0:04:58.540
but there's other files as well.

90
0:04:58.540 --> 0:05:01.340
Those need to be in sync in the whole cluster,

91
0:05:01.340 --> 0:05:03.940
and they need to be basically the same,

92
0:05:03.940 --> 0:05:06.300
they should have the same hash, ideally,

93
0:05:06.300 --> 0:05:08.580
and then you should also have a shared secret,

94
0:05:08.580 --> 0:05:11.700
so that nobody can, a rogue client,

95
0:05:11.700 --> 0:05:13.820
cannot just add a worker node to the cluster

96
0:05:13.820 --> 0:05:16.020
and start doing malicious things.

97
0:05:16.020 --> 0:05:18.780
So you have, usually it's a munch secret,

98
0:05:18.780 --> 0:05:21.260
it's called the demon called munch,

99
0:05:21.260 --> 0:05:25.060
and you have a shared secret as well for the whole cluster.

100
0:05:25.060 --> 0:05:27.140
And this fact is important,

101
0:05:27.140 --> 0:05:28.900
it's very relevant for this talk.

102
0:05:30.500 --> 0:05:32.500
Now, up to containers.

103
0:05:32.500 --> 0:05:34.660
So containers are increasingly becoming

104
0:05:34.660 --> 0:05:37.860
a super popular tool to run infrastructure

105
0:05:37.860 --> 0:05:41.820
for reproducibility, for automating deployments,

106
0:05:41.820 --> 0:05:46.100
and just in general, they're becoming super ubiquitous

107
0:05:46.100 --> 0:05:50.820
in our industry, and I think for good reasons.

108
0:05:53.260 --> 0:05:56.940
And they are, I think, very good use cases

109
0:05:56.940 --> 0:05:59.620
for using containers with Slurm.

110
0:06:01.220 --> 0:06:03.620
In this talk, I will focus on the use case

111
0:06:03.620 --> 0:06:05.900
where you use containers for,

112
0:06:05.900 --> 0:06:08.380
on the user and client side of things.

113
0:06:08.380 --> 0:06:11.500
So those tools that will talk to Slurm,

114
0:06:11.500 --> 0:06:14.860
to the controller mostly, to do things on the cluster.

115
0:06:14.860 --> 0:06:16.140
So this could be some automation

116
0:06:16.140 --> 0:06:19.340
that you have run to do whatever, for instance,

117
0:06:19.340 --> 0:06:22.140
you could use it for monitoring purposes,

118
0:06:22.140 --> 0:06:25.780
you could write a tool that does health checks

119
0:06:25.780 --> 0:06:28.380
on the cluster for accounting,

120
0:06:28.380 --> 0:06:31.780
where I've used it extensively for accounting as well,

121
0:06:31.780 --> 0:06:33.900
but also integration with other services, right?

122
0:06:33.900 --> 0:06:38.420
What if you want to connect the Jupyter Notebook with Slurm,

123
0:06:38.420 --> 0:06:40.620
you will end up with some tools

124
0:06:40.620 --> 0:06:42.420
that talk to the controller.

125
0:06:46.700 --> 0:06:50.340
Now, there are basically two scenarios

126
0:06:50.340 --> 0:06:53.980
in which you would use containers,

127
0:06:53.980 --> 0:06:56.060
you can use containers with Slurm.

128
0:06:56.060 --> 0:06:58.300
On the left, we have the local use case,

129
0:06:58.300 --> 0:07:01.100
that means, imagine you have a front-end mode,

130
0:07:01.100 --> 0:07:04.860
you have a machine that's configured where it uses SSH too,

131
0:07:04.860 --> 0:07:07.060
and from there, they can run the Slurm commands

132
0:07:07.060 --> 0:07:10.900
to launch jobs, to track their job usage, et cetera,

133
0:07:10.900 --> 0:07:13.300
it's conventionally called the front-end mode

134
0:07:13.300 --> 0:07:14.140
for the cluster.

135
0:07:15.020 --> 0:07:19.500
So if you just add the Slurm client container on that node,

136
0:07:19.500 --> 0:07:21.940
it's very simple, because you can just, as I said,

137
0:07:21.940 --> 0:07:26.180
you need a secret with Munch,

138
0:07:26.180 --> 0:07:27.540
and you need the config files,

139
0:07:27.540 --> 0:07:28.700
and that scenario is very simple

140
0:07:28.700 --> 0:07:30.020
because you can just do bind mounts,

141
0:07:30.020 --> 0:07:33.700
and you can access the Munch socket to talk to Slurm,

142
0:07:33.700 --> 0:07:37.220
and you bind mount the Slurm config directory,

143
0:07:37.220 --> 0:07:39.220
and you're done, basically.

144
0:07:39.220 --> 0:07:41.340
So that's sort of easy.

145
0:07:41.340 --> 0:07:46.340
However, what if you have, for the use case on the right,

146
0:07:46.460 --> 0:07:48.860
you have the distributed or remote use case,

147
0:07:48.860 --> 0:07:53.860
and in that case, you may run your Slurm client container

148
0:07:54.420 --> 0:07:57.260
in a different service, that's in a different network,

149
0:07:57.260 --> 0:08:01.140
or you may run it on Kubernetes, or somewhere else.

150
0:08:01.140 --> 0:08:03.700
In that case, you obviously can't just do the bind mounts,

151
0:08:03.700 --> 0:08:07.420
because you need to give it all those things.

152
0:08:08.740 --> 0:08:11.500
So you would have to give it all the Slurm config files,

153
0:08:11.500 --> 0:08:14.060
and somehow the Munch shared key,

154
0:08:14.060 --> 0:08:17.100
so that your external service can talk to your cluster,

155
0:08:17.100 --> 0:08:19.460
right, specifically to the Slurm controller.

156
0:08:22.260 --> 0:08:26.060
Now, this is an extraction from a Dockerfile,

157
0:08:26.060 --> 0:08:27.140
this is the Naive approach,

158
0:08:27.140 --> 0:08:30.980
this is how I started trying things, easy, right?

159
0:08:31.900 --> 0:08:33.980
You just take the Slurmconf,

160
0:08:33.980 --> 0:08:37.220
and you just copy it to the destination, right?

161
0:08:37.220 --> 0:08:39.340
And this will absolutely work.

162
0:08:39.340 --> 0:08:42.620
But I was not happy with this approach,

163
0:08:42.620 --> 0:08:44.780
because then you end up managing two copies

164
0:08:44.780 --> 0:08:47.500
of your Slurmconf, and I really like having

165
0:08:47.500 --> 0:08:49.380
a single source of truth for,

166
0:08:49.380 --> 0:08:50.940
when you do configuration management,

167
0:08:50.940 --> 0:08:52.820
and automation of your infrastructure,

168
0:08:52.820 --> 0:08:55.020
I really like having a single source of truth.

169
0:08:55.020 --> 0:08:57.940
And managing this in this way with containers

170
0:08:57.940 --> 0:09:01.420
is very fiddly, because it's very easy

171
0:09:01.420 --> 0:09:02.620
that you will forget to update it,

172
0:09:02.620 --> 0:09:04.500
or something that will fail to update it automatically,

173
0:09:04.500 --> 0:09:06.700
it's, eh, it's just not ideal,

174
0:09:06.700 --> 0:09:09.700
I didn't like this approach, but it will work, it will work.

175
0:09:11.660 --> 0:09:14.100
And some of you who know Slurm may say,

176
0:09:14.100 --> 0:09:16.300
oh, but Pablo, why wouldn't you just use

177
0:09:16.300 --> 0:09:18.100
Slurm's config-less feature?

178
0:09:18.100 --> 0:09:22.180
So Slurmconf-less is a new feature since Slurm 20 or so,

179
0:09:22.180 --> 0:09:25.900
that will basically allow a client

180
0:09:25.900 --> 0:09:28.740
to just pull the config files from Slurm.

181
0:09:28.740 --> 0:09:32.380
So the Slurm-D demons that run on the worker nodes,

182
0:09:32.380 --> 0:09:36.980
when they start, they will just grab the Slurm config files.

183
0:09:36.980 --> 0:09:40.340
So you can just remove the needs,

184
0:09:40.340 --> 0:09:43.020
so you can copy the Slurmconf file, right?

185
0:09:43.020 --> 0:09:45.340
Well, it's a trick question.

186
0:09:47.220 --> 0:09:51.620
Not necessarily, because then you need to run

187
0:09:51.620 --> 0:09:54.220
a Slurm-D demon in your container,

188
0:09:54.220 --> 0:09:57.100
and you also need the Munch demon.

189
0:09:57.100 --> 0:10:01.860
And it sounds easy, but it's really not, trust me.

190
0:10:01.860 --> 0:10:03.620
You will need to do a lot of hacks,

191
0:10:03.620 --> 0:10:08.620
this is an instruction from a container that I was creating,

192
0:10:08.940 --> 0:10:12.500
and you run in lots of awful, awful things.

193
0:10:12.500 --> 0:10:15.660
Like Slurm-Demon, the Slurm-Demon expects

194
0:10:15.660 --> 0:10:18.620
there's a release agent file to exist in the C group,

195
0:10:18.620 --> 0:10:21.900
and the containers, they just don't create it.

196
0:10:21.900 --> 0:10:24.260
If I tried it on Docker, I tried it on different

197
0:10:24.260 --> 0:10:27.100
Kubernetes versions, it just doesn't exist.

198
0:10:27.100 --> 0:10:29.340
I don't know why, I couldn't find out why,

199
0:10:29.340 --> 0:10:31.700
if anybody knows, please tell me.

200
0:10:31.700 --> 0:10:34.420
I googling around a font that could have been related

201
0:10:34.420 --> 0:10:37.020
to some privileged escalation issues.

202
0:10:37.020 --> 0:10:38.780
However, if you just remount the C groups,

203
0:10:38.780 --> 0:10:42.660
the file appears, so I'm not sure what's going on there.

204
0:10:43.660 --> 0:10:46.500
Another fun story is that, for instance,

205
0:10:46.500 --> 0:10:49.980
if you're using Kubernetes, Kubernetes likes to

206
0:10:49.980 --> 0:10:53.420
give a Simlink to your secrets,

207
0:10:53.420 --> 0:10:56.700
and Munch refuses to take the secret from a Simlink

208
0:10:56.700 --> 0:10:58.780
for security reasons, makes sense.

209
0:10:58.780 --> 0:11:01.380
So there's no notworks, you will need to put in hacks,

210
0:11:01.380 --> 0:11:03.340
and it's hacks on top of hacks on top of hacks

211
0:11:03.340 --> 0:11:05.580
just to run these two demons.

212
0:11:05.580 --> 0:11:09.260
And yeah, I was not very happy with this approach either.

213
0:11:10.540 --> 0:11:15.540
So basically I was faced with two options.

214
0:11:15.540 --> 0:11:17.020
When you're in rough with this situation,

215
0:11:17.020 --> 0:11:18.180
you're faced with two options.

216
0:11:18.180 --> 0:11:21.700
Either you basically do the first naive approach,

217
0:11:21.700 --> 0:11:24.300
where you just copy all the stuff into your Slurm container,

218
0:11:24.300 --> 0:11:27.620
you manage a copy of your Slurm config files,

219
0:11:27.620 --> 0:11:30.700
but as I said, if you wanna consist a single source

220
0:11:30.700 --> 0:11:34.100
of truth, this might not be ideal.

221
0:11:34.100 --> 0:11:36.740
You also need, of course, in the case of use case,

222
0:11:36.740 --> 0:11:38.700
unless you need Munch, and you need to supply

223
0:11:38.700 --> 0:11:42.100
the Munch key, or you can try the conflictless approach,

224
0:11:42.100 --> 0:11:44.180
but then you need to add Slurm D to your container,

225
0:11:44.180 --> 0:11:47.260
so it can pull via conflictless to your conflict files,

226
0:11:47.260 --> 0:11:48.860
but then anyway, you also need Munch,

227
0:11:48.860 --> 0:11:52.740
and you need to add the Munch key to your container somehow

228
0:11:52.740 --> 0:11:53.580
and managing secrets.

229
0:11:53.580 --> 0:11:54.580
I mean, if you're running Kubernetes,

230
0:11:54.580 --> 0:11:55.700
it might not be a big issue,

231
0:11:55.700 --> 0:11:57.140
or some other container manager,

232
0:11:57.140 --> 0:12:01.140
but you will still need to maintain all these extra demons

233
0:12:01.140 --> 0:12:05.380
with nasty hacks, and we don't always like

234
0:12:05.380 --> 0:12:09.340
all these having lots of hacks in our infrastructure.

235
0:12:09.340 --> 0:12:10.900
There's a third option, by the way,

236
0:12:10.900 --> 0:12:14.340
which is trying to go secretless.

237
0:12:14.340 --> 0:12:16.180
It doesn't work in combination with conflictless,

238
0:12:16.180 --> 0:12:18.940
where you try to use JSON web tokens,

239
0:12:18.940 --> 0:12:21.100
but it gives a lot of issues, it doesn't really work,

240
0:12:21.100 --> 0:12:23.980
I tried it, so I didn't include it here.

241
0:12:23.980 --> 0:12:26.700
Just mentioning it in case somebody thought about it.

242
0:12:29.220 --> 0:12:31.440
So Pablo, you talked about the bad and the ugly,

243
0:12:31.440 --> 0:12:34.180
what about the good, is there any good part to this?

244
0:12:34.180 --> 0:12:35.960
I'm glad you asked, yes.

245
0:12:35.960 --> 0:12:39.140
What if we had a single shot CLI tool

246
0:12:39.140 --> 0:12:43.020
that just a very simple tool that just was able

247
0:12:43.020 --> 0:12:44.900
to authenticate to the controller,

248
0:12:44.900 --> 0:12:47.420
either using Munch or JSON web tokens,

249
0:12:47.420 --> 0:12:48.980
which Slurm also supports,

250
0:12:48.980 --> 0:12:52.220
and just fetch the config files and then it's done.

251
0:12:53.460 --> 0:12:56.140
That's all you really want to do, right?

252
0:12:56.140 --> 0:13:00.620
Because then your tools, the Slurm tools can work

253
0:13:00.620 --> 0:13:02.180
because they have the Slurm config files,

254
0:13:02.180 --> 0:13:05.020
and just by having the JSON web token in your environment,

255
0:13:05.020 --> 0:13:09.380
you can just talk to the Slurm controller.

256
0:13:09.380 --> 0:13:12.100
And yeah, that's the tool that I wrote.

257
0:13:12.100 --> 0:13:14.920
It's a very simple tool, it just does exactly

258
0:13:14.920 --> 0:13:17.660
what I described there, and it's open source,

259
0:13:17.660 --> 0:13:22.660
you can find it on GitHub, I uploaded it in the past month.

260
0:13:23.860 --> 0:13:26.220
Fun story about this, as I said,

261
0:13:26.220 --> 0:13:28.580
I had the idea for this when I was back at CERN,

262
0:13:28.580 --> 0:13:32.140
I worked on this a year ago already,

263
0:13:32.140 --> 0:13:35.160
but then I somehow lost the source.

264
0:13:35.160 --> 0:13:36.960
I don't know what happened.

265
0:13:36.960 --> 0:13:40.300
Just before I left CERN, the source was just lost.

266
0:13:40.300 --> 0:13:43.540
I don't know why, I must have deleted it by accident,

267
0:13:43.540 --> 0:13:45.740
I don't know what happened.

268
0:13:45.740 --> 0:13:47.420
So after I left CERN, I kept in contact

269
0:13:47.420 --> 0:13:49.000
with my ex-colleagues and they were telling me

270
0:13:49.000 --> 0:13:50.640
that they wanted to do this integration

271
0:13:50.640 --> 0:13:55.640
between the SWAN, which is the, who here knows SWAN, anybody?

272
0:13:56.100 --> 0:13:58.020
Okay, one, two, three.

273
0:13:58.020 --> 0:14:00.980
Yeah, so it's the Jupyter notebook service for CERN,

274
0:14:00.980 --> 0:14:05.100
which also does analytics, and we wanted to connect it

275
0:14:05.100 --> 0:14:07.180
to SLURM, and we run into all these issues

276
0:14:07.180 --> 0:14:08.740
because this is a service that's exposed

277
0:14:08.740 --> 0:14:11.060
to the whole internet, so we didn't want to have

278
0:14:11.060 --> 0:14:13.780
the munch key for the SLURM cluster in the container,

279
0:14:13.780 --> 0:14:15.300
et cetera.

280
0:14:15.300 --> 0:14:18.660
Anyway, so then I left CERN and then, yeah,

281
0:14:18.660 --> 0:14:20.340
my colleagues were telling me, oh, it would have been

282
0:14:20.340 --> 0:14:22.980
so useful to have this, what a pity.

283
0:14:22.980 --> 0:14:26.740
And then a few months ago, I just, yeah,

284
0:14:26.740 --> 0:14:28.640
I just didn't like the fact that I had lost the source

285
0:14:28.640 --> 0:14:32.820
and all these days, I spent a couple days

286
0:14:32.820 --> 0:14:35.540
reverse engineering the SLURM protocol,

287
0:14:35.540 --> 0:14:39.180
and I just didn't like losing it, so I just rewrote it

288
0:14:39.180 --> 0:14:43.140
more properly in Python and just made it public.

289
0:14:43.140 --> 0:14:46.500
So if you're interested in making client containers

290
0:14:46.500 --> 0:14:49.700
like this, feel free to give it a try.

291
0:14:52.140 --> 0:14:53.440
It looks a bit like this.

292
0:14:55.420 --> 0:14:58.520
It's very simple, you can choose between munch

293
0:14:58.520 --> 0:15:02.460
or JWT, JSON Web Tokens Authentication.

294
0:15:02.460 --> 0:15:04.900
If you choose JWT, which is the most simple one,

295
0:15:04.900 --> 0:15:08.300
you just need an environment variable with a token,

296
0:15:09.220 --> 0:15:11.620
and you can tell it where you want to store

297
0:15:11.620 --> 0:15:16.620
the config files, and then you have verbosity as an option.

298
0:15:16.980 --> 0:15:21.080
So it's very simple, it has very little dependencies.

299
0:15:21.080 --> 0:15:26.080
So the tool talks several SLURM protocol versions,

300
0:15:31.840 --> 0:15:33.720
because with every major release,

301
0:15:33.720 --> 0:15:38.020
SLURM changes the protocol versions.

302
0:15:38.020 --> 0:15:40.740
So you can list them with minus L,

303
0:15:40.740 --> 0:15:43.800
and it will show you basically all the versions

304
0:15:43.800 --> 0:15:44.900
that it supports.

305
0:15:46.840 --> 0:15:49.680
And then, yeah, so imagine you have a SLURM Web Token

306
0:15:49.680 --> 0:15:53.160
in this variable, you can just tell it to do

307
0:15:53.160 --> 0:15:56.520
JSON Web Token Authentication with the server.

308
0:15:56.520 --> 0:15:58.720
It supports multiple controllers in case you have

309
0:15:58.720 --> 0:16:01.240
high availability set up in your SLURM clusters,

310
0:16:01.240 --> 0:16:04.360
so you can specify a list of servers that it will retry

311
0:16:04.360 --> 0:16:07.280
until it succeeds, and then you tell it the protocol version

312
0:16:07.280 --> 0:16:09.480
of the SLURM CTLD, because it needs to know

313
0:16:09.480 --> 0:16:12.280
what protocol it should talk.

314
0:16:12.280 --> 0:16:15.840
The protocol version negotiation, I think it doesn't exist

315
0:16:15.840 --> 0:16:17.560
in the SLURM protocol, so you have to tell it

316
0:16:17.560 --> 0:16:19.320
which version you want it to talk.

317
0:16:19.320 --> 0:16:21.360
And that's it, and then it will just download

318
0:16:21.360 --> 0:16:25.920
the SLURM config files and happy days for your containers.

319
0:16:28.600 --> 0:16:31.560
Conclusions, I think I'm ahead of time.

320
0:16:33.840 --> 0:16:37.240
So this tool called straw, it can simplify the cost

321
0:16:37.240 --> 0:16:41.700
of creating and maintaining your SLURM client containers.

322
0:16:41.700 --> 0:16:43.560
It can also increase the security because you don't need

323
0:16:43.560 --> 0:16:47.000
to put the munch key everywhere where you're running

324
0:16:47.000 --> 0:16:50.680
your client containers, JSON Web Tokens, Sophist.

325
0:16:51.880 --> 0:16:56.840
Caveats, caveats, I think this tool should not exist.

326
0:16:58.720 --> 0:17:01.560
Because ideally this would be supported upstream.

327
0:17:01.560 --> 0:17:06.560
So if anybody has any influence on SkedMD SLURM development,

328
0:17:08.280 --> 0:17:10.600
yeah, I think it would be nice if we had this

329
0:17:10.600 --> 0:17:11.760
built in into SLURM.

330
0:17:11.760 --> 0:17:16.760
And then the second caveat is that the JSON Web Tokens,

331
0:17:18.560 --> 0:17:20.920
they need to build, the token needs to be associated

332
0:17:20.920 --> 0:17:23.520
with either, with a SLURM user, basically.

333
0:17:24.640 --> 0:17:28.200
So ideally, you would be able to just generate

334
0:17:28.200 --> 0:17:31.760
a JSON Web Token for a user that's gonna run

335
0:17:31.760 --> 0:17:35.060
on the SLURM cluster, and then if the secret

336
0:17:35.060 --> 0:17:37.480
for some reason is exposed, you've only exposed

337
0:17:37.480 --> 0:17:40.600
the JSON Web Token of a single user.

338
0:17:40.600 --> 0:17:44.440
However, this is a limitation built into the SLURM,

339
0:17:44.440 --> 0:17:45.820
into SLURM, basically.

340
0:17:46.820 --> 0:17:49.920
You cannot pull over the protocol of the SLURM config file

341
0:17:49.920 --> 0:17:53.600
unless the token belongs to the SLURM user or to root.

342
0:17:54.540 --> 0:17:56.100
Still, I think it's an improvement over having

343
0:17:56.100 --> 0:17:59.320
your munch key available everywhere.

344
0:17:59.320 --> 0:18:01.440
And yeah, feel free to try it out.

345
0:18:02.760 --> 0:18:06.120
That was it, I'm happy to answer any questions you might have.

346
0:18:06.120 --> 0:18:11.120
Thank you very much, Pablo.

347
0:18:16.400 --> 0:18:17.560
Time for questions.

348
0:18:19.480 --> 0:18:23.480
So what kind of clients do need the config file?

349
0:18:23.480 --> 0:18:25.660
Could you do everything over REST nowadays?

350
0:18:25.660 --> 0:18:29.560
Like, is it still necessary to use the config file?

351
0:18:29.560 --> 0:18:33.720
Yes, so anything that wants to run S run, S batch,

352
0:18:33.720 --> 0:18:37.080
S queue, S info, for instance, if you have the Jupyter

353
0:18:37.080 --> 0:18:40.040
notebook plugins, they will run just on those commands.

354
0:18:40.040 --> 0:18:43.200
Or if you wanna run a client that uses PySLURM, for instance,

355
0:18:44.260 --> 0:18:47.200
or any library, really, anything that uses libslurm

356
0:18:47.200 --> 0:18:51.360
underneath will automatically read the config files, right?

357
0:18:51.360 --> 0:18:56.280
So of course, you can write your own client,

358
0:18:56.280 --> 0:18:58.360
handwritten from scratch, that just interacts

359
0:18:58.360 --> 0:19:01.160
with the SLURM RESTD to do stuff.

360
0:19:01.160 --> 0:19:05.320
Yes, but you cannot leverage all the existing

361
0:19:05.320 --> 0:19:10.320
user client tools, and the libslurm, PySLURM, et cetera.

362
0:19:10.840 --> 0:19:15.160
So if you wanna create a Python tool, for instance,

363
0:19:15.160 --> 0:19:18.040
that leverages PySLURM, this would be,

364
0:19:18.960 --> 0:19:20.160
I think, a good solution.

365
0:19:21.760 --> 0:19:23.760
I think SLURM does have a REST API,

366
0:19:23.760 --> 0:19:26.240
but it's considered very insecure.

367
0:19:26.240 --> 0:19:29.040
So even the documentation tells you don't use this.

368
0:19:29.040 --> 0:19:33.760
Maybe, I just didn't understand, like, for a long time now,

369
0:19:33.760 --> 0:19:36.560
why you, everyone needs the config file, right?

370
0:19:36.560 --> 0:19:38.600
I mean, why does it need to be in sync?

371
0:19:38.600 --> 0:19:40.560
Like, couldn't they just exchange the information

372
0:19:40.560 --> 0:19:42.760
over the protocols, and just say, like,

373
0:19:42.760 --> 0:19:44.400
this is your SLURM server?

374
0:19:44.400 --> 0:19:45.760
Yeah, that's the config-less feature,

375
0:19:45.760 --> 0:19:47.080
that's the config-less feature, essentially.

376
0:19:47.080 --> 0:19:48.940
Yeah, but the config-less feature just downloads

377
0:19:48.940 --> 0:19:51.520
the config, look next, like, config-less, okay.

378
0:19:51.520 --> 0:19:52.360
Yes.

379
0:19:52.360 --> 0:19:54.920
Download the config, don't need the config beforehand.

380
0:19:56.160 --> 0:19:58.240
It's like serverless, there's always a server somewhere.

381
0:19:58.240 --> 0:20:00.240
Yes, yeah, exactly.

382
0:20:01.080 --> 0:20:03.760
So, that's just how SLURM works.

383
0:20:03.760 --> 0:20:04.600
Yeah.

384
0:20:04.600 --> 0:20:05.440
Yep.

385
0:20:11.760 --> 0:20:13.040
So, I'm still a little confused

386
0:20:13.040 --> 0:20:14.600
about the SLURM client container.

387
0:20:14.600 --> 0:20:16.120
So the container is an application

388
0:20:16.120 --> 0:20:17.840
on the actual SLURM client,

389
0:20:17.840 --> 0:20:20.120
because you have to document, in the SLURM Conf,

390
0:20:20.120 --> 0:20:22.120
you have to sort of say what your clients are,

391
0:20:22.120 --> 0:20:24.720
so that the scheduler can intelligently

392
0:20:24.720 --> 0:20:27.000
decide how to schedule jobs, right?

393
0:20:27.000 --> 0:20:27.880
I'm missing something.

394
0:20:27.880 --> 0:20:29.760
No, you don't really need to declare

395
0:20:29.760 --> 0:20:32.240
all the clients for SLURM.

396
0:20:32.240 --> 0:20:35.200
You just need to declare the worker nodes

397
0:20:35.200 --> 0:20:38.880
that are part of it, but you can have any,

398
0:20:38.880 --> 0:20:40.360
I mean, it depends on how you've configured it.

399
0:20:40.360 --> 0:20:42.240
You can limit it, you can limit in SLURM

400
0:20:42.240 --> 0:20:44.560
which clients are allowed to connect,

401
0:20:44.560 --> 0:20:45.760
but you don't have to.

402
0:20:45.760 --> 0:20:48.880
So you could just, but even if you do,

403
0:20:48.880 --> 0:20:51.580
you will need this, because you will,

404
0:20:51.580 --> 0:20:54.420
even if you authorize a host name to connect as a client,

405
0:20:54.420 --> 0:20:57.680
it will need to have the munch key

406
0:20:57.680 --> 0:21:00.240
and the SLURM Conf files, et cetera.

407
0:21:00.240 --> 0:21:01.960
Does this answer your question, or are you?

408
0:21:01.960 --> 0:21:04.880
Well, no, so when you, in the SLURM.conf,

409
0:21:04.880 --> 0:21:07.440
you sort of detail what your positions are,

410
0:21:07.440 --> 0:21:10.000
and you have to kind of tell it what the capabilities are

411
0:21:10.000 --> 0:21:11.440
of your clients, of your SLURM clients, right?

412
0:21:11.440 --> 0:21:13.440
So that SLURM can decide how to schedule jobs.

413
0:21:13.440 --> 0:21:15.240
I'm missing something cool about it.

414
0:21:15.240 --> 0:21:17.480
Well, I think you're thinking about the compute nodes.

415
0:21:17.480 --> 0:21:18.560
Yeah, I am.

416
0:21:18.560 --> 0:21:21.280
Yeah, the node names, part of the SLURM Conf.

417
0:21:21.280 --> 0:21:23.160
Right, so the containers run on the compute nodes.

418
0:21:23.160 --> 0:21:24.840
No, the containers would be,

419
0:21:24.840 --> 0:21:28.240
let me go back to one of the slides where,

420
0:21:28.240 --> 0:21:33.240
so you're thinking maybe about the compute nodes,

421
0:21:33.360 --> 0:21:35.640
each of which runs a SLURM D daemon,

422
0:21:35.640 --> 0:21:37.400
and those you have to declare.

423
0:21:37.400 --> 0:21:39.280
Yes, I think in 2023, by the way,

424
0:21:39.280 --> 0:21:42.360
you will be able to dynamically spawn compute nodes,

425
0:21:42.360 --> 0:21:45.520
but that's future.

426
0:21:46.520 --> 0:21:49.080
What I'm talking about is all the users and client tools

427
0:21:49.080 --> 0:21:52.600
that connect to the controller to run SQS info,

428
0:21:52.600 --> 0:21:54.920
like when you use SLURM, and you,

429
0:21:54.920 --> 0:21:59.520
so if you had some tooling that you automated

430
0:21:59.520 --> 0:22:03.240
to gather metrics from SLURM, or yeah,

431
0:22:03.240 --> 0:22:05.080
a Jupyter Notebook service, for instance,

432
0:22:05.080 --> 0:22:08.520
that connects to your cluster that wants to launch jobs,

433
0:22:08.520 --> 0:22:10.880
that wants to run as batch SQ, whatever,

434
0:22:10.880 --> 0:22:12.720
that's in that domain.

435
0:22:12.720 --> 0:22:15.760
Yeah, I mean, the newest version of Werewolf runs containers

436
0:22:15.760 --> 0:22:17.400
on my back for the stream.

437
0:22:17.400 --> 0:22:18.240
Sorry.

438
0:22:19.440 --> 0:22:20.840
I think the newest version of Werewolf

439
0:22:20.840 --> 0:22:23.960
is set up to run containers on the SLURM clients, right?

440
0:22:23.960 --> 0:22:26.960
It's sort of, you're actually launching containers

441
0:22:26.960 --> 0:22:29.000
as applications, so that was kind of.

442
0:22:29.000 --> 0:22:30.720
That's on the compute nodes.

443
0:22:30.720 --> 0:22:31.960
On the compute nodes, yes.

444
0:22:31.960 --> 0:22:33.760
Yeah, yeah, that's the compute nodes.

445
0:22:37.600 --> 0:22:39.120
Thank you for your talk.

446
0:22:39.120 --> 0:22:40.120
So I have a question.

447
0:22:40.120 --> 0:22:44.000
You are telling that you can pull the configuration

448
0:22:44.000 --> 0:22:48.240
with your tool, but there are many, fine,

449
0:22:48.240 --> 0:22:51.440
you can't pull with configless, for example,

450
0:22:51.440 --> 0:22:54.360
all the Spunk plugins, or I think,

451
0:22:54.360 --> 0:22:56.440
to apologize, you can pull it, but various,

452
0:22:56.440 --> 0:22:59.040
like I said, Spunk plugins and so on.

453
0:22:59.040 --> 0:23:01.800
So how do you manage this kind of config file

454
0:23:01.800 --> 0:23:05.160
that are not ended by default by SLURM?

455
0:23:05.160 --> 0:23:06.120
Right, that's correct.

456
0:23:06.120 --> 0:23:08.520
So when you use the configless feature,

457
0:23:08.520 --> 0:23:12.040
it will download the Serm Conf, the Cgroup Conf,

458
0:23:12.040 --> 0:23:14.120
a lot of config files, but it will not download

459
0:23:14.120 --> 0:23:17.040
your plugin files.

460
0:23:17.040 --> 0:23:18.440
But I think those are usually not needed

461
0:23:18.440 --> 0:23:20.760
if you're running a client, because those are just,

462
0:23:20.760 --> 0:23:24.200
usually just needed for the Slurm D-demons,

463
0:23:24.200 --> 0:23:25.840
for the worker nodes.

464
0:23:25.840 --> 0:23:27.440
Like the epilogue, the prologue,

465
0:23:27.440 --> 0:23:29.720
you mean all of those plugins, scripts, right?

466
0:23:29.720 --> 0:23:30.840
The authentication plugins.

467
0:23:30.840 --> 0:23:32.960
Those are usually needed by the Slurm D-demon,

468
0:23:32.960 --> 0:23:35.080
but if you're just writing a client,

469
0:23:35.960 --> 0:23:39.240
but say you're automating something with PySlurm

470
0:23:39.240 --> 0:23:41.000
to interact with it, you don't need those files.

471
0:23:41.000 --> 0:23:43.540
And Slurm will happily, you can happily run,

472
0:23:43.540 --> 0:23:46.020
Sinfo is run as batch, or SQ.

473
0:23:46.020 --> 0:23:47.600
You can happily run all of those commands

474
0:23:47.600 --> 0:23:49.400
without those files.

475
0:23:49.400 --> 0:23:52.360
Yeah, okay, so if I just summarize,

476
0:23:52.360 --> 0:23:54.640
the ID is just to create some front-end nodes,

477
0:23:54.640 --> 0:23:57.640
but not to really work nodes.

478
0:23:57.640 --> 0:23:59.020
That's right.

479
0:23:59.020 --> 0:23:59.860
So,

480
0:24:01.940 --> 0:24:06.940
so if you wanna use configless to set up a front-end node,

481
0:24:07.000 --> 0:24:09.220
you might need those files from somewhere else.

482
0:24:09.220 --> 0:24:12.080
But if you're just creating a container

483
0:24:12.080 --> 0:24:14.400
to just interact with Slurm and send Slurm commands,

484
0:24:14.400 --> 0:24:16.120
you don't need them, basically.

485
0:24:17.120 --> 0:24:20.760
Because the plugin files are usually the,

486
0:24:20.760 --> 0:24:23.560
yeah, the epilogue prologue for the Slurm D

487
0:24:23.560 --> 0:24:24.960
or the Slurm CTLD,

488
0:24:25.880 --> 0:24:30.880
and that's not what these Slurm client containers are about.

489
0:24:33.040 --> 0:24:35.160
So short answer, you usually don't need them.

490
0:24:35.160 --> 0:24:40.160
Hello, thank you for the talk.

491
0:24:44.920 --> 0:24:49.920
I'm wondering, in huge institutions like InCERN or EPFL,

492
0:24:50.160 --> 0:24:55.160
would you run your own forked or patched Slurm

493
0:24:55.540 --> 0:25:00.540
so you could fix maybe the authentication privileges?

494
0:25:01.520 --> 0:25:02.360
Yes.

495
0:25:02.360 --> 0:25:03.840
Or is it just not done because it's a...

496
0:25:03.840 --> 0:25:06.280
I've never carried any Slurm patches, to be honest.

497
0:25:06.280 --> 0:25:08.880
I've always, both at Slurm and EPFL,

498
0:25:08.880 --> 0:25:11.160
we just use Slurm out of the box.

499
0:25:11.160 --> 0:25:13.420
It works well enough for our use cases.

500
0:25:14.660 --> 0:25:16.400
It is true that you could, for instance,

501
0:25:16.400 --> 0:25:19.400
do a patch to enable finer,

502
0:25:19.400 --> 0:25:22.040
good on the similarity for the permissions.

503
0:25:22.040 --> 0:25:23.880
For instance, you could enable any user

504
0:25:23.880 --> 0:25:25.240
to pull the config file.

505
0:25:25.240 --> 0:25:27.400
That would be a nice patch.

506
0:25:27.400 --> 0:25:28.800
We don't do it.

507
0:25:28.800 --> 0:25:29.640
Okay, thank you.

508
0:25:29.640 --> 0:25:32.480
Okay.

509
0:25:32.480 --> 0:25:34.440
We have time for one short question.

510
0:25:35.720 --> 0:25:36.560
Hi, thanks.

511
0:25:36.560 --> 0:25:38.320
We actually are very interested in this

512
0:25:38.320 --> 0:25:42.160
because we are applying,

513
0:25:42.160 --> 0:25:44.360
we have a Jupyter hub frontend

514
0:25:44.360 --> 0:25:48.240
that actually talks to Slurm cluster through SSH

515
0:25:48.240 --> 0:25:50.040
because we don't want to install all that stuff

516
0:25:50.040 --> 0:25:52.880
like the Mange and the full Slurm deployment

517
0:25:52.880 --> 0:25:55.260
into the Jupyter hub host.

518
0:25:55.260 --> 0:25:57.640
And I'm wondering, how does it talk, actually,

519
0:25:57.640 --> 0:25:58.480
to Slurm control?

520
0:25:58.480 --> 0:26:01.080
Is Slurm control always listening to any,

521
0:26:03.680 --> 0:26:06.120
any of hosts that will talk to it?

522
0:26:06.120 --> 0:26:08.520
Or is there any restrictions to who is connecting

523
0:26:08.520 --> 0:26:10.320
to the Slurm control daemon?

524
0:26:12.240 --> 0:26:15.600
So there's an alloc nodes setting in the Slurmconf,

525
0:26:15.600 --> 0:26:19.080
I believe, which will allow you to restrict

526
0:26:19.080 --> 0:26:22.680
from which nodes you can allocate resources.

527
0:26:22.680 --> 0:26:24.760
So you can limit it.

528
0:26:24.760 --> 0:26:26.480
However, if you don't have that,

529
0:26:26.480 --> 0:26:30.040
I think Slurm will happily accept anything

530
0:26:30.040 --> 0:26:32.080
because if you have the shared secret,

531
0:26:32.080 --> 0:26:34.280
it's considered good enough.

532
0:26:34.280 --> 0:26:35.120
Okay.

533
0:26:35.120 --> 0:26:36.120
Or a valid JSON web token.

534
0:26:36.120 --> 0:26:36.960
Okay.

535
0:26:36.960 --> 0:26:37.780
Yeah.

536
0:26:37.780 --> 0:26:39.040
Thank you.

537
0:26:39.040 --> 0:26:40.200
Thank you very much, Pablo.

538
0:26:40.200 --> 0:26:41.040
Thanks.

539
0:26:41.040 --> 0:26:41.880
Thanks.

540
0:26:41.880 --> 0:26:42.720
Thanks.

541
0:26:42.720 --> 0:26:43.560
Thanks.

542
0:26:43.560 --> 0:26:44.400
Thanks.

543
0:26:44.400 --> 0:27:01.360
Okay, thanks everybody very much.

