1
0:00:00.000 --> 0:00:11.160
Okay, final lightning talk for today is Ludovic talking about Geeks.

2
0:00:11.160 --> 0:00:13.880
All right, thank you.

3
0:00:13.880 --> 0:00:14.880
Hello HPC people.

4
0:00:14.880 --> 0:00:17.120
So my name is Ludovic Cortez.

5
0:00:17.120 --> 0:00:23.000
I work at INRIER, which is a French research institute in France in computer science.

6
0:00:23.000 --> 0:00:26.960
And I work as a research engineer, so I'm very much concerned about engineering issues

7
0:00:26.960 --> 0:00:29.080
in general.

8
0:00:29.080 --> 0:00:31.560
And in particular, I'm concerned about deployments.

9
0:00:31.560 --> 0:00:37.560
So if you're an HPC dev room aficionado, we've probably met before.

10
0:00:37.560 --> 0:00:41.720
I gave a couple of talks, I guess, in this room.

11
0:00:41.720 --> 0:00:43.200
More specifically about Geeks.

12
0:00:43.200 --> 0:00:45.000
So maybe you've heard about Geeks.

13
0:00:45.000 --> 0:00:46.520
It's a software deployment tool.

14
0:00:46.520 --> 0:00:52.080
So we have Easy Build, Spark, also RPM, well, you know, app, etc.

15
0:00:52.080 --> 0:00:55.400
And this is yet another deployment tool, if you will.

16
0:00:55.400 --> 0:01:00.040
But we have this very particular vision, the grand vision, where we're trying to build

17
0:01:00.040 --> 0:01:04.480
a tool for reproducible research and HPC.

18
0:01:04.480 --> 0:01:07.640
So the thing here that you see is the vision, so to speak.

19
0:01:07.640 --> 0:01:13.520
So at one end of the spectrum, we have research articles, and we want the research to be solid.

20
0:01:13.520 --> 0:01:17.040
So we want the computational workflows to be reproducible.

21
0:01:17.040 --> 0:01:21.320
And at the other end of the spectrum on the left, we have archives, source code archives,

22
0:01:21.320 --> 0:01:27.120
software heritage, which we really need to have if we want that scientific source code

23
0:01:27.120 --> 0:01:29.320
to remain available over time.

24
0:01:29.320 --> 0:01:34.040
And in the middle, while we need a bunch of tools, in particular, deployment tools like

25
0:01:34.040 --> 0:01:38.120
Geeks to reproduce, well, to deploy software reproducibly.

26
0:01:38.120 --> 0:01:39.720
Yes.

27
0:01:39.720 --> 0:01:44.680
So in a nutshell, yes, Geeks provides actual tools for reproducible research people.

28
0:01:44.680 --> 0:01:48.760
I'm not going to go into the details, but basically you can say, all right, I've made

29
0:01:48.760 --> 0:01:53.160
an experimental computational experiment, so now I'm going to pin the exact revision

30
0:01:53.160 --> 0:01:54.160
of Geeks that I used.

31
0:01:54.160 --> 0:01:56.360
This is the first command here.

32
0:01:56.360 --> 0:02:02.120
And the second command is sometime later, or some colleague wants to reproduce a result.

33
0:02:02.120 --> 0:02:06.280
And so they use a time machine to jump to that specific revision of Geeks, and from

34
0:02:06.280 --> 0:02:11.680
there they deploy the exact same packages that I have in that manifest file, bit for

35
0:02:11.680 --> 0:02:13.000
bit.

36
0:02:13.000 --> 0:02:14.000
That's the idea.

37
0:02:14.000 --> 0:02:15.760
All right.

38
0:02:15.760 --> 0:02:22.520
So in HPC, I guess most people in this room would agree we have two obsessions.

39
0:02:22.520 --> 0:02:26.880
That's MPI and AVX, well, vector instructions.

40
0:02:26.880 --> 0:02:28.640
We want things to run fast, right?

41
0:02:28.640 --> 0:02:32.380
We have those fancy clusters, so we want to make sure that the communications are going

42
0:02:32.380 --> 0:02:33.380
to be fast.

43
0:02:33.380 --> 0:02:37.720
We want to make sure we're going to use the latest vector instructions of our CPUs, and

44
0:02:37.720 --> 0:02:39.680
that makes a lot of sense.

45
0:02:39.680 --> 0:02:45.780
But sometimes we're going maybe we have preconceptions about the implications of all this.

46
0:02:45.780 --> 0:02:49.440
So here I'm quoting Todd Gamblin, who's maybe in this room actually.

47
0:02:49.440 --> 0:02:52.400
Hi, Todd, if you see me.

48
0:02:52.400 --> 0:02:57.120
This is an example where we, well, Todd here was saying, you know, binaries, distributions

49
0:02:57.120 --> 0:03:02.800
like Debian or Geeks or Fedora, for example, are just targeting the baseline of the CPU,

50
0:03:02.800 --> 0:03:06.920
like A6664 without AVX, for example.

51
0:03:06.920 --> 0:03:11.520
And that's a problem for performance, because of course if you have that latest fancy Intel

52
0:03:11.520 --> 0:03:15.720
processor, then you probably want to use those vector instructions.

53
0:03:15.720 --> 0:03:22.320
But the conclusion that because of this, we cannot use, you know, binary distributions,

54
0:03:22.320 --> 0:03:26.920
distributions like Geeks or Debian that provide binaries is not entirely accurate.

55
0:03:26.920 --> 0:03:30.800
That's the point I'm trying to make in this talk.

56
0:03:30.800 --> 0:03:35.720
So yeah, as most of you know, there's a whole bunch of vector extensions.

57
0:03:35.720 --> 0:03:37.720
It keeps growing.

58
0:03:37.720 --> 0:03:42.600
You know, like every few years we have new vector extensions in Intel or AMD CPUs or

59
0:03:42.600 --> 0:03:46.400
even ARH64 CPUs, Power9, et cetera.

60
0:03:46.400 --> 0:03:51.640
And it's even worse if you look at the actual CPU models.

61
0:03:51.640 --> 0:03:53.080
For example, this is just for Intel.

62
0:03:53.080 --> 0:03:55.360
There's a whole bunch of things.

63
0:03:55.360 --> 0:03:59.840
It's not always a superset of the previous CPU.

64
0:03:59.840 --> 0:04:02.800
You know, we were discussing it the other day for dinner.

65
0:04:02.800 --> 0:04:04.360
And yeah, sometimes it's complicated.

66
0:04:04.360 --> 0:04:09.240
You cannot tell that Skylake ABX is exactly a superset of Skylake.

67
0:04:09.240 --> 0:04:10.240
This is complicated.

68
0:04:10.240 --> 0:04:15.000
And yet you want to be able to target this CPU specifically, this microarchitecture.

69
0:04:15.000 --> 0:04:17.640
And it makes a big deal of a difference.

70
0:04:17.640 --> 0:04:20.320
So this is an example from an Eigen benchmark.

71
0:04:20.320 --> 0:04:27.480
So Eigen is a C++ library for linear algebra, specifically targeting small matrices.

72
0:04:27.480 --> 0:04:32.800
And well, you know, if on my laptop if I'm targeting, if I'm compiling with MR equals

73
0:04:32.800 --> 0:04:39.400
to Skylake, then I get throughput that's three times the baseline performance.

74
0:04:39.400 --> 0:04:40.880
So it's a pretty big deal.

75
0:04:40.880 --> 0:04:42.400
So we definitely want to use that.

76
0:04:42.400 --> 0:04:49.120
We want to be able to compile specifically for the CPU microarchitecture that we have.

77
0:04:49.120 --> 0:04:55.280
But so the good news is that to a large extent, that's a solved problem for a long time.

78
0:04:55.280 --> 0:05:02.160
So there is this thing called function multiversioning that is already used in a number of performance

79
0:05:02.160 --> 0:05:03.280
critical libraries.

80
0:05:03.280 --> 0:05:07.720
So if you look at libc for string comparison, or if you look at openblast, if you look at

81
0:05:07.720 --> 0:05:15.200
FFTW, GMP for multiprecision arithmetic, you know, many libraries, programming languages,

82
0:05:15.200 --> 0:05:18.600
run times already use function multiversioning.

83
0:05:18.600 --> 0:05:20.040
So what's the deal here?

84
0:05:20.040 --> 0:05:24.920
Well roughly you, when you have function multiversioning, you can say, well, I have one function that

85
0:05:24.920 --> 0:05:28.360
does some linear algebra stuff, for example.

86
0:05:28.360 --> 0:05:33.880
And I'm actually providing several variants of that function, and when I start my program

87
0:05:33.880 --> 0:05:38.840
at runtime, the loader or, you know, the runtime system is going to pick the most optimized

88
0:05:38.840 --> 0:05:40.880
one for the CPU I have at hand.

89
0:05:40.880 --> 0:05:41.880
Right?

90
0:05:41.880 --> 0:05:46.440
So if I use GMP, for example, for multiprecision, multiprecision arithmetic, it's going to

91
0:05:46.440 --> 0:05:49.880
pick the fastest implementation it has, you know.

92
0:05:49.880 --> 0:05:55.040
So you can compile GMP once, and then it's going to use the right thing at runtime.

93
0:05:55.040 --> 0:06:00.880
And even if you're using GCC or Clang, you can specify in your C code, well, I want this

94
0:06:00.880 --> 0:06:07.080
particular function to be cloned, so to have several variants for each CPU micro-architectures,

95
0:06:07.080 --> 0:06:11.720
and GCC or Clang is going to create several variants of that function so that it can pick

96
0:06:11.720 --> 0:06:15.320
the right one at runtime.

97
0:06:15.320 --> 0:06:21.400
So kind of a solved problem in a way, while except in some cases.

98
0:06:21.400 --> 0:06:28.720
Well, one particular case where we have a problem is C++ template libraries, like Eigen,

99
0:06:28.720 --> 0:06:31.840
which I was mentioning before.

100
0:06:31.840 --> 0:06:36.080
They are not able to benefit from function multiversioning in any way, so when you compile

101
0:06:36.080 --> 0:06:41.520
your Eigen benchmark, well, you really have to use march equals to Skylake, for example,

102
0:06:41.520 --> 0:06:44.680
if you were targeting a skylight CPU.

103
0:06:44.680 --> 0:06:49.400
And this is because if you look at Eigen headers, for example, where there are many places where

104
0:06:49.400 --> 0:06:54.780
you have EAV depth, do I have AVX 512 at compilation time?

105
0:06:54.780 --> 0:06:58.480
If yes, then I'm going to use the optimized implementation, otherwise I'm going to use

106
0:06:58.480 --> 0:07:00.680
the baseline implementation.

107
0:07:00.680 --> 0:07:05.400
And this is all happening at compilation time, so you really have to have a solution at compilation

108
0:07:05.400 --> 0:07:08.400
time to address this.

109
0:07:08.400 --> 0:07:11.680
And so this is where Geeks comes in.

110
0:07:11.680 --> 0:07:16.400
So Geeks is, you know, it's a distribution, like Debian, like I was saying, that's targeting

111
0:07:16.400 --> 0:07:21.440
the baseline instruction set, but we came up with a new thing that's called package

112
0:07:21.440 --> 0:07:22.440
multiversioning.

113
0:07:22.440 --> 0:07:27.880
It's actually one year old or something, which is roughly the idea is taking the same idea

114
0:07:27.880 --> 0:07:34.400
as function multiversioning, but applying it at the level of entire packages.

115
0:07:34.400 --> 0:07:37.320
So let's say I have those Eigen benchmarks.

116
0:07:37.320 --> 0:07:44.240
I can run them using just the baseline x8664 architecture using this Geeks shell command.

117
0:07:44.240 --> 0:07:51.080
It's taking the Eigen benchmarks package and in that package running the bench plus gem

118
0:07:51.080 --> 0:07:55.160
command on a small matrix.

119
0:07:55.160 --> 0:08:01.160
And then I can say, all right, now I want to tune that code specifically for my CPU,

120
0:08:01.160 --> 0:08:09.320
and then I just put that extra dash dash tune option, and it's telling Geeks, all right,

121
0:08:09.320 --> 0:08:16.000
please optimize that Eigen benchmarks package directly for the CPU I'm on, which is Skylake

122
0:08:16.000 --> 0:08:17.960
in this case.

123
0:08:17.960 --> 0:08:19.200
And this is it.

124
0:08:19.200 --> 0:08:23.560
And what happens behind the scenes is that on the fly Geeks is creating a new package

125
0:08:23.560 --> 0:08:24.560
variant.

126
0:08:24.560 --> 0:08:29.800
So it's taking that Eigen benchmarks package, creating a new package variant that is built

127
0:08:29.800 --> 0:08:35.800
specifically with a compiler wrapper that passes the march equals to Skylake flag.

128
0:08:35.800 --> 0:08:39.720
And I get the performance and I'm happy.

129
0:08:39.720 --> 0:08:43.400
Right, so this is in Geeks since 2022.

130
0:08:43.400 --> 0:08:47.920
And it's still reproducible, you know, because we can still say, all right, what precise

131
0:08:47.920 --> 0:08:49.040
option did I use?

132
0:08:49.040 --> 0:08:50.920
What dash dash tune option did I use?

133
0:08:50.920 --> 0:08:52.400
And it's Skylake, all right?

134
0:08:52.400 --> 0:08:55.680
So the build process of the package remains reproducible, right?

135
0:08:55.680 --> 0:09:01.000
I'm still getting the same binary if I use dash dash tune equals to Skylake on my laptop

136
0:09:01.000 --> 0:09:05.760
or on some HPC cluster or whatever.

137
0:09:05.760 --> 0:09:09.960
And there are no world rebuilds, which means that the build farm, for example, the official

138
0:09:09.960 --> 0:09:16.280
build farm of the project is providing several variants of those packages, those, you know,

139
0:09:16.280 --> 0:09:21.440
performance sensitive packages built for Skylake, Skylake AVX, 512, you know, different things.

140
0:09:21.440 --> 0:09:26.560
So if you install them, most likely you're going to get a pre-built binary that specifically

141
0:09:26.560 --> 0:09:28.600
optimize for that CPU.

142
0:09:28.600 --> 0:09:30.360
And if not, well, that's fine.

143
0:09:30.360 --> 0:09:32.440
It's going to be to build it for you.

144
0:09:32.440 --> 0:09:34.580
That's okay.

145
0:09:34.580 --> 0:09:42.160
So my conclusion here is, you know, we keep talking about performance of MPI, vector instruction

146
0:09:42.160 --> 0:09:43.160
and so forth.

147
0:09:43.160 --> 0:09:45.520
Well, I think we can have performance.

148
0:09:45.520 --> 0:09:49.320
We can have portable performance that we should aim for.

149
0:09:49.320 --> 0:09:51.160
And we can still have reproducibility.

150
0:09:51.160 --> 0:09:54.920
We don't have to sacrifice reproducibility for performance.

151
0:09:54.920 --> 0:09:57.120
That's my take-home message.

152
0:09:57.120 --> 0:09:58.120
Thank you.

153
0:09:58.120 --> 0:10:06.160
Thank you very much.

154
0:10:06.160 --> 0:10:08.400
Again time for one question.

155
0:10:08.400 --> 0:10:14.640
Okay, yeah, this whole dash tune thing looks awesome.

156
0:10:14.640 --> 0:10:18.800
But what if the majority of the computation time is spent in libraries that that library

157
0:10:18.800 --> 0:10:19.960
is actually using?

158
0:10:19.960 --> 0:10:22.760
How do I tell it to optimize those instead as well?

159
0:10:22.760 --> 0:10:23.760
Right.

160
0:10:23.760 --> 0:10:29.520
So the way it works in gigs, you can annotate packages that really need to be tunable, right?

161
0:10:29.520 --> 0:10:34.000
So you can add a property to a package like so it would be Eigen benchmarks in this case,

162
0:10:34.000 --> 0:10:37.280
or it could be the GNU scientific library, GSL.

163
0:10:37.280 --> 0:10:39.760
And you said this package needs to be tunable.

164
0:10:39.760 --> 0:10:43.920
So if I use dash dash tune, please tune specifically this package.

165
0:10:43.920 --> 0:10:48.040
And it's going to work even if you're installing, you know, an application that actually depends

166
0:10:48.040 --> 0:10:50.440
on GSL, for example.

167
0:10:50.440 --> 0:10:51.440
Right.

168
0:10:51.440 --> 0:10:54.320
All right, thanks a lot, Ludovic.

